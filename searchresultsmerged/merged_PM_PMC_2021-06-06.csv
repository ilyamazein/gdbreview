,DOI,PMID,PMCID,Shortlist,GDBs,GDBs,Author,Title,Publication Year,Publication Title,ISBN,Abstract Note,Date,Date Added,Pages,Issue,Volume,Journal Abbreviation,Short Title,Library Catalog,Extra,Link Attachments,Automatic Tags,GDBs,GDBs,Labels
0,10.1002/ehf2.12218,28988439,PMC5793978,A,Neo4j,Neo4j,"Ferreira, João Pedro; Machu, Jean‐Loup; Girerd, Nicolas; Jaisser, Frederic; Thum, Thomas; Butler, Javed; González, Arantxa; Diez, Javier; Heymans, Stephane; McDonald, Kenneth; Gyöngyösi, Mariann; Firat, Hueseyin; Rossignol, Patrick; Pizard, Anne; Zannad, Faiez",Rationale of the FIBROTARGETS study designed to identify novel biomarkers of myocardial fibrosis,2017,ESC Heart Failure,,"Aims Myocardial fibrosis alters the cardiac architecture favouring the development of cardiac dysfunction, including arrhythmias and heart failure. Reducing myocardial fibrosis may improve outcomes through the targeted diagnosis and treatment of emerging fibrotic pathways. The European‐Commission‐funded ‘FIBROTARGETS’ is a multinational academic and industrial consortium with the main aims of (i) characterizing novel key mechanistic pathways involved in the metabolism of fibrillary collagen that may serve as biotargets, (ii) evaluating the potential anti‐fibrotic properties of novel or repurposed molecules interfering with the newly identified biotargets, and (iii) characterizing bioprofiles based on distinct mechanistic phenotypes involving the aforementioned biotargets. These pathways will be explored by performing a systematic and collaborative search for mechanisms and targets of myocardial fibrosis. These mechanisms will then be translated into individualized diagnostic tools and specific therapeutic pharmacological options for heart failure. Methods and results The FIBROTARGETS consortium has merged data from 12 patient cohorts in a common database available to individual consortium partners. The database consists of >12 000 patients with a large spectrum of cardiovascular clinical phenotypes. It integrates community‐based population cohorts, cardiovascular risk cohorts, and heart failure cohorts. Conclusions The FIBROTARGETS biomarker programme is aimed at exploring fibrotic pathways allowing the bioprofiling of patients into specific ‘fibrotic’ phenotypes and identifying new therapeutic targets that will potentially enable the development of novel and tailored anti‐fibrotic therapies for heart failure.",2017-10-07,2021-06-05 20:55:40; 2021-06-05 21:11:16; 2021-06-05 20:36:32,139-148,1,5,ESC Heart Fail,,PubMed Central,PMID: 28988439 PMCID: PMC5793978,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5793978/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
1,10.1002/humu.22857,26269093,PMC5473253,A,Neo4j,Neo4j,"Mungall, Christopher J.; Washington, Nicole L.; Nguyen-Xuan, Jeremy; Condit, Christopher; Smedley, Damian; Köhler, Sebastian; Groza, Tudor; Shefchek, Kent; Hochheiser, Harry; Robinson, Peter N.; Lewis, Suzanna E.; Haendel, Melissa A.",Use of Model Organism and Disease Databases to Support Matchmaking for Human Disease Gene Discovery,2015,Human mutation,,"The Matchmaker Exchange API allows searching a patient's genotypic or phenotypic profiles across clinical sites, for the purposes of cohort discovery and variant-disease causal validation. This API can be used not only to search for matching patients, but also to match against public disease and model organism data. This public disease data enables matching known diseases and variant-phenotype associations using phenotype semantic similarity algorithms developed by the Monarch Initiative. The model data can provide additional evidence to aid diagnosis, suggest relevant models for disease mechanism and treatment exploration, and identify collaborators across the translational divide. The Monarch Initiative provides an implementation of this API for searching multiple integrated sources of data that contextualize the knowledge about any given patient or patient family into the greater biomedical knowledge landscape. While this corpus of data can aid diagnosis, it is also the beginning of research to improve understanding of rare human diseases.",2015-10,2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-05 20:37:08,979-984,10,36,Hum Mutat,,PubMed Central,PMID: 26269093 PMCID: PMC5473253,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5473253/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
2,10.1002/humu.23610,30095202,PMC7374944,A,Neo4j,Neo4j,"Riggs, Erin R.; Nelson, Tristan; Merz, Andrew; Ackley, Todd; Bunke, Brian; Collins, Christin D.; Collinson, Morag N.; Fan, Yao-Shan; Goodenberger, McKinsey L.; Golden, Denae M.; Haglund-Hazy, Linda; Krgovic, Danijela; Lamb, Allen N.; Lewis, Zoe; Li, Guang; Liu, Yajuan; Meck, Jeanne; Neufeld-Kaiser, Whitney; Runke, Cassandra K.; Sanmann, Jennifer N.; Stavropoulos, Dimitri J.; Strong, Emma; Su, Meng; Tayeh, Marwan K.; Vokac, Nadja Kokalj; Thorland, Erik C.; Andersen, Erica; Martin, Christa L.",Copy Number Variant Discrepancy Resolution Using the ClinGen Dosage Sensitivity Map Results in Updated Clinical Interpretations in ClinVar,2018,Human mutation,,"Conflict resolution in genomic variant interpretation is a critical step towards improving patient care. Evaluating interpretation discrepancies in copy number variants (CNVs) typically involves assessing overlapping genomic content with focus on genes/regions that may be subject to dosage sensitivity (haploinsufficiency (HI) and/or triplosensitivity (TS)). CNVs containing dosage sensitive genes/regions are generally interpreted as “likely pathogenic” (LP) or “pathogenic” (P), and CNVs involving the same known dosage sensitive gene(s) should receive the same clinical interpretation. We compared the Clinical Genome Resource (ClinGen) Dosage Map, a publicly available resource documenting known HI and TS genes/regions, against germline, clinical CNV interpretations within the ClinVar database. We identified 251 CNVs overlapping known dosage sensitive genes/regions but not classified as LP or P; these were sent back to their original submitting laboratories for re-evaluation. Of 246 CNVs re-evaluated, an updated clinical classification was warranted in 157 cases (63.8%); no change was made to the current classification in 79 cases (32.1%); and 10 cases (4.1%) resulted in other types of updates to ClinVar records. This effort will add curated interpretation data into the public domain and allow laboratories to focus attention on more complex discrepancies.",2018-11,2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:36:32,1650-1659,11,39,Hum Mutat,,PubMed Central,PMID: 30095202 PMCID: PMC7374944,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7374944/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
3,10.1002/ijc.31809,30121958,PMC6587976,,,,"Eilertsen, Ina A.; Sveen, Anita; Strømme, Jonas M.; Skotheim, Rolf I.; Nesbakken, Arild; Lothe, Ragnhild A.",Alternative splicing expands the prognostic impact of KRAS in microsatellite stable primary colorectal cancer,2019,International Journal of Cancer,,"KRAS mutation is a well‐known marker for poor response to targeted treatment and patient prognosis in microsatellite stable (MSS) colorectal cancer (CRC). However, variation in clinical outcomes among patients wild‐type for KRAS underlines that this is not a homogeneous population. Here, we evaluated the prognostic impact of KRAS alternative splicing in relation to mutation status in a single‐hospital series of primary MSS CRCs (N = 258). Using splicing‐sensitive microarrays and RNA sequencing, the relative expression of KRAS‐4A versus KRAS‐4B transcript variants was confirmed to be down‐regulated in CRC compared to normal colonic mucosa (N = 41; p ≤ 0.001). This was independent of mutation status, however, gene set enrichment analysis revealed that the effect of splicing on KRAS signaling was specific to the KRAS wild‐type subgroup, in which low relative KRAS‐4A expression was associated with a higher level of KRAS signaling (p = 0.005). In concordance, the prognostic value of KRAS splicing was also dependent on mutation status, and for patients with Stage I–III KRAS wild‐type MSS CRC, low relative KRAS‐4A expression was associated with inferior overall survival (HR: 2.36, 95% CI: 1.07–5.18, p = 0.033), a result not found in mutant cases (p interaction = 0.026). The prognostic association in the wild‐type subgroup was independent of clinicopathological factors, including cancer stage in multivariable analysis (HR: 2.68, 95% CI: 1.18–6.09, p = 0.018). This suggests that KRAS has prognostic value beyond mutation status in MSS CRC, and highlights the importance of molecular heterogeneity in the clinically relevant KRAS wild‐type subgroup.,  What's new? , Patients with microsatellite stable (MSS) colorectal cancer (CRC) that lacks KRAS mutation benefit from targeted therapy. Nonetheless, variations in clinical outcome suggest that KRAS wild‐type CRC is a heterogeneous disease. Here, two KRAS transcript variants, KRAS‐4A and KRAS‐4B, generated through alternative splicing, were investigated in relation to KRAS mutation status and MSS CRC prognosis. Aberrant splicing resulting in low expression of the KRAS‐4A transcript variant, relative to the KRAS‐4B transcript, was associated with increased KRAS signaling and poor patient prognosis specifically in KRAS wild‐type MSS CRC. The findings suggest that KRAS splicing is of prognostic relevance in KRAS wild‐type CRC.",2019-02-15,2021-06-05 21:11:16,841-847,4,144,Int J Cancer,,PubMed Central,PMID: 30121958 PMCID: PMC6587976,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6587976/,,,,PMC:Query2
4,10.1002/lrh2.10019,31245557,PMC6516719,A,Neo4j,Neo4j,"Curcin, Vasa",Embedding data provenance into the Learning Health System to facilitate reproducible research,2016,Learning Health Systems,,"Introduction The learning health system (LHS) community has taken up the challenge of bringing the complex relationship between clinical research and practice into this brave new world. At the heart of the LHS vision is the notion of routine capture, transformation, and dissemination of data and knowledge, with various use cases, such as clinical studies, quality improvement initiatives, and decision support, constructed on top of specific routes that the data is taking through the system. In order to stop this increased data volume and analytical complexity from obfuscating the research process, it is essential to establish trust in the system through implementing reproducibility and auditability throughout the workflow. Methods Data provenance technologies can automatically capture the trace of the research task and resulting data, thereby facilitating reproducible research. While some computational domains, such as bioinformatics, have embraced the technology through provenance‐enabled execution middlewares, disciplines based on distributed, heterogeneous software, such as medical research, are only starting on the road to adoption, motivated by the institutional pressures to improve transparency and reproducibility. Results Guided by the experiences of the TRANSFoRm project, we present the opportunities that data provenance offers to the LHS community. We illustrate how provenance can facilitate documenting 21 CFR Part 11 compliance for Food and Drug Administration submissions and provide auditability for decisions made by the decision support tools and discuss the transformational effect of routine provenance capture on data privacy, study reporting, and publishing medical research. Conclusions If the scaling up of the LHS is to succeed, we have to embed mechanisms to verify trust in the system inside our research instruments. In the research world increasingly reliant on electronic tools, provenance gives us a lingua franca to achieve traceability, which we have shown to be essential to building these mechanisms. To realize the vision of making computable provenance a feasible approach to implementing reproducibility in the LHS, we have to provide viable mechanisms for adoption. These include defining meaningful provenance models for problem domains and also introducing provenance support to existing tools in a minimally invasive manner.",2016-12-27,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:37:08,,2,1,Learn Health Syst,,PubMed Central,PMID: 31245557 PMCID: PMC6516719,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6516719/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
5,10.1002/mbo3.218,25336405,PMC4263516,,,,"Jiménez, Esther; Sánchez, Borja; Farina, Annarita; Margolles, Abelardo; Rodríguez, Juan M",Characterization of the bile and gall bladder microbiota of healthy pigs,2014,MicrobiologyOpen,,"Bile is a biological fluid synthesized in the liver, stored and concentrated in the gall bladder (interdigestive), and released into the duodenum after food intake. The microbial populations of different parts of mammal's gastrointestinal tract (stomach, small and large intestine) have been extensively studied; however, the characterization of bile microbiota had not been tackled until now. We have studied, by culture-dependent techniques and a 16S rRNA gene-based analysis, the microbiota present in the bile, gall bladder mucus, and biopsies of healthy sows. Also, we have identified the most abundant bacterial proteins in the bile samples. Our data show that the gall bladder ecosystem is mainly populated by members of the phyla Proteobacteria, Firmicutes, and Bacteroidetes. Furthermore, fluorescent in situ hybridization (FISH) and transmission electron microscopy (TEM) allowed us to visualize the presence of individual bacteria of different morphological types, in close association with either the epithelium or the erythrocytes, or inside the epithelial cells. Our work has generated new knowledge of bile microbial profiles and functions and might provide the basis for future studies on the relationship between bile microbiota, gut microbiota, and health.",2014-12,2021-06-05 21:12:40,937-949,6,3,Microbiologyopen,,PubMed Central,PMID: 25336405 PMCID: PMC4263516,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4263516/,,,,PMC:Query2
6,10.1002/minf.202000013,32390334,,A,Neo4j,Neo4j,"Murali, Vidhya; Königs, Cassandra; Deekshitula, Sarvani; Nukala, Saranya; Santhi, Maddala Divya; Athri, Prashanth",CompoundDB4j: Integrated Drug Resource of Heterogeneous Chemical Databases,2020,Molecular Informatics,,"Computational approaches to analyze various drug/ compound centered analysis often present a need to map attributes from multiple drug databases. In this study, we provide a Neo4j repository that integrates two of the most prominent open source drug databases, DrugBank and ChEMBL, with a goal of establishing an integrated data visualization and analysis tool for drug discovery studies. The drugs present in DrugBank are mapped to their counterparts in ChEMBL. The integration of these resources and the harmonization using knowledge graph serialization using Neo4j lead to identification of relationships between drugs and other related features that are otherwise spread across two different resources. A common data format, a prerequisite to populate the Neo4j database, enables users to identify new relationships central to drug discovery research, like Drug Target Interactions (DTI). The resource is freely available at: https://github.com/ambf0632/CompoundDB4j.",2020-09,2021-06-05 21:24:28; 2021-06-05 21:06:22; 2021-06-05 21:16:51,e2000013,9,39,Mol Inform,CompoundDB4j,PubMed,PMID: 32390334,http://www.ncbi.nlm.nih.gov/pubmed/32390334,ChEMBL; Cheminformatics; Dataintegration; DrugBank; Neo4j,Neo4j,Neo4j,PubMed:Neo4j; PubMed:Query3; PubMed:Query2
7,10.1002/minf.202000116,32725965,PMC8047896,A,Neo4j; COVID19,Neo4j; COVID19,"Dafniet, Bryan; Cerisier, Natacha; Audouze, Karine; Taboureau, Olivier",Drug‐target‐ADR Network and Possible Implications of Structural Variants in Adverse Events,2020,Molecular Informatics,,"Adverse drug reactions (ADRs) are of major concern in drug safety. However, due to the biological complexity of human systems, understanding the underlying mechanisms involved in development of ADRs remains a challenging task. Here, we applied network sciences to analyze a tripartite network between 1000 drugs, 1407 targets, and 6164 ADRs. It allowed us to suggest drug targets susceptible to be associated to ADRs and organs, based on the system organ class (SOC). Furthermore, a score was developed to determine the contribution of a set of proteins to ADRs. Finally, we identified proteins that might increase the susceptibility of genes to ADRs, on the basis of knowledge about genomic structural variation in genes encoding proteins targeted by drugs. Such analysis should pave the way to individualize drug therapy and precision medicine.,",2020-12,2021-06-05 20:35:57; 2021-06-05 21:35:36; 2021-06-05 20:54:31; 2021-06-05 21:10:08,,12,39,Mol Inform,,PubMed Central,PMID: 32725965 PMCID: PMC8047896,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8047896/,,Neo4j; COVID19,Neo4j; COVID19,PMC:Query3; PMC:Neo4j; PMC:COVID19; PMC:Query2
8,10.1002/mp.13114,30226286,PMC8082598,,,,"Mayo, C S; Phillips, M; McNutt, T R; Palta, J; Dekker, A; Miller, R C; Xiao, Y; Moran, J M; Matuszak, M M; Gabriel, P; Ayan, A S; Prisciandaro, J; Thor, M; Dixit, N; Popple, R; Killoran, J; Kaleba, E; Kantor, M; Ruan, D; Kapoor, R; Kessler, M L; Lawrence, T S",Treatment Data and Technical Process Challenges for Practical Big Data Efforts in Radiation Oncology,2018,Medical physics,,"The term Big Data has come to encompass a number of concepts and uses within medicine. This paper lays out the relevance and application of large collections of data in the radiation oncology community. We describe the potential importance and uses in clinical practice. The important concepts are then described and how they have been or could be implemented are discussed. Impediments to progress in the collection and use of sufficient quantities of data are also described. Finally, recommendations for how the community can move forward to achieve the potential of Big Data in radiation oncology are provided.",2018-10,2021-06-05 21:11:16,e793-e810,10,45,Med Phys,,PubMed Central,PMID: 30226286 PMCID: PMC8082598,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8082598/,,,,PMC:Query2
9,10.1002/mp.14322,32521049,PMC7754296,,,,"Kalendralis, Petros; Shi, Zhenwei; Traverso, Alberto; Choudhury, Ananya; Sloep, Matthijs; Zhovannik, Ivan; Starmans, Martijn P.A.; Grittner, Detlef; Feltens, Peter; Monshouwer, Rene; Klein, Stefan; Fijten, Rianne; Aerts, Hugo; Dekker, Andre; van Soest, Johan; Wee, Leonard; Kalendralis, Petros; Shi, Zhenwei; Traverso, Alberto; Choudhury, Ananya; Sloep, Matthijs; Zhovannik, Ivan; Starmans, Martijn P. A.; Grittner, Detlef; Feltens, Peter; Monshouwer, Rene; Klein, Stefan; Fijten, Rianne; Aerts, Hugo; Dekker, Andre; van Soest, Johan; Wee, Leonard","FAIR‐compliant clinical, radiomics and DICOM metadata of RIDER, interobserver, Lung1 and head‐Neck1 TCIA collections; FAIR-compliant clinical, radiomics and DICOM metadata of RIDER, interobserver, Lung1 and head-Neck1 TCIA collections",2020,Medical Physics,,"PURPOSE: One of the most frequently cited radiomics investigations showed that features automatically extracted from routine clinical images could be used in prognostic modeling. These images have been made publicly accessible via The Cancer Imaging Archive (TCIA). There have been numerous requests for additional explanatory metadata on the following datasets - RIDER, Interobserver, Lung1, and Head-Neck1. To support repeatability, reproducibility, generalizability, and transparency in radiomics research, we publish the subjects' clinical data, extracted radiomics features, and digital imaging and communications in medicine (DICOM) headers of these four datasets with descriptive metadata, in order to be more compliant with findable, accessible, interoperable, and reusable (FAIR) data management principles. ACQUISITION AND VALIDATION METHODS: Overall survival time intervals were updated using a national citizens registry after internal ethics board approval. Spatial offsets of the primary gross tumor volume (GTV) regions of interest (ROIs) associated with the Lung1 CT series were improved on the TCIA. GTV radiomics features were extracted using the open-source Ontology-Guided Radiomics Analysis Workflow (O-RAW). We reshaped the output of O-RAW to map features and extraction settings to the latest version of Radiomics Ontology, so as to be consistent with the Image Biomarker Standardization Initiative (IBSI). Digital imaging and communications in medicine metadata was extracted using a research version of Semantic DICOM (SOHARD, GmbH, Fuerth; Germany). Subjects' clinical data were described with metadata using the Radiation Oncology Ontology. All of the above were published in Resource Descriptor Format (RDF), that is, triples. Example SPARQL queries are shared with the reader to use on the online triples archive, which are intended to illustrate how to exploit this data submission. DATA FORMAT: The accumulated RDF data are publicly accessible through a SPARQL endpoint where the triples are archived. The endpoint is remotely queried through a graph database web application at http://sparql.cancerdata.org. SPARQL queries are intrinsically federated, such that we can efficiently cross-reference clinical, DICOM, and radiomics data within a single query, while being agnostic to the original data format and coding system. The federated queries work in the same way even if the RDF data were partitioned across multiple servers and dispersed physical locations. POTENTIAL APPLICATIONS: The public availability of these data resources is intended to support radiomics features replication, repeatability, and reproducibility studies by the academic community. The example SPARQL queries may be freely used and modified by readers depending on their research question. Data interoperability and reusability are supported by referencing existing public ontologies. The RDF data are readily findable and accessible through the aforementioned link. Scripts used to create the RDF are made available at a code repository linked to this submission: https://gitlab.com/UM-CDS/FAIR-compliant_clinical_radiomics_and_DICOM_metadata.; Purpose One of the most frequently cited radiomics investigations showed that features automatically extracted from routine clinical images could be used in prognostic modeling. These images have been made publicly accessible via The Cancer Imaging Archive (TCIA). There have been numerous requests for additional explanatory metadata on the following datasets — RIDER, Interobserver, Lung1, and Head–Neck1. To support repeatability, reproducibility, generalizability, and transparency in radiomics research, we publish the subjects’ clinical data, extracted radiomics features, and digital imaging and communications in medicine (DICOM) headers of these four datasets with descriptive metadata, in order to be more compliant with findable, accessible, interoperable, and reusable (FAIR) data management principles. Acquisition and validation methods Overall survival time intervals were updated using a national citizens registry after internal ethics board approval. Spatial offsets of the primary gross tumor volume (GTV) regions of interest (ROIs) associated with the Lung1 CT series were improved on the TCIA. GTV radiomics features were extracted using the open‐source Ontology‐Guided Radiomics Analysis Workflow (O‐RAW). We reshaped the output of O‐RAW to map features and extraction settings to the latest version of Radiomics Ontology, so as to be consistent with the Image Biomarker Standardization Initiative (IBSI). Digital imaging and communications in medicine metadata was extracted using a research version of Semantic DICOM (SOHARD, GmbH, Fuerth; Germany). Subjects’ clinical data were described with metadata using the Radiation Oncology Ontology. All of the above were published in Resource Descriptor Format (RDF), that is, triples. Example SPARQL queries are shared with the reader to use on the online triples archive, which are intended to illustrate how to exploit this data submission. Data format The accumulated RDF data are publicly accessible through a SPARQL endpoint where the triples are archived. The endpoint is remotely queried through a graph database web application at http://sparql.cancerdata.org. SPARQL queries are intrinsically federated, such that we can efficiently cross‐reference clinical, DICOM, and radiomics data within a single query, while being agnostic to the original data format and coding system. The federated queries work in the same way even if the RDF data were partitioned across multiple servers and dispersed physical locations. Potential applications The public availability of these data resources is intended to support radiomics features replication, repeatability, and reproducibility studies by the academic community. The example SPARQL queries may be freely used and modified by readers depending on their research question. Data interoperability and reusability are supported by referencing existing public ontologies. The RDF data are readily findable and accessible through the aforementioned link. Scripts used to create the RDF are made available at a code repository linked to this submission: https://gitlab.com/UM‐CDS/FAIR‐compliant_clinical_radiomics_and_DICOM_metadata.",2020-11,2021-06-05 21:06:22; 2021-06-05 21:10:08,5931-5940,11,47,Med Phys,,PubMed; PubMed Central,PMID: 32521049 PMCID: PMC7754296,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7754296/; http://www.ncbi.nlm.nih.gov/pubmed/32521049,"Databases, Factual; datasets; FAIR; Germany; Humans; Metadata; radiomics; repeatability; reproducibility; Reproducibility of Results; Workflow",,,PubMed:Query2; PMC:Query2
10,10.1002/pmic.201400206,25263569,PMC4256132,,,,"Woo, Sunghee; Cha, Seong Won; Guest, Clark; Na, Seungjin; Bafna, Vineet; Liu, Tao; Smith, Richard D; Rodland, Karin D; Payne, Samuel",Proteogenomic strategies for identification of aberrant cancer peptides using large-scale Next Generation Sequencing data,2014,Proteomics,,"Cancer is driven by the acquisition of somatic DNA lesions. Distinguishing the early driver mutations from subsequent passenger mutations is key to molecular sub-typing of cancers, understanding cancer progression, and the discovery of novel biomarkers. The advances of genomics technologies (whole-genome exome, and transcript sequencing, collectively referred to as NGS(Next Gengeration Sequencing)) have fueled recent studies on somatic mutation discovery. However, the vision is challenged by the complexity, redundancy, and errors in genomic data, and the difficulty of investigating the proteome translated portion of aberrant genes using only genomic approaches. Combination of proteomic and genomic technologies are increasingly being employed., Various strategies have been employed to allow the usage of large scale NGS data for conventional MS/MS searches. This paper provides a discussion of applying different strategies relating to large database search, and FDR(False Discovery Rate) based error control, and their implication to cancer proteogenomics. Moreover, it extends and develops the idea of a unified genomic variant database that can be searched by any mass spectrometry sample. A total of 879 BAM files downloaded from TCGA repository were used to create a 4.34 GB unified FASTA database which contained 2, 787, 062 novel splice junctions, 38, 464 deletions, 1, 105 insertions, and 182, 302 substitutions. Proteomic data from a single ovarian carcinoma sample (439, 858 spectra) was searched against the database. By applying the most conservative FDR measure, we have identified 524 novel peptides and 65, 578 known peptides at 1% FDR threshold. The novel peptides include interesting examples of doubly mutated peptides, frame-shifts, and non-sample-recruited mutations, which emphasize the strength of our approach.",2014-12,2021-06-05 21:12:40,2719-2730,0,14,Proteomics,,PubMed Central,PMID: 25263569 PMCID: PMC4256132,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4256132/,,,,PMC:Query2
11,10.1002/pmic.201400377,25475079,PMC4409855,A,AllegroGraph; Neo4j,AllegroGraph; Neo4j,"Wang, Rui; Perez-Riverol, Yasset; Hermjakob, Henning; Vizcaíno, Juan Antonio",Open source libraries and frameworks for biological data visualisation: A guide for developers,2015,Proteomics,,"Recent advances in high-throughput experimental techniques have led to an exponential increase in both the size and the complexity of the data sets commonly studied in biology. Data visualisation is increasingly used as the key to unlock this data, going from hypothesis generation to model evaluation and tool implementation. It is becoming more and more the heart of bioinformatics workflows, enabling scientists to reason and communicate more effectively. In parallel, there has been a corresponding trend towards the development of related software, which has triggered the maturation of different visualisation libraries and frameworks. For bioinformaticians, scientific programmers and software developers, the main challenge is to pick out the most fitting one(s) to create clear, meaningful and integrated data visualisation for their particular use cases. In this review, we introduce a collection of open source or free to use libraries and frameworks for creating data visualisation, covering the generation of a wide variety of charts and graphs. We will focus on software written in Java, JavaScript or Python. We truly believe this software offers the potential to turn tedious data into exciting visual stories.",2015-04,2021-06-06 06:38:41; 2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-05 20:37:08,1356-1374,8,15,Proteomics,Open source libraries and frameworks for biological data visualisation,PubMed Central,PMID: 25475079 PMCID: PMC4409855,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4409855/,,AllegroGraph; Neo4j,AllegroGraph; Neo4j,PMC:Query3; PMC:Neo4j; PMC:AllegroGraph; PMC:Query2
12,10.1002/pro.3786,31724275,PMC6933861,A,Neo4j,Neo4j,"Prisant, Michael G.; Williams, Christopher J.; Chen, Vincent B.; Richardson, Jane S.; Richardson, David C.","New tools in MolProbity validation: CaBLAM for CryoEM backbone, UnDowser to rethink ""waters,"" and NGL Viewer to recapture online 3D graphics; New tools in MolProbity validation: CaBLAM for CryoEM backbone, UnDowser to rethink “waters,” and NGL Viewer to recapture online 3D graphics",2020,Protein Science: A Publication of the Protein Society; Protein Science : A Publication of the Protein Society,,"The MolProbity web service provides macromolecular model validation to help correct local errors, for the structural biology community worldwide. Here we highlight new validation features, and also describe how we are fighting back against outside developments which compromise that mission. Our new tool called UnDowser analyzes the properties and context of clashing HOH ""waters"" to diagnose what they might actually represent; a dozen distinct scenarios are illustrated and described. We now treat alternate conformations more thoroughly, and switching to the Neo4j database (graphical rather than relational) enables cleaner, more comprehensive, and much larger reference datasets. A problematic outside change is that refinement software now increasingly restrains traditional validation criteria (geometry, clashes, rotamers, and even Ramachandran) in order to supplement the sparser experimental data at 3-4 Å resolutions typical of modern cryoEM. But unfortunately the broad density allows model optimization without fixing underlying problems, which means these structures often score much better on validation than they really are. CaBLAM, our tool designed for evaluating peptide orientations at lower resolutions, was described in the previous Tools issue, and here we demonstrate its effectiveness in diagnosing local errors even when other validation outliers have been artificially removed. Sophisticated hacking of the MolProbity server has required continual monitoring and various security measures short of restricting user access. The deprecation of Java applets now prevents KiNG interactive online display of outliers on the 3D model during a MolProbity run, but that important functionality has now been recaptured with a modified version of the Javascript NGL Viewer.; The MolProbity web service provides macromolecular model validation to help correct local errors, for the structural biology community worldwide. Here we highlight new validation features, and also describe how we are fighting back against outside developments which compromise that mission. Our new tool called UnDowser analyzes the properties and context of clashing HOH “waters” to diagnose what they might actually represent; a dozen distinct scenarios are illustrated and described. We now treat alternate conformations more thoroughly, and switching to the Neo4j database (graphical rather than relational) enables cleaner, more comprehensive, and much larger reference datasets. A problematic outside change is that refinement software now increasingly restrains traditional validation criteria (geometry, clashes, rotamers, and even Ramachandran) in order to supplement the sparser experimental data at 3–4 Å resolutions typical of modern cryoEM. But unfortunately the broad density allows model optimization without fixing underlying problems, which means these structures often score much better on validation than they really are. CaBLAM, our tool designed for evaluating peptide orientations at lower resolutions, was described in the previous Tools issue, and here we demonstrate its effectiveness in diagnosing local errors even when other validation outliers have been artificially removed. Sophisticated hacking of the MolProbity server has required continual monitoring and various security measures short of restricting user access. The deprecation of Java applets now prevents KiNG interactive online display of outliers on the 3D model during a MolProbity run, but that important functionality has now been recaptured with a modified version of the Javascript NGL Viewer.",2020-01,2021-06-05 20:35:57; 2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 21:10:37; 2021-06-05 20:55:01; 2021-06-05 21:24:28,315-329,1,29,Protein Sci,New tools in MolProbity validation,PubMed; PubMed Central,PMID: 31724275 PMCID: PMC6933861,http://www.ncbi.nlm.nih.gov/pubmed/31724275; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6933861/,"backbone conformation; chiral volumes; Computational Biology; Cryoelectron Microscopy; Crystallography, X-Ray; Imaging, Three-Dimensional; ion binding; Macromolecular Substances; Models, Molecular; Molecular Conformation; Neo4j; overfitting; Ramachandran restraints; server security; Software; structure validation; water analysis; Web Browser",Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
13,10.1002/psp4.12171,28504472,PMC5445227,A,Virtuoso,Virtuoso,"Wilkins, JJ; Chan, PLS; Chard, J; Smith, G; Smith, MK; Beer, M; Dunn, A; Flandorfer, C; Franklin, C; Gomeni, R; Harnisch, L; Kaye, R; Moodie, S; Sardu, ML; Wang, E; Watson, E; Wolstencroft, K; Cheung, SYA",Thoughtflow: Standards and Tools for Provenance Capture and Workflow Definition to Support Model‐Informed Drug Discovery and Development,2017,CPT: Pharmacometrics & Systems Pharmacology,,"Pharmacometric analyses are complex and multifactorial. It is essential to check, track, and document the vast amounts of data and metadata that are generated during these analyses (and the relationships between them) in order to comply with regulations, support quality control, auditing, and reporting. It is, however, challenging, tedious, error‐prone, and time‐consuming, and diverts pharmacometricians from the more useful business of doing science. Automating this process would save time, reduce transcriptional errors, support the retention and transfer of knowledge, encourage good practice, and help ensure that pharmacometric analyses appropriately impact decisions. The ability to document, communicate, and reconstruct a complete pharmacometric analysis using an open standard would have considerable benefits. In this article, the Innovative Medicines Initiative (IMI) Drug Disease Model Resources (DDMoRe) consortium proposes a set of standards to facilitate the capture, storage, and reporting of knowledge (including assumptions and decisions) in the context of model‐informed drug discovery and development (MID3), as well as to support reproducibility: “Thoughtflow.” A prototype software implementation is provided.",2017-05,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:59:14,285-292,5,6,CPT Pharmacometrics Syst Pharmacol,Thoughtflow,PubMed Central,PMID: 28504472 PMCID: PMC5445227,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5445227/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
14,10.1002/rcm.7368,26443413,,A,,,"Mulholland, Daniel S.; Poitrasson, Franck; Boaventura, Geraldo R.",Effects of different water storage procedures on the dissolved Fe concentration and isotopic composition of chemically contrasted waters from the Amazon River Basin,2015,Rapid communications in mass spectrometry: RCM,,"RATIONALE: Although recent studies have investigated the Fe isotopic composition of dissolved, colloidal and particulate phases from continental and oceanic natural waters, few efforts have been made to evaluate whether water sample storage and the separation of different pore-size fractions through filtration can cause any change to the Fe isotopic compositions. The present study investigates the possible biases introduced by different water storage conditions on the dissolved Fe concentration and isotopic composition of chemically different waters. METHODS: Water samples were collected from an organic-rich river and from mineral particulate-rich rivers. Filtered and unfiltered water samples were stored either at room temperature or frozen at -18°C in order to assess possible biases due to (i) different water storage temperature, and (ii) storage of bulk (unfiltered) vs filtered water. Iron isotope measurements were performed by Multicollector Inductively Coupled Plasma Mass Spectrometry with a Thermo Electron Neptune instrument, after Fe purification using anion-exchange resins. RESULTS: Our data reveal that bulk water storage at room temperature without filtration produces minor changes in the dissolved Fe isotopic composition of mineral particulate-rich waters, but significant isotopic composition changes in organic-rich waters. In both cases, however, the impact of the different procedures on the Fe concentrations was strong. On the other hand, the bulk water stored frozen without filtration produced more limited changes in the dissolved Fe concentrations, and also on isotopic compositions, relative to the samples filtered in the field. The largest effect was again observed for the organic-rich waters. CONCLUSIONS: These findings suggest that a time lag between water collection and filtration may cause isotopic exchanges between the dissolved and particulate Fe fractions. When it is not possible to filter the samples in the field immediately after collection, the less detrimental approach is to freeze the bulk water sample until filtration, to reduce isotopic artifacts.",2015-11-15,2021-06-05 21:24:28; 2021-06-05 21:06:22,2102-2108,21,29,Rapid Commun Mass Spectrom,,PubMed,PMID: 26443413,http://www.ncbi.nlm.nih.gov/pubmed/26443413,"Brazil; Chemistry Techniques, Analytical; Filtration; Fresh Water; Iron; Iron Isotopes; Rivers; Solubility",,,PubMed:Query3; PubMed:Query2
15,10.1007/978-1-4842-6252-8_8,,PMC7989888,A,Azure; COVID19,Azure; COVID19,"Chawla, Harsh; Khattar, Pankaj",Model and Serve,2020,Data Lake Analytics on Microsoft Azure,,"Model and Serve is the final phase of a data analytics solution (Figure 8-1). In this phase, transformed data is consumed for the final output, either through visualization or any dependent applications. The entire data journey is planned, based on the target use case. In this chapter, the discussion is on the various scenarios that are applicable in this phase, and how to decide on technologies based on the cost and efficiency.",2020-10-09,2021-06-05 21:35:36; 2021-06-06 07:29:41; 2021-06-05 20:54:31; 2021-06-05 21:10:08,181-209,,,Data Lake Analytics on Microsoft Azure,,PubMed Central,PMID:  PMCID: PMC7989888,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7989888/,,Azure; COVID19,Azure; COVID19,PMC:Query3; PMC:Azure; PMC:COVID19; PMC:Query2
16,10.1007/978-1-4939-6783-4_1,28150231,PMC5506686,,,,"Chen, Chuming; Huang, Hongzhan; Wu, Cathy H.",Protein Bioinformatics Databases and Resources,2017,"Methods in molecular biology (Clifton, N.J.)",,"Many publicly available data repositories and resources have been developed to support protein related information management, data-driven hypothesis generation and biological knowledge discovery. To help researchers quickly find the appropriate protein related informatics resources, we present a comprehensive review (with categorization and description) of major protein bioinformatics databases in this chapter. We also discuss the challenges and opportunities for developing next-generation protein bioinformatics databases and resources to support data integration and data analytics in the Big Data era.",2017,2021-06-05 21:12:01,3-39,,1558,Methods Mol Biol,,PubMed Central,PMID: 28150231 PMCID: PMC5506686,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5506686/,,,,PMC:Query2
17,10.1007/978-3-030-40608-0_17,,PMC7206624,,,,"Dondi, Riccardo; Mauri, Giancarlo; Zoppis, Italo",Complexity Issues of String to Graph Approximate Matching,2020,Language and Automata Theory and Applications,,"The problem of matching a query string to a directed graph, whose vertices are labeled by strings, has application in different fields, from data mining to computational biology. Several variants of the problem have been considered, depending on the fact that the match is exact or approximate and, in this latter case, which edit operations are considered and where are allowed. In this paper we present results on the complexity of the approximate matching problem, where edit operations are symbol substitutions and are allowed only on the graph labels or both on the graph labels and the query string. We introduce a variant of the problem that asks whether there exists a path in a graph that represents a query string with any number of edit operations and we show that is NP-complete, even when labels have length one and in the case the alphabet is binary. Moreover, when it is parameterized by the length of the input string and graph labels have length one, we show that the problem is fixed-parameter tractable and it is unlikely to admit a polynomial kernel. The NP-completeness of this problem leads to the inapproximability (within any factor) of the approximate matching when edit operations are allowed only on the graph labels. Moreover, we show that the variants of approximate string matching to graph we consider are not fixed-parameter tractable, when the parameter is the number of edit operations, even for graphs that have distance one from a DAG. The reduction for this latter result allows us to prove the inapproximability of the variant where edit operations can be applied both on the query string and on graph labels.",2020-01-07,2021-06-05 21:10:08,248-259,,12038,Language and Automata Theory and Applications,,PubMed Central,PMID:  PMCID: PMC7206624,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206624/,,,,PMC:Query2
18,10.1007/978-3-030-45439-5_50,,PMC7148211,A,Neo4j,Neo4j,"Witschel, Hans Friedrich; Riesen, Kaspar; Grether, Loris",KvGR: A Graph-Based Interface for Explorative Sequential Question Answering on Heterogeneous Information Sources,2020,Advances in Information Retrieval,,"Exploring a knowledge base is often an iterative process: initially vague information needs are refined by interaction. We propose a novel approach for such interaction that supports sequential question answering (SQA) on knowledge graphs. As opposed to previous work, we focus on exploratory settings, which we support with a visual representation of graph structures, helping users to better understand relationships. In addition, our approach keeps track of context – an important challenge in SQA – by allowing users to make their focus explicit via subgraph selection. Our results show that the interaction principle is either understood immediately or picked up very quickly – and that the possibility of exploring the information space iteratively is appreciated.",2020-03-17,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,760-773,,12035,Advances in Information Retrieval,KvGR,PubMed Central,PMID:  PMCID: PMC7148211,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7148211/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
19,10.1007/978-3-030-45442-5_79,,PMC7148032,A,Neo4j,Neo4j,"Kamphuis, Chris",Graph Databases for Information Retrieval,2020,Advances in Information Retrieval,,"Graph models have been deployed in the context of information retrieval for many years. Computations involving the graph structure are often separated from computations related to the base ranking. In recent years, graph data management has been a topic of interest in database research. We propose to deploy graph database management systems to implement existing and novel graph-based models for information retrieval. For this a unifying mapping from a graph query language to graph based retrieval models needs to be developed; extending standard graph database operations with functionality for keyword search. We also investigate how data structures and algorithms for ranking should change in presence of continuous database updates. We want to investigate how temporal decay can affect ranking when data is continuously updated. Finally, can databases be deployed for efficient two-stage retrieval approaches?",2020-03-24,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,608-612,,12036,Advances in Information Retrieval,,PubMed Central,PMID:  PMCID: PMC7148032,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7148032/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
20,10.1007/978-3-030-47240-5_17,,PMC7198243,A,Virtuoso,Virtuoso,"Mukhamedshin, Damir; Nevzorova, Olga; Kirillovich, Alexander","Using FLOSS for Storing, Processing and Linking Corpus Data",2020,Open Source Systems,,"Corpus data is widely used to solve different linguistic, educational and applied problems. The Tatar corpus management system (http://tugantel.tatar) is specifically developed for Turkic languages. The functionality of our corpus management system includes a search of lexical units, morphological and lexical search, a search of syntactic units, a search of N-grams and others. The search is performed using open source tools (database management system MariaDB, Redis data store). This article describes the process of choosing FLOSS for the main components of our system and also processing a search query and building a linked open dataset based on corpus data.",2020-05-05,2021-06-05 21:10:08; 2021-06-05 20:54:31; 2021-06-05 20:59:14,177-182,,582,Open Source Systems,,PubMed Central,PMID:  PMCID: PMC7198243,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7198243/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
21,10.1007/978-3-030-49161-1_29,,PMC7256379,,,,"Koutsomitropoulos, Dimitrios A.; Andriopoulos, Andreas D.",Automated MeSH Indexing of Biomedical Literature Using Contextualized Word Representations,2020,Artificial Intelligence Applications and Innovations,,"Appropriate indexing of resources is necessary for their efficient search, discovery and utilization. Relying solely on manual effort is time-consuming, costly and error prone. On the other hand, the special nature, volume and broadness of biomedical literature pose barriers for automated methods. We argue that current word embedding algorithms can be efficiently used to support the task of biomedical text classification. Both deep- and shallow network approaches are implemented and evaluated. Large datasets of biomedical citations and full texts are harvested for their metadata and used for training and testing. The ontology representation of Medical Subject Headings provides machine-readable labels and specifies the dimensionality of the problem space. These automated approaches are still far from entirely substituting human experts, yet they can be useful as a mechanism for validation and recommendation. Dataset balancing, distributed processing and training parallelization in GPUs, all play an important part regarding the effectiveness and performance of proposed methods.",2020-05-06,2021-06-05 21:10:08,343-354,,583,Artificial Intelligence Applications and Innovations,,PubMed Central,PMID:  PMCID: PMC7256379,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7256379/,,,,PMC:Query2
22,10.1007/978-3-030-49161-1_9,,PMC7256382,A,Neo4j,Neo4j,"Giarelis, Nikolaos; Kanakaris, Nikos; Karacapilidis, Nikos",An Innovative Graph-Based Approach to Advance Feature Selection from Multiple Textual Documents,2020,Artificial Intelligence Applications and Innovations,,"This paper introduces a novel graph-based approach to select features from multiple textual documents. The proposed solution enables the investigation of the importance of a term into a whole corpus of documents by utilizing contemporary graph theory methods, such as community detection algorithms and node centrality measures. Compared to well-tried existing solutions, evaluation results show that the proposed approach increases the accuracy of most text classifiers employed and decreases the number of features required to achieve ‘state-of-the-art’ accuracy. Well-known datasets used for the experimentations reported in this paper include 20Newsgroups, LingSpam, Amazon Reviews and Reuters.",2020-05-06,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,96-106,,583,Artificial Intelligence Applications and Innovations,,PubMed Central,PMID:  PMCID: PMC7256382,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7256382/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
23,10.1007/978-3-030-49165-9_10,,PMC7225519,A,Neo4j,Neo4j,"Piperagkas, Grigorios; Angarita, Rafael; Issarny, Valérie","Social Participation Network: Linking Things, Services and People to Support Participatory Processes",2020,Advanced Information Systems Engineering Workshops,,"Digital technologies have impacted almost every aspect of our society, including how people participate in activities that matter to them. Indeed, digital participation allows people to be involved in different societal activities at an unprecedented scale through the use of Information and Communication Technologies (ICT). Still, enabling participation at scale requires making it seamless for people to: interact with a variety of software platforms, get information from connected physical objects and software services, and communicate and collaborate with their peers. Toward this objective, this paper introduces and formalizes the concept of Social Participation Network, which captures the diverse participation relationships – between people, digital services and connected things – supporting participatory processes. The paper further presents the early design of an associated online service to support the creation and management of Social Participation Networks. The design advocates the instantiation of Social Participation Networks within distinct participation contexts—spanning, e.g., private institutions, neighbor communities, and governmental institutions—so that the participants’ information and contributions to participation remain isolated and private within the given context.",2020-04-29,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,109-120,,382,Advanced Information Systems Engineering Workshops,Social Participation Network,PubMed Central,PMID:  PMCID: PMC7225519,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7225519/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
24,10.1007/978-3-030-49190-1_18,,PMC7256426,A,Neo4j,Neo4j,"Drakopoulos, Georgios; Giannoukou, Ioanna; Mylonas, Phivos; Sioutas, Spyros","The Converging Triangle of Cultural Content, Cognitive Science, and Behavioral Economics",2020,Artificial Intelligence Applications and Innovations. AIAI 2020 IFIP WG 12.5 International Workshops,,"How online cultural content is chosen based on conscious or subconscious criteria is an central question across a broad spectrum of sciences and for the entertainment industry, including content providers and distributors. To this end, a number of tailored analytics forming the backbone of recommendation engines specialized for retrieving cultural content are proposed. Their strength derives directly from well-established principles of cognitive science and behavioral economics, both scientific fields exploring aspects of human decision making. Another novel contribution of this conference paper is that these analytics are implemented in Neo4j expressed as Cypher queries. Various aspects of the cultural content and digital consumers can be naturally represented by appropriately configured vertices, whereas edges represent various connections indicating content delivery preferences. Early experiments conducted over a synthetic dataset mimicking the distributions of preferences and ratings of well-known movie datasets are encouraging as the proposed analytics outperformed the baseline of a multilayer feedforward neural network of various configurations. The synthetic dataset contains enriched preferences of mobile digital consumers of cultural content regarding literature of the Greek region of Ionian Islands.",2020-05-04,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,200-212,,585,Artificial Intelligence Applications and Innovations. AIAI 2020 IFIP WG 12.5 International Workshops,,PubMed Central,PMID:  PMCID: PMC7256426,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7256426/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
25,10.1007/978-3-030-49435-3_27,,PMC7266453,A,Neo4j,Neo4j,"Sunkle, Sagar; Saxena, Krati; Patil, Ashwini; Kulkarni, Vinay; Jain, Deepak; Chacko, Rinu; Rai, Beena",Information Extraction and Graph Representation for the Design of Formulated Products,2020,Advanced Information Systems Engineering,,"Formulated products like cosmetics, personal and household care, and pharmaceutical products are ubiquitous in everyday life. The multi-billion-dollar formulated products industry depends primarily on experiential knowledge for the design of new products. Vast knowledge of formulation ingredients and recipes exists in offline and online resources. Experts often use rudimentary searches over this data to find ingredients and construct recipes. This state of the art leads to considerable time to market and cost. We present an approach for formulated product design that enables extraction, storage, and non-trivial search of details required for product variant generation. Our contributions are threefold. First, we show how various information extraction techniques can be used to extract ingredients and recipe actions from textual sources. Second, we describe how to store this highly connected information as a graph database with an extensible domain model. And third, we demonstrate an aid to experts in putting together a new product based on non-trivial search. In an ongoing proof of concept, we use 410 formulations of various cosmetic creams to demonstrate these capabilities with promising results.",2020-05-09,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,433-448,,12127,Advanced Information Systems Engineering,,PubMed Central,PMID:  PMCID: PMC7266453,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7266453/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
26,10.1007/978-3-030-49435-3_5,,PMC7266452,A,ArangoDB,ArangoDB,"Liebenberg, Martin; Jarke, Matthias",Information Systems Engineering with Digital Shadows: Concept and Case Studies,2020,Advanced Information Systems Engineering,,"The production sector has faced many difficulties in taking full advantage of opportunities found in other web application domains. Production research has focused on sophisticated mathematical models ranging from molecular materials modeling to efficient production control to inter-company supply network logistics. Often, these models have no closed-form solutions; this led to intense simulation research for individual modeling viewpoints, often labeled “Digital Twins”., However, the complexity of the overall system precludes Digital Twins covering more than just a few system perspectives, especially if near-realtime performance is required. Moreover, the wide variety of individual situations and behaviors is usually captured only as statistical uncertainty. In order to achieve better performance and more context adaptation, the interdisciplinary research cluster “Internet of Production” at RWTH Aachen University is exploring the concept of “Digital Shadows”. Digital Shadows can be understood as compact views on dynamic processes, usually combining condensed measurement data with highly efficient simplified mathematical models. In this exploratory paper, we argue based on a couple of initial case studies that Digital Shadows are not just valuable carriers of deep engineering knowledge but due to their small size also help in reducing network congestion and enabling edge computing. These properties could make Digital Shadows an interesting solution to address resilience in other information-intensive dynamic systems.",2020-05-09,2021-06-05 20:54:31; 2021-06-05 21:10:08; 2021-06-06 06:42:51,70-84,,12127,Advanced Information Systems Engineering,Information Systems Engineering with Digital Shadows,PubMed Central,PMID:  PMCID: PMC7266452,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7266452/,,ArangoDB,ArangoDB,PMC:Query3; PMC:Query2; PMC:ArangoDB
27,10.1007/978-3-030-49461-2_30,,PMC7250611,A,ArangoDB,ArangoDB,"Jiménez-Ruiz, Ernesto; Hassanzadeh, Oktie; Efthymiou, Vasilis; Chen, Jiaoyan; Srinivas, Kavitha",SemTab 2019: Resources to Benchmark Tabular Data to Knowledge Graph Matching Systems,2020,The Semantic Web,,"Tabular data to Knowledge Graph matching is the process of assigning semantic tags from knowledge graphs (e.g., Wikidata or DBpedia) to the elements of a table. This task is a challenging problem for various reasons, including the lack of metadata (e.g., table and column names), the noisiness, heterogeneity, incompleteness and ambiguity in the data. The results of this task provide significant insights about potentially highly valuable tabular data, as recent works have shown, enabling a new family of data analytics and data science applications. Despite significant amount of work on various flavors of this problem, there is a lack of a common framework to conduct a systematic evaluation of state-of-the-art systems. The creation of the Semantic Web Challenge on Tabular Data to Knowledge Graph Matching (SemTab) aims at filling this gap. In this paper, we report about the datasets, infrastructure and lessons learned from the first edition of the SemTab challenge.",2020-05-07,2021-06-05 20:54:31; 2021-06-05 21:10:08; 2021-06-06 06:42:51,514-530,,12123,The Semantic Web,SemTab 2019,PubMed Central,PMID:  PMCID: PMC7250611,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7250611/,,ArangoDB,ArangoDB,PMC:Query3; PMC:Query2; PMC:ArangoDB
28,10.1007/978-3-030-49461-2_5,,PMC7250607,,,,"Stoilos, Giorgos; Juric, Damir; Wartak, Szymon; Schulz, Claudia; Khodadadi, Mohammad",Hybrid Reasoning Over Large Knowledge Bases Using On-The-Fly Knowledge Extraction,2020,The Semantic Web,,"The success of logic-based methods for comparing entities heavily depends on the axioms that have been described for them in the Knowledge Base (KB). Due to the incompleteness of even large and well engineered KBs, such methods suffer from low recall when applied in real-world use cases. To address this, we designed a reasoning framework that combines logic-based subsumption with statistical methods for on-the-fly knowledge extraction. Statistical methods extract additional (missing) axioms for the compared entities with the goal of tackling the incompleteness of KBs and thus improving recall. Although this can be beneficial, it can also introduce noise (false positives or false negatives). Hence, our framework uses heuristics to assess whether knowledge extraction is likely to be advantageous and only activates the statistical components if this is the case. We instantiate our framework by combining lightweight logic-based reasoning implemented on top of existing triple-stores with an axiom extraction method that is based on the labels of concepts. Our work was motivated by industrial use cases over which we evaluate our instantiated framework, showing that it outperforms approaches that are only based on textual information. Besides the best combination of precision and recall, our implementation is also scalable and is currently used in an industrial production environment.",2020-05-07,2021-06-05 21:10:08,69-85,,12123,The Semantic Web,,PubMed Central,PMID:  PMCID: PMC7250607,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7250607/,,,,PMC:Query2
29,10.1007/978-3-030-50146-4_31,,PMC7274312,A,Neo4j,Neo4j,"Rezaei, Navid; Reformat, Marek Z.; Yager, Ronald R.",Image-Based World-perceiving Knowledge Graph (WpKG) with Imprecision,2020,Information Processing and Management of Uncertainty in Knowledge-Based Systems,,"Knowledge graphs are a data format that enables the representation of semantics. Most of the available graphs focus on the representation of facts, their features, and relations between them. However, from the point of view of possible applications of semantically rich data formats in intelligent, real-world scenarios, there is a need for knowledge graphs that describe contextual information regarding realistic and casual relations between items in the real world., In this paper, we present a methodology of generating knowledge graphs addressing such a need. We call them World-perceiving Knowledge Graphs – WpKG. The process of their construction is based on analyzing images. We apply deep learning image processing methods to extract scene graphs. We combine these graphs, and process the obtained graph to determine importance of relations between items detected on the images. The generated WpKG is used as a basis for constructing possibility graphs. We illustrate the process and show some snippets of the generated knowledge and possibility graphs.",2020-05-18,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,415-428,,1237,Information Processing and Management of Uncertainty in Knowledge-Based Systems,,PubMed Central,PMID:  PMCID: PMC7274312,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7274312/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
30,10.1007/978-3-030-50417-5_36,,PMC7302836,,,,"Manouvrier, Maude; Pautasso, Cesare; Rukoz, Marta",Microservice Disaster Crash Recovery: A Weak Global Referential Integrity Management,2020,Computational Science – ICCS 2020,,"Microservices which use polyglot persistence (using multiple data storage techniques) cannot be recovered in a consistent state from backups taken independently. As a consequence, references across microservice boundaries may break after disaster recovery. In this paper, we give a weak global consistency definition for microservice architectures and present a recovery protocol which takes advantage of cached referenced data to reduce the amnesia interval for the recovered microservice, i.e., the time interval after the most recent backup, during which state changes may have been lost.",2020-06-15,2021-06-05 21:10:08,482-495,,12138,Computational Science – ICCS 2020,Microservice Disaster Crash Recovery,PubMed Central,PMID:  PMCID: PMC7302836,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7302836/,,,,PMC:Query2
31,10.1007/978-3-030-51372-6_19,,PMC7314700,,,,"McCreesh, Ciaran; Prosser, Patrick; Trimble, James",The Glasgow Subgraph Solver: Using Constraint Programming to Tackle Hard Subgraph Isomorphism Problem Variants,2020,Graph Transformation,,"The Glasgow Subgraph Solver provides an implementation of state of the art algorithms for subgraph isomorphism problems. It combines constraint programming concepts with a variety of strong but fast domain-specific search and inference techniques, and is suitable for use on a wide range of graphs, including many that are found to be computationally hard by other solvers. It can also be equipped with side constraints, and can easily be adapted to solve other subgraph matching problem variants. We outline its key features from the view of both users and algorithm developers, and discuss future directions.",2020-05-31,2021-06-05 21:10:08,316-324,,12150,Graph Transformation,The Glasgow Subgraph Solver,PubMed Central,PMID:  PMCID: PMC7314700,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7314700/,,,,PMC:Query2
32,10.1007/978-3-030-51466-2_28,,PMC7309490,,,,"Martens, Wim",Formal Languages in Information Extraction and Graph Databases,2020,Beyond the Horizon of Computability,,,2020-06-24,2021-06-05 21:10:08,306-309,,12098,Beyond the Horizon of Computability,,PubMed Central,PMID:  PMCID: PMC7309490,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7309490/,,,,PMC:Query2
33,10.1007/978-3-030-52683-2_12,,PMC7338149,A,JanusGraph,JanusGraph,"Leichtnam, Laetitia; Totel, Eric; Prigent, Nicolas; Mé, Ludovic",Sec2graph: Network Attack Detection Based on Novelty Detection on Graph Structured Data,2020,"Detection of Intrusions and Malware, and Vulnerability Assessment",,"Being able to timely detect new kinds of attacks in highly distributed, heterogeneous and evolving networks without generating too many false alarms is especially challenging. Many researchers proposed various anomaly detection techniques to identify events that are inconsistent with past observations. While supervised learning is often used to that end, security experts generally do not have labeled datasets and labeling their data would be excessively expensive. Unsupervised learning, that does not require labeled data should then be used preferably, even if these approaches have led to less relevant results. We introduce in this paper a unified and unique graph representation called security objects’ graphs. This representation mixes and links events of different kinds and allows a rich description of the activities to be analyzed. To detect anomalies in these graphs, we propose an unsupervised learning approach based on auto-encoder. Our hypothesis is that as security objects’ graphs bring a rich vision of the normal situation, an auto-encoder is able to build a relevant model of this situation. To validate this hypothesis, we apply our approach to the CICIDS2017 dataset and show that although our approach is unsupervised, its detection results are as good, and even better than those obtained by many supervised approaches.",2020-06-11,2021-06-06 07:06:30; 2021-06-05 20:54:31; 2021-06-05 21:10:08,238-258,,12223,"Detection of Intrusions and Malware, and Vulnerability Assessment",Sec2graph,PubMed Central,PMID:  PMCID: PMC7338149,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7338149/,,JanusGraph,JanusGraph,PMC:Query3; PMC:JanusGraph; PMC:Query2
34,10.1007/978-3-030-58808-3_6,,PMC7974849,,,,"Bogdanov, Alexander; Degtyarev, Alexander; Shchegoleva, Nadezhda; Khvatov, Valery",Data Quality in a Decentralized Environment,2020,Computational Science and Its Applications – ICCSA 2020,,One of the most important aspects of applying distributed ledger technologies in the field of big data is ensuring the necessary data quality and calculating the corresponding metrics. The paper proposes a conceptual framework for working with Master Data in a decentralized environment. The greatest effect of this framework methods is increasing a real-time integrity for the data segments that have the direct impact on overall data quality. The proposed approach provides the result thanks to a special platform architecture similar to the blockchain and built-in artificial intelligence agents - oracles.,2020-08-20,2021-06-05 21:10:08,58-71,,12251,Computational Science and Its Applications – ICCSA 2020,,PubMed Central,PMID:  PMCID: PMC7974849,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7974849/,,,,PMC:Query2
35,10.1007/978-3-030-58811-3_7,,PMC7974699,A,Neo4j,Neo4j,"Esposito, Dario; Polignano, Marco; Basile, Pierpaolo; de Gemmis, Marco; Primiceri, Davide; Lisi, Stefano; Casaburi, Mauro; Basile, Giorgio; Mennitti, Matteo; Carella, Valentina; Manzari, Vito",DECiSION: Data-drivEn Customer Service InnovatiON,2020,Computational Science and Its Applications – ICCSA 2020,,"The paper presents DECiSION, an innovative framework in the field of Information Seeking Support Systems, able to retrieve all the data involved in a decision-making process, and to process, categorize and make them available in a useful form for the ultimate purpose of the user request. The platform is equipped with natural language understanding capabilities, allowing the interpretation of user requests and the identification of information sources from which to independently retrieve the information needed for the sensemaking task. The project foresees the implementation of a chatbot, which acts as a virtual assistant, and a conversational recommender system, able to dialogue with the user to discover their preferences and orient their answers in a personalized way. The goal is therefore to create an intelligent system to answer autonomously and comprehensively questions posed in natural language about a specific reference domain, to support the decision-making process. The paper describes the general architecture of the framework and then focuses on the key component that automatically translate the natural language user query into a machine-readable query for the service repository.",2020-08-19,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,94-103,,12252,Computational Science and Its Applications – ICCSA 2020,DECiSION,PubMed Central,PMID:  PMCID: PMC7974699,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7974699/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
36,10.1007/978-3-030-59833-4_7,,PMC7586441,A,GraphDB,GraphDB,"Graux, Damien; Sejdiu, Gezim; Stadler, Claus; Napolitano, Giulio; Lehmann, Jens",MINDS: A Translator to Embed Mathematical Expressions Inside SPARQL Queries,2020,Semantic Systems. In the Era of Knowledge Graphs,,"The recent deployments of semantic web tools and the expansion of available linked datasets have given users the opportunity of building increasingly complex applications. These emerging use cases often require queries containing mathematical formulas such as euclidean distances or unit conversions. Currently, the latest SPARQL standard (version 1.1) only embeds basic math operators. Thus, to address this shortcoming, some popular SPARQL evaluators provide built-in tools to cover specific needs; however, such tools are not standard yet. To offer users a more generic solution, we propose and share MINDS, a translator of mathematical expressions into SPARQL-compliant bindings which can be understood by any evaluator. MINDS thereby facilitates the query design whenever mathematical computations are needed in a SPARQL query.",2020-10-27,2021-06-06 06:54:16; 2021-06-05 20:54:31; 2021-06-05 21:09:36,104-117,,12378,Semantic Systems. In the Era of Knowledge Graphs,MINDS,PubMed Central,PMID:  PMCID: PMC7586441,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7586441/,,GraphDB,GraphDB,PMC:Query3; PMC:GraphDB; PMC:Query2
37,10.1007/978-3-030-71903-6_11,,PMC7971784,A,Neo4j; COVID19; ArangoDB; Azure; OrientDB,Neo4j; COVID19; ArangoDB; Azure; OrientDB,"Rousidis, Dimitrios; Koukaras, Paraskevas; Tjortjis, Christos",Examination of NoSQL Transition and Data Mining Capabilities,2021,Metadata and Semantic Research,,"An estimated 2.5 quintillion bytes of data are created every day. This data explosion, along with new datatypes, objects, and the wide usage of social media networks, with an estimated 3.8 billion users worldwide, make the exploitation and manipulation of data by relational databases, cumbersome and problematic. NoSQL databases introduce new capabilities aiming at improving the functionalities offered by traditional SQL DBMS. This paper elaborates on ongoing research regarding NoSQL, focusing on the background behind their development, their basic characteristics, their categorization and the noticeable increase in popularity. Functional advantages and data mining capabilities that come with the usage of graph databases are also presented. Common data mining tasks with graphs are presented, facilitating implementation, as well as efficiency. The aim is to highlight concepts necessary for incorporating data mining techniques and graph database functionalities, eventually proposing an analytical framework offering a plethora of domain specific analytics. For example, a virus outbreak analytics framework allowing health and government officials to make appropriate decisions.",2021-02-22,2021-06-05 20:35:57; 2021-06-05 21:35:36; 2021-06-06 07:29:41; 2021-06-05 20:54:31; 2021-06-06 06:42:51; 2021-06-05 21:09:36; 2021-06-06 06:49:06,110-115,,1355,Metadata and Semantic Research,,PubMed Central,PMID:  PMCID: PMC7971784,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7971784/,,Neo4j; COVID19; ArangoDB; Azure; OrientDB,Neo4j; COVID19; ArangoDB; Azure; OrientDB,PMC:Query2; PMC:OrientDB; PMC:Query3; PMC:Neo4j; PMC:Azure; PMC:COVID19; PMC:ArangoDB
38,10.1007/978-3-030-71903-6_14,,PMC7971833,A,Virtuoso; OrientDB; Neo4j,Virtuoso; OrientDB; Neo4j,"Koukaras, Paraskevas; Rousidis, Dimitrios; Tjortjis, Christos","An Introduction to Information Network Modeling Capabilities, Utilizing Graphs",2021,Metadata and Semantic Research,,"This paper presents research on Information Network (IN) modeling using graph mining. The theoretical background along with a review of relevant literature is showcased, pertaining the concepts of IN model types, network schemas and graph measures. Ongoing research involves experimentation and evaluation on bipartite and star network schemas, generating test subjects using Social Media, Energy or Healthcare data. Our contribution is showcased by two proof-of-concept simulations we plan to extend.",2021-02-22,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36; 2021-06-06 06:49:06; 2021-06-05 20:59:14,134-140,,1355,Metadata and Semantic Research,,PubMed Central,PMID:  PMCID: PMC7971833,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7971833/,,Virtuoso; OrientDB; Neo4j,Virtuoso; OrientDB; Neo4j,PMC:Query2; PMC:OrientDB; PMC:Query3; PMC:Neo4j; PMC:Virtuoso
39,10.1007/978-3-030-71903-6_2,,PMC7971818,A,Virtuoso,Virtuoso,"Sanchez-Alonso, Salvador; Sicilia, Miguel A.; Rajabi, Enayat; Mora-Cantallops, Marçal; Garcia-Barriocanal, Elena",Class and Instance Equivalences in the Web of Linked Data: Distribution and Graph Structure,2021,Metadata and Semantic Research,,"The Web of Linked Open Data (LOD) is a decentralized effort in publishing datasets using a set of conventions to make them accesssible, notably thought RDF and SPARQL. Links across nodes in published datasets are thus critical in getting value for the LOD cloud as a collective effort. Connectivity among the datasets can occur through these links. Equivalence relationship is one of the fundamental links that connects different schemas or datasets, and is used to assert either class or instance equivalence. In this article, we report an empirical study on the equivalences found in over 59 million triples from datasets accessible via SPARQL endpoints in open source data portals. Metrics from graph analysis have been used to examine the relationships between repositories and determine their relative importance as well as their ability to facilitate knowledge discovery.",2021-02-22,2021-06-05 20:54:31; 2021-06-05 20:59:14; 2021-06-05 21:09:36,13-21,,1355,Metadata and Semantic Research,Class and Instance Equivalences in the Web of Linked Data,PubMed Central,PMID:  PMCID: PMC7971818,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7971818/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
40,10.1007/978-3-030-71903-6_24,,PMC7971831,A,GraphDB,GraphDB,"Kessler, Ingmar; Perzylo, Alexander; Rickert, Markus",Ontology-Based Decision Support System for the Nitrogen Fertilization of Winter Wheat,2021,Metadata and Semantic Research,,"Digital technologies are already used in several aspects of agriculture. However, decision-making in crop production is still often a manual process that relies on various heterogeneous data sources. Small-scale farmers and their local consultants are particularly burdened by increasingly complex requirements. Regional circumstances and regulations play an essential role and need to be considered. This paper presents an ontology-based decision support system for the nitrogen fertilization of winter wheat in Bavaria, Germany. Semantic Web and Linked Data technologies were employed to both reuse and model new common semantic structures for interrelated knowledge. Many relevant general and regional data sources from multiple domains were not yet available in RDF. Hence, we used several tools to transform relevant data into corresponding OWL ontologies and combined them in a central knowledge base. The GUI application of the decision support system queries it to parameterize requests to external web services and to show relevant information in an integrated view. It further uses SPARQL queries to automatically generate recommendations for farmers and their consultants.",2021-02-22,2021-06-06 06:54:16; 2021-06-05 20:54:31; 2021-06-05 21:09:36,245-256,,1355,Metadata and Semantic Research,,PubMed Central,PMID:  PMCID: PMC7971831,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7971831/,,GraphDB,GraphDB,PMC:Query3; PMC:GraphDB; PMC:Query2
41,10.1007/978-3-030-71903-6_5,,PMC7971790,A,ArangoDB; OrientDB; Neo4j,ArangoDB; OrientDB; Neo4j,"Samuelsen, Simen Dyve; Nikolov, Nikolay; Soylu, Ahmet; Roman, Dumitru",An Approach for Representing and Storing RDF Data in Multi-model Databases,2021,Metadata and Semantic Research,,"The emergence of NoSQL multi-model databases, natively supporting scalable and unified storage and querying of various data models, presents new opportunities for storing and managing RDF data. In this paper, we propose an approach to store RDF data in multi-model databases. We identify various aspects of representing the RDF data structure into a multi-model data structure and discuss their advantages and disadvantages. Furthermore, we implement and evaluate the proposed approach in a prototype using ArangoDB—a popular multi-model database.",2021-02-22,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-06 06:42:51; 2021-06-05 21:09:36; 2021-06-06 06:49:06,47-52,,1355,Metadata and Semantic Research,,PubMed Central,PMID:  PMCID: PMC7971790,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7971790/,,ArangoDB; OrientDB; Neo4j,ArangoDB; OrientDB; Neo4j,PMC:Query2; PMC:OrientDB; PMC:Query3; PMC:Neo4j; PMC:ArangoDB
42,10.1007/978-3-030-71903-6_9,,PMC7971826,A,GraphDB,GraphDB,"Fiorelli, Manuel; Stellato, Armando",Lifting Tabular Data to RDF: A Survey,2021,Metadata and Semantic Research,,"Tabular data formats (e.g. CSV and spreadsheets) combine ease of use, versatility and compatibility with information management systems. Despite their numerous advantages, these formats typically rely on column headers and out-of-band agreement to convey semantics. There is clearly a large gap with respect to the Semantic Web, which uses RDF as a graph-based data model, while relying on ontologies for well-defined semantics. Several systems have been developed to close this gap, supporting the conversion of tabular data to RDF. This study is a survey of these systems, which have been analyzed and compared. We identified commonalities and differences among them, discussed different approaches and derived useful insights on the task.",2021-02-22,2021-06-06 06:54:16; 2021-06-05 20:54:31; 2021-06-05 21:09:36,85-96,,1355,Metadata and Semantic Research,Lifting Tabular Data to RDF,PubMed Central,PMID:  PMCID: PMC7971826,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7971826/,,GraphDB,GraphDB,PMC:Query3; PMC:GraphDB; PMC:Query2
43,10.1007/978-3-319-62543-0_8,,PMC7122011,A,Neo4j,Neo4j,"Chen, Chaomei; Song, Min",Patterns and Trends in Semantic Predications,2017,Representing Scientific Knowledge,,"We demonstrate a series of studies of semantic predications from Semantic MEDLINE, including the detection of semantic predications with burstness and in association with conflict, contradictory, or other sources of uncertainties of scientific knowledge. Semantic networks of predications are analyzed within the framework of structural variations. Examples in this chapter represent scientific knowledge at a level of granularity that differs from those studies of scientific knowledge at the level of articles or journals of scholarly communication.",2017-11-28,2021-06-05 20:55:40; 2021-06-05 21:11:16; 2021-06-05 20:36:32,283-336,,,Representing Scientific Knowledge,,PubMed Central,PMID:  PMCID: PMC7122011,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7122011/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
44,10.1007/978-3-642-13818-8_32,25621321,PMC4303908,A,Virtuoso,Virtuoso,"Sahoo, Satya S.; Bodenreider, Olivier; Hitzler, Pascal; Sheth, Amit; Thirunarayan, Krishnaprasad",Provenance Context Entity (PaCE): Scalable Provenance Tracking for Scientific RDF Data,2010,"Scientific and statistical database management : International Conference, SSDBM ... : proceedings. International Conference on Scientific and Statistical Database Management",,"The Resource Description Framework (RDF) format is being used by a large number of scientific applications to store and disseminate their datasets. The provenance information, describing the source or lineage of the datasets, is playing an increasingly significant role in ensuring data quality, computing trust value of the datasets, and ranking query results. Current provenance tracking approaches using the RDF reification vocabulary suffer from a number of known issues, including lack of formal semantics, use of blank nodes, and application-dependent interpretation of reified RDF triples. In this paper, we introduce a new approach called Provenance Context Entity (PaCE) that uses the notion of provenance context to create provenance-aware RDF triples. We also define the formal semantics of PaCE through a simple extension of the existing RDF(S) semantics that ensures compatibility of PaCE with existing Semantic Web tools and implementations. We have implemented the PaCE approach in the Biomedical Knowledge Repository (BKR) project at the US National Library of Medicine. The evaluations demonstrate a minimum of 49% reduction in total number of provenance-specific RDF triples generated using the PaCE approach as compared to RDF reification. In addition, performance for complex queries improves by three orders of magnitude and remains comparable to the RDF reification approach for simpler provenance queries.",2010,2021-06-05 21:13:27; 2021-06-05 20:56:20; 2021-06-05 20:59:14,461-470,,6187,Sci Stat Database Manag,Provenance Context Entity (PaCE),PubMed Central,PMID: 25621321 PMCID: PMC4303908,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4303908/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
45,10.1007/s00224-017-9802-9,31258387,PMC6560828,A,Virtuoso; AllegroGraph,Virtuoso; AllegroGraph,"Kaminski, Mark; Kostylev, Egor V.",Complexity and Expressive Power of Weakly Well-Designed SPARQL,2018,Theory of Computing Systems,,"SPARQL is the standard query language for RDF data. The distinctive feature of SPARQL is the OPTIONAL operator, which allows for partial answers when complete answers are not available due to lack of information. However, optional matching is computationally expensive—query answering is PSPACE-complete. The well-designed fragment of SPARQL achieves much better computational properties by restricting the use of optional matching—query answering becomes coNP-complete. On the downside, well-designed SPARQL captures far from all real-life queries—in fact, only about half of the queries over DBpedia that use OPTIONAL are well-designed. In the present paper, we study queries outside of well-designed SPARQL. We introduce the class of weakly well-designed queries that subsumes well-designed queries and includes most common meaningful non-well-designed queries: our analysis shows that the new fragment captures over 99% of DBpedia queries with OPTIONAL. At the same time, query answering for weakly well-designed SPARQL remains coNP-complete, and our fragment is in a certain sense maximal for this complexity. We show that the fragment’s expressive power is strictly in-between well-designed and full SPARQL. Finally, we provide an intuitive normal form for weakly well-designed queries and study the complexity of containment and equivalence.",2018,2021-06-05 20:55:40; 2021-06-06 06:38:41; 2021-06-05 21:12:01; 2021-06-05 20:59:14,772-809,4,62,Theory Comput Syst,,PubMed Central,PMID: 31258387 PMCID: PMC6560828,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6560828/,,Virtuoso; AllegroGraph,Virtuoso; AllegroGraph,PMC:Query3; PMC:AllegroGraph; PMC:Query2; PMC:Virtuoso
46,10.1007/s00287-021-01343-1,,PMC7891475,A,Neo4j; COVID19,Neo4j; COVID19,"Humm, Bernhard G.; Bense, Hermann; Fuchs, Michael; Gernhardt, Benjamin; Hemmje, Matthias; Hoppe, Thomas; Kaupp, Lukas; Lothary, Sebastian; Schäfer, Kai-Uwe; Thull, Bernhard; Vogel, Tobias; Wenning, Rigo","Machine intelligence today: applications, methodology, and technology",2021,Informatik Spektrum,,"Machine intelligence, a.k.a. artificial intelligence (AI) is one of the most prominent and relevant technologies today. It is in everyday use in the form of AI applications and has a strong impact on society. This article presents selected results of the 2020 Dagstuhl workshop on applied machine intelligence. Selected AI applications in various domains, namely culture, education, and industrial manufacturing are presented. Current trends, best practices, and recommendations regarding AI methodology and technology are explained. The focus is on ontologies (knowledge-based AI) and machine learning.",2021-02-18,2021-06-05 20:35:57; 2021-06-05 21:35:36; 2021-06-05 20:54:31; 2021-06-05 21:09:36,1-11,,,,Machine intelligence today,PubMed Central,PMID:  PMCID: PMC7891475,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7891475/,,Neo4j; COVID19,Neo4j; COVID19,PMC:Query3; PMC:Neo4j; PMC:COVID19; PMC:Query2
47,10.1007/s00521-021-06053-z,33994670,PMC8111057,,,,"Koutsomitropoulos, Dimitrios A.; Andriopoulos, Andreas D.",Thesaurus-based word embeddings for automated biomedical literature classification,2021,Neural Computing & Applications,,"The special nature, volume and broadness of biomedical literature pose barriers for automated classification methods. On the other hand, manually indexing is time-consuming, costly and error prone. We argue that current word embedding algorithms can be efficiently used to support the task of biomedical text classification even in a multilabel setting, with many distinct labels. The ontology representation of Medical Subject Headings provides machine-readable labels and specifies the dimensionality of the problem space. Both deep- and shallow network approaches are implemented. Predictions are determined by the similarity between extracted features from contextualized representations of abstracts and headings. The addition of a separate classifier for transfer learning is also proposed and evaluated. Large datasets of biomedical citations are harvested for their metadata and used for training and testing. These automated approaches are still far from entirely substituting human experts, yet they can be useful as a mechanism for validation and recommendation. Dataset balancing, distributed processing and training parallelization in GPUs, all play an important part regarding the effectiveness and performance of proposed methods.",2021-05-11,2021-06-05 21:09:36,1-14,,,Neural Comput Appl,,PubMed Central,PMID: 33994670 PMCID: PMC8111057,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8111057/,,,,PMC:Query2
48,10.1007/s00607-020-00837-2,,PMC7437110,,,,"Satti, Fahad Ahmed; Ali, Taqdir; Hussain, Jamil; Khan, Wajahat Ali; Khattak, Asad Masood; Lee, Sungyoung",Ubiquitous Health Profile (UHPr): a big data curation platform for supporting health data interoperability,2020,Computing,,"The lack of Interoperable healthcare data presents a major challenge, towards achieving ubiquitous health care. The plethora of diverse medical standards, rather than common standards, is widening the gap of interoperability. While many organizations are working towards a standardized solution, there is a need for an alternate strategy, which can intelligently mediate amongst a variety of medical systems, not complying with any mainstream healthcare standards while utilizing the benefits of several standard merging initiates, to eventually create digital health personas. The existence and efficiency of such a platform is dependent upon the underlying storage and processing engine, which can acquire, manage and retrieve the relevant medical data. In this paper, we present the Ubiquitous Health Profile (UHPr), a multi-dimensional data storage solution in a semi-structured data curation engine, which provides foundational support for archiving heterogeneous medical data and achieving partial data interoperability in the healthcare domain. Additionally, we present the evaluation results of this proposed platform in terms of its timeliness, accuracy, and scalability. Our results indicate that the UHPr is able to retrieve an error free comprehensive medical profile of a single patient, from a set of slightly over 116.5 million serialized medical fragments for 390,101 patients while maintaining a good scalablity ratio between amount of data and its retrieval speed.",2020-08-19,2021-06-05 21:10:08,1-36,,,,Ubiquitous Health Profile (UHPr),PubMed Central,PMID:  PMCID: PMC7437110,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7437110/,,,,PMC:Query2
49,10.1007/s10115-015-0910-z,27746515,PMC5058368,,,,"Shen, Yelong; Phan, NhatHai; Xiao, Xiao; Jin, Ruoming; Sun, Junfeng; Piniewski, Brigitte; Kil, David; Dou, Dejing",Dynamic Socialized Gaussian Process Models for Human Behavior Prediction in a Health Social Network,2016,Knowledge and information systems,,"Modeling and predicting human behaviors, such as the level and intensity of physical activity, is a key to preventing the cascade of obesity and helping spread healthy behaviors in a social network. In our conference paper, we have developed a social influence model, named Socialized Gaussian Process (SGP), for socialized human behavior modeling. Instead of explicitly modeling social influence as individuals' behaviors influenced by their friends' previous behaviors, SGP models the dynamic social correlation as the result of social influence. The SGP model naturally incorporates personal behavior factor and social correlation factor (i.e., the homophily principle: Friends tend to perform similar behaviors) into a unified model. And it models the social influence factor (i.e., an individual's behavior can be affected by his/her friends) implicitly in dynamic social correlation schemes. The detailed experimental evaluation has shown the SGP model achieves better prediction accuracy compared with most of baseline methods. However, a Socialized Random Forest model may perform better at the beginning compared with the SGP model. One of the main reasons is the dynamic social correlation function is purely based on the users' sequential behaviors without considering other physical activity-related features. To address this issue, we further propose a novel “multi-feature SGP model” (mfSGP) which improves the SGP model by using multiple physical activity-related features in the dynamic social correlation learning. Extensive experimental results illustrate that the mfSGP model clearly outperforms all other models in terms of prediction accuracy and running time.",2016-11,2021-06-05 21:12:40,455-479,2,49,Knowl Inf Syst,,PubMed Central,PMID: 27746515 PMCID: PMC5058368,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5058368/,,,,PMC:Query2
50,10.1007/s10142-015-0433-4,25722247,PMC4361730,A,Neo4j,Neo4j,"Land, Miriam; Hauser, Loren; Jun, Se-Ran; Nookaew, Intawat; Leuze, Michael R.; Ahn, Tae-Hyuk; Karpinets, Tatiana; Lund, Ole; Kora, Guruprased; Wassenaar, Trudy; Poudel, Suresh; Ussery, David W.",Insights from 20 years of bacterial genome sequencing,2015,Functional & Integrative Genomics,,"Since the first two complete bacterial genome sequences were published in 1995, the science of bacteria has dramatically changed. Using third-generation DNA sequencing, it is possible to completely sequence a bacterial genome in a few hours and identify some types of methylation sites along the genome as well. Sequencing of bacterial genome sequences is now a standard procedure, and the information from tens of thousands of bacterial genomes has had a major impact on our views of the bacterial world. In this review, we explore a series of questions to highlight some insights that comparative genomics has produced. To date, there are genome sequences available from 50 different bacterial phyla and 11 different archaeal phyla. However, the distribution is quite skewed towards a few phyla that contain model organisms. But the breadth is continuing to improve, with projects dedicated to filling in less characterized taxonomic groups. The clustered regularly interspaced short palindromic repeats (CRISPR)-Cas system provides bacteria with immunity against viruses, which outnumber bacteria by tenfold. How fast can we go? Second-generation sequencing has produced a large number of draft genomes (close to 90 % of bacterial genomes in GenBank are currently not complete); third-generation sequencing can potentially produce a finished genome in a few hours, and at the same time provide methlylation sites along the entire chromosome. The diversity of bacterial communities is extensive as is evident from the genome sequences available from 50 different bacterial phyla and 11 different archaeal phyla. Genome sequencing can help in classifying an organism, and in the case where multiple genomes of the same species are available, it is possible to calculate the pan- and core genomes; comparison of more than 2000 Escherichia coli genomes finds an E. coli core genome of about 3100 gene families and a total of about 89,000 different gene families. Why do we care about bacterial genome sequencing? There are many practical applications, such as genome-scale metabolic modeling, biosurveillance, bioforensics, and infectious disease epidemiology. In the near future, high-throughput sequencing of patient metagenomic samples could revolutionize medicine in terms of speed and accuracy of finding pathogens and knowing how to treat them.",2015,2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-05 20:37:08,141-161,2,15,Funct Integr Genomics,,PubMed Central,PMID: 25722247 PMCID: PMC4361730,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4361730/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
51,10.1007/s10270-016-0571-8,30220905,PMC6132656,A,OrientDB; Neo4j,OrientDB; Neo4j,"Szárnyas, Gábor; Izsó, Benedek; Ráth, István; Varró, Dániel",The Train Benchmark: cross-technology performance evaluation of continuous model queries,2018,Software and Systems Modeling,,"In model-driven development of safety-critical systems (like automotive, avionics or railways), well-formedness of models is repeatedly validated in order to detect design flaws as early as possible. In many industrial tools, validation rules are still often implemented by a large amount of imperative model traversal code which makes those rule implementations complicated and hard to maintain. Additionally, as models are rapidly increasing in size and complexity, efficient execution of validation rules is challenging for the currently available tools. Checking well-formedness constraints can be captured by declarative queries over graph models, while model update operations can be specified as model transformations. This paper presents a benchmark for systematically assessing the scalability of validating and revalidating well-formedness constraints over large graph models. The benchmark defines well-formedness validation scenarios in the railway domain: a metamodel, an instance model generator and a set of well-formedness constraints captured by queries, fault injection and repair operations (imitating the work of systems engineers by model transformations). The benchmark focuses on the performance of query evaluation, i.e. its execution time and memory consumption, with a particular emphasis on reevaluation. We demonstrate that the benchmark can be adopted to various technologies and query engines, including modeling tools; relational, graph and semantic databases. The Train Benchmark is available as an open-source project with continuous builds from https://github.com/FTSRG/trainbenchmark.",2018,2021-06-06 06:49:06; 2021-06-05 21:06:22; 2021-06-05 20:37:08; 2021-06-05 21:12:01; 2021-06-05 20:55:40,1365-1393,4,17,Softw Syst Model,The Train Benchmark,PubMed; PubMed Central,PMID: 30220905 PMCID: PMC6132656,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6132656/; http://www.ncbi.nlm.nih.gov/pubmed/30220905,Graph databases; Performance benchmark; Query evaluation; Relational databases; Semantic databases; Well-formedness validation,OrientDB; Neo4j,OrientDB; Neo4j,PMC:Query2; PMC:OrientDB; PMC:Query3; PMC:Neo4j; PubMed:Query2
52,10.1007/s10270-019-00725-0,31975977,PMC6944265,A,OrientDB; Neo4j,OrientDB; Neo4j,"Haeusler, Martin; Trojer, Thomas; Kessler, Johannes; Farwick, Matthias; Nowakowski, Emmanuel; Breu, Ruth",ChronoSphere: a graph-based EMF model repository for IT landscape models,2019,Software and Systems Modeling,,"IT Landscape models are representing the real-world IT infrastructure of a company. They include hardware assets such as physical servers and storage media, as well as virtual components like clusters, virtual machines and applications. These models are a critical source of information in numerous tasks, including planning, error detection and impact analysis. The responsible stakeholders often struggle to keep such a large and densely connected model up-to-date due to its inherent size and complexity, as well as due to the lack of proper tool support. Even though modeling techniques are very suitable for this domain, existing tools do not offer the required features, scalability or flexibility. In order to solve these challenges and meet the requirements that arise from this application domain, we combine domain-driven modeling concepts with scalable graph-based repository technology and a custom language for model-level queries. We analyze in detail how we synthesized these requirements from the application domain and how they relate to the features of our repository. We discuss the architecture of our solution which comprises the entire data management stack, including transactions, queries, versioned persistence and metamodel evolution. Finally, we evaluate our approach in a case study where our open-source repository implementation is employed in a production environment in an industrial context, as well as in a comparative benchmark with an existing state-of-the-art solution.",2019,2021-06-06 06:49:06; 2021-06-05 21:06:22; 2021-06-05 21:10:37; 2021-06-05 20:55:01; 2021-06-05 20:36:32,3487-3526,6,18,Softw Syst Model,ChronoSphere,PubMed; PubMed Central,PMID: 31975977 PMCID: PMC6944265,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6944265/; http://www.ncbi.nlm.nih.gov/pubmed/31975977,Graph database; IT landscape; Model repositories; Model-driven engineering; Versioning,OrientDB; Neo4j,OrientDB; Neo4j,PMC:Query2; PMC:OrientDB; PMC:Query3; PMC:Neo4j; PubMed:Query2
53,10.1007/s10278-016-9894-9,27440183,PMC5114234,,,,"Ferreira Junior, José Raniery; Oliveira, Marcelo Costa; de Azevedo-Marques, Paulo Mazzoncini",Cloud-Based NoSQL Open Database of Pulmonary Nodules for Computer-Aided Lung Cancer Diagnosis and Reproducible Research,2016,Journal of Digital Imaging,,"Lung cancer is the leading cause of cancer-related deaths in the world, and its main manifestation is pulmonary nodules. Detection and classification of pulmonary nodules are challenging tasks that must be done by qualified specialists, but image interpretation errors make those tasks difficult. In order to aid radiologists on those hard tasks, it is important to integrate the computer-based tools with the lesion detection, pathology diagnosis, and image interpretation processes. However, computer-aided diagnosis research faces the problem of not having enough shared medical reference data for the development, testing, and evaluation of computational methods for diagnosis. In order to minimize this problem, this paper presents a public nonrelational document-oriented cloud-based database of pulmonary nodules characterized by 3D texture attributes, identified by experienced radiologists and classified in nine different subjective characteristics by the same specialists. Our goal with the development of this database is to improve computer-aided lung cancer diagnosis and pulmonary nodule detection and classification research through the deployment of this database in a cloud Database as a Service framework. Pulmonary nodule data was provided by the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI), image descriptors were acquired by a volumetric texture analysis, and database schema was developed using a document-oriented Not only Structured Query Language (NoSQL) approach. The proposed database is now with 379 exams, 838 nodules, and 8237 images, 4029 of them are CT scans and 4208 manually segmented nodules, and it is allocated in a MongoDB instance on a cloud infrastructure.",2016-12,2021-06-05 21:12:01,716-729,6,29,J Digit Imaging,,PubMed Central,PMID: 27440183 PMCID: PMC5114234,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5114234/,,,,PMC:Query2
54,10.1007/s10822-013-9646-6,23636795,PMC4205101,,,,"Tseng, Y. Jane; Martin, Eric; Bologa, Cristian; Shelat, Anang A.",Cheminformatics Aspects of High Throughput Screening: from Robots to Models: Symposium Summary,2013,Journal of computer-aided molecular design,,"The “Cheminformatics aspects of high throughput screening (HTS): from robots to models” symposium was part of the Computers in Chemistry (COMP) technical program at the American Chemical Society National Meeting in Denver, Colorado during the fall of 2011. This symposium brought together researchers from high throughput screening centersand molecular modelers from academia and industry to discuss the integration of currently available high throughput screening data and assays with computational analysis. The topics discussed at this symposium covered the data-infrastructure at various academic, hospital, and NIH-funded high throughput screening centers, the cheminformatics and molecular modeling methods used in real world examples to guide screening and hit-finding, and how academic and non-profit organizations can benefit from current high throughput screening cheminformatics resources. Specifically, this article also covers the remarks and discussions in the open panel discussion in thesymposium and summarizes the following talks on “Accurate Kinase virtual screening: biochemical, cellular and selectivity”, “Selective, privileged and promiscuous chemical patterns in high-throughput screening” and “Visualizing and exploring relationships among HTS hits using network graphs”.",2013-05,2021-06-05 21:13:27,443-453,5,27,J Comput Aided Mol Des,Cheminformatics Aspects of High Throughput Screening,PubMed Central,PMID: 23636795 PMCID: PMC4205101,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4205101/,,,,PMC:Query2
55,10.1007/s10916-020-1538-4,32166501,PMC7067737,,,,"Schrodt, Jens; Dudchenko, Aleksei; Knaup-Gregori, Petra; Ganzinger, Matthias",Graph-Representation of Patient Data: a Systematic Literature Review,2020,Journal of Medical Systems,,"Graph theory is a well-established theory with many methods used in mathematics to study graph structures. In the field of medicine, electronic health records (EHR) are commonly used to store and analyze patient data. Consequently, it seems straight-forward to perform research on modeling EHR data as graphs. This systematic literature review aims to investigate the frontiers of the current research in the field of graphs representing and processing patient data. We want to show, which areas of research in this context need further investigation. The databases MEDLINE, Web of Science, IEEE Xplore and ACM digital library were queried by using the search terms health record, graph and related terms. Based on the “Preferred Reporting Items for Systematic Reviews and Meta-Analysis” (PRISMA) statement guidelines the articles were screened and evaluated using full-text analysis. Eleven out of 383 articles found in systematic literature review were finally included for analysis in this literature review. Most of them use graphs to represent temporal relations, often representing the connection among laboratory data points. Only two papers report that the graph data were further processed by comparing the patient graphs using similarity measurements. Graphs representing individual patients are hardly used in research context, only eleven papers considered such kind of graphs in their investigations. The potential of graph theoretical algorithms, which are already well established, could help increasing this research field, but currently there are too few papers to estimate how this area of research will develop. Altogether, the use of such patient graphs could be a promising technique to develop decision support systems for diagnosis, medication or therapy of patients using similarity measurements or different kinds of analysis.",2020,2021-06-05 21:10:08,,4,44,J Med Syst,Graph-Representation of Patient Data,PubMed Central,PMID: 32166501 PMCID: PMC7067737,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7067737/,,,,PMC:Query2
56,10.1007/s11518-019-5453-5,32837111,PMC7282698,,,,"Sahoh, Bukhoree; Choksuriwong, Anant",Automatic Semantic Description Extraction from Social Big Data for Emergency Management,2020,Journal of Systems Science and Systems Engineering,,"Emergency events are unexpected and dangerous situations which the authorities must manage and respond to as quickly as possible. The main objectives of emergency management are to provide human safety and security, and Social Big Data (SBD) offers an important information source, created directly from eyewitness reports, to assist with these issues. However, the manual extraction of hidden meaning from SBD is both time-consuming and labor-intensive, which are major drawbacks for a process that needs accurate information to be produced in real-time. The solution is an automatic approach to knowledge discovery, and we propose a semantic description technique based on the use of triple store indexing for named entity recognition and relation extraction. Our technique can discover hidden SBD information more effectively than traditional approaches, and can be used for intelligent emergency management.",2020-06-09,2021-06-05 21:10:08,1-17,,,J Syst Sci Syst Eng,,PubMed Central,PMID: 32837111 PMCID: PMC7282698,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7282698/,,,,PMC:Query2
57,10.1007/s12553-016-0175-x,28344915,PMC5346419,,,,"Müller, Heimo; Malservet, Nicolas; Quinlan, Philip; Reihs, Robert; Penicaud, Matthieu; Chami, Antoine; Zatloukal, Kurt; Dagher, George",From the evaluation of existing solutions to an all-inclusive package for biobanks,2017,Health and Technology,,"The domain of biobanking has gone through many stages and as a result there are a wide range of commercial and open source software solutions available. The utilization of these software tools requires different levels of domain and technical skills for installation, configuration and ultimate us of these biobank software tools. To compound this complexity the biobanking community are required to work together in order to share knowledge and jointly build solutions to underpin the research infrastructure. We have evaluated the available tools, described them in a catalogue (BiobankApps) and made a selection of tools available to biobanks in a reference toolbox (BIBBOX) that are use-case driven. In the BiobankApps tool catalogue, both commercial and open source software solutions related to the biobanking domain are included, classified and evaluated. The evaluation covers: 1) “user review” by an authenticated user 2) domain expert: quick analysis by BBMRI members and 3) domain expert: detailed analysis and test installation with real world data. The evaluation is paired with a survey across the more “advanced” (from a technology perspective) biobanks to investigate what tools are currently used and summarises known benefits/drawbacks of the respective packages. In the second step we recommend tools for specific use cases, and install, configure and connect these in the BIBBOX framework. This service also builds on the existing work in the United Kingdom in seeking to establish the motivations for different stakeholders to become involved and therefore assisting in prioritising the use-cases based on the level of need and support within the research community. All tools associated to a use-case are available as BIBBOX applications (technically this is achieved by docker containers), which are integrated in the BIBBOX framework with central identification and user management. In future work we plan to share the acquired knowledge with other networks, develop an Application Programmable Interface (API) for the exchange of metadata with other tool catalogues and work on an ontology for the evaluation of biobank software.",2017,2021-06-05 21:12:01,89-95,1,7,Health Technol (Berl),,PubMed Central,PMID: 28344915 PMCID: PMC5346419,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5346419/,,,,PMC:Query2
58,10.1007/s13218-020-00686-3,32999532,PMC7497697,,,,"Schneider, Thomas; Šimkus, Mantas",Ontologies and Data Management: A Brief Survey,2020,Kunstliche Intelligenz,,"Information systems have to deal with an increasing amount of data that is heterogeneous, unstructured, or incomplete. In order to align and complete data, systems may rely on taxonomies and background knowledge that are provided in the form of an ontology. This survey gives an overview of research work on the use of ontologies for accessing incomplete and/or heterogeneous data.",2020,2021-06-05 21:10:08,329-353,3,34,Kunstliche Intell (Oldenbourg),Ontologies and Data Management,PubMed Central,PMID: 32999532 PMCID: PMC7497697,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7497697/,,,,PMC:Query2
59,10.1007/s13222-016-0245-2,29368755,PMC5750838,A,Neo4j,Neo4j,"Müller, Bernd; Poley, Christoph; Pössel, Jana; Hagelstein, Alexandra; Gübitz, Thomas",LIVIVO – the Vertical Search Engine for Life Sciences,2017,Datenbank-Spektrum,,"The explosive growth of literature and data in the life sciences challenges researchers to keep track of current advancements in their disciplines. Novel approaches in the life science like the One Health paradigm require integrated methodologies in order to link and connect heterogeneous information from databases and literature resources. Current publications in the life sciences are increasingly characterized by the employment of trans-disciplinary methodologies comprising molecular and cell biology, genetics, genomic, epigenomic, transcriptional and proteomic high throughput technologies with data from humans, plants, and animals. The literature search engine LIVIVO empowers retrieval functionality by incorporating various literature resources from medicine, health, environment, agriculture and nutrition. LIVIVO is developed in-house by ZB MED – Information Centre for Life Sciences. It provides a user-friendly and usability-tested search interface with a corpus of 55 Million citations derived from 50 databases. Standardized application programming interfaces are available for data export and high throughput retrieval. The search functions allow for semantic retrieval with filtering options based on life science entities. The service oriented architecture of LIVIVO uses four different implementation layers to deliver search services. A Knowledge Environment is developed by ZB MED to deal with the heterogeneity of data as an integrative approach to model, store, and link semantic concepts within literature resources and databases. Future work will focus on the exploitation of life science ontologies and on the employment of NLP technologies in order to improve query expansion, filters in faceted search, and concept based relevancy rankings in LIVIVO.",2017,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:37:08,29-34,1,17,Datenbank Spektrum,,PubMed Central,PMID: 29368755 PMCID: PMC5750838,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5750838/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
60,10.1007/s13222-020-00359-3,33132802,PMC7586412,A,Neo4j,Neo4j,,News,2020,Datenbank-Spektrum,,,2020-10-26,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36,1-4,,,Datenbank Spektrum,,PubMed Central,PMID: 33132802 PMCID: PMC7586412,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7586412/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
61,10.1007/s13222-021-00365-z,33519333,PMC7822585,,,,"Dittrich, Jens; Maltry, Marcel",Database (Lecture) Streams on the Cloud,2021,Datenbank-Spektrum,,"This is an experience report on teaching the undergrad lecture Big Data Engineering at Saarland University in summer term 2020 online. We describe our teaching philosophy, the tools used, what worked and what did not work. As we received extremely positive feedback from the students, we will continue to use the same teaching model for other lectures in the future.",2021-01-22,2021-06-05 21:09:36,1-8,,,Datenbank Spektrum,,PubMed Central,PMID: 33519333 PMCID: PMC7822585,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7822585/,,,,PMC:Query2
62,10.1007/s13222-021-00369-9,33654483,PMC7905979,A,Neo4j; COVID19,Neo4j; COVID19,,News,2021,Datenbank-Spektrum,,,2021-02-25,2021-06-05 20:35:57; 2021-06-05 21:35:36; 2021-06-05 20:54:31; 2021-06-05 21:09:36,1-4,,,Datenbank Spektrum,,PubMed Central,PMID: 33654483 PMCID: PMC7905979,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7905979/,,Neo4j; COVID19,Neo4j; COVID19,PMC:Query3; PMC:Neo4j; PMC:COVID19; PMC:Query2
63,10.1007/s13755-020-00130-8,33680447,PMC7910781,A,GraphDB; COVID19,GraphDB; COVID19,"Huang, Zhisheng; Hu, Qing; Liao, Mingqun; Miao, Cong; Wang, Chengyi; Liu, Guanghua",Knowledge Graphs of Kawasaki Disease,2021,Health Information Science and Systems,,"Kawasaki Disease is a vasculitis syndrome that is extremely harmful to children. Kawasaki Disease can cause severe symptoms of ischemic heart disease or develop into ischemic heart disease, leading to death in children. Researchers and clinicians need to analyze various knowledge and data resources to explore aspects of Kawasaki Disease. Knowledge Graphs have become an important AI approach to integrating various types of complex knowledge and data resources. In this paper, we present an approach for the construction of Knowledge Graphs of Kawasaki Disease. It integrates a wide range of knowledge resources related to Kawasaki Disease, including clinical guidelines, clinical trials, drug knowledge bases, medical literature, and others. It provides a basic integration foundation of knowledge and data concerning Kawasaki Disease for clinical study. In this paper, we will show that this disease-specific Knowledge Graphs are useful for exploring various aspects of Kawasaki Disease.",2021-02-27,2021-06-05 21:35:36; 2021-06-06 06:54:16; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,1,9,Health Inf Sci Syst,,PubMed Central,PMID: 33680447 PMCID: PMC7910781,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7910781/,,GraphDB; COVID19,GraphDB; COVID19,PMC:Query3; PMC:COVID19; PMC:Query2; PMC:GraphDB
64,10.1007/s13755-020-0102-4,32175080,PMC7046853,A,,,"Li, Xin; Liu, Haoyang; Zhao, Xu; Zhang, Guigang; Xing, Chunxiao",Automatic approach for constructing a knowledge graph of knee osteoarthritis in Chinese,2020,Health Information Science and Systems,,"In this study, a medical knowledge graph is constructed from the electronic medical record text of knee osteoarthritis patients to support intelligent medical applications such as knowledge retrieval and decision support, and to promote the sharing of medical resources. After constructing the domain ontology of knee osteoarthritis and manually labeling, we trained a machine learning model to automatically perform entity recognition and entity relation extraction, and then used a graph database to construct the knowledge graph of knee osteoarthritis. The experiment proves that the knowledge graph is comprehensive and reliable, and the knowledge graph construction method proposed in this study is effective.",2020-12,2021-06-05 21:06:22,12,1,8,Health Inf Sci Syst,,PubMed,PMID: 32175080 PMCID: PMC7046853,http://www.ncbi.nlm.nih.gov/pubmed/32175080,Electronic medical record; Entity recognition; Entity relation extraction; Knee osteoarthritis; Knowledge graph,,,PubMed:Query2
65,10.1007/s40708-015-0023-1,27747563,PMC4737668,,,,"Cao, Bokai; Kong, Xiangnan; Zhang, Jingyuan; Yu, Philip S.; Ragin, Ann B.",Identifying HIV-induced subgraph patterns in brain networks with side information,2015,Brain Informatics,,"Investigating brain connectivity networks for neurological disorder identification has attracted great interest in recent years, most of which focus on the graph representation alone. However, in addition to brain networks derived from the neuroimaging data, hundreds of clinical, immunologic, serologic, and cognitive measures may also be documented for each subject. These measures compose multiple side views encoding a tremendous amount of supplemental information for diagnostic purposes, yet are often ignored. In this paper, we study the problem of subgraph selection from brain networks with side information guidance and propose a novel solution to find an optimal set of subgraph patterns for graph classification by exploring a plurality of side views. We derive a feature evaluation criterion, named gSide, to estimate the usefulness of subgraph patterns based upon side views. Then we develop a branch-and-bound algorithm, called gMSV, to efficiently search for optimal subgraph patterns by integrating the subgraph mining process and the procedure of discriminative feature selection. Empirical studies on graph classification tasks for neurological disorders using brain networks demonstrate that subgraph patterns selected by the multi-side-view-guided subgraph selection approach can effectively boost graph classification performances and are relevant to disease diagnosis.",2015-11-16,2021-06-05 21:12:40,211-223,4,2,Brain Inform,,PubMed Central,PMID: 27747563 PMCID: PMC4737668,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4737668/,,,,PMC:Query2
66,10.1007/s41109-016-0011-2,30533501,PMC6245199,,,,"Schiller, Benjamin; Deusser, Clemens; Castrillon, Jeronimo; Strufe, Thorsten",Compile- and run-time approaches for the selection of efficient data structures for dynamic graph analysis,2016,Applied Network Science,,"Graphs are used to model a wide range of systems from different disciplines including social network analysis, biology, and big data processing. When analyzing these constantly changing dynamic graphs at a high frequency, performance is the main concern. Depending on the graph size and structure, update frequency, and read accesses of the analysis, the use of different data structures can yield great performance variations. Even for expert programmers, it is not always obvious, which data structure is the best choice for a given scenario., In previous work, we presented an approach for handling the selection of the most efficient data structures automatically using a compile-time approach well-suited for constant workloads., We extend this work with a measurement study of seven data structures and use the results to fit actual cost estimation functions. In addition, we evaluate our approach for the computations of seven different graph metrics. In analyses of real-world dynamic graphs with a constant workload, our approach achieves a speedup of up to 5.4× compared to basic data structure configurations., Such a compile-time based approach cannot yield optimal results when the behavior of the system changes later and the workload becomes non-constant. To close this gap we present a run-time approach which provides live profiling and facilitates automatic exchanges of data structures during execution. We analyze the performance of this approach using an artificial, non-constant workload where our approach achieves speedups of up to 7.3× compared to basic configurations.",2016,2021-06-05 21:12:01,,1,1,Appl Netw Sci,,PubMed Central,PMID: 30533501 PMCID: PMC6245199,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6245199/,,,,PMC:Query2
67,10.1007/s41109-016-0015-y,30533503,PMC6245218,A,Neo4j,Neo4j,"Kuzmin, Konstantin; Lu, Xiaoyan; Mukherjee, Partha Sarathi; Zhuang, Juntao; Gaiteri, Chris; Szymanski, Boleslaw K.",Supporting novel biomedical research via multilayer collaboration networks,2016,Applied Network Science,,"The value of research containing novel combinations of molecules can be seen in many innovative and award-winning research programs. Despite calls to use innovative approaches to address common diseases, an increasing majority of research funding goes toward ""safe"" incremental research. Counteracting this trend by nurturing novel and potentially transformative scientific research is challenging and it must be supported in competition with established research programs. Therefore, we propose a tool that helps to resolve the tension between safe/fundable research vs. high-risk/potentially transformational research. It does this by identifying hidden overlapping interests around novel molecular research topics. Specifically, it identifies paths of molecular interactions that connect research topics and hypotheses that would not typically be associated, as the basis for scientific collaboration. Because these collaborations are related to the scientists' present trajectory, they are low risk and can be initiated rapidly. Unlike most incremental steps, these collaborations have the potential for leaps in understanding, as they reposition research for novel disease applications. We demonstrate the use of this tool to identify scientists who could contribute to understanding the cellular role of genes with novel associations with Alzheimer's disease, which have not been thoroughly characterized, in part due to the funding emphasis on established research.; The value of research containing novel combinations of molecules can be seen in many innovative and award-winning research programs. Despite calls to use innovative approaches to address common diseases, an increasing majority of research funding goes toward “safe” incremental research. Counteracting this trend by nurturing novel and potentially transformative scientific research is challenging and it must be supported in competition with established research programs. Therefore, we propose a tool that helps to resolve the tension between safe/fundable research vs. high-risk/potentially transformational research. It does this by identifying hidden overlapping interests around novel molecular research topics. Specifically, it identifies paths of molecular interactions that connect research topics and hypotheses that would not typically be associated, as the basis for scientific collaboration. Because these collaborations are related to the scientists’ present trajectory, they are low risk and can be initiated rapidly. Unlike most incremental steps, these collaborations have the potential for leaps in understanding, as they reposition research for novel disease applications. We demonstrate the use of this tool to identify scientists who could contribute to understanding the cellular role of genes with novel associations with Alzheimer’s disease, which have not been thoroughly characterized, in part due to the funding emphasis on established research.",2016,2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 20:37:08; 2021-06-05 21:12:01; 2021-06-05 20:55:40; 2021-06-05 21:24:28,11,1,1,Appl Netw Sci,,PubMed; PubMed Central,PMID: 30533503 PMCID: PMC6245218,http://www.ncbi.nlm.nih.gov/pubmed/30533503; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6245218/,Coauthorship networks; Collaboration networks; Disruptive science; Heterogeneous multilayer networks; Molecular networks; Neo4j; Network analysis; Personalized PageRank; PubMed,Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
68,10.1007/s41109-017-0035-2,30443578,PMC6214274,,,,"Renoust, Benjamin; Claver, Vivek; Baffier, Jean-François",Multiplex flows in citation networks,2017,Applied Network Science,,"Knowledge is created and transmitted through generations, and innovation is often seen as a process generated from collective intelligence. There is rising interest in studying how innovation emerges from the blending of accumulated knowledge, and from which path an innovation mostly inherits. A citation network can be seen as a perfect example of one generative process leading to innovation. However, the impact and influence of scientific publication are always difficult to capture and measure. We offer a new take on investigating how the knowledge circulates and is transmitted, inspired by the notion of “stream of knowledge”. We propose to look at this question under the lens of flows in directed acyclic graphs (DAGs). In this framework inspired by the work of Strahler, we can also account for other well known measures of influence such as the h-index. We propose then to analyze flows of influence in a citation networks as an ascending flow. From this point on, we can take a finer look at the diffusion of knowledge through the lens of a multiplex network. In this network, each citation of a specific work constitutes one layer of interaction. Within our framework, we design three measures of multiplex flows in DAGs, namely the aggregated, sum and selective flow, to better understand how citations are influenced. We conduct our experiments with the arXiv HEP-Th dataset, and find insights through the visualization of these multiplex networks.",2017,2021-06-05 21:12:01,,1,2,Appl Netw Sci,,PubMed Central,PMID: 30443578 PMCID: PMC6214274,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6214274/,,,,PMC:Query2
69,10.1016/B978-0-12-388408-4.00002-2,23195119,PMC4222244,A,AllegroGraph; OrientDB; Neo4j,AllegroGraph; OrientDB; Neo4j,"Baker, Erich J.",Biological Databases for Behavioral Neurobiology,2012,International review of neurobiology,,"Databases are, at their core, abstractions of data and their intentionally derived relationships. They serve as a central organizing metaphor and repository, supporting or augmenting nearly all bioinformatics. Behavioral domains provide a unique stage for contemporary databases, as research in this area spans diverse data types, locations, and data relationships. This chapter provides foundational information on the diversity and prevalence of databases, how data structures support the various needs of behavioral neuroscience analysis and interpretation. The focus is on the classes of databases, data curation, and advanced applications in bioinformatics using examples largely drawn from research efforts in behavioral neuroscience.",2012,2021-06-05 21:13:27; 2021-06-06 06:49:06; 2021-06-06 06:38:41; 2021-06-05 20:37:08; 2021-06-05 20:56:20,19-38,,103,Int Rev Neurobiol,,PubMed Central,PMID: 23195119 PMCID: PMC4222244,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4222244/,,AllegroGraph; OrientDB; Neo4j,AllegroGraph; OrientDB; Neo4j,PMC:AllegroGraph; PMC:Query2; PMC:OrientDB; PMC:Query3; PMC:Neo4j
70,10.1016/B978-0-12-803206-0.00001-8,,PMC7149322,,,,"Sittig, Dean F.",Category Definitions,2017,Clinical Informatics Literacy,,,2017,2021-06-05 21:12:01,1-170,,,Clinical Informatics Literacy,,PubMed Central,PMID:  PMCID: PMC7149322,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7149322/,,,,PMC:Query2
71,10.1016/B978-0-12-824536-1.00011-3,,PMC8137888,,,,"Acheme, Ijegwa David; Vincent, Olufunke Rebecca",Machine-learning models for predicting survivability in COVID-19 patients,2021,Data Science for COVID-19,,"COVID-19 is a disease currently ravaging the world, bringing unprecedented health and economic challenges to several nations. There are presently close to five million reported cases in over 200 countries with fatalities numbering over 300,000 persons. This study presents machine-learning models for the prediction and visualization of the significant factors that determine the survivability of COVID-19 patients. This study develops prediction models using a decision tree, logistic regression (LR), gradient boosting, and LR algorithms to identify the significant factors and predict the survivability of COVID-19 patients. The results of the simulation showed that the LR model had the lowest prediction accuracy. The other three showed over 95% correct accuracy and indicated that the essential factors in determining patients' survivability were underlying health conditions and age. The findings of this study agreed with the medical claims that patients with underlying health challenges and those advanced in age are liable to have complications; hence, providing a research-based credence to this belief. This proposed model thus serves as a decision support system for the management of COVID-19 patients, as well as predicts a patient’s chances of survival at the first presentation at the hospitals.",2021,2021-06-05 21:09:36,317-336,,,Data Science for COVID-19,,PubMed Central,PMID:  PMCID: PMC8137888,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8137888/,,,,PMC:Query2
72,10.1016/j.cell.2016.05.069,27372738,PMC4967013,,,,"Zhang, Hui; Liu, Tao; Zhang, Zhen; Payne, Samuel H; Zhang, Bai; McDermott, Jason E; Zhou, Jian-Ying; Petyuk, Vladislav A; Chen, Li; Ray, Debjit; Sun, Shisheng; Yang, Feng; Chen, Lijun; Wang, Jing; Shah, Punit; Cha, Seong Won; Aiyetan, Paul; Woo, Sunghee; Tian, Yuan; Gritsenko, Marina A; Clauss, Therese R; Choi, Caitlin; Monroe, Matthew E; Thomas, Stefani; Nie, Song; Wu, Chaochao; Moore, Ronald J; Yu, Kun-Hsing; Tabb, David L; Fenyö, David; Bafna, Vineet; Wang, Yue; Rodriguez, Henry; Boja, Emily S; Hiltke, Tara; Rivers, Robert C; Sokoll, Lori; Zhu, Heng; Shih, Ie-Ming; Cope, Leslie; Pandey, Akhilesh; Zhang, Bing; Snyder, Michael P; Levine, Douglas A; Smith, Richard D; Chan, Daniel W; Rodland, Karin D",Integrated proteogenomic characterization of human high grade serous ovarian cancer,2016,Cell,,"To provide a detailed analysis of the molecular components and underlying mechanisms associated with ovarian cancer, we performed a comprehensive mass spectrometry-based proteomic characterization of 174 ovarian tumors previously analyzed by The Cancer Genome Atlas (TCGA), of which 169 were high-grade serous carcinomas (HGSC). Integrating our proteomic measurements with the genomic data yielded a number of insights into disease such as how different copy number alternations influence the proteome, the proteins associated with chromosomal instability, the sets of signaling pathways that diverse genome rearrangements converge on, as well as the ones most associated with short overall survival. Specific protein acetylations associated with homologous recombination deficiency suggest a potential means for stratifying patients for therapy. In addition to providing a valuable resource, these findings provide a view of how the somatic genome drives the cancer proteome and associations between protein and post-translational modification levels and clinical outcomes in HGSC.,",2016-07-28,2021-06-05 21:12:01,755-765,3,166,Cell,,PubMed Central,PMID: 27372738 PMCID: PMC4967013,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4967013/,,,,PMC:Query2
73,10.1016/j.celrep.2019.09.017,31618642,PMC6899527,A,Neo4j,Neo4j,"Lobentanzer, Sebastian; Hanin, Geula; Klein, Jochen; Soreq, Hermona",Integrative Transcriptomics Reveals Sexually Dimorphic Control of the Cholinergic/Neurokine Interface in Schizophrenia and Bipolar Disorder,2019,Cell Reports,,"RNA sequencing analyses are often limited to identifying lowest p value transcripts, which does not address polygenic phenomena. To overcome this limitation, we developed an integrative approach that combines large-scale transcriptomic meta-analysis of patient brain tissues with single-cell sequencing data of CNS neurons, short RNA sequencing of human male- and female-originating cell lines, and connectomics of transcription factor and microRNA interactions with perturbed transcripts. We used this pipeline to analyze cortical transcripts of schizophrenia and bipolar disorder patients. Although these pathologies show massive transcriptional parallels, their clinically well-known sexual dimorphisms remain unexplained. Our method reveals the differences between afflicted men and women and identifies disease-affected pathways of cholinergic transmission and gp130-family neurokine controllers of immune function interlinked by microRNAs. This approach may open additional perspectives for seeking biomarkers and therapeutic targets in other transmitter systems and diseases.,                                        •               Single-cell transcriptomes reveal a unique profile of cortical cholinergic neurons                                         •               Female- and male-derived cells show distinct neurokine-induced miRNA responses                                         •               Differentially enriched microRNA families constitute a self-organizing network                                         •               Integrative analysis identifies mir-10/mir-199 regulators of cholinergic function                                 , Lobentanzer et al. show how bioinformatically supported high-throughput techniques such as short RNA sequencing can bridge the gap between traditional molecular interaction studies and purely bioinformatic prediction paradigms in an example focused on disentangling the sexual dimorphism in microRNA regulation of the cholinergic/neurokine interface in mental disorders.",2019-10-15,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,764-777.e5,3,29,Cell Rep,,PubMed Central,PMID: 31618642 PMCID: PMC6899527,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6899527/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
74,10.1016/j.cmpb.2018.08.007,30337067,PMC6196742,A,Neo4j,Neo4j,"Chen, Luyao; Aziz, Md Momin; Mohammed, Noman; Jiang, Xiaoqian; Chen, Luyao; Al Aziz, Md Momin; Mohammed, Noman; Jiang, Xiaoqian",Secure Large-Scale Genome Data Storage and Query; Secure large-scale genome data storage and query,2018,Computer Methods and Programs in Biomedicine; Computer methods and programs in biomedicine,,"Background and Objective Cloud computing plays a vital role in big data science with its scalable and cost-efficient architecture. Largescale genome data storage and computations would benefit from using these latest cloud computing infrastructures, to save cost and speedup discoveries. However, due to the privacy and security concerns, data owners are often disinclined to put sensitive data in a public cloud environment without enforcing some protective measures. An ideal solution is to develop secure genome database that supports encrypted data deposition and query. Methods Nevertheless, it is a challenging task to make such a system fast and scalable enough to handle real-world demands providing data security as well. In this paper, we propose a novel, secure mechanism to support secure count queries on an open source graph database (Neo4j) and evaluated the performance on a realworld dataset of around 735,317 Single Nucleotide Polymorphisms (SNPs). In particular, we propose a new tree indexing method that offers constant time complexity (proportion to the tree depth), which was the bottleneck of existing approaches. Results The proposed method significantly improves the runtime of query execution compared to the existing techniques. It takes less than one minute to execute an arbitrary count query on a dataset of 212 GB, while the best-known algorithm takes around 7 minutes. Conclusions The outlined framework and experimental results show the applicability of utilizing graph database for securely storing large-scale genome data in untrusted environment. Furthermore, the crypto-system and security assumptions underlined are much suitable for such use cases which be generalized in future work.; BACKGROUND AND OBJECTIVE: Cloud computing plays a vital role in big data science with its scalable and cost-efficient architecture. Large-scale genome data storage and computations would benefit from using these latest cloud computing infrastructures, to save cost and speedup discoveries. However, due to the privacy and security concerns, data owners are often disinclined to put sensitive data in a public cloud environment without enforcing some protective measures. An ideal solution is to develop secure genome database that supports encrypted data deposition and query. METHODS: Nevertheless, it is a challenging task to make such a system fast and scalable enough to handle real-world demands providing data security as well. In this paper, we propose a novel, secure mechanism to support secure count queries on an open source graph database (Neo4j) and evaluated the performance on a real-world dataset of around 735,317 Single Nucleotide Polymorphisms (SNPs). In particular, we propose a new tree indexing method that offers constant time complexity (proportion to the tree depth), which was the bottleneck of existing approaches. RESULTS: The proposed method significantly improves the runtime of query execution compared to the existing techniques. It takes less than one minute to execute an arbitrary count query on a dataset of 212  GB, while the best-known algorithm takes around 7  min. CONCLUSIONS: The outlined framework and experimental results show the applicability of utilizing graph database for securely storing large-scale genome data in untrusted environment. Furthermore, the crypto-system and security assumptions underlined are much suitable for such use cases which be generalized in future work.",2018-10,2021-06-05 21:11:16; 2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 20:55:01; 2021-06-05 21:24:28; 2021-06-05 20:36:32,129-137,,165,Comput Methods Programs Biomed,,PubMed; PubMed Central,PMID: 30337067 PMCID: PMC6196742,http://www.ncbi.nlm.nih.gov/pubmed/30337067; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6196742/,"Big Data; Cloud Computing; Computer Security; Databases, Genetic; Genome data storage Neo4j; Genome, Human; Graph database; Homomorphic encryption; Humans; Information Storage and Retrieval; Polymorphism, Single Nucleotide; Search Engine; Secure computation on genome data; Secure genome data storage",Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
75,10.1016/j.csbj.2018.08.002,30181840,PMC6120721,,,,"Kleinaki, Athina-Styliani; Mytis-Gkometh, Petros; Drosatos, George; Efraimidis, Pavlos S.; Kaldoudi, Eleni",A Blockchain-Based Notarization Service for Biomedical Knowledge Retrieval,2018,Computational and Structural Biotechnology Journal,,"Biomedical research and clinical decision depend increasingly on scientific evidence realized by a number of authoritative databases, mostly public and continually enriched via peer scientific contributions. Given the dynamic nature of biomedical evidence data and their usage in the sensitive domain of biomedical science, it is important to ensure retrieved data integrity and non-repudiation. In this work, we present a blockchain-based notarization service that uses smart digital contracts to seal a biomedical database query and the respective results. The goal is to ensure that retrieved data cannot be modified after retrieval and that the database cannot validly deny that the particular data has been provided as a result of a specific query. Biomedical evidence data versioning is also supported. The feasibility of the proposed notarization approach is demonstrated using a real blockchain infrastructure and is tested on two different biomedical evidence databases: a publicly available medical risk factor reference repository and on the PubMed database of biomedical literature references and abstracts.",2018-08-17,2021-06-05 21:11:16,288-297,,16,Comput Struct Biotechnol J,,PubMed Central,PMID: 30181840 PMCID: PMC6120721,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6120721/,,,,PMC:Query2
76,10.1016/j.csbj.2019.07.008,31452858,PMC6700205,A,OrientDB,OrientDB,"Hendling, Michaela; Barišić, Ivan",In-silico Design of DNA Oligonucleotides: Challenges and Approaches,2019,Computational and Structural Biotechnology Journal,,"DNA oligonucleotides are essential components of a high number of technologies in molecular biology. The key event of each oligonucleotide-based assay is the specific binding between oligonucleotides and their target DNA. However, single-stranded DNA molecules also tend to bind to unintended targets or themselves. The probability of such unspecific binding increases with the complexity of an assay. Therefore, accurate data management and design workflows are necessary to optimize the in-silico design of primers and probes. Important considerations concerning computational infrastructure and run time need to be made for both data management and the design process. Data retrieval, data updates, storage, filtering and analysis are the main parts of a sequence data management system. Each part needs to be well-implemented as the resulting sequences form the basis for the oligonucleotide design. Important key features, such as the oligonucleotide length, melting temperature, secondary structures and primer dimer formation, as well as the specificity, should be considered for the in-silico selection of oligonucleotides. The development of an efficient oligonucleotide design workflow demands the right balance between the precision of the applied computer models, the general expenditure of time, and computational workload., This paper gives an overview of important parameters during the design process, starting from the data retrieval, up to the design parameters for optimized oligonucleotide design.,                         Unlabelled Image",2019-07-29,2021-06-06 06:49:06; 2021-06-05 20:55:01; 2021-06-05 21:10:37,1056-1065,,17,Comput Struct Biotechnol J,In-silico Design of DNA Oligonucleotides,PubMed Central,PMID: 31452858 PMCID: PMC6700205,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6700205/,,OrientDB,OrientDB,PMC:Query3; PMC:Query2; PMC:OrientDB
77,10.1016/j.csbj.2021.01.037,33680352,PMC7892627,,,,"Ruiz-Saavedra, Sergio; García-González, Herminio; Arboleya, Silvia; Salazar, Nuria; Emilio Labra-Gayo, José; Díaz, Irene; Gueimonde, Miguel; González, Sonia; de los Reyes-Gavilán, Clara G.",Intestinal microbiota alterations by dietary exposure to chemicals from food cooking and processing. Application of data science for risk prediction,2021,Computational and Structural Biotechnology Journal,,"Diet is one of the main sources of exposure to toxic chemicals with carcinogenic potential, some of which are generated during food processing, depending on the type of food (primarily meat, fish, bread and potatoes), cooking methods and temperature. Although demonstrated in animal models at high doses, an unequivocal link between dietary exposure to these compounds with disease has not been proven in humans. A major difficulty in assessing the actual intake of these toxic compounds is the lack of standardised and harmonised protocols for collecting and analysing dietary information. The intestinal microbiota (IM) has a great influence on health and is altered in some diseases such as colorectal cancer (CRC). Diet influences the composition and activity of the IM, and the net exposure to genotoxicity of potential dietary carcinogens in the gut depends on the interaction among these compounds, IM and diet. This review analyses critically the difficulties and challenges in the study of interactions among these three actors on the onset of CRC. Machine Learning (ML) of data obtained in subclinical and precancerous stages would help to establish risk thresholds for the intake of toxic compounds generated during food processing as related to diet and IM profiles, whereas Semantic Web could improve data accessibility and usability from different studies, as well as helping to elucidate novel interactions among those chemicals, IM and diet.",2021-01-29,2021-06-05 21:09:36,1081-1091,,19,Comput Struct Biotechnol J,,PubMed Central,PMID: 33680352 PMCID: PMC7892627,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7892627/,,,,PMC:Query2
78,10.1016/j.dam.2015.07.017,27034526,PMC4809059,,,,"Hoppe, Travis; Petrone, Anna",Integer sequence discovery from small graphs,2016,"Discrete Applied Mathematics (Amsterdam, Netherlands: 1988); Discrete applied mathematics (Amsterdam, Netherlands : 1988)",,"We have exhaustively enumerated all simple, connected graphs of a finite order and have computed a selection of invariants over this set. Integer sequences were constructed from these invariants and checked against the Online Encyclopedia of Integer Sequences (OEIS). 141 new sequences were added and six sequences were extended. From the graph database, we were able to programmatically suggest relationships among the invariants. It will be shown that we can readily visualize any sequence of graphs with a given criteria. The code has been released as an open-source framework for further analysis and the database was constructed to be extensible to invariants not considered in this work.",2016-03-11,2021-06-05 21:06:22; 2021-06-05 21:12:40,172-181,,201,Discrete Appl Math,,PubMed; PubMed Central,PMID: 27034526 PMCID: PMC4809059,http://www.ncbi.nlm.nih.gov/pubmed/27034526; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4809059/,,,,PubMed:Query2; PMC:Query2
79,10.1016/j.dib.2017.09.032,29214195,PMC5712049,,,,"Useche, Sergio; Cendales, Boris; Gómez, Viviola","Work stress, fatigue and risk behaviors at the wheel: Data to assess the association between psychosocial work factors and risky driving on Bus Rapid Transit drivers",2017,Data in Brief,,"This Data in Brief (DiB) article presents a hierarchical multiple linear regression model that examine the associations between psychosocial work factors and risk behaviors at the wheel in Bus Rapid Transit (BRT) drivers (n=524). The data were collected using a structured self-administrable questionnaire made of measurements of wok stress (job strain and effort- reward imbalance), fatigue (need for recovery and chronic fatigue), psychological distress and demographics (professional driving experience, hours driven per day and days working per week). The data contains 4 parts: descriptive statistics, bivariate correlations between the study variables and a regression model predicting risk behaviors at the wheel and the entire study dataset. For further information, it is convenient to read the full article entitled “Stress-related Psychosocial Factors at Work, Fatigue, and Risky Driving Behavior in Bus Rapid Transport (BRT) Drivers”, published in Accident Analysis & Prevention.",2017-09-25,2021-06-05 21:12:01,335-339,,15,Data Brief,"Work stress, fatigue and risk behaviors at the wheel",PubMed Central,PMID: 29214195 PMCID: PMC5712049,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5712049/,,,,PMC:Query2
80,10.1016/j.dib.2018.05.036,29892649,PMC5993012,,,,"Useche, Sergio; Montoro, Luis; Cendales, Boris; Gómez, Viviola","Job strain in public transport drivers: Data to assess the relationship between demand-control model indicators, traffic accidents and sanctions",2018,Data in Brief,,"This Data in Brief (DiB) article examines the association between the Job Demand-Control (JDC) model of stress and traffic safety outcomes (accidents and sanctions) in public transport drivers (n = 780). The data was collected using a structured self-administrable questionnaire composed of measurements of work stress (Job Content Questionnaire), and demographics (professional driving experience, hours and days working/driving per week). The data contains 4 parts: descriptive statistics, bivariate correlations between the study variables, analysis of variance (ANOVA) and Post-Hoc comparisons between drivers classified different quadrants of the JDC model. For further information, it is convenient to read the full article entitled “Working conditions, job strain and traffic safety among three groups of public transport drivers”, published in Safety and Health at Work (SHAW)  (Useche et al., 2018).",2018-05-18,2021-06-05 21:11:16,293-298,,19,Data Brief,Job strain in public transport drivers,PubMed Central,PMID: 29892649 PMCID: PMC5993012,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5993012/,,,,PMC:Query2
81,10.1016/j.dib.2018.10.150,30596133,PMC6307338,A,Virtuoso,Virtuoso,"Ljungberg, M. Cecilia; Sadi, Mayce; Wang, Yunguan; Aronow, Bruce J.; Xu, Yan; Kao, Rong J.; Liu, Ying; Gaddis, Nathan; Ardini-Poleske, Maryanne E.; Umrod, Tipparat; Ambalavanan, Namasivayam; Nicola, Teodora; Kaminski, Naftali; Ahangari, Farida; Sontag, Ryan; Corley, Richard A.; Ansong, Charles; Carson, James P.",Spatial distribution of marker gene activity in the mouse lung during alveolarization,2018,Data in Brief,,"This data is a curated collection of visual images of gene expression patterns from the pre- and post-natal mouse lung, accompanied by associated mRNA probe sequences and RNA-Seq expression profiles. Mammalian lungs undergo significant growth and cellular differentiation before and after the transition to breathing air. Documenting normal lung development is an important step in understanding abnormal lung development, as well as the challenges faced during a preterm birth. Images in this dataset indicate the spatial distribution of mRNA transcripts for over 500 different genes that are active during lung development, as initially determined via RNA-Seq. Images were systematically acquired using high-throughput in situ hybridization with non-radioactive digoxigenin-labeled mRNA probes across mouse lungs from developmental time points E16.5, E18.5, P7, and P28. The dataset was produced as part of The Molecular Atlas of Lung Development Program (LungMAP) and is hosted at https://lungmap.net. This manuscript describes the nature of the data and the protocols for generating the dataset.",2018-11-03,2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:59:14,365-372,,22,Data Brief,,PubMed Central,PMID: 30596133 PMCID: PMC6307338,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6307338/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
82,10.1016/j.dib.2018.12.066,30671509,PMC6327100,,,,"Useche, Sergio A.; Alonso, Francisco; Montoro, Luis; Tomas, José M.","When age means safety: Data to assess trends and differences on rule knowledge, risk perception, aberrant and positive road behaviors, and traffic crashes of cyclists",2018,Data in Brief,,"This data article examines the association between age, knowledge of traffic rules, risk perception, risky and positive behaviors on the road and traffic safety outcomes of cyclists. The data was collected using a structured self-administrable and online-based questionnaire, applied to a full sample of 1064 cyclists. The data contains 4 parts: descriptive statistics; graphical trends for each study variable according to age; Post-Hoc (Tukey-HSD) comparisons between cyclists classified in the different age groups; and, finally, the dataset for further explorations in this regard. For further information, it is convenient to read the full article entitled “Explaining Self-Reported Traffic Crashes of Cyclists: An Empirical Study based on Age and Road Risky Behaviors” (Useche et al., 2019) [1].",2018-12-23,2021-06-05 21:10:37,627-634,,22,Data Brief,When age means safety,PubMed Central,PMID: 30671509 PMCID: PMC6327100,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6327100/,,,,PMC:Query2
83,10.1016/j.dib.2019.104005,31198827,PMC6557728,,,,"Rath, Michael; Mäder, Patrick","The SEOSS 33 dataset — Requirements, bug reports, code history, and trace links for entire projects",2019,Data in Brief,,"This paper provides a systematically retrieved dataset consisting of 33 open-source software projects containing a large number of typed artifacts and trace links between them. The artifacts stem from the projects' issue tracking system and source version control system to enable their joint analysis. Enriched with additional metadata, such as time stamps, release versions, component information, and developer comments, the dataset is highly suitable for empirical research, e.g., in requirements and software traceability analysis, software evolution, bug and feature localization, and stakeholder collaboration. It can stimulate new research directions, facilitate the replication of existing studies, and act as benchmark for the comparison of competing approaches. The data is hosted on Harvard Dataverse using DOI 10.7910/DVN/PDDZ4Q accessible via https://bit.ly/2wukCHc.",2019-05-24,2021-06-05 21:10:37,,,25,Data Brief,,PubMed Central,PMID: 31198827 PMCID: PMC6557728,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6557728/,,,,PMC:Query2
84,10.1016/j.eswa.2019.113046,32288329,PMC7126664,,,,"Bashir, Shariq",An efficient pattern growth approach for mining fault tolerant frequent itemsets,2020,Expert Systems with Applications,,"•               Mining fault tolerant (FT) frequent itemsets are computationally expensive.                                         •               Related algorithms are Apriori-like candidate generation-and-test approaches.                                         •               Apriori-like algorithms generate exponential number of candidate itemsets.                                         •               We propose mining FT frequent itemsets using frequent pattern growth approach.                                         •               The proposed approach mines complete set of itemsets with less computational cost.                                 , Mining fault tolerant (FT) frequent itemsets from transactional databases are computationally more expensive than mining exact matching frequent itemsets. Previous algorithms mine FT frequent itemsets using Apriori heuristic. Apriori-like algorithms generate exponential number of candidate itemsets including the itemsets that do not exist in the database. These algorithms require multiple scans of database for counting the support of candidate FT itemsets. In this paper we present a novel algorithm, which mines FT frequent itemsets using frequent pattern growth approach (FT-PatternGrowth). FT-PatternGrowth adopts a divide-and-conquer technique and recursively projects transactional database into a set of smaller projected transactional databases and mines FT frequent itemsets in each projected database by exploring only locally frequent items. This mines the complete set of FT frequent itemsets and substantially reduces those candidate itemsets that do not exist in the database. FT-PatternGrowth stores the transactional database in a highly condensed much smaller data structure called frequent pattern tree (FP-tree). The support of candidate itemsets are counted directly from the FP-tree without scanning the original database multiple times. This improves the processing speed of algorithm. Our experiments on benchmark databases indicates mining FT frequent itemsets using FT-PatternGrowth is highly efficient than Apriori-like algorithms.",2020-04-01,2021-06-05 21:10:37,113046,,143,Expert Syst Appl,,PubMed Central,PMID: 32288329 PMCID: PMC7126664,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7126664/,,,,PMC:Query2
85,10.1016/j.future.2015.09.006,26688598,PMC4681010,A,Neo4j,Neo4j,"Chard, Kyle; Lidman, Mattias; McCollam, Brendan; Bryan, Josh; Ananthakrishnan, Rachana; Tuecke, Steven; Foster, Ian","Globus Nexus: A Platform-as-a-Service Provider of Research Identity, Profile, and Group Management",2016,Future generations computer systems : FGCS,,"Globus Nexus is a professionally hosted Platform-as-a-Service that provides identity, profile and group management functionality for the research community. Many collaborative e-Science applications need to manage large numbers of user identities, profiles, and groups. However, developing and maintaining such capabilities is often challenging given the complexity of modern security protocols and requirements for scalable, robust, and highly available implementations. By outsourcing this functionality to Globus Nexus, developers can leverage best-practice implementations without incurring development and operations overhead. Users benefit from enhanced capabilities such as identity federation, flexible profile management, and user-oriented group management. In this paper we present Globus Nexus, describe its capabilities and architecture, summarize how several e-Science applications leverage these capabilities, and present results that characterize its scalability, reliability, and availability.",2016-03-01,2021-06-05 20:55:40; 2021-06-05 21:12:40; 2021-06-05 20:37:08,571-583,,56,Future Gener Comput Syst,Globus Nexus,PubMed Central,PMID: 26688598 PMCID: PMC4681010,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4681010/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
86,10.1016/j.future.2020.09.030,33071400,PMC7546693,A,Neo4j; COVID19,Neo4j; COVID19,"Arafeh, Mohamad; Ceravolo, Paolo; Mourad, Azzam; Damiani, Ernesto; Bellini, Emanuele",Ontology based recommender system using social network data,2021,Future Generations Computer Systems,,"Online Social Network (OSN) is considered a key source of information for real-time decision making. However, several constraints lead to decreasing the amount of information that a researcher can have while increasing the time of social network mining procedures. In this context, this paper proposes a new framework for sampling Online Social Network (OSN). Domain knowledge is used to define tailored strategies that can decrease the budget and time required for mining while increasing the recall. An ontology supports our filtering layer in evaluating the relatedness of nodes. Our approach demonstrates that the same mechanism can be advanced to prompt recommendations to users. Our test cases and experimental results emphasize the importance of the strategy definition step in our social miner and the application of ontologies on the knowledge graph in the domain of recommendation analysis.,                                        •               Framework for sampling social network.                                         •               Tailored strategies to decrease the time and the cost of mining.                                         •               Scalable social network filters using Event Subscribers.                                         •               A graph-based recommender system using an improved Adamic Adar algorithm.",2021-02,2021-06-05 20:35:57; 2021-06-05 21:35:36; 2021-06-05 20:54:31; 2021-06-05 21:10:08,769-779,,115,Future Gener Comput Syst,,PubMed Central,PMID: 33071400 PMCID: PMC7546693,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7546693/,,Neo4j; COVID19,Neo4j; COVID19,PMC:Query3; PMC:Neo4j; PMC:COVID19; PMC:Query2
87,10.1016/j.ijpddr.2018.03.006,29649665,PMC6039303,A,Neo4j,Neo4j,"Geyer, Kathrin K.; Munshi, Sabrina E.; Vickers, Martin; Squance, Michael; Wilkinson, Toby J.; Berrar, Daniel; Chaparro, Cristian; Swain, Martin T.; Hoffmann, Karl F.","The anti-fecundity effect of 5-azacytidine (5-AzaC) on Schistosoma mansoni is linked to dis-regulated transcription, translation and stem cell activities",2018,International Journal for Parasitology: Drugs and Drug Resistance,,"Uncontrolled host immunological reactions directed against tissue-trapped eggs precipitate a potentially lethal, pathological cascade responsible for schistosomiasis. Blocking schistosome egg production, therefore, presents a strategy for simultaneously reducing immunopathology as well as limiting disease transmission in endemic or emerging areas. We recently demonstrated that the ribonucleoside analogue 5-azacytidine (5-AzaC) inhibited Schistosoma mansoni oviposition, egg maturation and ovarian development. While these anti-fecundity effects were associated with a loss of DNA methylation, other molecular processes affected by 5-AzaC were not examined at the time. By comparing the transcriptomes of 5-AzaC-treated females to controls, we provide evidence that this ribonucleoside analogue also modulates other crucial aspects of schistosome egg-laying biology. For example, S. mansoni gene products associated with amino acid-, carbohydrate-, fatty acid-, nucleotide- and tricarboxylic acid (TCA)- homeostasis are all dysregulated in 5-AzaC treated females. To validate the metabolic pathway most significantly affected by 5-AzaC, amino acid metabolism, nascent protein synthesis was subsequently quantified in adult schistosomes. Here, 5-AzaC inhibited this process by 68% ±16.7% (SEM) in male- and 81% ±4.8% (SEM) in female-schistosomes. Furthermore, the transcriptome data indicated that adult female stem cells were also affected by 5-AzaC. For instance, 40% of transcripts associated with proliferating schistosome cells were significantly down-regulated by 5-AzaC. This finding correlated with a considerable reduction (95%) in the number of 5-ethynyl-2′-deoxyuridine (EdU) positive cells found in 5-AzaC-treated females. In addition to protein coding genes, the effect that 5-AzaC had on repetitive element expression was also assessed. Here, 46 repeats were found differentially transcribed between 5-AzaC-treated and control females with long terminal repeat (LTR) and DNA transposon classes being amongst the most significant. This study demonstrates that the anti-fecundity activity of 5-AzaC affects more than just DNA methylation in schistosome parasites. Further characterisation of these processes may reveal novel targets for schistosomiasis control.,                         Image 1                                 ,                                        •               The ribonucleoside 5-azacytidine (5-AzaC) inhibits schistosome egg production.                                         •               5-AzaC modulates schistosome transcription and translation.                                         •               Schistosome stem cell proliferation and maintenance are affected by 5-AzaC.",2018-04-01,2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:36:32,213-222,2,8,Int J Parasitol Drugs Drug Resist,,PubMed Central,PMID: 29649665 PMCID: PMC6039303,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6039303/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
88,10.1016/j.is.2013.05.007,31523102,PMC4010299,,,,"Liptchinsky, Vitaliy; Khazankin, Roman; Schulte, Stefan; Satzger, Benjamin; Truong, Hong-Linh; Dustdar, Schahram",On modeling context-aware social collaboration processes,2014,Information Systems,,"Modeling collaboration processes is a challenging task. Existing modeling approaches are not capable of expressing the unpredictable, non-routine nature of human collaboration, which is influenced by the social context of involved collaborators. We propose a modeling approach which considers collaboration processes as the evolution of a network of collaborative documents along with a social network of collaborators. Our modeling approach, accompanied by a graphical notation and formalization, allows to capture the influence of complex social structures formed by collaborators, and therefore facilitates such activities as the discovery of socially coherent teams, social hubs, or unbiased experts. We demonstrate the applicability and expressiveness of our approach and notation, and discuss their strengths and weaknesses.,                                        •               We propose a modeling approach and a visual modeling notation for social collaboration processes.                                         •               We consider collaboration processes as the evolution of a network of documents and people.                                         •               The visual modeling notation is a fusion of statecharts and graph query languages.                                         •               The approach is supported by a formal definition to enable automatic reasoning and verification.                                         •               We present sensitive use cases to demonstrate expressiveness and usefulness of our approach.",2014-07,2021-06-05 21:12:40,66-82,,43,Inf Syst,,PubMed Central,PMID: 31523102 PMCID: PMC4010299,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4010299/,,,,PMC:Query2
89,10.1016/j.jaci.2017.04.021,28479327,PMC5671382,,,,"Turi, Kedir N; Romick-Rosendale, Lindsey; Ryckman, Kelli K; Hartert, Tina V",A review of metabolomics approaches and their application in identifying causal pathways of childhood asthma,2018,The Journal of allergy and clinical immunology,,"As asthma is a disease that results from host x environment interactions, an approach which allows assessment of the impact of the environment on the host is needed to understand disease. Metabolomics has appealing potential as an application to study pathways to childhood asthma development. The objective of this review is to provide an overview of metabolomics methods, and their application to understanding host x environment pathways in asthma development. We reviewed recent literature on advances in metabolomics and their application to study pathways to childhood asthma development. We highlighted 1) the potential of metabolomics in understanding the pathogenesis of disease and the discovery of biomarkers, 2) choice of metabolomics techniques, biospecimen handling, and data analysis, 3) the application to studying the role of environment on asthma development, 4) review of metabolomics applied to the outcome of asthma, 5) recommendations for application of metabolomics based –omics data integration in understanding disease pathogenesis, and 6) limitations. In conclusion metabolomics allows use of biospecimens to identify useful biomarkers and pathways involved in disease development, and subsequently to inform a greater understanding of the disease pathogenesis and endotypes, and predicting the clinical course of childhood asthma phenotypes.",2018-04,2021-06-05 21:12:01,1191-1201,4,141,J Allergy Clin Immunol,,PubMed Central,PMID: 28479327 PMCID: PMC5671382,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5671382/,,,,PMC:Query2
90,10.1016/j.jaci.2017.12.992,29378288,PMC5927619,A,Neo4j,Neo4j,"Jupe, Steve; Ray, Keith; Roca, Corina Duenas; Varusai, Thawfeek; Shamovsky, Veronica; Stein, Lincoln; D’Eustachio, Peter; Hermjakob, Henning; Jupe, Steve; Ray, Keith; Roca, Corina Duenas; Varusai, Thawfeek; Shamovsky, Veronica; Stein, Lincoln; D'Eustachio, Peter; Hermjakob, Henning",Interleukins and their signaling pathways in the Reactome biological pathway database,2018,The Journal of Allergy and Clinical Immunology; The Journal of allergy and clinical immunology,,"BACKGROUND: There is a wealth of biological pathway information available in the scientific literature, but it is spread across many thousands of publications. Alongside publications that contain definitive experimental discoveries are many others that have been dismissed as spurious, found to be irreproducible, or are contradicted by later results and consequently now considered controversial. Many descriptions and images of pathways are incomplete stylized representations that assume the reader is an expert and familiar with the established details of the process, which are consequently not fully explained. Pathway representations in publications frequently do not represent a complete, detailed, and unambiguous description of the molecules involved; their precise posttranslational state; or a full account of the molecular events they undergo while participating in a process. Although this might be sufficient to be interpreted by an expert reader, the lack of detail makes such pathways less useful and difficult to understand for anyone unfamiliar with the area and of limited use as the basis for computational models. OBJECTIVE: Reactome was established as a freely accessible knowledge base of human biological pathways. It is manually populated with interconnected molecular events that fully detail the molecular participants linked to published experimental data and background material by using a formal and open data structure that facilitates computational reuse. These data are accessible on a Web site in the form of pathway diagrams that have descriptive summaries and annotations and as downloadable data sets in several formats that can be reused with other computational tools. The entire database and all supporting software can be downloaded and reused under a Creative Commons license. METHODS: Pathways are authored by expert biologists who work with Reactome curators and editorial staff to represent the consensus in the field. Pathways are represented as interactive diagrams that include as much molecular detail as possible and are linked to literature citations that contain supporting experimental details. All newly created events undergo a peer-review process before they are added to the database and made available on the associated Web site. New content is added quarterly. RESULTS: The 63rd release of Reactome in December 2017 contains 10,996 human proteins participating in 11,426 events in 2,179 pathways. In addition, analytic tools allow data set submission for the identification and visualization of pathway enrichment and representation of expression profiles as an overlay on Reactome pathways. Protein-protein and compound-protein interactions from several sources, including custom user data sets, can be added to extend pathways. Pathway diagrams and analytic result displays can be downloaded as editable images, human-readable reports, and files in several standard formats that are suitable for computational reuse. Reactome content is available programmatically through a REpresentational State Transfer (REST)-based content service and as a Neo4J graph database. Signaling pathways for IL-1 to IL-38 are hierarchically classified within the pathway ""signaling by interleukins."" The classification used is largely derived from Akdis et al. CONCLUSION: The addition to Reactome of a complete set of the known human interleukins, their receptors, and established signaling pathways linked to annotations of relevant aspects of immune function provides a significant computationally accessible resource of information about this important family. This information can be extended easily as new discoveries become accepted as the consensus in the field. A key aim for the future is to increase coverage of gene expression changes induced by interleukin signaling.",2018-04,2021-06-05 21:11:16; 2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 20:55:40; 2021-06-05 21:24:28; 2021-06-05 20:36:32,1411-1416,4,141,J Allergy Clin Immunol,,PubMed; PubMed Central,PMID: 29378288 PMCID: PMC5927619,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5927619/; http://www.ncbi.nlm.nih.gov/pubmed/29378288,"database; Databases, Factual; diagram; Humans; illustration; Interleukins; Internet; pathways; Protein Interaction Maps; Proteins; Reactome; Signal Transduction; signaling; Software",Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
91,10.1016/j.jbi.2010.09.004,20851208,PMC3071752,A,AllegroGraph,AllegroGraph,"Deus, Helena F.; Veiga, Diogo F.; Freire, Pablo R.; Weinstein, John N.; Mills, Gordon B.; Almeida, Jonas S.",Exposing the cancer genome atlas as a SPARQL endpoint,2010,Journal of biomedical informatics,,"The Cancer Genome Atlas (TCGA) is a multidisciplinary, multi-institutional effort to characterize several types of cancer. Datasets from biomedical domains such as TCGA present a particularly challenging task for those interested in dynamically aggregating its results because the data sources are typically both heterogeneous and distributed. The Linked Data best practices offer a solution to integrate and discover data with those characteristics, namely through exposure of data as Web services supporting SPARQL, the Resource Description Framework query language. Most SPARQL endpoints, however, cannot easily be queried by data experts. Furthermore, exposing experimental data as SPARQL endpoints remains a challenging task because, in most cases, data must first be converted to Resource Description Framework triples. In line with those requirements, we have developed an infrastructure to expose clinical, demographic and molecular data elements generated by TCGA as a SPARQL endpoint by assigning elements to entities of the Simple Sloppy Semantic Database (S3DB) management model. All components of the infrastructure are available as independent Representational State Transfer (REST) Web services to encourage reusability, and a simple interface was developed to automatically assemble SPARQL queries by navigating a representation of the TCGA domain. A key feature of the proposed solution that greatly facilitates assembly of SPARQL queries is the distinction between the TCGA domain descriptors and data elements. Furthermore, the use of the S3DB management model as a mediator enables queries to both public and protected data without the need for prior submission to a single data source.",2010-12,2021-06-05 21:13:27; 2021-06-06 06:38:41; 2021-06-05 20:56:20,998-1008,6,43,J Biomed Inform,,PubMed Central,PMID: 20851208 PMCID: PMC3071752,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3071752/,,AllegroGraph,AllegroGraph,PMC:Query3; PMC:AllegroGraph; PMC:Query2
92,10.1016/j.jbi.2011.11.012,22154838,PMC3306517,,,,"Xiang, Yang; Lu, Kewei; James, Stephen L.; Borlawsky, Tara B.; Huang, Kun; Payne, Philip R.O.",k-neighborhood Decentralization: A Comprehensive Solution to Index the UMLS for Large Scale Knowledge Discovery,2012,Journal of Biomedical Informatics,,"The Unified Medical Language System (UMLS) is the largest thesaurus in the biomedical informatics domain. Previous works have shown that knowledge constructs comprised of transitively-associated UMLS concepts are effective for discovering potentially novel biomedical hypotheses. However, the extremely large size of the UMLS becomes a major challenge for these applications. To address this problem, we designed a k-neighborhood Decentralization Labeling Scheme (kDLS) for the UMLS, and the corresponding method to effectively evaluate the kDLS indexing results. kDLS provides a comprehensive solution for indexing the UMLS for very efficient large scale knowledge discovery. We demonstrated that it is highly effective to use kDLS paths to prioritize disease-gene relations across the whole genome, with extremely high fold-enrichment values. To our knowledge, this is the first indexing scheme capable of supporting efficient large scale knowledge discovery on the UMLS as a whole. Our expectation is that kDLS will become a vital engine for retrieving information and generating hypotheses from the UMLS for future medical informatics applications.",2012-04,2021-06-05 21:13:27,323-336,2,45,J Biomed Inform,k-neighborhood Decentralization,PubMed Central,PMID: 22154838 PMCID: PMC3306517,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3306517/,,,,PMC:Query2
93,10.1016/j.jbi.2015.08.016,26305513,,A,,,"Campbell, W. Scott; Pedersen, Jay; McClay, James C.; Rao, Praveen; Bastola, Dhundy; Campbell, James R.",An alternative database approach for management of SNOMED CT and improved patient data queries,2015,Journal of Biomedical Informatics,,"OBJECTIVE: SNOMED CT is the international lingua franca of terminologies for human health. Based in Description Logics (DL), the terminology enables data queries that incorporate inferences between data elements, as well as, those relationships that are explicitly stated. However, the ontologic and polyhierarchical nature of the SNOMED CT concept model make it difficult to implement in its entirety within electronic health record systems that largely employ object oriented or relational database architectures. The result is a reduction of data richness, limitations of query capability and increased systems overhead. The hypothesis of this research was that a graph database (graph DB) architecture using SNOMED CT as the basis for the data model and subsequently modeling patient data upon the semantic core of SNOMED CT could exploit the full value of the terminology to enrich and support advanced data querying capability of patient data sets. METHODS: The hypothesis was tested by instantiating a graph DB with the fully classified SNOMED CT concept model. The graph DB instance was tested for integrity by calculating the transitive closure table for the SNOMED CT hierarchy and comparing the results with transitive closure tables created using current, validated methods. The graph DB was then populated with 461,171 anonymized patient record fragments and over 2.1 million associated SNOMED CT clinical findings. Queries, including concept negation and disjunction, were then run against the graph database and an enterprise Oracle relational database (RDBMS) of the same patient data sets. The graph DB was then populated with laboratory data encoded using LOINC, as well as, medication data encoded with RxNorm and complex queries performed using LOINC, RxNorm and SNOMED CT to identify uniquely described patient populations. RESULTS: A graph database instance was successfully created for two international releases of SNOMED CT and two US SNOMED CT editions. Transitive closure tables and descriptive statistics generated using the graph database were identical to those using validated methods. Patient queries produced identical patient count results to the Oracle RDBMS with comparable times. Database queries involving defining attributes of SNOMED CT concepts were possible with the graph DB. The same queries could not be directly performed with the Oracle RDBMS representation of the patient data and required the creation and use of external terminology services. Further, queries of undefined depth were successful in identifying unknown relationships between patient cohorts. CONCLUSION: The results of this study supported the hypothesis that a patient database built upon and around the semantic model of SNOMED CT was possible. The model supported queries that leveraged all aspects of the SNOMED CT logical model to produce clinically relevant query results. Logical disjunction and negation queries were possible using the data model, as well as, queries that extended beyond the structural IS_A hierarchy of SNOMED CT to include queries that employed defining attribute-values of SNOMED CT concepts as search parameters. As medical terminologies, such as SNOMED CT, continue to expand, they will become more complex and model consistency will be more difficult to assure. Simultaneously, consumers of data will increasingly demand improvements to query functionality to accommodate additional granularity of clinical concepts without sacrificing speed. This new line of research provides an alternative approach to instantiating and querying patient data represented using advanced computable clinical terminologies.",2015-10,2021-06-05 21:06:22,350-357,,57,J Biomed Inform,,PubMed,PMID: 26305513,http://www.ncbi.nlm.nih.gov/pubmed/26305513,"Databases; Databases, Factual; Humans; Information Storage and Retrieval; Logical Observation Identifiers Names and Codes; Medical terminology; Ontology; Search Engine; Semantics; SNOMED CT; Systematized Nomenclature of Medicine; Vocabulary, Controlled",,,PubMed:Query2
94,10.1016/j.jbi.2017.03.003,28284761,PMC5441848,,,,"Cohen, Trevor; Widdows, Dominic",Embedding of Semantic Predications,2017,Journal of biomedical informatics,,"This paper concerns the generation of distributed vector representations of biomedical concepts from structured knowledge, in the form of subject-relation-object triplets known as semantic predications. Specifically, we evaluate the extent to which a representational approach we have developed for this purpose previously, known as Predication-based Semantic Indexing (PSI), might benefit from insights gleaned from neural-probabilistic language models, which have enjoyed a surge in popularity in recent years as a means to generate distributed vector representations of terms from free text. To do so, we develop a novel neural-probabilistic approach to encoding predications, called Embedding of Semantic Predications (ESP), by adapting aspects of the Skipgram with Negative Sampling (SGNS) algorithm to this purpose. We compare ESP and PSI across a number of tasks including recovery of encoded information, estimation of semantic similarity and relatedness, and identification of potentially therapeutic and harmful relationships using both analogical retrieval and supervised learning. We find advantages for ESP in some, but not all of these tasks, revealing the contexts in which the additional computational work of neural-probabilistic modeling is justified.,",2017-04,2021-06-05 21:12:01,150-166,,68,J Biomed Inform,,PubMed Central,PMID: 28284761 PMCID: PMC5441848,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5441848/,,,,PMC:Query2
95,10.1016/j.jbi.2019.103171,31004797,,A,,,"Mondal, Safikureshi; Mukherjee, Nandini",An efficient reachability query based pruning algorithm in e-health scenario,2019,Journal of Biomedical Informatics,,"We propose a Disease-Symptom graph database for our mobile-assisted e-healthcare application. A large Disease-Symptom graph is stored in the cloud and accessed using mobile devices over the Internet. Query and search are the fundamental operations of graph databases. However, while searching the Disease-Symptom graph for making preliminary diagnosis of diseases, queries become complex due to the complex structure of data and also queries are too hard to write and interpret. Moreover, it is not possible to access the graph frequently due to limited bandwidth of the network, transmission delay, and higher cost. Subgraph generation or pruning algorithm for appropriate inputs is one of the solutions to this problem. In this paper, we propose an efficient pruning algorithm by introducing a new approach to decompose the Disease-Symptom graph into a series of symptom trees (ST). All the Symptom trees are merged to build a pruned subgraph which is our requirement. We demonstrate the efficiency and effectiveness of our pruning algorithm both analytically and empirically and validate on Disease-Symptom graph database, as well as other real graph databases. Also a comparison is done with an efficient existing reachability based Chain Cover algorithm after modifying it ChainCoverPrune as pruning algorithm. These two algorithms are tested for storage and access parametric measures for querying the synthetic and real directed databases to show the efficiency of the proposed algorithm.",2019-06,2021-06-05 21:06:22,103171,,94,J Biomed Inform,,PubMed,PMID: 31004797,http://www.ncbi.nlm.nih.gov/pubmed/31004797,Algorithms; Chain Cover; Datasets as Topic; graph database; Pruning algorithm; Reachability Query; Telemedicine,,,PubMed:Query2
96,10.1016/j.jbi.2020.103549,32871286,,A,Neo4j,Neo4j,"Mondal, Safikureshi; Basu, Anwesha; Mukherjee, Nandini",Building a trust-based doctor recommendation system on top of multilayer graph database,2020,Journal of Biomedical Informatics,,"In healthcare applications, developing a data model for storing patient-doctor relationships is important. Though relational models are popular for many commercial and business applications, they may not be appropriate for modeling patient-doctor relationships due to their inherent irregular nature and complexities. In this paper, as a case study, we propose to build a doctor recommendation system for the patients. The recommendation system is built on top of a multilayer graph data model. Contemporary research papers have already shown that multilayer graph data models can be efficiently used in many applications where large, heterogeneous data are to be modeled. As part of the recommendation system, the paper also introduces a concept of trust which is one important ingredient of any kind of recommendation. The trust factor introduced in the paper exploits certain characteristics of the multilayer graph model. The paper also presents some analysis to demonstrate the efficiency of the graph data model in comparison with relational data model.",2020-10,2021-06-05 21:24:28; 2021-06-05 21:06:22; 2021-06-05 21:16:51,103549,,110,J Biomed Inform,,PubMed,PMID: 32871286,http://www.ncbi.nlm.nih.gov/pubmed/32871286,E-healthcare; Multilayer graph data model; Neo4j; NoSQL; Patient-doctor relationship; Trust Model,Neo4j,Neo4j,PubMed:Neo4j; PubMed:Query3; PubMed:Query2
97,10.1016/j.jbi.2021.103696,33571675,PMC7869625,A,Neo4j; COVID19,Neo4j; COVID19,"Zhang, Rui; Hristovski, Dimitar; Schutte, Dalton; Kastrin, Andrej; Fiszman, Marcelo; Kilicoglu, Halil",Drug repurposing for COVID-19 via knowledge graph completion,2021,Journal of Biomedical Informatics,,"Objective To discover candidate drugs to repurpose for COVID-19 using literature-derived knowledge and knowledge graph completion methods. Methods We propose a novel, integrative, and neural network-based literature-based discovery (LBD) approach to identify drug candidates from PubMed and other COVID-19-focused research literature. Our approach relies on semantic triples extracted using SemRep (via SemMedDB). We identified an informative and accurate subset of semantic triples using filtering rules and an accuracy classifier developed on a BERT variant. We used this subset to construct a knowledge graph, and applied five state-of-the-art, neural knowledge graph completion algorithms (i.e., TransE, RotatE, DistMult, ComplEx, and STELP) to predict drug repurposing candidates. The models were trained and assessed using a time slicing approach and the predicted drugs were compared with a list of drugs reported in the literature and evaluated in clinical trials. These models were complemented by a discovery pattern-based approach. Results Accuracy classifier based on PubMedBERT achieved the best performance (F1 = 0.854) in identifying accurate semantic predications. Among five knowledge graph completion models, TransE outperformed others (MR = 0.923, Hits@1 = 0.417). Some known drugs linked to COVID-19 in the literature were identified, as well as others that have not yet been studied. Discovery patterns enabled identification of additional candidate drugs and generation of plausible hypotheses regarding the links between the candidate drugs and COVID-19. Among them, five highly ranked and novel drugs (i.e., paclitaxel, SB 203580, alpha 2-antiplasmin, metoclopramide, and oxymatrine) and the mechanistic explanations for their potential use are further discussed. Conclusion We showed that a LBD approach can be feasible not only for discovering drug candidates for COVID-19, but also for generating mechanistic explanations. Our approach can be generalized to other diseases as well as to other clinical questions. Source code and data are available at https://github.com/kilicogluh/lbd-covid.",2021-03,2021-06-05 20:35:57; 2021-06-05 21:35:36; 2021-06-05 20:54:31; 2021-06-05 21:09:36,103696,,115,J Biomed Inform,,PubMed Central,PMID: 33571675 PMCID: PMC7869625,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7869625/,,Neo4j; COVID19,Neo4j; COVID19,PMC:Query3; PMC:Neo4j; PMC:COVID19; PMC:Query2
98,10.1016/j.jbi.2021.103747,33753269,,A,,,"Giménez-Solano, V. M.; Maldonado, J. A.; Boscá, D.; Salas-García, S.; Robles, M.",Definition and validation of SNOMED CT subsets using the expression constraint language,2021,Journal of Biomedical Informatics,,"BACKGROUND: SNOMED CT Expression Constraint Language (ECL) is a declarative language developed by SNOMED International for the definition of SNOMED CT Expression Constraints (ECs). ECs are executable expressions that define intensional subsets of clinical meanings by stating constraints over the logic definition of concepts. The execution of an EC on some SNOMED CT substrate yields the intended subset, and it requires an execution engine able to receive an EC as input, execute it, and return the matching concepts. An important issue regarding subsets of clinical concepts is their use in terminology binding between clinical information models and terminologies for defining the set of valid values of codified data. OBJECTIVE: To define and implement methods for the simplification, semantic validation and execution of ECs over a graph-oriented SNOMED CT database, and to provide a method for the visual representation of subsets in order to explore, understand and validate its content, as well as to develop an EC execution platform, called SNQuery, which makes use of these methods. METHODS: Since SNOMED CT is a directed and acyclic graph, we have used a graph-oriented database to represent the content of SNOMED CT, where the schema and instances are represented as graphs and the data manipulation is expressed by graph-oriented operations. For the execution of ECs over the graph database, it is performed a translation process in which ECs are translated into a set of Cypher Query Language queries. We have defined some EC simplification methods that leverage the logic structure underlying SNOMED CT. The purpose of these methods is to reduce the complexity of ECs and, in turn, its execution time, as well as to validate them from a SNOMED CT Concept Model and logical definition points of view. We also have developed a graphic representation based on the circle packing geometrical concept, which allows validating subsets, as well as pre-defined refsets and the terminology itself. RESULTS: We have developed SNQuery, a platform for the definition of intensional subsets of SNOMED CT concepts by means of the execution of ECs over a graph-oriented SNOMED CT database. Additionally, we have incorporated methods for the simplification and semantic validation of ECs, as well as for the visualization of subsets as a mechanism to understand and validate them. SNQuery has been evaluated in terms of EC execution times. CONCLUSION: In this paper, we provide methods to simplify, semantically validate and execute ECs over a graph-oriented database. We also offer a method to visualize the intensional subsets obtained by executing ECs to explore, understand and validate them, as well as refsets and the terminology itself. The definition of intensional subsets is useful to bind content between clinical information models and clinical terminologies, which is a necessary step to achieve semantic interoperability between EHR systems.",2021-05,2021-06-05 21:06:22,103747,,117,J Biomed Inform,,PubMed,PMID: 33753269,http://www.ncbi.nlm.nih.gov/pubmed/33753269,Expression constraint language; Expression constraint simplification; Graph database; SNOMED CT; Subset visualization,,,PubMed:Query2
99,10.1016/j.jclepro.2020.124262,32982077,PMC7508020,,,,"García-Berná, José A.; Fernández-Alemán, José L.; Carrillo de Gea, Juan M.; Toval, Ambrosio; Mancebo, Javier; Calero, Coral; García, Félix",Energy efficiency in software: A case study on sustainability in personal health records,2021,Journal of Cleaner Production,,"A personal health record is an eHealth technology in which users can observe their progress over time for a given condition. A research gap was identified in the literature concerning the study of the amount of energy that these systems need for their operation, and the energy efficiency that may be attained depending on their design. After the selection of five representative personal health records, a total of 20 tasks commonly done, and based on previous work, were performed with regard to two proposed scenarios, namely patient use and health personnel usage. The power consumption of the main components of a host machine was measured during the performance of the proposed duties. To that end, a hardware tool called the Energy Efficiency Tester was employed. The data collected were analyzed statistically, and significant differences were found in the respective consumption of the display (χ2 (4) = 23.782, p = 0.000), the processor (χ2 (4) = 29.018, p = 0.000) and the whole PC (χ2 (4) = 28.582, p = 0.000). For all of these components, NoMoreClipBoard was the personal health record that required the least energy (57.699 W for the display, 3.162 W for the processor and 181.113 W for the whole PC). A total of two strong correlations were found in the energy consumption between the hard disk and the graphics card (r = 0.791, p < 0.001), and the processor and the PC (r = 0.950, p < 0.001). Some features generated special amounts of power consumption, such as the news wall found on PatientsLikeMe, or the use of load icons that had an impact on most PC components. In addition, an in-depth analysis of the user interfaces was performed. A discussion was carried out on the design of the user interfaces, also taking into account recommendations drawn from the literature, checking for their implementation in the personal health records selected. With the aim of promoting sustainability among software developers, a best practice guideline on sustainable software design was proposed. Basic sustainability recommendations were collected for professionals to consider when developing a software system in general, and a personal health record in particular.,                                        •               GUI contributes to sustainability.                                         •               Strong correlations were found in energy expenditures between PC components.                                         •               NoMoreClipboard generated the lowest average power consumption.                                         •               Findings highlighted the importance of software recommendations for sustainability.",2021-02-01,2021-06-05 21:10:08,124262,,282,J Clean Prod,Energy efficiency in software,PubMed Central,PMID: 32982077 PMCID: PMC7508020,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7508020/,,,,PMC:Query2
100,10.1016/j.jmsy.2019.07.003,32116404,PMC7047720,,,,"Kulvatunyou, Boonserm (Serm); Oh, Hakju; Ivezic, Nenad; Nieman, Scott T.","Standards-based Semantic Integration of Manufacturing Information: Past, Present, and Future",2019,Journal of manufacturing systems,,"Service-oriented architecture (SOA) has been identified as a key to enabling the emerging manufacturing paradigms such as smart manufacturing, Industrie 4.0, and cloud manufacturing where things (i.e., various kinds of devices and software systems) from heterogeneous sources have to be dynamically connected. Data exchange standards are playing an increasingly important role to reduce risks associated with investments in these Industrial Internet of Things (IIoT) and adoptions of those emerging manufacturing paradigms. This paper looks back into the history of the standards for carrying the semantics of data across systems (or things), how they are developed, maintained, and represented, and then presents an insight into the current trends. In particular, the paper discusses the emerging move in data exchange standards practices toward model-based development and usage. We present functional requirements for a system supporting the model-based approach and conclude with implications and future directions.",2019,2021-06-05 21:10:37,,,52,J Manuf Syst,Standards-based Semantic Integration of Manufacturing Information,PubMed Central,PMID: 32116404 PMCID: PMC7047720,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7047720/,,,,PMC:Query2
101,10.1016/j.mehy.2020.110395,33341328,PMC7695568,,,,"Rickett, Christopher D.; Maschhoff, Kristyn J.; Sukumar, Sreenivas R.",Does tetanus vaccination contribute to reduced severity of the COVID-19 infection?,2021,Medical Hypotheses,,"We present the hypothesis to the scientific community actively designing clinical trials and recommending public health guidelines to control the pandemic that – “Tetanus vaccination may be contributing to reduced severity of the COVID-19 infection” – and urge further research to validate or invalidate the effectiveness of the tetanus toxoid vaccine against COVID-19. This hypothesis was revealed by an explainable artificial intelligence system unleashed on open public biomedical datasets. As a foundation for scientific rigor, we describe the data and the artificial intelligence system, document the provenance and methodology used to derive the hypothesis and also gather potentially relevant data/evidence from recent studies. We conclude that while correlations may not be reason for causation, correlations from multiple sources is more than a serendipitous coincidence that is worthy of further and deeper investigation.",2021-01,2021-06-05 21:09:36,110395,,146,Med Hypotheses,,PubMed Central,PMID: 33341328 PMCID: PMC7695568,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7695568/,,,,PMC:Query2
102,10.1016/j.patter.2020.100105,33205138,PMC7660444,A,Neo4j,Neo4j,"Arnaud, Elizabeth; Laporte, Marie-Angélique; Kim, Soonho; Aubert, Céline; Leonelli, Sabina; Miro, Berta; Cooper, Laurel; Jaiswal, Pankaj; Kruseman, Gideon; Shrestha, Rosemary; Buttigieg, Pier Luigi; Mungall, Christopher J.; Pietragalla, Julian; Agbona, Afolabi; Muliro, Jacqueline; Detras, Jeffrey; Hualla, Vilma; Rathore, Abhishek; Das, Roma Rani; Dieng, Ibnou; Bauchet, Guillaume; Menda, Naama; Pommier, Cyril; Shaw, Felix; Lyon, David; Mwanzia, Leroy; Juarez, Henry; Bonaiuti, Enrico; Chiputwa, Brian; Obileye, Olatunbosun; Auzoux, Sandrine; Yeumo, Esther Dzalé; Mueller, Lukas A.; Silverstein, Kevin; Lafargue, Alexandra; Antezana, Erick; Devare, Medha; King, Brian",The Ontologies Community of Practice: A CGIAR Initiative for Big Data in Agrifood Systems,2020,Patterns,,"Heterogeneous and multidisciplinary data generated by research on sustainable global agriculture and agrifood systems requires quality data labeling or annotation in order to be interoperable. As recommended by the FAIR principles, data, labels, and metadata must use controlled vocabularies and ontologies that are popular in the knowledge domain and commonly used by the community. Despite the existence of robust ontologies in the Life Sciences, there is currently no comprehensive full set of ontologies recommended for data annotation across agricultural research disciplines. In this paper, we discuss the added value of the Ontologies Community of Practice (CoP) of the CGIAR Platform for Big Data in Agriculture for harnessing relevant expertise in ontology development and identifying innovative solutions that support quality data annotation. The Ontologies CoP stimulates knowledge sharing among stakeholders, such as researchers, data managers, domain experts, experts in ontology design, and platform development teams.,                                        •               FAIR agricultural data must use ontologies that are popular in the knowledge domain                                         •               CGIAR Ontologies Community of Practice holds expertise for agricultural data annotation                                         •               The Community selects innovative solutions to assist the data annotation with ontologies                                         •               The Community develops multidisciplinary open-source ontologies for agricultural data                                 , Digital technology use in agriculture and agrifood systems research accelerates the production of multidisciplinary data, which spans genetics, environment, agroecology, biology, and socio-economics. Quality labeling of data secures its online findability, reusability, interoperability, and reliable interpretation, through controlled vocabularies organized into meaningful and computer-readable knowledge domains called ontologies. There is currently no full set of recommended ontologies for agricultural research, so data scientists, data managers, and database developers struggle to find validated terminology. The Ontologies Community of Practice of the CGIAR Platform for Big Data in Agriculture harnesses international expertise in knowledge representation and ontology development to produce missing ontologies, identifies best practices, and guides data labeling by teams managing multidisciplinary information platforms to release the FAIR data underpinning the evidence of research impact., The deployment of digital technology in Agriculture and Food Science accelerates the production of large quantities of multidisciplinary data. The Ontologies Community of Practice (CoP) of the CGIAR Platform for Big Data in Agriculture harnesses the international ontology expertise that can guide teams managing multidisciplinary agricultural information platforms to increase the data interoperability and reusability. The CoP develops and promotes ontologies to support quality data labeling across domains, e.g., Agronomy Ontology, Crop Ontology, Environment Ontology, Plant Ontology, and Socio-Economic Ontology.",2020-09-25,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,,7,1,Patterns (N Y),The Ontologies Community of Practice,PubMed Central,PMID: 33205138 PMCID: PMC7660444,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7660444/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
103,10.1016/j.patter.2020.100155,33196056,PMC7649624,A,Neo4j; COVID19,Neo4j; COVID19,"Reese, Justin T.; Unni, Deepak; Callahan, Tiffany J.; Cappelletti, Luca; Ravanmehr, Vida; Carbon, Seth; Shefchek, Kent A.; Good, Benjamin M.; Balhoff, James P.; Fontana, Tommaso; Blau, Hannah; Matentzoglu, Nicolas; Harris, Nomi L.; Munoz-Torres, Monica C.; Haendel, Melissa A.; Robinson, Peter N.; Joachimiak, Marcin P.; Mungall, Christopher J.",KG-COVID-19: A Framework to Produce Customized Knowledge Graphs for COVID-19 Response,2020,Patterns,,"Integrated, up-to-date data about SARS-CoV-2 and COVID-19 is crucial for the ongoing response to the COVID-19 pandemic by the biomedical research community. While rich biological knowledge exists for SARS-CoV-2 and related viruses (SARS-CoV, MERS-CoV), integrating this knowledge is difficult and time-consuming, since much of it is in siloed databases or in textual format. Furthermore, the data required by the research community vary drastically for different tasks; the optimal data for a machine learning task, for example, is much different from the data used to populate a browsable user interface for clinicians. To address these challenges, we created KG-COVID-19, a flexible framework that ingests and integrates heterogeneous biomedical data to produce knowledge graphs (KGs), and applied it to create a KG for COVID-19 response. This KG framework also can be applied to other problems in which siloed biomedical data must be quickly integrated for different research applications, including future pandemics.,                                        •               KG-COVID-19 is a framework for producing customized COVID-19 knowledge graphs                                         •               Our knowledge graph and framework is free, open-source, and FAIR                                         •               KG-COVID-19 integrates a wide range of COVID-19-related data in an ontology-aware way                                         •               Our KG has been applied to use cases including ML tasks, hypothesis-based querying                                 , An effective response to the COVID-19 pandemic relies on integration of many different types of data available about SARS-CoV-2 and related viruses. KG-COVID-19 is a framework for producing knowledge graphs that can be customized for downstream applications including machine learning tasks, hypothesis-based querying, and browsable user interface to enable researchers to explore COVID-19 data and discover relationships., An effective response to the COVID-19 pandemic relies on integration of many different types of data available about SARS-CoV-2 and related viruses. KG-COVID-19 is a framework for producing knowledge graphs that can be customized for downstream applications including machine learning tasks, hypothesis-based querying, and browsable user interface to enable researchers to explore COVID-19 data and discover relationships.",2020-11-09,2021-06-05 20:35:57; 2021-06-05 21:35:36; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,1,2,Patterns (N Y),KG-COVID-19,PubMed Central,PMID: 33196056 PMCID: PMC7649624,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7649624/,,Neo4j; COVID19,Neo4j; COVID19,PMC:Query3; PMC:Neo4j; PMC:COVID19; PMC:Query2
104,10.1016/j.radonc.2019.11.019,31911366,,A,,,"Deist, Timo M.; Dankers, Frank J. W. M.; Ojha, Priyanka; Scott Marshall, M.; Janssen, Tomas; Faivre-Finn, Corinne; Masciocchi, Carlotta; Valentini, Vincenzo; Wang, Jiazhou; Chen, Jiayan; Zhang, Zhen; Spezi, Emiliano; Button, Mick; Jan Nuyttens, Joost; Vernhout, René; van Soest, Johan; Jochems, Arthur; Monshouwer, René; Bussink, Johan; Price, Gareth; Lambin, Philippe; Dekker, Andre",Distributed learning on 20 000+ lung cancer patients - The Personal Health Train,2020,Radiotherapy and Oncology: Journal of the European Society for Therapeutic Radiology and Oncology,,"BACKGROUND AND PURPOSE: Access to healthcare data is indispensable for scientific progress and innovation. Sharing healthcare data is time-consuming and notoriously difficult due to privacy and regulatory concerns. The Personal Health Train (PHT) provides a privacy-by-design infrastructure connecting FAIR (Findable, Accessible, Interoperable, Reusable) data sources and allows distributed data analysis and machine learning. Patient data never leaves a healthcare institute. MATERIALS AND METHODS: Lung cancer patient-specific databases (tumor staging and post-treatment survival information) of oncology departments were translated according to a FAIR data model and stored locally in a graph database. Software was installed locally to enable deployment of distributed machine learning algorithms via a central server. Algorithms (MATLAB, code and documentation publicly available) are patient privacy-preserving as only summary statistics and regression coefficients are exchanged with the central server. A logistic regression model to predict post-treatment two-year survival was trained and evaluated by receiver operating characteristic curves (ROC), root mean square prediction error (RMSE) and calibration plots. RESULTS: In 4 months, we connected databases with 23 203 patient cases across 8 healthcare institutes in 5 countries (Amsterdam, Cardiff, Maastricht, Manchester, Nijmegen, Rome, Rotterdam, Shanghai) using the PHT. Summary statistics were computed across databases. A distributed logistic regression model predicting post-treatment two-year survival was trained on 14 810 patients treated between 1978 and 2011 and validated on 8 393 patients treated between 2012 and 2015. CONCLUSION: The PHT infrastructure demonstrably overcomes patient privacy barriers to healthcare data sharing and enables fast data analyses across multiple institutes from different countries with different regulatory regimens. This infrastructure promotes global evidence-based medicine while prioritizing patient privacy.",2020-03,2021-06-05 21:06:22,189-200,,144,Radiother Oncol,,PubMed,PMID: 31911366,http://www.ncbi.nlm.nih.gov/pubmed/31911366,Algorithms; Big data; China; Distributed learning; FAIR data; Federated learning; Humans; Lung cancer; Lung Neoplasms; Machine learning; Machine Learning; Prediction modeling; Privacy; Survival analysis,,,PubMed:Query2
105,10.1016/j.smhl.2018.07.007,30547078,PMC6289266,,,,"Dhami, Devendra Singh; Kunapuli, Gautam; Das, Mayukh; Page, David; Natarajan, Sriraam",Drug-Drug Interaction Discovery: Kernel Learning from Heterogeneous Similarities,2018,"Smart health (Amsterdam, Netherlands)",,"We develop a pipeline to mine complex drug interactions by combining different similarities and interaction types (molecular, structural, phenotypic, genomic etc). Our goal is to learn an optimal kernel from these heterogeneous similarities in a supervised manner. We formulate an extensible framework that can easily integrate new interaction types into a rich model. The core of our pipeline features a novel kernel-learning approach that tunes the weights of the heterogeneous similarities, and fuses them into a Similarity-based Kernel for Identifying Drug-Drug interactions and Discovery, or SKID3. Experimental evaluation on the DrugBank database shows that SKID3 effectively combines similarities generated from chemical reaction pathways (which generally improve precision) and molecular and structural fingerprints (which generally improve recall) into a single kernel that gets the best of both worlds, and consequently demonstrates the best performance.",2018-12,2021-06-05 21:11:16,88-100,,9-10,Smart Health (Amst),Drug-Drug Interaction Discovery,PubMed Central,PMID: 30547078 PMCID: PMC6289266,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6289266/,,,,PMC:Query2
106,10.1016/j.tplants.2018.03.008,29602571,PMC6217801,,,,"Huang, Yanyan; Jamieson, Pierce; Shan, Libo",The APEX approaches: a unified LRR-RK network revealed,2018,Trends in plant science,,"Leucine-rich repeat receptor kinases (LRR-RKs) represent a large and functionally diverse family of transmembrane proteins critical for signal recognition and transduction at the plant cell plasma membrane. Here, we discuss a recent report which used a systems-level approach to validate key paradigms by constructing an LRR-RK interaction network model.",2018-05,2021-06-05 21:11:16,372-374,5,23,Trends Plant Sci,The APEX approaches,PubMed Central,PMID: 29602571 PMCID: PMC6217801,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6217801/,,,,PMC:Query2
107,10.1017/cts.2017.62,,PMC6799498,A,Neo4j,Neo4j,"Elkin, Peter; Mullin, Sarah; Sethi, Sanjay; Sinha, Shyamashree; Sinha, Animesh",2240,2018,Journal of Clinical and Translational Science,,"OBJECTIVES/SPECIFIC AIMS: To create a new semantically correct high-throughput phenotyping (HTP) platform. To demonstrate the utility of the HTP platform for observational research and can allow clinical investigators to perform studies in 5 minutes. To demonstrate the improved accuracy of observational research using this platform when compared with traditional observational research methods. To demonstrate that patients who have Roseacea are at increased risk of having obstructive sleep apnea (OSA). METHODS/STUDY POPULATION: This population is a set of 212,343 patients in the outpatient setting cared for in the Buffalo area over a 6-year period. All records for these patients were included in the study. Structured data was imported into an OMOP (OHDSI) database and all of the notes and reports were parsed by our HTP system which produces SNOMED CT codes. Each code is designated as a positive, negative or uncertain assertion and compositional expressions are automatically generated. We store the codified data 750,000,000 codes in Berkley DB, a NOSQL database, and we keep the compositional graphs in both Neo4J and in GraphDB (a triple store). Labs are coded in LOINC and drugs using RxNorm. We have developed a Web interface in .Net named BMI Search, which allows real-time query by subject matter experts. We analyzed the accuracy of structured Versus unstructured data by identifiying NVAF cases with ICD9 codes and then looked for any additional cases based on the SNOMED CT encodings of the clinical record. This was validated by 2 clinical human review of a set of 300 randomly selected cases. Separately we ran a study to determine the relative risk of OSA with and without Rosacea using the data set described above. We compared the rates using a Pearson χ2 test. RESULTS/ANTICIPATED RESULTS: We are able to parse 7,000,000 records in an hour and a half on 1 node with 4 CPUs. This yielded 750,000,000 SNOMED CT codes. The HTP data set yielded 1849 cases using ICD9 codes and another 873 using the HTP-NLU data, leading to a final data set of 2722 cases from our population of 212,343 patients. In total, 580 patients had Rosacea;5443 patients had OSA without Rosacea and 51 patients had OSA with Rosacea. Patients with Rosaca had an 8.8% risk of OSA whereas patients without Rosacia only had a 2.6% risk of OSA. This was highly statistically significant with a p<0.0001 (Pearson χ2 test). The number needed to test was only 12. DISCUSSION/SIGNIFICANCE OF IMPACT: HTP can change how we do observational research and can lead to more accurate and more prolific investigation. This rapid turn around is part of what is necessary for both precision medicine and to create a learning health system. Patients with Rosacea are at increased risk of and should be screened for OSA.",2018-05-10,2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:36:32,13,Suppl 1,1,J Clin Transl Sci,,PubMed Central,PMID:  PMCID: PMC6799498,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6799498/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
108,10.1017/cts.2017.69,,PMC6799651,A,Neo4j,Neo4j,"Sinha, Shyamashree; Burstein, Gale; Leonard, Kenneth E.; Murphy, Timothy; Elkin, Peter",2327,2018,Journal of Clinical and Translational Science,,"OBJECTIVES/SPECIFIC AIMS: Dependence and abuse of prescription opioid pain medication has substantially increased over the last decade. The consistent rise in opioid dependence contributes to the rising prescription drug overdose deaths over the last decade. The study of the distribution and determinants of opioid dependence among patients who are treated with chronic pain medications prescribed by their healthcare providers would aid in answering some key questions about potential abuse and overdose on opioids. The descriptive epidemiology of opioid dependence would help in identifying the vulnerable age group, race, ethnicity, and type of opioid pain medications that more commonly result in dependence. METHODS/STUDY POPULATION: We implemented an Observational Medical Outcomes Partnership/Observational Health Data Sciences and Informatics (OMOP/OHDSI) database, to hold structured EHR data from our Allscripts patient records. We also created a high-throughput phenotyping, natural language processing system that can parse 7,000,000 clinical notes in 1.5 hours. This runs as a web service and provides a modular component based NLP system. After the full semantic parse, we match the content against any number of ontologies. For each match we tag it as either a positive, negative, or uncertain assertion. We then perform automated compositional expressions. The codes are stored in a Berkley database (BDB) NOSQL database and the compositional expressions are stored in Neo4J (a graph database) and Graph DB (a triple store). This flexibility allows rapid retrieval of complex questions in real time. The High-Throughput Phenotyping (HTP) Natural Language Processing (NLP) Subsystem (HTP-NLP) is software that produces, given biomedical text, semantic annotations of the text. The semantic annotations identify conceptual entities—their attributes, the relations they have with other entities and the events they participate in, as expressed in the input text. The conceptual entities, relations, attributes, and events identified are specified by various knowledge representations (KRs) as documented in Coding Sources. Examples of coding sources are medical terminologies [eg, SNOMED CT, RxNorm, LOINC and open biomedical ontologies (OBO) foundry ontologies, eg, gene ontology (GO), functional model of anatomy, OBI, and others]. The annotation results may be displayed or output in formats suitable for further processing. Entity identified is assigned a truth value from 0 to 1. Values from the text are assigned to entities from ontologies such as SNOMED CT. The retrospective analysis of EHR data from local clinic patients was performed using queries on the problem list, demographic data, and medication list of all the patients in the database. The OMOP/OHDSI database was collected from Allscripts EHRs from 2010 to 2015. This common data model helps in the systematic analysis of disparate observational databases of clinic records from the primary care and family medicine clinics in Western New York region. The database contained 212,343 patient records that were parsed and deidentified. Specific research IDs were assigned to each of the patient records and stored in a secure firewall device for data analytics. The entire 212,343 records were queried for opioid dependence from the ICD-9 and 10 diagnostic codes and SNOMED CT codes mapped to both the clinical notes and the problem list for each patient based on the mapped ICD and SNOMED CT codes. In total, 1356 patients were identified as to having opioid dependence. The records were stratified into 7 age groups from age 18 to 28 and ending with age 79–89 years. RESULTS/ANTICIPATED RESULTS: Of the 212,343 patients in the database 1356 patients revealed opioid dependence on the problem list, ICD9-10 codes and prescription opioid pain medication with or without Buprenorphine and Naloxone (Suboxone) in the medication list. The prevalence of opioid dependence in the clinic population was 0.64% (95% CI: 0.61%–0.67%) over a 5-year period. The 7,000,000 patient records generated 750,000,000 SNOMED CT codes (on average 107 codes per record). The highest numbers of opioid dependence were seen in the 29 to 38 years’ age group. That comprised 39.38% (95% CI: 36.78%–41.98%) of the total opioid dependent population but accounted for only 2.03% of whole clinic population in this age group (95% CI: 1.86% to 2.2%). The subjects were then stratified by race and ethnicity. There were 1005 patients with opioid dependence, in the non-Hispanic population (total number 108,402). Among the White non-Hispanic or Latino population with opioid dependence, 41.33% (95% CI: 38.27%–44.39%) were 29–38 years old. The next common age group among the White Non-Hispanic opioid dependent subjects was 19–28 years, comprising of 22.48% (95% CI: 19.88%–25.08%) of the total number of White non-Hispanic or Latino opioid dependent population. Among the total clinic population Hispanics comprise 51.24%, but they comprise only 2.58% (95% CI: 1.74%–3.42%) of the total opioid dependent population. The non-Hispanic population comprise 51.05% of total clinic population while the percent of people who are opioid dependent is 83.26% (95% CI: 83.04%–83.48%) of the total 1356 opioid dependent population. DISCUSSION/SIGNIFICANCE OF IMPACT: The trends of opioid dependence among the clinic population in the study indicate that the prevalence is more in a certain section of the population. The predominance is among the non-Hispanic White population in the 19–38 years of age. The prevalence in younger age implies that the complications related to opioid dependence would be there for a longer duration of time. The prevalence of dependence in this clinic population would be rising if this trend continues. Interventions at curbing prescription opioid dependence is necessary for the vulnerable population. The findings suggest that a broad based approach is necessary to address this problem. The distribution of opioid dependence in this patient population indicate the need for special attention to these specific age group and race ethnicities. The young age of many of the addicted patients demonstrate the risks of legitimate opioid prescriptions in leading this age group towards addiction and implies the need for routine screening for substance abuse. The evidence of complications of opioid overdose among long-term opioid users and risk of abuse with other agents including illicit agents makes the need for an approach that uses real-time interventions in addition to effect long-term improvement in addiction rates. A potentially cost-effective approach to implement monitoring programs and clinical decision support tools would be to develop inter operable linkage from the EHRs to the state Department of Healths’ prescription monitoring programs.",2018-05-10,2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:36:32,15,Suppl 1,1,J Clin Transl Sci,,PubMed Central,PMID:  PMCID: PMC6799651,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6799651/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
109,10.1021/acs.analchem.0c04698,33249827,PMC7807424,,,,"Rampler, Evelyn; Abiead, Yasin El; Schoeny, Harald; Rusz, Mate; Hildebrand, Felina; Fitz, Veronika; Koellensperger, Gunda","Recurrent Topics in Mass Spectrometry-Based Metabolomics and Lipidomics—Standardization, Coverage, and Throughput",2021,Analytical Chemistry,,,2021-01-12,2021-06-05 21:09:36,519-545,1,93,Anal Chem,,PubMed Central,PMID: 33249827 PMCID: PMC7807424,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7807424/,,,,PMC:Query2
110,10.1021/acs.jcim.0c00947,33245234,,A,,,"Matter, Hans; Buning, Christian; Stefanescu, Dan Dragos; Ruf, Sven; Hessler, Gerhard",Using Graph Databases to Investigate Trends in Structure-Activity Relationship Networks,2020,Journal of Chemical Information and Modeling,,"Mining the steadily increasing amount of chemical and biological data is a key challenge in drug discovery. Graph databases offer viable alternatives for capturing interrelationships between molecules and for generating novel insights for design. In a graph database, molecules and their properties are mapped to nodes, while relationships are described by edges. Here, we introduce a graph database for navigation in chemical space, analogue searching, and structure-activity relationship (SAR) analysis. We illustrate this concept using hERG channel inhibitors from ChEMBL to extract SAR knowledge. This graph database is built using different relationships, namely 2D-fingerprint similarity, matched molecular pairs, topomer distances, and structure-activity landscape indices (SALI). Typical applications include retrieving analogues linked by single or multiple edge paths to the query compound as well as detection of nonadditive SAR features. Finally, we identify triplets of linked molecules for clustering. The speed of searching and analysis allows the user to interactively navigate the database and to address complex questions in real-time.",2020-12-28,2021-06-05 21:06:22,6120-6134,12,60,J Chem Inf Model,,PubMed,PMID: 33245234,http://www.ncbi.nlm.nih.gov/pubmed/33245234,,,,PubMed:Query2
111,10.1021/acs.jcim.0c01280,33502186,,A,,,"Gimadiev, Timur; Nugmanov, Ramil; Batyrshin, Dinar; Madzhidov, Timur; Maeda, Satoshi; Sidorov, Pavel; Varnek, Alexandre",Combined Graph/Relational Database Management System for Calculated Chemical Reaction Pathway Data,2021,Journal of Chemical Information and Modeling,,"Presently, quantum chemical calculations are widely used to generate extensive data sets for machine learning applications; however, generally, these sets only include information on equilibrium structures and some close conformers. Exploration of potential energy surfaces provides important information on ground and transition states, but analysis of such data is complicated due to the number of possible reaction pathways. Here, we present RePathDB, a database system for managing 3D structural data for both ground and transition states resulting from quantum chemical calculations. Our tool allows one to store, assemble, and analyze reaction pathway data. It combines relational database CGR DB for handling compounds and reactions as molecular graphs with a graph database architecture for pathway analysis by graph algorithms. Original condensed graph of reaction technology is used to store any chemical reaction as a single graph.",2021-02-22,2021-06-05 21:06:22,554-559,2,61,J Chem Inf Model,,PubMed,PMID: 33502186,http://www.ncbi.nlm.nih.gov/pubmed/33502186,,,,PubMed:Query2
112,10.1021/acs.jcim.7b00589,29300482,PMC6063520,A,Neo4j,Neo4j,"Capuzzi, Stephen J.; Thornton, Thomas E.; Liu, Kammy; Baker, Nancy; Lam, Wai In; O’Banion, Colin P.; Muratov, Eugene N.; Pozefsky, Diane; Tropsha, Alexander",Chemotext: A Publicly-Available Web Server for Mining Drug-Target-Disease Relationships in PubMed,2018,Journal of chemical information and modeling,,"Elucidation of the mechanistic relationships between drugs, their targets, and diseases is at the core of modern drug discovery research. Thousands of studies relevant to the drug-target-disease (DTD) triangle have been published and annotated in the Medline/PubMed database. Mining this database affords rapid identification of all published studies that confirm connections between vertices of this triangle or enable new inferences of such connections. To this end, we describe the development of Chemotext, a publicly-available Web server that mines the entire compendium of published literature in PubMed annotated by Medline Subject Heading (MeSH) terms. The goal of Chemotext is to identify all known drug-target-disease relationships and infer missing links between vertices of the DTD triangle. As a proof-of-concept, we show that Chemotext could be instrumental in generating new drug repurposing hypotheses or annotating clinical outcomes pathways for known drugs. The Chemotext Web server is freely-available at http://chemotext.mml.unc.edu.,",2018-02-26,2021-06-05 20:55:40; 2021-06-05 21:11:16; 2021-06-05 20:36:32,212-218,2,58,J Chem Inf Model,Chemotext,PubMed Central,PMID: 29300482 PMCID: PMC6063520,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6063520/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
113,10.1021/acs.jmedchem.7b00809,28712298,,A,,,"Hall, Richard J.; Murray, Christopher W.; Verdonk, Marcel L.",The Fragment Network: A Chemistry Recommendation Engine Built Using a Graph Database,2017,Journal of Medicinal Chemistry,,"The hit validation stage of a fragment-based drug discovery campaign involves probing the SAR around one or more fragment hits. This often requires a search for similar compounds in a corporate collection or from commercial suppliers. The Fragment Network is a graph database that allows a user to efficiently search chemical space around a compound of interest. The result set is chemically intuitive, naturally grouped by substitution pattern and meaningfully sorted according to the number of observations of each transformation in medicinal chemistry databases. This paper describes the algorithms used to construct and search the Fragment Network and provides examples of how it may be used in a drug discovery context.",2017-07-27,2021-06-05 21:06:22,6440-6450,14,60,J Med Chem,The Fragment Network,PubMed,PMID: 28712298,http://www.ncbi.nlm.nih.gov/pubmed/28712298,"Databases, Chemical; Drug Discovery; Models, Molecular; Pharmaceutical Preparations; Protease Inhibitors; Proto-Oncogene Proteins c-akt; RNA Helicases; Small Molecule Libraries; Viral Nonstructural Proteins",,,PubMed:Query2
114,10.1021/acs.jmedchem.9b01989,32338900,PMC8007104,A,Neo4j,Neo4j,"Recanatini, Maurizio; Cabrelle, Chiara",Drug Research Meets Network Science: Where Are We?,2020,Journal of Medicinal Chemistry,,", Network theory provides one of the most potent analysis tools for the study of complex systems. In this paper, we illustrate the network-based perspective in drug research and how it is coherent with the new paradigm of drug discovery. We first present data sources from which networks are built, then show some examples of how the networks can be used to investigate drug-related systems. A section is devoted to network-based inference applications, i.e., prediction methods based on interactomes, that can be used to identify putative drug–target interactions without resorting to 3D modeling. Finally, we present some aspects of Boolean networks dynamics, anticipating that it might become a very potent modeling framework to develop in silico screening protocols able to simulate phenotypic screening experiments. We conclude that network applications integrated with machine learning and 3D modeling methods will become an indispensable tool for computational drug discovery in the next years.",2020-08-27,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,8653-8666,16,63,J Med Chem,Drug Research Meets Network Science,PubMed Central,PMID: 32338900 PMCID: PMC8007104,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8007104/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
115,10.1021/ci400368v,23991755,PMC3819714,A,OrientDB,OrientDB,"Menikarachchi, Lochana C.; Hill, Dennis W.; Hamdalla, Mai A.; Mandoiu, Ion I.; Grant, David F.","In silico enzymatic synthesis of a 400,000 compound biochemical database for non-targeted metabolomics",2013,Journal of chemical information and modeling,,"Current methods of structure identification in mass spectrometry based non-targeted metabolomics rely on matching experimentally determined features of an unknown compound to those of candidate compounds contained in biochemical databases. A major limitation of this approach is the relatively small number of compounds currently included in these databases. If the correct structure is not present in a database it cannot be identified, and if it cannot be identified it cannot be included in a database. Thus, there is an urgent need to augment metabolomics databases with rationally designed biochemical structures using alternative means. In this study, we present a database of in silico enzymatically synthesized metabolites (IIMDB) to partially address this problem. The database, which is available from http://metabolomics.pharm.uconn.edu/iimdb/, includes ~23,000 known compounds (mammalian metabolites, drugs, secondary plant metabolites and glycerophospholipids) collected from existing biochemical databases plus more than 400,000 computationally generated human phase I and phase II metabolites of these known compounds. The IIMDB database features a user-friendly web interface and a programmer-friendly RESTful web service. Ninety-five percent of the computationally generated metabolites in IIMDB were not found in any existing database. However, 21,640 were identical to compounds already listed in PubChem, HMDB, KEGG or HumanCyc. Furthermore, a vast majority of these in silico metabolites were scored as biological using BioSM, a software program that identifies biochemical structures in chemical structure space. These results suggest that in silico biochemical synthesis represents a viable approach for significantly augmenting biochemical databases for non-targeted metabolomics applications.",2013-09-23,2021-06-05 21:13:27; 2021-06-06 06:49:06; 2021-06-05 20:56:20,,9,53,J Chem Inf Model,,PubMed Central,PMID: 23991755 PMCID: PMC3819714,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3819714/,,OrientDB,OrientDB,PMC:Query3; PMC:Query2; PMC:OrientDB
116,10.1021/ci8002478,19072298,PMC2631088,,,,"Podolyan, Yevgeniy; Karypis, George",Common Pharmacophore Identification Using Frequent Clique Detection Algorithm,2009,Journal of chemical information and modeling,,"The knowledge of a pharmacophore, or the 3D arrangement of features in the biologically active molecule that is responsible for its pharmacological activity, can help in the search and design of a new or better drug acting upon the same or related target. In this paper we describe two new algorithms based on the frequent clique detection in the molecular graphs. The first algorithm mines all frequent cliques that are present in at least one of the conformers of each (or a portion of all) molecules. The second algorithm exploits the similarities among the different conformers of the same molecule and achieves an order of magnitude performance speedup compared to the first algorithm. Both algorithms are guaranteed to find all common pharmacophores in the dataset, which is confirmed by the validation on the set of molecules for which pharmacophores have been determined experimentally. In addition, these algorithms are able to scale to datasets with arbitrarily large number of conformers per molecule and identify multiple ligand binding modes or multiple binding sites of the target.",2009-01,2021-06-05 21:13:27,13-21,1,49,J Chem Inf Model,,PubMed Central,PMID: 19072298 PMCID: PMC2631088,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2631088/,,,,PMC:Query2
117,10.1021/jm100600y,20958049,PMC3438292,,,,"Hajjo, Rima; Grulke, Christopher; Golbraikh, Alexander; Setola, Vincent; Huang, Xi-Ping; Roth, Bryan L.; Tropsha, Alexander","The Development, Validation, and Use of Quantitative Structure Activity Relationship Models of 5-Hydroxytryptamine (2B) Receptor Ligands to Identify Novel Receptor Binders and Putative Valvulopathic Compounds among Common Drugs",2010,Journal of medicinal chemistry,,"Some antipsychotic drugs are known to cause valvular heart disease by activating serotonin 5-HT2B receptors. We have developed and validated binary classification QSAR models capable of predicting potential 5-HT2B binders. The classification accuracies of the models to discriminate 5-HT2B actives from the inactives were as high as 80% for the external test set. These models were used to screen in silico 59,000 compounds included in the World Drug Index and 122 compounds were predicted as actives with high confidence. Ten of them were tested in radioligand binding assays and nine were found active suggesting a success rate of 90%. All validated binders were then tested in functional assays and one compound was identified as a true 5-HT2B agonist. We suggest that the QSAR models developed in this study could be used as reliable predictors to flag drug candidates that are likely to cause valvulopathy.",2010-11-11,2021-06-05 21:13:27,7573-7586,21,53,J Med Chem,,PubMed Central,PMID: 20958049 PMCID: PMC3438292,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3438292/,,,,PMC:Query2
118,10.1021/pr400294c,23802565,PMC4034692,,,,"Woo, Sunghee; Cha, Seong Won; Merrihew, Gennifer; He, Yupeng; Castellana, Natalie; Guest, Clark; MacCoss, Michael; Bafna, Vineet",Proteogenomic database construction driven from large scale RNA-seq data,2014,Journal of Proteome Research; Journal of proteome research,,"The advent of inexpensive RNA-Seq technologies and other deep sequencing technologies for RNA has the promise to radically improve genomic annotation, providing information on transcribed regions and splicing events in a variety of cellular conditions. Using MS based proteogenomics, many of these events can be confirmed directly at the protein level. However, the integration of large amounts of redundant RNA-seq data and mass spectrometry data poses a challenging problem. Our manuscript addresses this by construction of a compact database that contains all useful information expressed in RNA-seq reads. Applying our method to cumulative C. elegans data reduced 496.2GB of aligned RNA-seq SAM files to 410MB of splice graph database written in FASTA format. This corresponds to 1000× compression of data size, without loss of sensitivity. We performed a proteogenomics study using the custom dataset, using a completely automated pipeline and identified a total of 4044 novel events, including 215 novel genes, 808 novel exons, 12 alternative splicings, 618 gene-boundary corrections, 245 exon-boundary changes, 938 frame-shifts, 1166 reverse-strands, and 42 translated UTR. Our results highlight the usefulness of transcript+proteomic integration for improved genome annotations.; The advent of inexpensive RNA-seq technologies and other deep sequencing technologies for RNA has the promise to radically improve genomic annotation, providing information on transcribed regions and splicing events in a variety of cellular conditions. Using MS-based proteogenomics, many of these events can be confirmed directly at the protein level. However, the integration of large amounts of redundant RNA-seq data and mass spectrometry data poses a challenging problem. Our paper addresses this by construction of a compact database that contains all useful information expressed in RNA-seq reads. Applying our method to cumulative C. elegans data reduced 496.2 GB of aligned RNA-seq SAM files to 410 MB of splice graph database written in FASTA format. This corresponds to 1000× compression of data size, without loss of sensitivity. We performed a proteogenomics study using the custom data set, using a completely automated pipeline, and identified a total of 4044 novel events, including 215 novel genes, 808 novel exons, 12 alternative splicings, 618 gene-boundary corrections, 245 exon-boundary changes, 938 frame shifts, 1166 reverse strands, and 42 translated UTRs. Our results highlight the usefulness of transcript + proteomic integration for improved genome annotations.",2014-01-03,2021-06-05 21:13:27; 2021-06-05 21:06:22,21-28,1,13,J Proteome Res,,PubMed; PubMed Central,PMID: 23802565 PMCID: PMC4034692,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4034692/; http://www.ncbi.nlm.nih.gov/pubmed/23802565,"Amino Acid Sequence; Animals; Automation; Caenorhabditis elegans; Databases, Genetic; Databases, Protein; Genome; Helminth Proteins; Molecular Sequence Data; Proteome; Sequence Analysis, RNA",,,PubMed:Query2; PMC:Query2
119,10.1021/pr501246w,25660940,,A,,,"Muth, Thilo; Behne, Alexander; Heyer, Robert; Kohrs, Fabian; Benndorf, Dirk; Hoffmann, Marcus; Lehtevä, Miro; Reichl, Udo; Martens, Lennart; Rapp, Erdmann",The MetaProteomeAnalyzer: a powerful open-source software suite for metaproteomics data analysis and interpretation,2015,Journal of Proteome Research,,"The enormous challenges of mass spectrometry-based metaproteomics are primarily related to the analysis and interpretation of the acquired data. This includes reliable identification of mass spectra and the meaningful integration of taxonomic and functional meta-information from samples containing hundreds of unknown species. To ease these difficulties, we developed a dedicated software suite, the MetaProteomeAnalyzer, an intuitive open-source tool for metaproteomics data analysis and interpretation, which includes multiple search engines and the feature to decrease data redundancy by grouping protein hits to so-called meta-proteins. We also designed a graph database back-end for the MetaProteomeAnalyzer to allow seamless analysis of results. The functionality of the MetaProteomeAnalyzer is demonstrated using a sample of a microbial community taken from a biogas plant.",2015-03-06,2021-06-05 21:06:22,1557-1565,3,14,J Proteome Res,The MetaProteomeAnalyzer,PubMed,PMID: 25660940,http://www.ncbi.nlm.nih.gov/pubmed/25660940,bioinformatics; Computer Graphics; environmental proteomics; mass spectrometry; Mass Spectrometry; metaproteomics; microbial communities; Proteome; software; Software,,,PubMed:Query2
120,10.1038/ncomms12585,27557562,PMC5007351,,,,"Pizzi, Giovanni; Gibertini, Marco; Dib, Elias; Marzari, Nicola; Iannaccone, Giuseppe; Fiori, Gianluca",Performance of arsenene and antimonene double-gate MOSFETs from first principles,2016,Nature Communications,,"In the race towards high-performance ultra-scaled devices, two-dimensional materials offer an alternative paradigm thanks to their atomic thickness suppressing short-channel effects. It is thus urgent to study the most promising candidates in realistic configurations, and here we present detailed multiscale simulations of field-effect transistors based on arsenene and antimonene monolayers as channels. The accuracy of first-principles approaches in describing electronic properties is combined with the efficiency of tight-binding Hamiltonians based on maximally localized Wannier functions to compute the transport properties of the devices. These simulations provide for the first time estimates on the upper limits for the electron and hole mobilities in the Takagi's approximation, including spin–orbit and multi-valley effects, and demonstrate that ultra-scaled devices in the sub-10-nm scale show a performance that is compliant with industry requirements.,  The family of two-dimensional materials is ever growing, and theoretical calculations are a useful tool to predict the suitability of emerging monolayers for electronic applications. Here, the authors perform accurate simulations of complete field-effect devices based on arsenene and antimonene.",2016-08-25,2021-06-05 21:12:01,,,7,Nat Commun,,PubMed Central,PMID: 27557562 PMCID: PMC5007351,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5007351/,,,,PMC:Query2
121,10.1038/s41422-019-0161-8,30940876,PMC6796856,,,,"Pelgrom, Leonard R.; Patente, Thiago A.; Sergushichev, Alexey; Esaulova, Ekaterina; Otto, Frank; Ozir-Fazalalikhan, Arifa; van der Zande, Hendrik J. P.; van der Ham, Alwin J.; van der Stel, Stefan; Artyomov, Maxim N.; Everts, Bart",LKB1 expressed in dendritic cells governs the development and expansion of thymus-derived regulatory T cells,2019,Cell Research,,"Liver Kinase B1 (LKB1) plays a key role in cellular metabolism by controlling AMPK activation. However, its function in dendritic cell (DC) biology has not been addressed. Here, we find that LKB1 functions as a critical brake on DC immunogenicity, and when lost, leads to reduced mitochondrial fitness and increased maturation, migration, and T cell priming of peripheral DCs. Concurrently, loss of LKB1 in DCs enhances their capacity to promote output of regulatory T cells (Tregs) from the thymus, which dominates the outcome of peripheral immune responses, as suggested by increased resistance to asthma and higher susceptibility to cancer in CD11cΔLKB1 mice. Mechanistically, we find that loss of LKB1 specifically primes thymic CD11b+ DCs to facilitate thymic Treg development and expansion, which is independent from AMPK signalling, but dependent on mTOR and enhanced phospholipase C β1-driven CD86 expression. Together, our results identify LKB1 as a critical regulator of DC-driven effector T cell and Treg responses both in the periphery and the thymus.",2019-05,2021-06-05 21:10:37,406-419,5,29,Cell Res,,PubMed Central,PMID: 30940876 PMCID: PMC6796856,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6796856/,,,,PMC:Query2
122,10.1038/s41431-019-0404-7,,PMC6778823,,,,,Abstracts from the 51st European Society of Human Genetics Conference: Posters,2019,European Journal of Human Genetics,,,2019-07,2021-06-05 21:10:37,1-688,Suppl 1,27,Eur J Hum Genet,Abstracts from the 51st European Society of Human Genetics Conference,PubMed Central,PMID:  PMCID: PMC6778823,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6778823/,,,,PMC:Query2
123,10.1038/s41431-019-0508-0,31527858,PMC6974615,A,OrientDB,OrientDB,"Nguengang Wakap, Stéphanie; Lambert, Deborah M.; Olry, Annie; Rodwell, Charlotte; Gueydan, Charlotte; Lanneau, Valérie; Murphy, Daniel; Le Cam, Yann; Rath, Ana",Estimating cumulative point prevalence of rare diseases: analysis of the Orphanet database,2020,European Journal of Human Genetics,,"Rare diseases, an emerging global public health priority, require an evidence-based estimate of the global point prevalence to inform public policy. We used the publicly available epidemiological data in the Orphanet database to calculate such a prevalence estimate. Overall, Orphanet contains information on 6172 unique rare diseases; 71.9% of which are genetic and 69.9% which are exclusively pediatric onset. Global point prevalence was calculated using rare disease prevalence data for predefined geographic regions from the ‘Orphanet Epidemiological file’ (http://www.orphadata.org/cgi-bin/epidemio.html). Of the 5304 diseases defined by point prevalence, 84.5% of those analysed have a point prevalence of <1/1 000 000. However 77.3–80.7% of the population burden of rare diseases is attributable to the 4.2% (n = 149) diseases in the most common prevalence range (1–5 per 10 000). Consequently national definitions of ‘Rare Diseases’ (ranging from prevalence of 5 to 80 per 100 000) represent a variable number of rare disease patients despite sharing the majority of rare disease in their scope. Our analysis yields a conservative, evidence-based estimate for the population prevalence of rare diseases of 3.5–5.9%, which equates to 263–446 million persons affected globally at any point in time. This figure is derived from data from 67.6% of the prevalent rare diseases; using the European definition of 5 per 10 000; and excluding rare cancers, infectious diseases, and poisonings. Future registry research and the implementation of rare disease codification in healthcare systems will further refine the estimates.",2020-02,2021-06-06 06:49:06; 2021-06-05 20:55:01; 2021-06-05 21:10:37,165-173,2,28,Eur J Hum Genet,Estimating cumulative point prevalence of rare diseases,PubMed Central,PMID: 31527858 PMCID: PMC6974615,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6974615/,,OrientDB,OrientDB,PMC:Query3; PMC:Query2; PMC:OrientDB
124,10.1038/s41467-018-04887-1,29930246,PMC6013493,,,,"Li, Xin; Collins, Liam; Miyazawa, Keisuke; Fukuma, Takeshi; Jesse, Stephen; Kalinin, Sergei V.",High-veracity functional imaging in scanning probe microscopy via Graph-Bootstrapping,2018,Nature Communications,,"The key objective of scanning probe microscopy (SPM) techniques is the optimal representation of the nanoscale surface structure and functionality inferred from the dynamics of the cantilever. This is particularly pertinent today, as the SPM community has seen a rapidly growing trend towards simultaneous capture of multiple imaging channels and complex modes of operation involving high-dimensional information-rich datasets, bringing forward the challenges of visualization and analysis, particularly for cases where the underlying dynamic model is poorly understood. To meet this challenge, we present a data-driven approach, Graph-Bootstrapping, based on low-dimensional manifold learning of the full SPM spectra and demonstrate its successes for high-veracity mechanical mapping on a mixed polymer thin film and resolving irregular hydration structure of calcite at atomic resolution. Using the proposed methodology, we can efficiently reveal and hierarchically represent salient material features with rich local details, further enabling denoising, classification, and high-resolution functional imaging., Scanning probe microscopy methods can generate high-dimensional data sets that correspond to a low-dimensional sample. Here, Li et al. develop a graphical bootstrapping method to quantitatively visualize large-scale high-dimensional datasets.",2018-06-21,2021-06-05 21:11:16,,,9,Nat Commun,,PubMed Central,PMID: 29930246 PMCID: PMC6013493,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6013493/,,,,PMC:Query2
125,10.1038/s41467-018-05544-3,30082872,PMC6079067,,,,"Huang, Jianfeng; Hörmann, Nicolas; Oveisi, Emad; Loiudice, Anna; De Gregorio, Gian Luca; Andreussi, Oliviero; Marzari, Nicola; Buonsanti, Raffaella",Potential-induced nanoclustering of metallic catalysts during electrochemical CO2 reduction,2018,Nature Communications,,"In catalysis science stability is as crucial as activity and selectivity. Understanding the degradation pathways occurring during operation and developing mitigation strategies will eventually improve catalyst design, thus facilitating the translation of basic science to technological applications. Herein, we reveal the unique and general degradation mechanism of metallic nanocatalysts during electrochemical CO2 reduction, exemplified by different sized copper nanocubes. We follow their morphological evolution during operation and correlate it with the electrocatalytic performance. In contrast with the most common coalescence and dissolution/precipitation mechanisms, we find a potential-driven nanoclustering to be the predominant degradation pathway. Grand-potential density functional theory calculations confirm the role of the negative potential applied to reduce CO2 as the main driving force for the clustering. This study offers a novel outlook on future investigations of stability and degradation reaction mechanisms of nanocatalysts in electrochemical CO2 reduction and, more generally, in electroreduction reactions., While the degradation of materials during usage is crucial in understanding their performance, it is challenging to understand the corrosion processes. Here, authors find copper nanoparticles to undergo an unusual potential-driven nanoclustering degradation pathway during carbon dioxide reduction.",2018-08-06,2021-06-05 21:11:16,,,9,Nat Commun,,PubMed Central,PMID: 30082872 PMCID: PMC6079067,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6079067/,,,,PMC:Query2
126,10.1038/s41467-019-11048-5,31316060,PMC6637138,,,,"Reisländer, Timo; Lombardi, Emilia Puig; Groelly, Florian J.; Miar, Ana; Porru, Manuela; Di Vito, Serena; Wright, Benjamin; Lockstone, Helen; Biroccio, Annamaria; Harris, Adrian; Londoño-Vallejo, Arturo; Tarsounas, Madalena",BRCA2 abrogation triggers innate immune responses potentiated by treatment with PARP inhibitors,2019,Nature Communications,,"Heterozygous germline mutations in BRCA2 predispose to breast and ovarian cancer. Contrary to non-cancerous cells, where BRCA2 deletion causes cell cycle arrest or cell death, tumors carrying BRCA2 inactivation continue to proliferate. Here we set out to investigate adaptation to loss of BRCA2 focusing on genome-wide transcriptome alterations. Human cells in which BRCA2 expression is inhibited for 4 or 28 days are subjected to RNA-seq analyses revealing a biphasic response to BRCA2 abrogation. The early, acute response consists of downregulation of genes involved in cell cycle progression, DNA replication and repair and is associated with cell cycle arrest in G1. Surprisingly, the late, chronic response consists predominantly of upregulation of interferon-stimulated genes (ISGs). Activation of the cGAS-STING-STAT pathway detected in these cells further substantiates the concept that BRCA2 abrogation triggers cell-intrinsic immune signaling. Importantly, we find that treatment with PARP inhibitors stimulates the interferon response in cells and tumors lacking BRCA2., BRCA2 plays important roles in cell physiology by promoting DNA replication and DNA double-strand breaks repair. Here the authors, reveal the impact of BRCA2 depletion on the cell transcriptional program with activation of the innate immune response that is potentiated by PARP inhibitor treatments.",2019-07-17,2021-06-05 21:10:37,,,10,Nat Commun,,PubMed Central,PMID: 31316060 PMCID: PMC6637138,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6637138/,,,,PMC:Query2
127,10.1038/s41467-019-11069-0,31292438,PMC6620318,A,Neo4j,Neo4j,"Nelson, Charlotte A.; Butte, Atul J.; Baranzini, Sergio E.",Integrating biomedical research and electronic health records to create knowledge-based biologically meaningful machine-readable embeddings,2019,Nature Communications,,"In order to advance precision medicine, detailed clinical features ought to be described in a way that leverages current knowledge. Although data collected from biomedical research is expanding at an almost exponential rate, our ability to transform that information into patient care has not kept at pace. A major barrier preventing this transformation is that multi-dimensional data collection and analysis is usually carried out without much understanding of the underlying knowledge structure. Here, in an effort to bridge this gap, Electronic Health Records (EHRs) of individual patients are connected to a heterogeneous knowledge network called Scalable Precision Medicine Oriented Knowledge Engine (SPOKE). Then an unsupervised machine-learning algorithm creates Propagated SPOKE Entry Vectors (PSEVs) that encode the importance of each SPOKE node for any code in the EHRs. We argue that these results, alongside the natural integration of PSEVs into any EHR machine-learning platform, provide a key step toward precision medicine., The Scalable Precision Medicine Oriented Knowledge Engine (SPOKE) is a heterogeneous knowledge network that integrates information from 29 public databases. Here, Nelson et al. extend SPOKE to embed clinical data from electronic health records to create medically meaningful barcodes for each medical variable.",2019-07-10,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,,,10,Nat Commun,,PubMed Central,PMID: 31292438 PMCID: PMC6620318,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6620318/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
128,10.1038/s41467-020-19177-y,33149111,PMC7642391,A,Neo4j,Neo4j,"Mishra, Vartika; Re, Diane B.; Le Verche, Virginia; Alvarez, Mariano J.; Vasciaveo, Alessandro; Jacquier, Arnaud; Doulias, Paschalis-Tomas; Greco, Todd M.; Nizzardo, Monica; Papadimitriou, Dimitra; Nagata, Tetsuya; Rinchetti, Paola; Perez-Torres, Eduardo J.; Politi, Kristin A.; Ikiz, Burcin; Clare, Kevin; Than, Manuel E.; Corti, Stefania; Ischiropoulos, Harry; Lotti, Francesco; Califano, Andrea; Przedborski, Serge",Systematic elucidation of neuron-astrocyte interaction in models of amyotrophic lateral sclerosis using multi-modal integrated bioinformatics workflow,2020,Nature Communications,,"Cell-to-cell communications are critical determinants of pathophysiological phenotypes, but methodologies for their systematic elucidation are lacking. Herein, we propose an approach for the Systematic Elucidation and Assessment of Regulatory Cell-to-cell Interaction Networks (SEARCHIN) to identify ligand-mediated interactions between distinct cellular compartments. To test this approach, we selected a model of amyotrophic lateral sclerosis (ALS), in which astrocytes expressing mutant superoxide dismutase-1 (mutSOD1) kill wild-type motor neurons (MNs) by an unknown mechanism. Our integrative analysis that combines proteomics and regulatory network analysis infers the interaction between astrocyte-released amyloid precursor protein (APP) and death receptor-6 (DR6) on MNs as the top predicted ligand-receptor pair. The inferred deleterious role of APP and DR6 is confirmed in vitro in models of ALS. Moreover, the DR6 knockdown in MNs of transgenic mutSOD1 mice attenuates the ALS-like phenotype. Our results support the usefulness of integrative, systems biology approach to gain insights into complex neurobiological disease processes as in ALS and posit that the proposed methodology is not restricted to this biological context and could be used in a variety of other non-cell-autonomous communication mechanisms., Neuron-astrocyte communication plays a key role in pathophysiology, however systematic approaches to unveil it are limited. Here, the authors propose SEARCHIN, a multi-modal integrated workflow, as a tool to identify cross-compartment ligand-receptor interactions, applied to ALS models.",2020-11-04,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,,11,Nat Commun,,PubMed Central,PMID: 33149111 PMCID: PMC7642391,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7642391/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
129,10.1038/s41467-021-21544-2,33627666,PMC7904840,A,Neo4j,Neo4j,"Zhang, Biyu; Tang, Chen; Yao, Yanli; Chen, Xiaohan; Zhou, Chi; Wei, Zhiting; Xing, Feiyang; Chen, Lan; Cai, Xiang; Zhang, Zhiyuan; Sun, Shuyang; Liu, Qi",The tumor therapy landscape of synthetic lethality,2021,Nature Communications,,"Synthetic lethality is emerging as an important cancer therapeutic paradigm, while the comprehensive selective treatment opportunities for various tumors have not yet been explored. We develop the Synthetic Lethality Knowledge Graph (SLKG), presenting the tumor therapy landscape of synthetic lethality (SL) and synthetic dosage lethality (SDL). SLKG integrates the large-scale entity of different tumors, drugs and drug targets by exploring a comprehensive set of SL and SDL pairs. The overall therapy landscape is prioritized to identify the best repurposable drug candidates and drug combinations with literature supports, in vitro pharmacologic evidence or clinical trial records. Finally, cladribine, an FDA-approved multiple sclerosis treatment drug, is selected and identified as a repurposable drug for treating melanoma with CDKN2A mutation by in vitro validation, serving as a demonstrating SLKG utility example for novel tumor therapy discovery. Collectively, SLKG forms the computational basis to uncover cancer-specific susceptibilities and therapy strategies based on the principle of synthetic lethality., Various methods have been proposed to identify synthetic lethality interactions, but selective treatment opportunities for various tumors have not yet been explored. Here, the authors develop the Synthetic Lethality Knowledge Graph webserver (SLKG, http://www.slkg.net) to explore the comprehensive tumor therapy landscape and uncover cancer-specific susceptibilities based on the principle of synthetic lethality.",2021-02-24,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,,12,Nat Commun,,PubMed Central,PMID: 33627666 PMCID: PMC7904840,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7904840/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
130,10.1038/s41540-018-0059-y,29872544,PMC5984630,A,Neo4j,Neo4j,"Mazein, Alexander; Ostaszewski, Marek; Kuperstein, Inna; Watterson, Steven; Le Novère, Nicolas; Lefaudeux, Diane; De Meulder, Bertrand; Pellet, Johann; Balaur, Irina; Saqi, Mansoor; Nogueira, Maria Manuela; He, Feng; Parton, Andrew; Lemonnier, Nathanaël; Gawron, Piotr; Gebel, Stephan; Hainaut, Pierre; Ollert, Markus; Dogrusoz, Ugur; Barillot, Emmanuel; Zinovyev, Andrei; Schneider, Reinhard; Balling, Rudi; Auffray, Charles",Systems medicine disease maps: community-driven comprehensive representation of disease mechanisms,2018,NPJ Systems Biology and Applications,,"The development of computational approaches in systems biology has reached a state of maturity that allows their transition to systems medicine. Despite this progress, intuitive visualisation and context-dependent knowledge representation still present a major bottleneck. In this paper, we describe the Disease Maps Project, an effort towards a community-driven computationally readable comprehensive representation of disease mechanisms. We outline the key principles and the framework required for the success of this initiative, including use of best practices, standards and protocols. We apply a modular approach to ensure efficient sharing and reuse of resources for projects dedicated to specific diseases. Community-wide use of disease maps will accelerate the conduct of biomedical research and lead to new disease ontologies defined from mechanism-based disease endotypes rather than phenotypes.",2018-06-02,2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:36:32,,,4,NPJ Syst Biol Appl,Systems medicine disease maps,PubMed Central,PMID: 29872544 PMCID: PMC5984630,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5984630/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
131,10.1038/s41586-020-2879-3,33149298,PMC7790857,A,Neo4j,Neo4j,"Özel, Mehmet Neset; Simon, Felix; Jafari, Shadi; Holguera, Isabel; Chen, Yen-Chung; Benhra, Najate; El-Danaf, Rana Naja; Kapuralin, Katarina; Malin, Jennifer Amy; Konstantinides, Nikolaos; Desplan, Claude",Neuronal diversity and convergence in a visual system developmental atlas,2021,Nature,,"Deciphering how neuronal diversity is established and maintained requires a detailed knowledge of neuronal gene expression throughout development. In contrast to mammalian brains,, the large neuronal diversity of the Drosophila optic lobes and its connectome– are almost completely characterized. However, a molecular characterization of this diversity, particularly during development, has been lacking. We present novel insights into brain development through a nearly exhaustive description of the transcriptomic diversity of the optic lobes. We acquired the transcriptome of 275,000 single-cells at adult and five pupal stages, and developed a machine learning framework to assign them to almost 200 cell-types at all timepoints. We discovered two large neuronal populations that wrap neuropils during development but die just before adulthood, as well as neuronal subtypes that partition dorsal and ventral visual circuits by differential Wnt signaling throughout development. Moreover, we showed that neurons of the same type but produced days apart synchronize their transcriptomes shortly after being produced. We also resolved during synaptogenesis neuronal subtypes that converge to indistinguishable transcriptomic profiles in adults while greatly differing in morphology and connectivity. Our datasets almost completely account for the known neuronal diversity of the optic lobes and serve as a paradigm to understand brain development across species.",2021-01,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36,88-95,7840,589,Nature,,PubMed Central,PMID: 33149298 PMCID: PMC7790857,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7790857/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
132,10.1038/s41597-020-00638-4,32901044,PMC7479590,,,,"Huber, Sebastiaan P.; Zoupanos, Spyros; Uhrin, Martin; Talirz, Leopold; Kahle, Leonid; Häuselmann, Rico; Gresch, Dominik; Müller, Tiziano; Yakutovich, Aliaksandr V.; Andersen, Casper W.; Ramirez, Francisco F.; Adorf, Carl S.; Gargiulo, Fernando; Kumbhar, Snehal; Passaro, Elsa; Johnston, Conrad; Merkys, Andrius; Cepellotti, Andrea; Mounet, Nicolas; Marzari, Nicola; Kozinsky, Boris; Pizzi, Giovanni","AiiDA 1.0, a scalable computational infrastructure for automated reproducible workflows and data provenance",2020,Scientific Data,,"The ever-growing availability of computing power and the sustained development of advanced computational methods have contributed much to recent scientific progress. These developments present new challenges driven by the sheer amount of calculations and data to manage. Next-generation exascale supercomputers will harden these challenges, such that automated and scalable solutions become crucial. In recent years, we have been developing AiiDA (aiida.net), a robust open-source high-throughput infrastructure addressing the challenges arising from the needs of automated workflow management and data provenance recording. Here, we introduce developments and capabilities required to reach sustained performance, with AiiDA supporting throughputs of tens of thousands processes/hour, while automatically preserving and storing the full data provenance in a relational database making it queryable and traversable, thus enabling high-performance data analytics. AiiDA’s workflow language provides advanced automation, error handling features and a flexible plugin model to allow interfacing with external simulation software. The associated plugin registry enables seamless sharing of extensions, empowering a vibrant user community dedicated to making simulations more robust, user-friendly and reproducible.",2020-09-08,2021-06-05 21:10:08,,,7,Sci Data,,PubMed Central,PMID: 32901044 PMCID: PMC7479590,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7479590/,,,,PMC:Query2
133,10.1038/s41597-020-00679-9,33046717,PMC7550340,A,Virtuoso,Virtuoso,"Chen, Chuming; Huang, Hongzhan; Ross, Karen E.; Cowart, Julie E.; Arighi, Cecilia N.; Wu, Cathy H.; Natale, Darren A.",Protein ontology on the semantic web for knowledge discovery,2020,Scientific Data,,"The Protein Ontology (PRO) provides an ontological representation of protein-related entities, ranging from protein families to proteoforms to complexes. Protein Ontology Linked Open Data (LOD) exposes, shares, and connects knowledge about protein-related entities on the Semantic Web using Resource Description Framework (RDF), thus enabling integration with other Linked Open Data for biological knowledge discovery. For example, proteins (or variants thereof) can be retrieved on the basis of specific disease associations. As a community resource, we strive to follow the Findability, Accessibility, Interoperability, and Reusability (FAIR) principles, disseminate regular updates of our data, support multiple methods for accessing, querying and downloading data in various formats, and provide documentation both for scientists and programmers. PRO Linked Open Data can be browsed via faceted browser interface and queried using SPARQL via YASGUI. RDF data dumps are also available for download. Additionally, we developed RESTful APIs to support programmatic data access. We also provide W3C HCLS specification compliant metadata description for our data. The PRO Linked Open Data is available at https://lod.proconsortium.org/.",2020-10-12,2021-06-05 20:54:31; 2021-06-05 20:59:14; 2021-06-05 21:09:36,,,7,Sci Data,,PubMed Central,PMID: 33046717 PMCID: PMC7550340,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7550340/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
134,10.1038/s41598-017-08848-4,28894088,PMC5593923,,,,"Peng, He; Liu, Zhihong; Yan, Xin; Ren, Jian; Xu, Jun",A de novo substructure generation algorithm for identifying the privileged chemical fragments of liver X receptorβ agonists,2017,Scientific Reports,,"Liver X receptorβ (LXRβ) is a promising therapeutic target for lipid disorders, atherosclerosis, chronic inflammation, autoimmunity, cancer and neurodegenerative diseases. Druggable LXRβ agonists have been explored over the past decades. However, the pocket of LXRβ ligand-binding domain (LBD) is too large to predict LXRβ agonists with novel scaffolds based on either receptor or agonist structures. In this paper, we report a de novo algorithm which drives privileged LXRβ agonist fragments by starting with individual chemical bonds (de novo) from every molecule in a LXRβ agonist library, growing the bonds into substructures based on the agonist structures with isomorphic and homomorphic restrictions, and electing the privileged fragments from the substructures with a popularity threshold and background chemical and biological knowledge. Using these privileged fragments as queries, we were able to figure out the rules to reconstruct LXRβ agonist molecules from the fragments. The privileged fragments were validated by building regularized logistic regression (RLR) and supporting vector machine (SVM) models as descriptors to predict a LXRβ agonist activities.",2017-09-11,2021-06-05 21:12:01,,,7,Sci Rep,,PubMed Central,PMID: 28894088 PMCID: PMC5593923,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5593923/,,,,PMC:Query2
135,10.1038/s41598-017-16674-x,29180758,PMC5703951,A,Neo4j,Neo4j,"Bean, Daniel M.; Wu, Honghan; Iqbal, Ehtesham; Dzahini, Olubanke; Ibrahim, Zina M.; Broadbent, Matthew; Stewart, Robert; Dobson, Richard J. B.",Knowledge graph prediction of unknown adverse drug reactions and validation in electronic health records,2017,Scientific Reports,,"Unknown adverse reactions to drugs available on the market present a significant health risk and limit accurate judgement of the cost/benefit trade-off for medications. Machine learning has the potential to predict unknown adverse reactions from current knowledge. We constructed a knowledge graph containing four types of node: drugs, protein targets, indications and adverse reactions. Using this graph, we developed a machine learning algorithm based on a simple enrichment test and first demonstrated this method performs extremely well at classifying known causes of adverse reactions (AUC 0.92). A cross validation scheme in which 10% of drug-adverse reaction edges were systematically deleted per fold showed that the method correctly predicts 68% of the deleted edges on average. Next, a subset of adverse reactions that could be reliably detected in anonymised electronic health records from South London and Maudsley NHS Foundation Trust were used to validate predictions from the model that are not currently known in public databases. High-confidence predictions were validated in electronic records significantly more frequently than random models, and outperformed standard methods (logistic regression, decision trees and support vector machines). This approach has the potential to improve patient safety by predicting adverse reactions that were not observed during randomised trials.",2017-11-27,2021-06-05 20:55:40; 2021-06-05 21:11:16; 2021-06-05 20:36:32,,,7,Sci Rep,,PubMed Central,PMID: 29180758 PMCID: PMC5703951,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5703951/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
136,10.1038/s41598-018-33498-5,30323202,PMC6189122,A,Neo4j,Neo4j,"Costa, Raquel L.; Boroni, Mariana; Soares, Marcelo A.",Distinct co-expression networks using multi-omic data reveal novel interventional targets in HPV-positive and negative head-and-neck squamous cell cancer,2018,Scientific Reports,,"The human papillomavirus (HPV) is present in a significant fraction of head-and-neck squamous cell cancer (HNSCC). The main goal of this study was to identify distinct co-expression patterns between HPV+ and HPV− HNSCC and to provide insights into potential regulatory mechanisms/effects within the analyzed networks. We selected cases deposited in The Cancer Genome Atlas database comprising data of gene expression, methylation profiles and mutational patterns, in addition to clinical information. The intersection among differentially expressed and differentially methylated genes showed the negative correlations between the levels of methylation and expression, suggesting that these genes have their expression levels regulated by methylation alteration patterns in their promoter. Weighted correlation network analysis was used to identify co-expression modules and a systematic approach was applied to refine them and identify key regulatory elements integrating results from the other omics. Three distinct co-expression modules were associated with HPV status and molecular signatures. Validation using independent studies reporting biological experimental data converged for the most significant genes in all modules. This study provides insights into complex genetic and epigenetic particularities in the development and progression of HNSCC according to HPV status, and contribute to unveiling specific genes/pathways as novel therapeutic targets in HNSCC.",2018-10-15,2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:36:32,,,8,Sci Rep,,PubMed Central,PMID: 30323202 PMCID: PMC6189122,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6189122/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
137,10.1038/s41598-019-43638-0,31073190,PMC6509164,A,Neo4j,Neo4j,"Di Benedetto, Paola; Panzera, Noemi; Cipriani, Paola; Mastroiaco, Valentina; Tessitore, Alessandra; Liakouli, Vasiliki; Ruscitti, Piero; Berardicurti, Onorina; Carubbi, Francesco; Guggino, Giuliana; Bianchi, Andrea; Di Marco, Antinisca; Ciccia, Francesco; Alesse, Edoardo; Giacomelli, Roberto","Mesenchymal stem cells of Systemic Sclerosis patients, derived from different sources, show a profibrotic microRNA profiling",2019,Scientific Reports,,"Systemic Sclerosis (SSc) is a disease with limited therapeutic possibilities. Mesenchymal stem cells (MSCs)-therapy could be a promising therapeutic option, however the ideal MSCs source has not yet been found. To address this problem, we perform comparison between bone marrow (BM)-MSCs and adipose (A)-MSCs, by the miRs expression profile, to identify the gene modulation in these two MSCs source. MicroRNAs (miRs) are RNAs sequences, regulating gene expression and MSCs, derived from different tissues, may differently respond to the SSc microenvironment. The miRs array was used for the miRs profiling and by DIANA-mirPath tool we identified the biological functions of the dysregulated miRs. In SSc-BM-MSCs, 6 miRs were significantly down-regulated and 4 miRs up-regulated. In SSc-A-MSCs, 11 miRs were significantly down-regulated and 3 miRs up-regulated. Interestingly, in both the sources, the involved pathways included the senescence mechanisms and the pro-fibrotic behaviour. Furthermore, both the MSCs sources showed potential compensatory ability. A deeper knowledge of this miRs signature might give more information about some pathogenic steps of the disease and in the same time clarify the possible therapeutic role of autologous MSCs in the regenerative therapy in SSc.",2019-05-09,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,,,9,Sci Rep,,PubMed Central,PMID: 31073190 PMCID: PMC6509164,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6509164/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
138,10.1038/s41598-020-75029-1,33093586,PMC7583304,,,,"Aguilera-Mendoza, Longendri; Marrero-Ponce, Yovani; García-Jacas, César R.; Chavez, Edgar; Beltran, Jesus A.; Guillen-Ramirez, Hugo A.; Brizuela, Carlos A.",Automatic construction of molecular similarity networks for visual graph mining in chemical space of bioactive peptides: an unsupervised learning approach,2020,Scientific Reports,,"The increasing interest in bioactive peptides with therapeutic potentials has been reflected in a large variety of biological databases published over the last years. However, the knowledge discovery process from these heterogeneous data sources is a nontrivial task, becoming the essence of our research endeavor. Therefore, we devise a unified data model based on molecular similarity networks for representing a chemical reference space of bioactive peptides, having an implicit knowledge that is currently not explicitly accessed in existing biological databases. Indeed, our main contribution is a novel workflow for the automatic construction of such similarity networks, enabling visual graph mining techniques to uncover new insights from the “ocean” of known bioactive peptides. The workflow presented here relies on the following sequential steps: (i) calculation of molecular descriptors by applying statistical and aggregation operators on amino acid property vectors; (ii) a two-stage unsupervised feature selection method to identify an optimized subset of descriptors using the concepts of entropy and mutual information; (iii) generation of sparse networks where nodes represent bioactive peptides, and edges between two nodes denote their pairwise similarity/distance relationships in the defined descriptor space; and (iv) exploratory analysis using visual inspection in combination with clustering and network science techniques. For practical purposes, the proposed workflow has been implemented in our visual analytics software tool (http://mobiosd-hub.com/starpep/), to assist researchers in extracting useful information from an integrated collection of 45120 bioactive peptides, which is one of the largest and most diverse data in its field. Finally, we illustrate the applicability of the proposed workflow for discovering central nodes in molecular similarity networks that may represent a biologically relevant chemical space known to date.",2020-10-22,2021-06-05 21:09:36,,,10,Sci Rep,Automatic construction of molecular similarity networks for visual graph mining in chemical space of bioactive peptides,PubMed Central,PMID: 33093586 PMCID: PMC7583304,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7583304/,,,,PMC:Query2
139,10.1038/s41598-021-90296-2,34040048,PMC8155020,,,,"Schultz, Bruce; Zaliani, Andrea; Ebeling, Christian; Reinshagen, Jeanette; Bojkova, Denisa; Lage-Rupprecht, Vanessa; Karki, Reagon; Lukassen, Sören; Gadiya, Yojana; Ravindra, Neal G.; Das, Sayoni; Baksi, Shounak; Domingo-Fernández, Daniel; Lentzen, Manuel; Strivens, Mark; Raschka, Tamara; Cinatl, Jindrich; DeLong, Lauren Nicole; Gribbon, Phil; Geisslinger, Gerd; Ciesek, Sandra; van Dijk, David; Gardner, Steve; Kodamullil, Alpha Tom; Fröhlich, Holger; Peitsch, Manuel; Jacobs, Marc; Hoeng, Julia; Eils, Roland; Claussen, Carsten; Hofmann-Apitius, Martin",A method for the rational selection of drug repurposing candidates from multimodal knowledge harmonization,2021,Scientific Reports,,"The SARS-CoV-2 pandemic has challenged researchers at a global scale. The scientific community’s massive response has resulted in a flood of experiments, analyses, hypotheses, and publications, especially in the field of drug repurposing. However, many of the proposed therapeutic compounds obtained from SARS-CoV-2 specific assays are not in agreement and thus demonstrate the need for a singular source of COVID-19 related information from which a rational selection of drug repurposing candidates can be made. In this paper, we present the COVID-19 PHARMACOME, a comprehensive drug-target-mechanism graph generated from a compilation of 10 separate disease maps and sources of experimental data focused on SARS-CoV-2/COVID-19 pathophysiology. By applying our systematic approach, we were able to predict the synergistic effect of specific drug pairs, such as Remdesivir and Thioguanosine or Nelfinavir and Raloxifene, on SARS-CoV-2 infection. Experimental validation of our results demonstrate that our graph can be used to not only explore the involved mechanistic pathways, but also to identify novel combinations of drug repurposing candidates.",2021-05-26,2021-06-05 21:09:36,,,11,Sci Rep,,PubMed Central,PMID: 34040048 PMCID: PMC8155020,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8155020/,,,,PMC:Query2
140,10.1038/s41684-018-0150-4,30224793,PMC6322546,A,Neo4j,Neo4j,"Howe, Douglas G.; Blake, Judith A.; Bradford, Yvonne M.; Bult, Carol J.; Calvi, Brian R.; Engel, Stacia R.; Kadin, James A.; Kaufman, Thom; Kishore, Ranjana; Laulederkind, Stanley J. F.; Lewis, Suzanna E.; Moxon, Sierra A. T.; Richardson, Joel E.; Smith, Cynthia",Model organism data evolving in support of translational medicine,2018,Lab animal,,"Model organism databases (MODs) have been collecting and integrating biomedical research data for 30 years and were designed to meet specific needs of each model organism research community. The contributions of model organism research to understanding biological systems would be hard to overstate. Modern molecular biology methods and cost reductions in nucleotide sequencing have opened avenues for direct application of model organism research to elucidating mechanisms of human diseases. Thus, the mandate for model organism research and databases has now grown to include facilitating use of these data in translational applications. Challenges in meeting this opportunity include the distribution of research data across many databases and websites, a lack of data format standards for some data types, and sustainability of scale and cost for genomic database resources like MODs. The issues of widely distributed data and application of data standards are some of the challenges addressed by FAIR data principles. The Alliance of Genome Resources is now moving to address these challenges by bringing together expertly curated research data from fly, mouse, rat, worm, yeast, zebrafish, and the Gene Ontology consortium. Centralized multi-species data access, integration, and format standardization will lower the data utilization barrier in comparative genomics and translational applications and will provide a framework in which sustainable scale and cost can be addressed. This article presents a brief historical perspective on how the Alliance model organisms are complimentary and how they have already contributed to understanding the etiology of human diseases. In addition, we discuss four challenges for using data from MODs in translational applications and how the Alliance is working to address them, in part by applying FAIR data principles. Ultimately, combined data from these animal models are more powerful than the sum of the parts.",2018-10,2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:36:32,277-289,10,47,Lab Anim (NY),,PubMed Central,PMID: 30224793 PMCID: PMC6322546,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6322546/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
141,10.1038/s41746-019-0162-5,31531395,PMC6736878,,,,"Kamdar, Maulik R.; Fernández, Javier D.; Polleres, Axel; Tudorache, Tania; Musen, Mark A.",Enabling Web-scale data integration in biomedicine through Linked Open Data,2019,NPJ Digital Medicine,,"The biomedical data landscape is fragmented with several isolated, heterogeneous data and knowledge sources, which use varying formats, syntaxes, schemas, and entity notations, existing on the Web. Biomedical researchers face severe logistical and technical challenges to query, integrate, analyze, and visualize data from multiple diverse sources in the context of available biomedical knowledge. Semantic Web technologies and Linked Data principles may aid toward Web-scale semantic processing and data integration in biomedicine. The biomedical research community has been one of the earliest adopters of these technologies and principles to publish data and knowledge on the Web as linked graphs and ontologies, hence creating the Life Sciences Linked Open Data (LSLOD) cloud. In this paper, we provide our perspective on some opportunities proffered by the use of LSLOD to integrate biomedical data and knowledge in three domains: (1) pharmacology, (2) cancer research, and (3) infectious diseases. We will discuss some of the major challenges that hinder the wide-spread use and consumption of LSLOD by the biomedical research community. Finally, we provide a few technical solutions and insights that can address these challenges. Eventually, LSLOD can enable the development of scalable, intelligent infrastructures that support artificial intelligence methods for augmenting human intelligence to achieve better clinical outcomes for patients, to enhance the quality of biomedical research, and to improve our understanding of living systems.",2019-09-10,2021-06-05 21:10:37,,,2,NPJ Digit Med,,PubMed Central,PMID: 31531395 PMCID: PMC6736878,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6736878/,,,,PMC:Query2
142,10.1038/s41746-020-0235-5,32140567,PMC7048845,A,Neo4j,Neo4j,"Woody, Stephen K; Burdick, David; Lapp, Hilmar; Huang, Erich S.",Application programming interfaces for knowledge transfer and generation in the life sciences and healthcare,2020,NPJ Digital Medicine,,"Storing very large amounts of data and delivering them to researchers in an efficient, verifiable, and compliant manner, is one of the major challenges faced by health care providers and researchers in the life sciences. The electronic health record (EHR) at a hospital or clinic currently functions as a silo, and although EHRs contain rich and abundant information that could be used to understand, improve, and learn from care as part learning health system access to these data is difficult, and the technical, legal, ethical, and social barriers are significant. If we create a microservice ecosystem where data can be accessed through APIs, these challenges become easier to overcome: a service-driven design decouples data from clients. This decoupling provides flexibility: different users can write in their preferred language and use different clients depending on their needs. APIs can be written for iOS apps, web apps, or an R library, and this flexibility highlights the potential ecosystem-building power of APIs. In this article, we use two case studies to illustrate what it means to participate in and contribute to interconnected ecosystems that powers APIs in a healthcare systems.",2020-02-28,2021-06-05 20:35:57; 2021-06-05 20:55:01; 2021-06-05 21:10:08,,,3,NPJ Digit Med,,PubMed Central,PMID: 32140567 PMCID: PMC7048845,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7048845/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
143,10.1038/s42003-018-0076-9,30271948,PMC6123781,,,,"Carbonell, Pablo; Jervis, Adrian J.; Robinson, Christopher J.; Yan, Cunyu; Dunstan, Mark; Swainston, Neil; Vinaixa, Maria; Hollywood, Katherine A.; Currin, Andrew; Rattray, Nicholas J. W.; Taylor, Sandra; Spiess, Reynard; Sung, Rehana; Williams, Alan R.; Fellows, Donal; Stanford, Natalie J.; Mulherin, Paul; Le Feuvre, Rosalind; Barran, Perdita; Goodacre, Royston; Turner, Nicholas J.; Goble, Carole; Chen, George Guoqiang; Kell, Douglas B.; Micklefield, Jason; Breitling, Rainer; Takano, Eriko; Faulon, Jean-Loup; Scrutton, Nigel S.",An automated Design-Build-Test-Learn pipeline for enhanced microbial production of fine chemicals,2018,Communications Biology,,"The microbial production of fine chemicals provides a promising biosustainable manufacturing solution that has led to the successful production of a growing catalog of natural products and high-value chemicals. However, development at industrial levels has been hindered by the large resource investments required. Here we present an integrated Design–Build-Test–Learn (DBTL) pipeline for the discovery and optimization of biosynthetic pathways, which is designed to be compound agnostic and automated throughout. We initially applied the pipeline for the production of the flavonoid (2S)-pinocembrin in Escherichia coli, to demonstrate rapid iterative DBTL cycling with automation at every stage. In this case, application of two DBTL cycles successfully established a production pathway improved by 500-fold, with competitive titers up to 88 mg L−1. The further application of the pipeline to optimize an alkaloids pathway demonstrates how it could facilitate the rapid optimization of microbial strains for production of any chemical compound of interest., Pablo Carbonell et al. present an automated pipeline for the discovery and optimization of biosynthetic pathways for microbial production of fine chemicals. They apply their pipeline to the production of the flavonoid (2S)-pinocembrin in Escherichia coli and show improvement of the pathway by 500-fold.",2018-06-08,2021-06-05 21:11:16,,,1,Commun Biol,,PubMed Central,PMID: 30271948 PMCID: PMC6123781,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6123781/,,,,PMC:Query2
144,10.1038/sdata.2018.99,29809172,PMC5972674,A,Neo4j,Neo4j,"Aryani, Amir; Poblet, Marta; Unsworth, Kathryn; Wang, Jingbo; Evans, Ben; Devaraju, Anusuriya; Hausstein, Brigitte; Klas, Claus-Peter; Zapilko, Benjamin; Kaplun, Samuele",A Research Graph dataset for connecting research data repositories using RD-Switchboard,2018,Scientific Data,,"This paper describes the open access graph dataset that shows the connections between Dryad, CERN, ANDS and other international data repositories to publications and grants across multiple research data infrastructures. The graph dataset was created using the Research Graph data model and the Research Data Switchboard (RD-Switchboard), a collaborative project by the Research Data Alliance DDRI Working Group (DDRI WG) with the aim to discover and connect the related research datasets based on publication co-authorship or jointly funded grants. The graph dataset allows researchers to trace and follow the paths to understanding a body of work. By mapping the links between research datasets and related resources, the graph dataset improves both their discovery and visibility, while avoiding duplicate efforts in data creation. Ultimately, the linked datasets may spur novel ideas, facilitate reproducibility and re-use in new applications, stimulate combinatorial creativity, and foster collaborations across institutions.",2018-05-29,2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:36:32,,,5,Sci Data,,PubMed Central,PMID: 29809172 PMCID: PMC5972674,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5972674/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
145,10.1038/srep19820,26804977,PMC4726433,A,Neo4j,Neo4j,"Saunders, Colleen J.; Jalali Sefid Dashti, Mahjoubeh; Gamieldien, Junaid",Semantic interrogation of a multi knowledge domain ontological model of tendinopathy identifies four strong candidate risk genes,2016,Scientific Reports,,"Tendinopathy is a multifactorial syndrome characterised by tendon pain and thickening, and impaired performance during activity. Candidate gene association studies have identified genetic factors that contribute to intrinsic risk of developing tendinopathy upon exposure to extrinsic factors. Bioinformatics approaches that data-mine existing knowledge for biological relationships may assist with the identification of candidate genes. The aim of this study was to data-mine functional annotation of human genes and identify candidate genes by ontology-seeded queries capturing the features of tendinopathy. Our BioOntological Relationship Graph database (BORG) integrates multiple sources of genomic and biomedical knowledge into an on-disk semantic network where human genes and their orthologs in mouse and rat are central concepts mapped to ontology terms. The BORG was used to screen all human genes for potential links to tendinopathy. Following further prioritisation, four strong candidate genes (COL11A2, ELN, ITGB3, LOX) were identified. These genes are differentially expressed in tendinopathy, functionally linked to features of tendinopathy and previously implicated in other connective tissue diseases. In conclusion, cross-domain semantic integration of multiple sources of biomedical knowledge, and interrogation of phenotypes and gene functions associated with disease, may significantly increase the probability of identifying strong and unobvious candidate genes in genetic association studies.",2016-01-25,2021-06-05 20:55:40; 2021-06-05 21:06:22; 2021-06-05 21:12:40; 2021-06-05 20:37:08,19820,,6,Sci Rep,,PubMed; PubMed Central,PMID: 26804977 PMCID: PMC4726433,http://www.ncbi.nlm.nih.gov/pubmed/26804977; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4726433/,"Animals; Collagen Type XI; Computational Biology; Databases, Factual; Genetic Association Studies; Genetic Predisposition to Disease; Genome, Human; Humans; Integrin beta3; Mice; Molecular Sequence Annotation; Rats; Scavenger Receptors, Class E; Semantics; Tendinopathy; Tendons",Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PubMed:Query2; PMC:Query2
146,10.1038/srep31356,27515999,PMC4981870,A,Neo4j,Neo4j,"Liu, Qi; Ding, Changjun; Chu, Yanguang; Chen, Jiafei; Zhang, Weixi; Zhang, Bingyu; Huang, Qinjun; Su, Xiaohua",PoplarGene: poplar gene network and resource for mining functional information for genes from woody plants,2016,Scientific Reports,,"Poplar is not only an important resource for the production of paper, timber and other wood-based products, but it has also emerged as an ideal model system for studying woody plants. To better understand the biological processes underlying various traits in poplar, e.g., wood development, a comprehensive functional gene interaction network is highly needed. Here, we constructed a genome-wide functional gene network for poplar (covering ~70% of the 41,335 poplar genes) and created the network web service PoplarGene, offering comprehensive functional interactions and extensive poplar gene functional annotations. PoplarGene incorporates two network-based gene prioritization algorithms, neighborhood-based prioritization and context-based prioritization, which can be used to perform gene prioritization in a complementary manner. Furthermore, the co-functional information in PoplarGene can be applied to other woody plant proteomes with high efficiency via orthology transfer. In addition to poplar gene sequences, the webserver also accepts Arabidopsis reference gene as input to guide the search for novel candidate functional genes in PoplarGene. We believe that PoplarGene (http://bioinformatics.caf.ac.cn/PoplarGene and http://124.127.201.25/PoplarGene) will greatly benefit the research community, facilitating studies of poplar and other woody plants.",2016-08-12,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:37:08,,,6,Sci Rep,PoplarGene,PubMed Central,PMID: 27515999 PMCID: PMC4981870,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4981870/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
147,10.1038/tp.2014.139,25646593,PMC4445744,,,,"Hunsberger, J G; Chibane, F L; Elkahloun, A G; Henderson, R; Singh, R; Lawson, J; Cruceanu, C; Nagarajan, V; Turecki, G; Squassina, A; Medeiros, C D; Del Zompo, M; Rouleau, G A; Alda, M; Chuang, D-M",Novel integrative genomic tool for interrogating lithium response in bipolar disorder,2015,Translational Psychiatry,,"We developed a novel integrative genomic tool called GRANITE (Genetic Regulatory Analysis of Networks Investigational Tool Environment) that can effectively analyze large complex data sets to generate interactive networks. GRANITE is an open-source tool and invaluable resource for a variety of genomic fields. Although our analysis is confined to static expression data, GRANITE has the capability of evaluating time-course data and generating interactive networks that may shed light on acute versus chronic treatment, as well as evaluating dose response and providing insight into mechanisms that underlie therapeutic versus sub-therapeutic doses or toxic doses. As a proof-of-concept study, we investigated lithium (Li) response in bipolar disorder (BD). BD is a severe mood disorder marked by cycles of mania and depression. Li is one of the most commonly prescribed and decidedly effective treatments for many patients (responders), although its mode of action is not yet fully understood, nor is it effective in every patient (non-responders). In an in vitro study, we compared vehicle versus chronic Li treatment in patient-derived lymphoblastoid cells (LCLs) (derived from either responders or non-responders) using both microRNA (miRNA) and messenger RNA gene expression profiling. We present both Li responder and non-responder network visualizations created by our GRANITE analysis in BD. We identified by network visualization that the Let-7 family is consistently downregulated by Li in both groups where this miRNA family has been implicated in neurodegeneration, cell survival and synaptic development. We discuss the potential of this analysis for investigating treatment response and even providing clinicians with a tool for predicting treatment response in their patients, as well as for providing the industry with a tool for identifying network nodes as targets for novel drug discovery.",2015-02,2021-06-05 21:12:40,e504,2,5,Transl Psychiatry,,PubMed Central,PMID: 25646593 PMCID: PMC4445744,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4445744/,,,,PMC:Query2
148,10.1039/C6GC01836J,28630595,PMC5473635,,,,"Alves, Vinicius M.; Capuzzi, Stephen J.; Muratov, Eugene; Braga, Rodolpho C.; Thornton, Thomas; Fourches, Denis; Strickland, Judy; Kleinstreuer, Nicole; Andrade, Carolina H.; Tropsha, Alexander",QSAR models of human data can enrich or replace LLNA testing for human skin sensitization,2016,Green chemistry : an international journal and green chemistry resource : GC,,"Skin sensitization is a major environmental and occupational health hazard. Although many chemicals have been evaluated in humans, there have been no efforts to model these data to date. We have compiled, curated, analyzed, and compared the available human and LLNA data. Using these data, we have developed reliable computational models and applied them for virtual screening of chemical libraries to identify putative skin sensitizers. The overall concordance between murine LLNA and human skin sensitization responses for a set of 135 unique chemicals was low (R = 28-43%), although several chemical classes had high concordance. We have succeeded to develop predictive QSAR models of all available human data with the external correct classification rate of 71%. A consensus model integrating concordant QSAR predictions and LLNA results afforded a higher CCR of 82% but at the expense of the reduced external dataset coverage (52%). We used the developed QSAR models for virtual screening of CosIng database and identified 1061 putative skin sensitizers; for seventeen of these compounds, we found published evidence of their skin sensitization effects. Models reported herein provide more accurate alternative to LLNA testing for human skin sensitization assessment across diverse chemical data. In addition, they can also be used to guide the structural optimization of toxic compounds to reduce their skin sensitization potential.",2016-12-21,2021-06-05 21:12:01,6501-6515,24,18,Green Chem,,PubMed Central,PMID: 28630595 PMCID: PMC5473635,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5473635/,,,,PMC:Query2
149,10.1039/c3np20111b,23447050,PMC3629923,A,Neo4j,Neo4j,"Hur, Manhoi; Campbell, Alexis Ann; Almeida-de-Macedo, Marcia; Li, Ling; Ransom, Nick; Jose, Adarsh; Crispin, Matt; Nikolau, Basil J.; Wurtele, Eve Syrkin",A global approach to analysis and interpretation of metabolic data for plant natural product discovery,2013,Natural product reports,,"Discovering molecular components and their functionality is key to the development of hypotheses concerning the organization and regulation of metabolic networks. The iterative experimental testing of such hypotheses is the trajectory that can ultimately enable accurate computational modelling and prediction of metabolic outcomes. This information can be particularly important for understanding the biology of natural products, whose metabolism itself is often only poorly defined. Here, we describe factors that must be in place to optimize the use of metabolomics in predictive biology. A key to achieving this vision is a collection of accurate time-resolved and spatially defined metabolite abundance data and associated metadata. One formidable challenge associated with metabolite profiling is the complexity and analytical limits associated with comprehensively determining the metabolome of an organism. Further, for metabolomics data to be efficiently used by the research community, it must be curated in publically available metabolomics databases. Such databases require clear, consistent formats, easy access to data and metadata, data download, and accessible computational tools to integrate genome system-scale datasets. Although transcriptomics and proteomics integrate the linear predictive power of the genome, the metabolome represents the nonlinear, final biochemical products of the genome, which results from the intricate system(s) that regulate genome expression. For example, the relationship of metabolomics data to the metabolic network is confounded by redundant connections between metabolites and gene-products. However, connections among metabolites are predictable through the rules of chemistry. Therefore, enhancing the ability to integrate the metabolome with anchor-points in the transcriptome and proteome will enhance the predictive power of genomics data. We detail a public database repository for metabolomics, tools and approaches for statistical analysis of metabolomics data, and methods for integrating these dataset with transcriptomic data to create hypotheses concerning specialized metabolism that generates the diversity in natural product chemistry. We discuss the importance of close collaborations among biologists, chemists, computer scientists and statisticians throughout the development of such integrated metabolism-centric databases and software.",2013-04,2021-06-05 21:13:27; 2021-06-05 20:56:20; 2021-06-05 20:37:08,565-583,4,30,Nat Prod Rep,,PubMed Central,PMID: 23447050 PMCID: PMC3629923,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3629923/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
150,10.1039/c7md00465f,30108724,PMC6072506,A,Neo4j,Neo4j,"Keefer, Christopher E.; Chang, George",The use of matched molecular series networks for cross target structure activity relationship translation and potency prediction,2017,MedChemComm,,"Matched molecular series (MMS) network for PDE2A, DGAT1, and HCV showing the relationships between shared MMS/target combinations., Matched molecular series (MMS) analysis is an extension of matched molecular pair (MMP) analysis where all of the MMPs belong to the same chemical series. An MMS within a biological assay is able to capture specific structure activity relationships resulting from chemical substitution at a single location in the molecule. Under this convention, an MMS has the ability to capture one specific interaction vector between the compounds in a series and their therapeutic target. MMS analysis has the potential to translate the SAR from one series to another even across different protein targets or assays. A significant limitation of this approach is the lack of chemical series with a sufficient number of overlapping fragments to establish a statistically strong SAR in most databases. This results in either an inability to perform MMS analysis altogether or a potentially high proportion of spurious matches from chance correlations when the MMS compound count is low. This paper presents the novel concept of an MMS Network, which captures the SAR relationships between a set of related MMSs and significantly enhances the performance of MMS analysis by reducing the number of spurious matches leading to the identification of unexpected and potentially transferable SAR across assays. The results of a full retrospective leave-one-out analysis and randomization simulation are provided, and examples of pharmaceutically relevant programs will be presented to demonstrate the potential of this method.",2017-10-11,2021-06-05 20:55:40; 2021-06-05 21:11:16; 2021-06-05 20:36:32,2067-2078,11,8,Medchemcomm,,PubMed Central,PMID: 30108724 PMCID: PMC6072506,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6072506/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
151,10.1039/d0md00375a,34041484,PMC8130625,,,,"St. Denis, Jeffrey D.; Hall, Richard J.; Murray, Christopher W.; Heightman, Tom D.; Rees, David C.",Fragment-based drug discovery: opportunities for organic synthesis,,RSC Medicinal Chemistry,,"This Review describes the increasing demand for organic synthesis to facilitate fragment-based drug discovery (FBDD), focusing on polar, unprotected fragments. In FBDD, X-ray crystal structures are used to design target molecules for synthesis with new groups added onto a fragment via specific growth vectors. This requires challenging synthesis which slows down drug discovery, and some fragments are not progressed into optimisation due to synthetic intractability. We have evaluated the output from Astex's fragment screenings for a number of programs, including urokinase-type plasminogen activator, hematopoietic prostaglandin D2 synthase, and hepatitis C virus NS3 protease-helicase, and identified fragments that were not elaborated due, in part, to a lack of commercially available analogues and/or suitable synthetic methodology. This represents an opportunity for the development of new synthetic research to enable rapid access to novel chemical space and fragment optimisation., Herein is described the concept of fragment sociability and the opportunities for organic chemistry to address the challenges of fragment elaboration.",,2021-06-05 21:09:36,321-329,3,12,RSC Med Chem,Fragment-based drug discovery,PubMed Central,PMID: 34041484 PMCID: PMC8130625,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8130625/,,,,PMC:Query2
152,10.1049/iet-syb.2015.0009,26997662,PMC4804358,,,,"Wang, Haizhou; Leung, Ming; Wandinger-Ness, Angela; Hudson, Laurie G.; Song, Mingzhou",Constrained inference of protein interaction networks for invadopodium formation in cancer,2016,IET systems biology,,"Integrating prior molecular network knowledge into interpretation of new experimental data is routine practice in biology research. However, a dilemma for deciphering interactome using Bayes’ rule is the demotion of novel interactions with low prior probabilities. Here we present constrained generalized logical network (CGLN) inference to predict novel interactions in dynamic networks, respecting previously known interactions and observed temporal coherence. It encodes prior interactions as probabilistic logic rules called local constraints, and forms global constraints using observed dynamic patterns. CGLN finds constraint-satisfying trajectories by solving a k-stops problem in the state space of dynamic networks and then reconstructs candidate networks. We benchmarked CGLN on randomly generated networks, and CGLN outperformed its alternatives when 50% or more interactions in a network are given as local constraints. CGLN is then applied to infer dynamic protein interaction networks regulating invadopodium formation in motile cancer cells. CGLN predicted 134 novel protein interactions for their involvement in invadopodium formation. The most frequently predicted interactions center around focal adhesion kinase (FAK) and tyrosine kinase substrate TKS4, and 14 interactions are supported by literature in molecular contexts related to invadopodium formation. As an alternative to the Bayesian paradigm, the CGLN method offers constrained network inference without requiring prior probabilities and thus can promote novel interactions, consistent with the discovery process of scientific facts that are not yet in common beliefs.",2016-04,2021-06-05 21:12:40,76-85,2,10,IET Syst Biol,,PubMed Central,PMID: 26997662 PMCID: PMC4804358,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4804358/,,,,PMC:Query2
153,10.1055/s-0039-1677933,31419827,PMC6697514,,,,"Dhombres, Ferdinand; Charlet, Jean; Dhombres, Ferdinand; Charlet, Jean; Section Editors for the IMIA Yearbook Section on Knowledge Representation and Management","Formal Medical Knowledge Representation Supports Deep Learning Algorithms, Bioinformatics Pipelines, Genomics Data Analysis, and Big Data Processes",2019,Yearbook of Medical Informatics,,"OBJECTIVE: To select, present, and summarize the best papers published in 2018 in the field of Knowledge Representation and Management (KRM). METHODS: A comprehensive and standardized review of the medical informatics literature was performed to select the most interesting papers published in 2018 in KRM, based on PubMed and ISI Web Of Knowledge queries. RESULTS: Four best papers were selected among the 962 publications retrieved following the Yearbook review process. The research areas in 2018 were mainly related to the ontology-based data integration for phenotype-genotype association mining, the design of ontologies and their application, and the semantic annotation of clinical texts. CONCLUSION: In the KRM selection for 2018, research on semantic representations demonstrated their added value for enhanced deep learning approaches in text mining and for designing novel bioinformatics pipelines based on graph databases. In addition, the ontology structure can enrich the analyses of whole genome expression data. Finally, semantic representations demonstrated promising results to process phenotypic big data.; Objective : To select, present, and summarize the best papers published in 2018 in the field of Knowledge Representation and Management (KRM). ,  Methods : A comprehensive and standardized review of the medical informatics literature was performed to select the most interesting papers published in 2018 in KRM, based on PubMed and ISI Web Of Knowledge queries. ,  Results : Four best papers were selected among the 962 publications retrieved following the Yearbook review process. The research areas in 2018 were mainly related to the ontology-based data integration for phenotype-genotype association mining, the design of ontologies and their application, and the semantic annotation of clinical texts. ,  Conclusion : In the KRM selection for 2018, research on semantic representations demonstrated their added value for enhanced deep learning approaches in text mining and for designing novel bioinformatics pipelines based on graph databases. In addition, the ontology structure can enrich the analyses of whole genome expression data. Finally, semantic representations demonstrated promising results to process phenotypic big data.",2019-08,2021-06-05 21:10:37; 2021-06-05 21:06:22,152-155,1,28,Yearb Med Inform,,PubMed; PubMed Central,PMID: 31419827 PMCID: PMC6697514,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6697514/; http://www.ncbi.nlm.nih.gov/pubmed/31419827,Artificial Intelligence; Big Data; Biological Ontologies; Computational Biology; Data Analysis; Data Mining; Deep Learning; Genetic Association Studies; Genomics; Knowledge Management; Semantics,,,PubMed:Query2; PMC:Query2
154,10.1073/pnas.1423041112,26385966,PMC4611642,A,Neo4j,Neo4j,"Hinchliff, Cody E.; Smith, Stephen A.; Allman, James F.; Burleigh, J. Gordon; Chaudhary, Ruchi; Coghill, Lyndon M.; Crandall, Keith A.; Deng, Jiabin; Drew, Bryan T.; Gazis, Romina; Gude, Karl; Hibbett, David S.; Katz, Laura A.; Laughinghouse, H. Dail; McTavish, Emily Jane; Midford, Peter E.; Owen, Christopher L.; Ree, Richard H.; Rees, Jonathan A.; Soltis, Douglas E.; Williams, Tiffani; Cranston, Karen A.",Synthesis of phylogeny and taxonomy into a comprehensive tree of life,2015,Proceedings of the National Academy of Sciences of the United States of America,,"Scientists have used gene sequences and morphological data to construct tens of thousands of evolutionary trees that describe the evolutionary history of animals, plants, and microbes. This study is the first, to our knowledge, to apply an efficient and automated process for assembling published trees into a complete tree of life. This tree and the underlying data are available to browse and download from the Internet, facilitating subsequent analyses that require evolutionary trees. The tree can be easily updated with newly published data. Our analysis of coverage not only reveals gaps in sampling and naming biodiversity but also further demonstrates that most published phylogenies are not available in digital formats that can be summarized into a tree of life., Reconstructing the phylogenetic relationships that unite all lineages (the tree of life) is a grand challenge. The paucity of homologous character data across disparately related lineages currently renders direct phylogenetic inference untenable. To reconstruct a comprehensive tree of life, we therefore synthesized published phylogenies, together with taxonomic classifications for taxa never incorporated into a phylogeny. We present a draft tree containing 2.3 million tips—the Open Tree of Life. Realization of this tree required the assembly of two additional community resources: (i) a comprehensive global reference taxonomy and (ii) a database of published phylogenetic trees mapped to this taxonomy. Our open source framework facilitates community comment and contribution, enabling the tree to be continuously updated when new phylogenetic and taxonomic data become digitally available. Although data coverage and phylogenetic conflict across the Open Tree of Life illuminate gaps in both the underlying data available for phylogenetic reconstruction and the publication of trees as digital objects, the tree provides a compelling starting point for community contribution. This comprehensive tree will fuel fundamental research on the nature of biological diversity, ultimately providing up-to-date phylogenies for downstream applications in comparative biology, ecology, conservation biology, climate change, agriculture, and genomics.",2015-10-13,2021-06-05 20:55:40; 2021-06-05 21:12:40; 2021-06-05 20:37:08,12764-12769,41,112,Proc Natl Acad Sci U S A,,PubMed Central,PMID: 26385966 PMCID: PMC4611642,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4611642/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
155,10.1073/pnas.1909145117,31871210,PMC6955372,,,,"Winkler, Ivana; Bitter, Catrin; Winkler, Sebastian; Weichenhan, Dieter; Thavamani, Abhishek; Hengstler, Jan G.; Borkham-Kamphorst, Erawan; Kohlbacher, Oliver; Plass, Christoph; Geffers, Robert; Weiskirchen, Ralf; Nordheim, Alfred",Identification of Pparγ-modulated miRNA hubs that target the fibrotic tumor microenvironment,2020,Proceedings of the National Academy of Sciences of the United States of America,,"Liver fibrosis interferes with normal organ function and supports tumor development in the liver. We uncovered a role of miRNAs in controlling liver fibrosis. In a comprehensive and systematic analysis we specify miRNA activities in targeting the fibrotic cellular microenvironment of the liver, in both mice and humans. We reveal and validate a complex network of 8 functionally connected miRNAs and 54 target genes to regulate structural, signaling, and remodeling components of the fibrotic extracellular matrix. We identify expression of this miRNA network to be controlled by the transcription factor Pparγ. Thus, we expand the antifibrotic function of Pparγ to controlling the synthesis of an antifibrotic miRNA network. This network may serve as a therapeutic target in antifibrotic therapies., Liver fibrosis interferes with normal liver function and facilitates hepatocellular carcinoma (HCC) development, representing a major threat to human health. Here, we present a comprehensive perspective of microRNA (miRNA) function on targeting the fibrotic microenvironment. Starting from a murine HCC model, we identify a miRNA network composed of 8 miRNA hubs and 54 target genes. We show that let-7, miR-30, miR-29c, miR-335, and miR-338 (collectively termed antifibrotic microRNAs [AF-miRNAs]) down-regulate key structural, signaling, and remodeling components of the extracellular matrix. During fibrogenic transition, these miRNAs are transcriptionally regulated by the transcription factor Pparγ and thus we identify a role of Pparγ as regulator of a functionally related class of AF-miRNAs. The miRNA network is active in human HCC, breast, and lung carcinomas, as well as in 2 independent mouse liver fibrosis models. Therefore, we identify a miRNA:mRNA network that contributes to formation of fibrosis in tumorous and nontumorous organs of mice and humans.",2020-01-07,2021-06-05 21:10:08,454-463,1,117,Proc Natl Acad Sci U S A,,PubMed Central,PMID: 31871210 PMCID: PMC6955372,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6955372/,,,,PMC:Query2
156,10.1073/pnas.1911030117,32123073,PMC7084093,,,,"Seshadhri, C.; Sharma, Aneesh; Stolman, Andrew; Goel, Ashish",The impossibility of low-rank representations for triangle-rich complex networks,2020,Proceedings of the National Academy of Sciences of the United States of America,,"Our main message is that the popular method of low-dimensional embeddings provably cannot capture important properties of real-world complex networks. A widely used algorithmic technique for modeling these networks is to construct a low-dimensional Euclidean embedding of the vertices of the network, where proximity of vertices is interpreted as the likelihood of an edge. Contrary to common wisdom, we argue that such graph embeddings do not capture salient properties of complex networks. We mathematically prove that low-dimensional embeddings cannot generate graphs with both low average degree and large clustering coefficients, which have been widely established to be empirically true for real-world networks. This establishes that popular low-dimensional embedding methods fail to capture significant structural aspects of real-world complex networks., The study of complex networks is a significant development in modern science, and has enriched the social sciences, biology, physics, and computer science. Models and algorithms for such networks are pervasive in our society, and impact human behavior via social networks, search engines, and recommender systems, to name a few. A widely used algorithmic technique for modeling such complex networks is to construct a low-dimensional Euclidean embedding of the vertices of the network, where proximity of vertices is interpreted as the likelihood of an edge. Contrary to the common view, we argue that such graph embeddings do not capture salient properties of complex networks. The two properties we focus on are low degree and large clustering coefficients, which have been widely established to be empirically true for real-world networks. We mathematically prove that any embedding (that uses dot products to measure similarity) that can successfully create these two properties must have a rank that is nearly linear in the number of vertices. Among other implications, this establishes that popular embedding techniques such as singular value decomposition and node2vec fail to capture significant structural aspects of real-world complex networks. Furthermore, we empirically study a number of different embedding techniques based on dot product, and show that they all fail to capture the triangle structure.",2020-03-17,2021-06-05 21:10:08,5631-5637,11,117,Proc Natl Acad Sci U S A,,PubMed Central,PMID: 32123073 PMCID: PMC7084093,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7084093/,,,,PMC:Query2
157,10.1073/pnas.1915516117,32522881,PMC7322065,,,,"Ma, Yifang; Mukherjee, Satyam; Uzzi, Brian",Mentorship and protégé success in STEM fields,2020,Proceedings of the National Academy of Sciences of the United States of America,,"Mentorship is arguably a scientist’s most significant collaborative relationship; yet of all collaborations, comparatively little research exists on the link between mentorship and protégé success. Using new large-scale data from the genealogical and performance records of 10s of thousands of scientists worldwide from 1960 to the present, we found that mentorship is associated with diverse forms of protégé success, significantly increasing protégés’ chances of producing celebrated research, being inducted into the National Academy of Science, and achieving superstardom. Paradoxically, protégés achieve their highest impact when they display intellectual independence from their mentors. Protégés do their best work when they break from their mentor’s research topics and coauthor no more than a small portion of their overall research with their mentors., Einstein believed that mentors are especially influential in a protégé’s intellectual development, yet the link between mentorship and protégé success remains a mystery. We marshaled genealogical data on nearly 40,000 scientists who published 1,167,518 papers in biomedicine, chemistry, math, or physics between 1960 and 2017 to investigate the relationship between mentorship and protégé achievement. In our data, we find groupings of mentors with similar records and reputations who attracted protégés of similar talents and expected levels of professional success. However, each grouping has an exception: One mentor has an additional hidden capability that can be mentored to their protégés. They display skill in creating and communicating prizewinning research. Because the mentor’s ability for creating and communicating celebrated research existed before the prize’s conferment, protégés of future prizewinning mentors can be uniquely exposed to mentorship for conducting celebrated research. Our models explain 34–44% of the variance in protégé success and reveals three main findings. First, mentorship strongly predicts protégé success across diverse disciplines. Mentorship is associated with a 2×-to-4× rise in a protégé’s likelihood of prizewinning, National Academy of Science (NAS) induction, or superstardom relative to matched protégés. Second, mentorship is significantly associated with an increase in the probability of protégés pioneering their own research topics and being midcareer late bloomers. Third, contrary to conventional thought, protégés do not succeed most by following their mentors’ research topics but by studying original topics and coauthoring no more than a small fraction of papers with their mentors.",2020-06-23,2021-06-05 21:10:08,14077-14083,25,117,Proc Natl Acad Sci U S A,,PubMed Central,PMID: 32522881 PMCID: PMC7322065,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7322065/,,,,PMC:Query2
158,10.1073/pnas.2003270117,33262283,PMC7749302,,,,"zu Ermgassen, Erasmus K. H. J.; Godar, Javier; Lathuillière, Michael J.; Löfgren, Pernilla; Gardner, Toby; Vasconcelos, André; Meyfroidt, Patrick","The origin, supply chain, and deforestation risk of Brazil’s beef exports",2020,Proceedings of the National Academy of Sciences of the United States of America,,"The trade in agricultural commodities is a mainstay of the globalized economy, though the complex nature of commodity supply chains makes it difficult to identify the origin of and impact embedded in products. We brought together detailed data on trade, agriculture, and logistics to produce a subnational map of the origin of Brazil’s exports of beef, offal, and live cattle. Brazil is the world’s largest beef exporter, exporting one-fifth of its total production, and the sector is a major driver of deforestation. We traced cattle from 2,800 municipalities through to 152 importing countries, via thousands of companies handling their export and import. Our work gives an unprecedented insight into the origin of food and impacts embedded in global supply chains., Though the international trade in agricultural commodities is worth more than $1.6 trillion/year, we still have a poor understanding of the supply chains connecting places of production and consumption and the socioeconomic and environmental impacts of this trade. In this study, we provide a wall-to-wall subnational map of the origin and supply chain of Brazilian meat, offal, and live cattle exports from 2015 to 2017, a trade worth more than $5.4 billion/year. Brazil is the world’s largest beef exporter, exporting approximately one-fifth of its production, and the sector has a notable environmental footprint, linked to one-fifth of all commodity-driven deforestation across the tropics. By combining official per-shipment trade records, slaughterhouse export licenses, subnational agricultural statistics, and data on the origin of cattle per slaughterhouse, we mapped the flow of cattle from more than 2,800 municipalities where cattle were raised to 152 exporting slaughterhouses where they were slaughtered, via the 204 exporting and 3,383 importing companies handling that trade, and finally to 152 importing countries. We find stark differences in the subnational origin of the sourcing of different actors and link this supply chain mapping to spatially explicit data on cattle-associated deforestation, to estimate the “deforestation risk” (in hectares/year) of each supply chain actor over time. Our results provide an unprecedented insight into the global trade of a deforestation-risk commodity and demonstrate the potential for improved supply chain transparency based on currently available data.",2020-12-15,2021-06-05 21:09:36,31770-31779,50,117,Proc Natl Acad Sci U S A,,PubMed Central,PMID: 33262283 PMCID: PMC7749302,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7749302/,,,,PMC:Query2
159,10.1074/jbc.RA118.004452,30139745,PMC6177588,,,,"Kumaraswamy, Anbarasu; Mamidi, Anitha; Desai, Pavitra; Sivagnanam, Ananthi; Perumalsamy, Lakshmi Revathi; Ramakrishnan, Chandrasekaran; Gromiha, Michael; Rajalingam, Krishnaraj; Mahalingam, Sundarasamy",The non-enzymatic RAS effector RASSF7 inhibits oncogenic c-Myc function,2018,The Journal of Biological Chemistry,,"c-Myc is a proto-oncogene controlling expression of multiple genes involved in cell growth and differentiation. Although the functional role of c-Myc as a transcriptional regulator has been intensively studied, targeting this protein in cancer remains a challenge. Here, we report a trimodal regulation of c-Myc function by the Ras effector, Ras-association domain family member 7 (RASSF7), a nonenzymatic protein modulating protein–protein interactions to regulate cell proliferation. Using HEK293T and HeLa cell lines, we provide evidence that RASSF7 destabilizes the c-Myc protein by promoting Cullin4B-mediated polyubiquitination and degradation. Furthermore, RASSF7 competed with MYC-associated factor X (MAX) in the formation of a heterodimeric complex with c-Myc and attenuated its occupancy on target gene promoters to regulate transcription. Consequently, RASSF7 inhibited c-Myc–mediated oncogenic transformation, and an inverse correlation between the expression levels of the RASSF7 and c-Myc genes was evident in human cancers. Furthermore, we found that RASSF7 interacts with c-Myc via its RA and leucine zipper (LZ) domains and LZ domain peptide is sufficient to inhibit c-Myc function, suggesting that this peptide might be used to target oncogenic c-Myc. These results unveil that RASSF7 and c-Myc are functionally linked in the control of tumorigenesis and open up potential therapeutic avenues for targeting the “undruggable” c-Myc protein in a subset of human cancers.",2018-10-05,2021-06-05 21:11:16,15691-15705,40,293,J Biol Chem,,PubMed Central,PMID: 30139745 PMCID: PMC6177588,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6177588/,,,,PMC:Query2
160,10.1074/mcp.M114.038299,25060758,PMC4223501,,,,"Kelkar, Dhanashree S.; Provost, Elayne; Chaerkady, Raghothama; Muthusamy, Babylakshmi; Manda, Srikanth S.; Subbannayya, Tejaswini; Selvan, Lakshmi Dhevi N.; Wang, Chieh-Huei; Datta, Keshava K.; Woo, Sunghee; Dwivedi, Sutopa B.; Renuse, Santosh; Getnet, Derese; Huang, Tai-Chung; Kim, Min-Sik; Pinto, Sneha M.; Mitchell, Christopher J.; Madugundu, Anil K.; Kumar, Praveen; Sharma, Jyoti; Advani, Jayshree; Dey, Gourav; Balakrishnan, Lavanya; Syed, Nazia; Nanjappa, Vishalakshi; Subbannayya, Yashwanth; Goel, Renu; Keshava Prasad, T. S.; Bafna, Vineet; Sirdeshmukh, Ravi; Gowda, Harsha; Wang, Charles; Leach, Steven D.; Pandey, Akhilesh",Annotation of the Zebrafish Genome through an Integrated Transcriptomic and Proteomic Analysis,2014,Molecular & Cellular Proteomics : MCP,,"Accurate annotation of protein-coding genes is one of the primary tasks upon the completion of whole genome sequencing of any organism. In this study, we used an integrated transcriptomic and proteomic strategy to validate and improve the existing zebrafish genome annotation. We undertook high-resolution mass-spectrometry-based proteomic profiling of 10 adult organs, whole adult fish body, and two developmental stages of zebrafish (SAT line), in addition to transcriptomic profiling of six organs. More than 7,000 proteins were identified from proteomic analyses, and ∼69,000 high-confidence transcripts were assembled from the RNA sequencing data. Approximately 15% of the transcripts mapped to intergenic regions, the majority of which are likely long non-coding RNAs. These high-quality transcriptomic and proteomic data were used to manually reannotate the zebrafish genome. We report the identification of 157 novel protein-coding genes. In addition, our data led to modification of existing gene structures including novel exons, changes in exon coordinates, changes in frame of translation, translation in annotated UTRs, and joining of genes. Finally, we discovered four instances of genome assembly errors that were supported by both proteomic and transcriptomic data. Our study shows how an integrative analysis of the transcriptome and the proteome can extend our understanding of even well-annotated genomes.",2014-11,2021-06-05 21:12:40,3184-3198,11,13,Mol Cell Proteomics,,PubMed Central,PMID: 25060758 PMCID: PMC4223501,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4223501/,,,,PMC:Query2
161,10.1074/mcp.M114.047126,26560066,PMC4762527,,,,"Kumar, Dhirendra; Yadav, Amit Kumar; Jia, Xinying; Mulvenna, Jason; Dash, Debasis",Integrated Transcriptomic-Proteomic Analysis Using a Proteogenomic Workflow Refines Rat Genome Annotation,2016,Molecular & Cellular Proteomics : MCP,,"Proteogenomic re-annotation and mRNA splicing information can lead to the discovery of various protein forms for eukaryotic model organisms like rat. However, detection of novel proteoforms using mass spectrometry proteomics data remains a formidable challenge. We developed EuGenoSuite, an open source multiple algorithmic proteomic search tool and utilized it in our in-house integrated transcriptomic-proteomic pipeline to facilitate automated proteogenomic analysis. Using four proteogenomic pipelines (integrated transcriptomic-proteomic, Peppy, Enosi, and ProteoAnnotator) on publicly available RNA-sequence and MS proteomics data, we discovered 363 novel peptides in rat brain microglia representing novel proteoforms for 249 gene loci in the rat genome. These novel peptides aided in the discovery of novel exons, translation of annotated untranslated regions, pseudogenes, and splice variants for various loci; many of which have known disease associations, including neurological disorders like schizophrenia, amyotrophic lateral sclerosis, etc. Novel isoforms were also discovered for genes implicated in cardiovascular diseases and breast cancer for which rats are considered model organisms. Our integrative multi-omics data analysis not only enables the discovery of new proteoforms but also generates an improved reference for human disease studies in the rat model.",2016-01,2021-06-05 21:12:40,329-339,1,15,Mol Cell Proteomics,,PubMed Central,PMID: 26560066 PMCID: PMC4762527,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4762527/,,,,PMC:Query2
162,10.1074/mcp.RA117.000397,29046389,PMC5724175,,,,"Cha, Seong Won; Bonissone, Stefano; Na, Seungjin; Pevzner, Pavel A.; Bafna, Vineet",The Antibody Repertoire of Colorectal Cancer,2017,Molecular & Cellular Proteomics : MCP,,"Immunotherapy is becoming increasingly important in the fight against cancers, using and manipulating the body's immune response to treat tumors. Understanding the immune repertoire—the collection of immunological proteins—of treated and untreated cells is possible at the genomic, but technically difficult at the protein level. Standard protein databases do not include the highly divergent sequences of somatic rearranged immunoglobulin genes, and may lead to miss identifications in a mass spectrometry search. We introduce a novel proteogenomic approach, AbScan, to identify these highly variable antibody peptides, by developing a customized antibody database construction method using RNA-seq reads aligned to immunoglobulin (Ig) genes., AbScan starts by filtering transcript (RNA-seq) reads that match the template for Ig genes. The retained reads are used to construct a repertoire graph using the “split” de Bruijn graph: a graph structure that improves on the standard de Bruijn graph to capture the high diversity of Ig genes in a compact manner. AbScan corrects for sequencing errors, and converts the graph to a format suitable for searching with MS/MS search tools. We used AbScan to create an antibody database from 90 RNA-seq colorectal tumor samples. Next, we used proteogenomic analysis to search MS/MS spectra of matched colorectal samples from the Clinical Proteomic Tumor Analysis Consortium (CPTAC) against the AbScan generated database. AbScan identified 1,940 distinct antibody peptides. Correlating with previously identified Single Amino-Acid Variants (SAAVs) in the tumor samples, we identified 163 pairs (antibody peptide, SAAV) with significant cooccurrence pattern in the 90 samples. The presence of coexpressed antibody and mutated peptides was correlated with survival time of the individuals. Our results suggest that AbScan (https://github.com/csw407/AbScan.git) is an effective tool for a proteomic exploration of the immune response in cancers.",2017-12,2021-06-05 21:11:16,2111-2124,12,16,Mol Cell Proteomics,,PubMed Central,PMID: 29046389 PMCID: PMC5724175,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5724175/,,,,PMC:Query2
163,10.1080/15476286.2015.1068496,26383775,PMC4615630,A,Neo4j,Neo4j,"Preusse, Martin; Marr, Carsten; Saunders, Sita; Maticzka, Daniel; Lickert, Heiko; Backofen, Rolf; Theis, Fabian",SimiRa: A tool to identify coregulation between microRNAs and RNA-binding proteins,2015,RNA Biology,,"microRNAs and microRNA-independent RNA-binding proteins are 2 classes of post-transcriptional regulators that have been shown to cooperate in gene-expression regulation. We compared the genome-wide target sets of microRNAs and RBPs identified by recent CLIP-Seq technologies, finding that RBPs have distinct target sets and favor gene interaction network hubs. To identify microRNAs and RBPs with a similar functional context, we developed simiRa, a tool that compares enriched functional categories such as pathways and GO terms. We applied simiRa to the known functional cooperation between Pumilio family proteins and miR-221/222 in the regulation of tumor supressor gene p27 and show that the cooperation is reflected by similar enriched categories but not by target genes. SimiRa also predicts possible cooperation of microRNAs and RBPs beyond direct interaction on the target mRNA for the nuclear RBP TAF15. To further facilitate research into cooperation of microRNAs and RBPs, we made simiRa available as a web tool that displays the functional neighborhood and similarity of microRNAs and RBPs: http://vsicb-simira.helmholtz-muenchen.de.",2015-09-18,2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-05 20:37:08,998-1009,9,12,RNA Biol,SimiRa,PubMed Central,PMID: 26383775 PMCID: PMC4615630,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4615630/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
164,10.1080/17460441.2016.1216967,27454129,PMC5045798,A,Virtuoso,Virtuoso,"Kim, Sunghwan",Getting the Most out of PubChem for Virtual Screening,2016,Expert opinion on drug discovery,,"Introduction With the emergence of the “big data” era, the biomedical research community has great interest in exploiting publicly available chemical information for drug discovery. PubChem is an example of public databases that provide a large amount of chemical information free of charge. Areas covered This article provides an overview of how PubChem’s data, tools, and services can be used for virtual screening and reviews recent publications that discuss important aspects of exploiting PubChem for drug discovery. Expert opinion PubChem offers comprehensive chemical information useful for drug discovery. It also provides multiple programmatic access routes, which are essential to build automated virtual screening pipelines that exploit PubChem data. In addition, PubChemRDF allows users to download PubChem data and load them into a local computing facility, facilitating data integration between PubChem and other resources. PubChem resources have been used in many studies for developing bioactivity and toxicity prediction models, discovering polypharmacologic (multi-target) ligands, and identifying new macromolecule targets of compounds (for drug-repurposing or off-target side effect prediction). These studies demonstrate the usefulness of PubChem as a key resource for computer-aided drug discovery and related area.",2016-09,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:59:14,843-855,9,11,Expert Opin Drug Discov,,PubMed Central,PMID: 27454129 PMCID: PMC5045798,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5045798/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
165,10.1089/big.2014.0068,25553272,PMC4276119,,,,"Hendler, James",Data Integration for Heterogenous Datasets,2014,Big Data,,"More and more, the needs of data analysts are requiring the use of data outside the control of their own organizations. The increasing amount of data available on the Web, the new technologies for linking data across datasets, and the increasing need to integrate structured and unstructured data are all driving this trend. In this article, we provide a technical overview of the emerging “broad data” area, in which the variety of heterogeneous data being used, rather than the scale of the data being analyzed, is the limiting factor in data analysis efforts. The article explores some of the emerging themes in data discovery, data integration, linked data, and the combination of structured and unstructured data.",2014-12-01,2021-06-05 21:12:40,205-215,4,2,Big Data,,PubMed Central,PMID: 25553272 PMCID: PMC4276119,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4276119/,,,,PMC:Query2
166,10.1089/big.2017.0012,28328252,PMC5374868,,,,"Huang, Lifu; May, Jonathan; Pan, Xiaoman; Ji, Heng; Ren, Xiang; Han, Jiawei; Zhao, Lin; Hendler, James A.",Liberal Entity Extraction: Rapid Construction of Fine-Grained Entity Typing Systems,2017,Big Data,,"The ability of automatically recognizing and typing entities in natural language without prior knowledge (e.g., predefined entity types) is a major challenge in processing such data. Most existing entity typing systems are limited to certain domains, genres, and languages. In this article, we propose a novel unsupervised entity-typing framework by combining symbolic and distributional semantics. We start from learning three types of representations for each entity mention: general semantic representation, specific context representation, and knowledge representation based on knowledge bases. Then we develop a novel joint hierarchical clustering and linking algorithm to type all mentions using these representations. This framework does not rely on any annotated data, predefined typing schema, or handcrafted features; therefore, it can be quickly adapted to a new domain, genre, and/or language. Experiments on genres (news and discussion forum) show comparable performance with state-of-the-art supervised typing systems trained from a large amount of labeled data. Results on various languages (English, Chinese, Japanese, Hausa, and Yoruba) and domains (general and biomedical) demonstrate the portability of our framework.",2017-03-01,2021-06-05 21:12:01,19-31,1,5,Big Data,Liberal Entity Extraction,PubMed Central,PMID: 28328252 PMCID: PMC5374868,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5374868/,,,,PMC:Query2
167,10.1089/cmb.2016.0095,27627442,,A,,,"Balaur, Irina; Saqi, Mansoor; Barat, Ana; Lysenko, Artem; Mazein, Alexander; Rawlings, Christopher J.; Ruskin, Heather J.; Auffray, Charles",EpiGeNet: A Graph Database of Interdependencies Between Genetic and Epigenetic Events in Colorectal Cancer,2017,Journal of Computational Biology: A Journal of Computational Molecular Cell Biology,,"The development of colorectal cancer (CRC)-the third most common cancer type-has been associated with deregulations of cellular mechanisms stimulated by both genetic and epigenetic events. StatEpigen is a manually curated and annotated database, containing information on interdependencies between genetic and epigenetic signals, and specialized currently for CRC research. Although StatEpigen provides a well-developed graphical user interface for information retrieval, advanced queries involving associations between multiple concepts can benefit from more detailed graph representation of the integrated data. This can be achieved by using a graph database (NoSQL) approach. Data were extracted from StatEpigen and imported to our newly developed EpiGeNet, a graph database for storage and querying of conditional relationships between molecular (genetic and epigenetic) events observed at different stages of colorectal oncogenesis. We illustrate the enhanced capability of EpiGeNet for exploration of different queries related to colorectal tumor progression; specifically, we demonstrate the query process for (i) stage-specific molecular events, (ii) most frequently observed genetic and epigenetic interdependencies in colon adenoma, and (iii) paths connecting key genes reported in CRC and associated events. The EpiGeNet framework offers improved capability for management and visualization of data on molecular events specific to CRC initiation and progression.",2017-10,2021-06-05 21:06:22,969-980,10,24,J Comput Biol,EpiGeNet,PubMed,PMID: 27627442,http://www.ncbi.nlm.nih.gov/pubmed/27627442,"colorectal cancer; Colorectal Neoplasms; Computational Biology; computational molecular biology; Computer Graphics; Databases, Factual; Epigenesis, Genetic; epigenetics; Gene Regulatory Networks; graph database; Humans; molecular interdependencies; networks; Software",,,PubMed:Query2
168,10.1089/cmb.2020.0231,32783648,,A,,,"Thapa, Ishwor; Ali, Hesham",A Multiomics Graph Database System for Biological Data Integration and Cancer Informatics,2021,Journal of Computational Biology: A Journal of Computational Molecular Cell Biology,,"The multiomics data are heterogeneous and come from different biological levels such as epigenetics, genomics, transcriptomics and proteomics. The development of high-throughput technologies has enabled researchers not only to study all the entities together but also to utilize information from different levels spanning DNA methylation, copy number variation (CNV), mutation, gene expression, and miRNA expression. With the recent advancement in image informatics, the field of radiomics is rapidly emerging. It can be expected that the information from microscopic images of the tissue will soon be part of many multiomics studies. Meanwhile, integration of different kinds of multiomics data to extract relevant biological information is currently a big challenge. This study is our ongoing effort to develop a model that properly integrates multiomics data and allows easy retrieval of information relevant to biological processes. In this article, we have enriched our previous graph database model to store gene expression, miRNA expression, DNA methylation, mutation, CNV, clinical data, including information of the image of tissue slides. To show that the model is working, we used data from the Cancer Genome Atlas for three cancer types.",2021-02,2021-06-05 21:06:22,209-219,2,28,J Comput Biol,,PubMed,PMID: 32783648,http://www.ncbi.nlm.nih.gov/pubmed/32783648,cancer informatics; data integration; graph database; multiomics,,,PubMed:Query2
169,10.1093/advances/nmaa057,32504536,PMC7490154,A,Neo4j,Neo4j,"Yang, Chen; Hawwash, Dana; De Baets, Bernard; Bouwman, Jildau; Lachat, Carl",Perspective: Towards Automated Tracking of Content and Evidence Appraisal of Nutrition Research,2020,"Advances in Nutrition (Bethesda, Md.)",,"Robust recommendations for healthy diets and nutrition require careful synthesis of available evidence. Given the increasing volume of research articles generated, the retrieval and synthesis of evidence are increasingly becoming laborious and time-consuming. Information technology could help to reduce workload for humans. To guide supervised learning however, human identification of key study characteristics is necessary. Reporting guidelines recommend that authors include essential content in articles and could generate manually labeled training data for automated evidence retrieval and synthesis. Here, we present a semiautomated approach to annotate, link, and track the content of nutrition research manuscripts. We used the STROBE extension for nutritional epidemiology (STROBE-nut) reporting guidelines to manually annotate a sample of 15 articles and converted the semantic information into linked data in a Neo4j graph database through an automated process. Six summary statistics were computed to estimate the reporting completeness of the articles. The content structure, presence of essential study characteristics as well as the reporting completeness of the articles are visualized automatically from the graph database. The archived linked data are interoperable through their annotations and relations. A graph database with linked data on essential study characteristics can enable Natural Language Processing in nutrition.",2020-09-01,2021-06-05 21:24:28; 2021-06-05 21:06:22; 2021-06-05 21:16:51,1079-1088,5,11,Adv Nutr,Perspective,PubMed,PMID: 32504536 PMCID: PMC7490154,http://www.ncbi.nlm.nih.gov/pubmed/32504536,"Databases, Factual; Diet; graph database; Humans; Nutritional Status; ontology; reporting guidelines; research semantics; standardization; STROBE-nut",Neo4j,Neo4j,PubMed:Neo4j; PubMed:Query3; PubMed:Query2
170,10.1093/bib/bbaa417,33569598,PMC7929418,A,Neo4j; COVID19,Neo4j; COVID19,"Pavel, Alisa; del Giudice, Giusy; Federico, Antonio; Di Lieto, Antonio; Kinaret, Pia A S; Serra, Angela; Greco, Dario",Integrated network analysis reveals new genes suggesting COVID-19 chronic effects and treatment,2021,Briefings in Bioinformatics,,"The COVID-19 disease led to an unprecedented health emergency, still ongoing worldwide. Given the lack of a vaccine or a clear therapeutic strategy to counteract the infection as well as its secondary effects, there is currently a pressing need to generate new insights into the SARS-CoV-2 induced host response. Biomedical data can help to investigate new aspects of the COVID-19 pathogenesis, but source heterogeneity represents a major drawback and limitation. In this work, we applied data integration methods to develop a Unified Knowledge Space (UKS) and used it to identify a new set of genes associated with SARS-CoV-2 host response, both in vitro and in vivo. Functional analysis of these genes reveals possible long-term systemic effects of the infection, such as vascular remodelling and fibrosis. Finally, we identified a set of potentially relevant drugs targeting proteins involved in multiple steps of the host response to the virus.",2021-02-11,2021-06-05 20:35:57; 2021-06-05 21:35:36; 2021-06-05 20:54:31; 2021-06-05 21:09:36,1430-1441,2,22,Brief Bioinform,,PubMed Central,PMID: 33569598 PMCID: PMC7929418,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7929418/,,Neo4j; COVID19,Neo4j; COVID19,PMC:Query3; PMC:Neo4j; PMC:COVID19; PMC:Query2
171,10.1093/bib/bbr033,22396487,PMC3294240,,,,"Wong, Elisabeth; Baur, Brittany; Quader, Saad; Huang, Chun-Hsi",Biological network motif detection: principles and practice,2012,Briefings in Bioinformatics,,"Network motifs are statistically overrepresented sub-structures (sub-graphs) in a network, and have been recognized as ‘the simple building blocks of complex networks’. Study of biological network motifs may reveal answers to many important biological questions. The main difficulty in detecting larger network motifs in biological networks lies in the facts that the number of possible sub-graphs increases exponentially with the network or motif size (node counts, in general), and that no known polynomial-time algorithm exists in deciding if two graphs are topologically equivalent. This article discusses the biological significance of network motifs, the motivation behind solving the motif-finding problem, and strategies to solve the various aspects of this problem. A simple classification scheme is designed to analyze the strengths and weaknesses of several existing algorithms. Experimental results derived from a few comparative studies in the literature are discussed, with conclusions that lead to future research directions.",2012-03,2021-06-05 21:13:27,202-215,2,13,Brief Bioinform,Biological network motif detection,PubMed Central,PMID: 22396487 PMCID: PMC3294240,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3294240/,,,,PMC:Query2
172,10.1093/bib/bbv011,25863278,PMC4652617,A,AllegroGraph,AllegroGraph,"Hoehndorf, Robert; Schofield, Paul N.; Gkoutos, Georgios V.",The role of ontologies in biological and biomedical research: a functional perspective,2015,Briefings in Bioinformatics,,"Ontologies are widely used in biological and biomedical research. Their success lies in their combination of four main features present in almost all ontologies: provision of standard identifiers for classes and relations that represent the phenomena within a domain; provision of a vocabulary for a domain; provision of metadata that describes the intended meaning of the classes and relations in ontologies; and the provision of machine-readable axioms and definitions that enable computational access to some aspects of the meaning of classes and relations. While each of these features enables applications that facilitate data integration, data access and analysis, a great potential lies in the possibility of combining these four features to support integrative analysis and interpretation of multimodal data. Here, we provide a functional perspective on ontologies in biology and biomedicine, focusing on what ontologies can do and describing how they can be used in support of integrative research. We also outline perspectives for using ontologies in data-driven science, in particular their application in structured data mining and machine learning applications.",2015-11,2021-06-06 06:38:41; 2021-06-05 20:56:20; 2021-06-05 21:12:40,1069-1080,6,16,Brief Bioinform,The role of ontologies in biological and biomedical research,PubMed Central,PMID: 25863278 PMCID: PMC4652617,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4652617/,,AllegroGraph,AllegroGraph,PMC:Query3; PMC:AllegroGraph; PMC:Query2
173,10.1093/bib/bbv118,26876889,PMC5221424,A,Neo4j,Neo4j,"Shameer, Khader; Badgeley, Marcus A; Miotto, Riccardo; Glicksberg, Benjamin S; Morgan, Joseph W; Dudley, Joel T","Translational bioinformatics in the era of real-time biomedical, health care and wellness data streams",2017,Briefings in Bioinformatics,,"Monitoring and modeling biomedical, health care and wellness data from individuals and converging data on a population scale have tremendous potential to improve understanding of the transition to the healthy state of human physiology to disease setting. Wellness monitoring devices and companion software applications capable of generating alerts and sharing data with health care providers or social networks are now available. The accessibility and clinical utility of such data for disease or wellness research are currently limited. Designing methods for streaming data capture, real-time data aggregation, machine learning, predictive analytics and visualization solutions to integrate wellness or health monitoring data elements with the electronic medical records (EMRs) maintained by health care providers permits better utilization. Integration of population-scale biomedical, health care and wellness data would help to stratify patients for active health management and to understand clinically asymptomatic patients and underlying illness trajectories. In this article, we discuss various health-monitoring devices, their ability to capture the unique state of health represented in a patient and their application in individualized diagnostics, prognosis, clinical or wellness intervention. We also discuss examples of translational bioinformatics approaches to integrating patient-generated data with existing EMRs, personal health records, patient portals and clinical data repositories. Briefly, translational bioinformatics methods, tools and resources are at the center of these advances in implementing real-time biomedical and health care analytics in the clinical setting. Furthermore, these advances are poised to play a significant role in clinical decision-making and implementation of data-driven medicine and wellness care.",2017-01,2021-06-05 20:55:40; 2021-06-05 21:12:40; 2021-06-05 20:37:08,105-124,1,18,Brief Bioinform,,PubMed Central,PMID: 26876889 PMCID: PMC5221424,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5221424/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
174,10.1093/bib/bbw001,26851224,PMC5221425,,,,"Luo, Yuan; Uzuner, Özlem; Szolovits, Peter",Bridging semantics and syntax with graph algorithms—state-of-the-art of extracting biomedical relations,2017,Briefings in Bioinformatics,,"Research on extracting biomedical relations has received growing attention recently, with numerous biological and clinical applications including those in pharmacogenomics, clinical trial screening and adverse drug reaction detection. The ability to accurately capture both semantic and syntactic structures in text expressing these relations becomes increasingly critical to enable deep understanding of scientific papers and clinical narratives. Shared task challenges have been organized by both bioinformatics and clinical informatics communities to assess and advance the state-of-the-art research. Significant progress has been made in algorithm development and resource construction. In particular, graph-based approaches bridge semantics and syntax, often achieving the best performance in shared tasks. However, a number of problems at the frontiers of biomedical relation extraction continue to pose interesting challenges and present opportunities for great improvement and fruitful research. In this article, we place biomedical relation extraction against the backdrop of its versatile applications, present a gentle introduction to its general pipeline and shared resources, review the current state-of-the-art in methodology advancement, discuss limitations and point out several promising future directions.",2017-01,2021-06-05 21:12:40,160-178,1,18,Brief Bioinform,,PubMed Central,PMID: 26851224 PMCID: PMC5221425,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5221425/,,,,PMC:Query2
175,10.1093/bib/bbw089,27769991,PMC5862344,,,,,"Computational pan-genomics: status, promises and challenges",2016,Briefings in Bioinformatics,,"Many disciplines, from human genetics and oncology to plant breeding, microbiology and virology, commonly face the challenge of analyzing rapidly increasing numbers of genomes. In case of Homo sapiens, the number of sequenced genomes will approach hundreds of thousands in the next few years. Simply scaling up established bioinformatics pipelines will not be sufficient for leveraging the full potential of such rich genomic data sets. Instead, novel, qualitatively different computational methods and paradigms are needed. We will witness the rapid extension of computational pan-genomics, a new sub-area of research in computational biology. In this article, we generalize existing definitions and understand a pan-genome as any collection of genomic sequences to be analyzed jointly or to be used as a reference. We examine already available approaches to construct and use pan-genomes, discuss the potential benefits of future technologies and methodologies and review open challenges from the vantage point of the above-mentioned biological disciplines. As a prominent example for a computational paradigm shift, we particularly highlight the transition from the representation of reference genomes as strings to representations as graphs. We outline how this and other challenges from different application domains translate into common computational problems, point out relevant bioinformatics techniques and identify open problems in computer science. With this review, we aim to increase awareness that a joint approach to computational pan-genomics can help address many of the problems currently faced in various domains.",2016-10-21,2021-06-05 21:12:01,118-135,1,19,Brief Bioinform,Computational pan-genomics,PubMed Central,PMID: 27769991 PMCID: PMC5862344,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5862344/,,,,PMC:Query2
176,10.1093/bib/bbw090,27742665,PMC5862271,,,,"Henkel, Ron; Hoehndorf, Robert; Kacprowski, Tim; Knüpfer, Christian; Liebermeister, Wolfram; Waltemath, Dagmar",Notions of similarity for systems biology models,2016,Briefings in Bioinformatics,,"Systems biology models are rapidly increasing in complexity, size and numbers. When building large models, researchers rely on software tools for the retrieval, comparison, combination and merging of models, as well as for version control. These tools need to be able to quantify the differences and similarities between computational models. However, depending on the specific application, the notion of ‘similarity’ may greatly vary. A general notion of model similarity, applicable to various types of models, is still missing. Here we survey existing methods for the comparison of models, introduce quantitative measures for model similarity, and discuss potential applications of combined similarity measures. To frame model comparison as a general problem, we describe a theoretical approach to defining and computing similarities based on a combination of different model aspects. The six aspects that we define as potentially relevant for similarity are underlying encoding, references to biological entities, quantitative behaviour, qualitative behaviour, mathematical equations and parameters and network structure. We argue that future similarity measures will benefit from combining these model aspects in flexible, problem-specific ways to mimic users’ intuition about model similarity, and to support complex model searches in databases.",2016-10-14,2021-06-05 21:12:01,77-88,1,19,Brief Bioinform,,PubMed Central,PMID: 27742665 PMCID: PMC5862271,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5862271/,,,,PMC:Query2
177,10.1093/bib/bbx151,29186305,PMC6585387,A,Neo4j,Neo4j,"Oulas, Anastasis; Minadakis, George; Zachariou, Margarita; Sokratous, Kleitos; Bourdakou, Marilena M; Spyrou, George M",Systems Bioinformatics: increasing precision of computational diagnostics and therapeutics through network-based approaches,2017,Briefings in Bioinformatics,,"Systems Bioinformatics is a relatively new approach, which lies in the intersection of systems biology and classical bioinformatics. It focuses on integrating information across different levels using a bottom-up approach as in systems biology with a data-driven top-down approach as in bioinformatics. The advent of omics technologies has provided the stepping-stone for the emergence of Systems Bioinformatics. These technologies provide a spectrum of information ranging from genomics, transcriptomics and proteomics to epigenomics, pharmacogenomics, metagenomics and metabolomics. Systems Bioinformatics is the framework in which systems approaches are applied to such data, setting the level of resolution as well as the boundary of the system of interest and studying the emerging properties of the system as a whole rather than the sum of the properties derived from the system’s individual components. A key approach in Systems Bioinformatics is the construction of multiple networks representing each level of the omics spectrum and their integration in a layered network that exchanges information within and between layers. Here, we provide evidence on how Systems Bioinformatics enhances computational therapeutics and diagnostics, hence paving the way to precision medicine. The aim of this review is to familiarize the reader with the emerging field of Systems Bioinformatics and to provide a comprehensive overview of its current state-of-the-art methods and technologies. Moreover, we provide examples of success stories and case studies that utilize such methods and tools to significantly advance research in the fields of systems biology and systems medicine.",2017-11-27,2021-06-05 20:55:40; 2021-06-05 21:11:16; 2021-06-05 20:36:32,806-824,3,20,Brief Bioinform,Systems Bioinformatics,PubMed Central,PMID: 29186305 PMCID: PMC6585387,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6585387/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
178,10.1093/bib/bby025,29684165,PMC6556902,A,Neo4j,Neo4j,"Saqi, Mansoor; Lysenko, Artem; Guo, Yi-Ke; Tsunoda, Tatsuhiko; Auffray, Charles",Navigating the disease landscape: knowledge representations for contextualizing molecular signatures,2018,Briefings in Bioinformatics,,"Large amounts of data emerging from experiments in molecular medicine are leading to the identification of molecular signatures associated with disease subtypes. The contextualization of these patterns is important for obtaining mechanistic insight into the aberrant processes associated with a disease, and this typically involves the integration of multiple heterogeneous types of data. In this review, we discuss knowledge representations that can be useful to explore the biological context of molecular signatures, in particular three main approaches, namely, pathway mapping approaches, molecular network centric approaches and approaches that represent biological statements as knowledge graphs. We discuss the utility of each of these paradigms, illustrate how they can be leveraged with selected practical examples and identify ongoing challenges for this field of research.",2018-04-19,2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:36:32,609-623,2,20,Brief Bioinform,Navigating the disease landscape,PubMed Central,PMID: 29684165 PMCID: PMC6556902,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6556902/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
179,10.1093/bib/bby087,30462164,PMC6433895,,,,"Neal, Maxwell Lewis; König, Matthias; Nickerson, David; Mısırlı, Göksel; Kalbasi, Reza; Dräger, Andreas; Atalag, Koray; Chelliah, Vijayalakshmi; Cooling, Michael T; Cook, Daniel L; Crook, Sharon; de Alba, Miguel; Friedman, Samuel H; Garny, Alan; Gennari, John H; Gleeson, Padraig; Golebiewski, Martin; Hucka, Michael; Juty, Nick; Myers, Chris; Olivier, Brett G; Sauro, Herbert M; Scharm, Martin; Snoep, Jacky L; Touré, Vasundra; Wipat, Anil; Wolkenhauer, Olaf; Waltemath, Dagmar",Harmonizing semantic annotations for computational models in biology,2018,Briefings in Bioinformatics,,"Life science researchers use computational models to articulate and test hypotheses about the behavior of biological systems. Semantic annotation is a critical component for enhancing the interoperability and reusability of such models as well as for the integration of the data needed for model parameterization and validation. Encoded as machine-readable links to knowledge resource terms, semantic annotations describe the computational or biological meaning of what models and data represent. These annotations help researchers find and repurpose models, accelerate model composition and enable knowledge integration across model repositories and experimental data stores. However, realizing the potential benefits of semantic annotation requires the development of model annotation standards that adhere to a community-based annotation protocol. Without such standards, tool developers must account for a variety of annotation formats and approaches, a situation that can become prohibitively cumbersome and which can defeat the purpose of linking model elements to controlled knowledge resource terms. Currently, no consensus protocol for semantic annotation exists among the larger biological modeling community. Here, we report on the landscape of current annotation practices among the COmputational Modeling in BIology NEtwork community and provide a set of recommendations for building a consensus approach to semantic annotation.",2018-11-21,2021-06-05 21:10:37,540-550,2,20,Brief Bioinform,,PubMed Central,PMID: 30462164 PMCID: PMC6433895,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6433895/,,,,PMC:Query2
180,10.1093/bioinformatics/btaa718,33175089,PMC7890668,A,Neo4j; COVID19,Neo4j; COVID19,"Korn, Daniel; Bobrowski, Tesia; Li, Michael; Kebede, Yaphet; Wang, Patrick; Owen, Phillips; Vaidya, Gaurav; Muratov, Eugene; Chirkova, Rada; Bizon, Chris; Tropsha, Alexander",COVID-KOP: integrating emerging COVID-19 data with the ROBOKOP database,2020,Bioinformatics,,"Summary In response to the COVID-19 pandemic, we established COVID-KOP, a new knowledgebase integrating the existing Reasoning Over Biomedical Objects linked in Knowledge Oriented Pathways (ROBOKOP) biomedical knowledge graph with information from recent biomedical literature on COVID-19 annotated in the CORD-19 collection. COVID-KOP can be used effectively to generate new hypotheses concerning repurposing of known drugs and clinical drug candidates against COVID-19 by establishing respective confirmatory pathways of drug action. Availability and implementation COVID-KOP is freely accessible at https://covidkop.renci.org/. For code and instructions for the original ROBOKOP, see: https://github.com/NCATS-Gamma/robokop.",2020-11-11,2021-06-05 20:35:57; 2021-06-05 21:35:36; 2021-06-05 20:54:31; 2021-06-05 21:09:36,586-587,4,37,Bioinformatics,COVID-KOP,PubMed Central,PMID: 33175089 PMCID: PMC7890668,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7890668/,,Neo4j; COVID19,Neo4j; COVID19,PMC:Query3; PMC:Neo4j; PMC:COVID19; PMC:Query2
181,10.1093/bioinformatics/btaa726,32810207,PMC8088324,,,,"Elsworth, Benjamin; Gaunt, Tom R",MELODI Presto: a fast and agile tool to explore semantic triples derived from biomedical literature,2020,Bioinformatics,,"Summary The field of literature-based discovery is growing in step with the volume of literature being produced. From modern natural language processing algorithms to high quality entity tagging, the methods and their impact are developing rapidly. One annotation object that arises from these approaches, the subject–predicate–object triple, is proving to be very useful in representing knowledge. We have implemented efficient search methods and an application programming interface, to create fast and convenient functions to utilize triples extracted from the biomedical literature by SemMedDB. By refining these data, we have identified a set of triples that focus on the mechanistic aspects of the literature, and provide simple methods to explore both enriched triples from single queries, and overlapping triples across two query lists. Availability and Implementation https://melodi-presto.mrcieu.ac.uk/. Supplementary information  are available at Bioinformatics online.",2020-08-18,2021-06-05 21:10:08,583-585,4,37,Bioinformatics,MELODI Presto,PubMed Central,PMID: 32810207 PMCID: PMC8088324,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8088324/,,,,PMC:Query2
182,10.1093/bioinformatics/btaa961,33165574,,A,,,"Liu, Yi; Elsworth, Benjamin; Erola, Pau; Haberland, Valeriia; Hemani, Gibran; Lyon, Matt; Zheng, Jie; Lloyd, Oliver; Vabistsevits, Marina; Gaunt, Tom R.",EpiGraphDB: a database and data mining platform for health data science,2020,"Bioinformatics (Oxford, England)",,"MOTIVATION: The wealth of data resources on human phenotypes, risk factors, molecular traits and therapeutic interventions presents new opportunities for population health sciences. These opportunities are paralleled by a growing need for data integration, curation and mining to increase research efficiency, reduce mis-inference and ensure reproducible research. RESULTS: We developed EpiGraphDB (https://epigraphdb.org/), a graph database containing an array of different biomedical and epidemiological relationships and an analytical platform to support their use in human population health data science. In addition, we present three case studies that illustrate the value of this platform. The first uses EpiGraphDB to evaluate potential pleiotropic relationships, addressing mis-inference in systematic causal analysis. In the second case study, we illustrate how protein-protein interaction data offer opportunities to identify new drug targets. The final case study integrates causal inference using Mendelian randomization with relationships mined from the biomedical literature to ""triangulate"" evidence from different sources. AVAILABILITY: The EpiGraphDB platform is openly available at https://epigraphdb.org. Code for replicating case study results is available at https://github.com/MRCIEU/epigraphdb as Jupyter notebooks using the API, and https://mrcieu.github.io/epigraphdb-r using the R package. SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.",2020-11-09,2021-06-05 21:06:22,,,,Bioinformatics,EpiGraphDB,PubMed,PMID: 33165574,http://www.ncbi.nlm.nih.gov/pubmed/33165574,,,,PubMed:Query2
183,10.1093/bioinformatics/btab424,34081107,,A,,,"Nair, Sreenath; Váradi, Mihály; Nadzirin, Nurul; Pravda, Lukáš; Anyango, Stephen; Mir, Saqib; Berrisford, John; Armstrong, David; Gutmanas, Aleksandras; Velankar, Sameer",PDBe Aggregated API: Programmatic access to an integrative knowledge graph of molecular structure data,2021,"Bioinformatics (Oxford, England)",,"SUMMARY: The PDBe aggregated API is an open-access and open-source RESTful API that provides programmatic access to a wealth of macromolecular structural data and their functional and biophysical annotations through 80+ API endpoints. The API is powered by the PDBe graph database (https://pdbe.org/graph-schema), an open-access integrative knowledge graph that can be used as a discovery tool to answer complex biological questions. AVAILABILITY AND IMPLEMENTATION: The PDBe aggregated API provides up-to-date access to the PDBe graph database, which has weekly releases with the latest data from the Protein Data Bank, integrated with updated annotations from UniProt, Pfam, CATH, SCOP and the PDBe-KB partner resources. The complete list of all the available API endpoints and their descriptions are available at https://pdbe.org/graph-api. The source code of the Python 3.6+ API application is publicly available at https://gitlab.ebi.ac.uk/pdbe-kb/services/pdbe-graph-api. SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.",2021-06-03,2021-06-05 21:06:22,,,,Bioinformatics,PDBe Aggregated API,PubMed,PMID: 34081107,http://www.ncbi.nlm.nih.gov/pubmed/34081107,,,,PubMed:Query2
184,10.1093/bioinformatics/btl647,17234640,,A,,,"Alekseyenko, Alexander V.; Lee, Christopher J.",Nested Containment List (NCList): a new algorithm for accelerating interval query of genome alignment and interval databases,2007,"Bioinformatics (Oxford, England)",,"MOTIVATION: The exponential growth of sequence databases poses a major challenge to bioinformatics tools for querying alignment and annotation databases. There is a pressing need for methods for finding overlapping sequence intervals that are highly scalable to database size, query interval size, result size and construction/updating of the interval database. RESULTS: We have developed a new interval database representation, the Nested Containment List (NCList), whose query time is O(n + log N), where N is the database size and n is the size of the result set. In all cases tested, this query algorithm is 5-500-fold faster than other indexing methods tested in this study, such as MySQL multi-column indexing, MySQL binning and R-Tree indexing. We provide performance comparisons both in simulated datasets and real-world genome alignment databases, across a wide range of database sizes and query interval widths. We also present an in-place NCList construction algorithm that yields database construction times that are approximately 100-fold faster than other methods available. The NCList data structure appears to provide a useful foundation for highly scalable interval database applications. AVAILABILITY: NCList data structure is part of Pygr, a bioinformatics graph database library, available at http://sourceforge.net/projects/pygr",2007-06-01,2021-06-05 21:06:22,1386-1393,11,23,Bioinformatics,Nested Containment List (NCList),PubMed,PMID: 17234640,http://www.ncbi.nlm.nih.gov/pubmed/17234640,"Algorithms; Base Sequence; Chromosome Mapping; Database Management Systems; Databases, Genetic; Information Storage and Retrieval; Molecular Sequence Data; Sequence Alignment; Sequence Analysis, DNA; Software",,,PubMed:Query2
185,10.1093/bioinformatics/btm343,17599926,,A,,,"Kim, Namshin; Lee, Christopher",QPRIMER: a quick web-based application for designing conserved PCR primers from multigenome alignments,2007,"Bioinformatics (Oxford, England)",,"We have developed a quick web-based application for designing conserved genomic PCR and RT-PCR primers from multigenome alignments targeting specific exons or introns. We used Pygr (The Python Graph Database Framework for Bioinformatics) to query intervals from multigenome alignments, which gives us less than a millisecond access to any intervals of any genome within multigenome alignments. PRIMER3 was used to extract optimal primers from a gene of interest. QPRIMER creates an electronic genomic PCR image from a set of conserved primers as well as summary pages for primer alignments and products. QPRIMER supports human, mouse, rat, chicken, dog, zebrafish and fruit fly. AVAILABILITY: http://www.bioinformatics.ucla.edu/QPRIMER/.",2007-09-01,2021-06-05 21:06:22,2331-2333,17,23,Bioinformatics,QPRIMER,PubMed,PMID: 17599926,http://www.ncbi.nlm.nih.gov/pubmed/17599926,Algorithms; Base Sequence; Chromosome Mapping; Conserved Sequence; DNA Primers; Internet; Molecular Sequence Data; Polymerase Chain Reaction; Sequence Alignment; Software,,,PubMed:Query2
186,10.1093/bioinformatics/btn186,18586736,PMC2718661,,,,"Cao, Yiqun; Jiang, Tao; Girke, Thomas",A maximum common substructure-based algorithm for searching and predicting drug-like compounds,2008,Bioinformatics,,"Motivation: The prediction of biologically active compounds is of great importance for high-throughput screening (HTS) approaches in drug discovery and chemical genomics. Many computational methods in this area focus on measuring the structural similarities between chemical structures. However, traditional similarity measures are often too rigid or consider only global similarities between structures. The maximum common substructure (MCS) approach provides a more promising and flexible alternative for predicting bioactive compounds., Results: In this article, a new backtracking algorithm for MCS is proposed and compared to global similarity measurements. Our algorithm provides high flexibility in the matching process, and it is very efficient in identifying local structural similarities. To predict and cluster biologically active compounds more efficiently, the concept of basis compounds is proposed that enables researchers to easily combine the MCS-based and traditional similarity measures with modern machine learning techniques. Support vector machines (SVMs) are used to test how the MCS-based similarity measure and the basis compound vectorization method perform on two empirically tested datasets. The test results show that MCS complements the well-known atom pair descriptor-based similarity measure. By combining these two measures, our SVM-based model predicts the biological activities of chemical compounds with higher specificity and sensitivity.,            Contact:           ycao@cs.ucr.edu         , Supplementary information: Supplementary data are available at Bioinformatics online.",2008-07-01,2021-06-05 21:13:27,i366-i374,13,24,Bioinformatics,,PubMed Central,PMID: 18586736 PMCID: PMC2718661,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2718661/,,,,PMC:Query2
187,10.1093/bioinformatics/btp080,19213739,PMC2660875,,,,"Georgii, Elisabeth; Dietmann, Sabine; Uno, Takeaki; Pagel, Philipp; Tsuda, Koji",Enumeration of condition-dependent dense modules in protein interaction networks,2009,Bioinformatics,,"Motivation: Modern systems biology aims at understanding how the different molecular components of a biological cell interact. Often, cellular functions are performed by complexes consisting of many different proteins. The composition of these complexes may change according to the cellular environment, and one protein may be involved in several different processes. The automatic discovery of functional complexes from protein interaction data is challenging. While previous approaches use approximations to extract dense modules, our approach exactly solves the problem of dense module enumeration. Furthermore, constraints from additional information sources such as gene expression and phenotype data can be integrated, so we can systematically mine for dense modules with interesting profiles., Results: Given a weighted protein interaction network, our method discovers all protein sets that satisfy a user-defined minimum density threshold. We employ a reverse search strategy, which allows us to exploit the density criterion in an efficient way. Our experiments show that the novel approach is feasible and produces biologically meaningful results. In comparative validation studies using yeast data, the method achieved the best overall prediction performance with respect to confirmed complexes. Moreover, by enhancing the yeast network with phenotypic and phylogenetic profiles and the human network with tissue-specific expression data, we identified condition-dependent complex variants., Availability: A C++ implementation of the algorithm is available at http://www.kyb.tuebingen.mpg.de/~georgii/dme.html., Contact: koji.tsuda@tuebingen.mpg.de, Supplementary information: Supplementary data are available at Bioinformatics online.",2009-04-01,2021-06-05 21:13:27,933-940,7,25,Bioinformatics,,PubMed Central,PMID: 19213739 PMCID: PMC2660875,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2660875/,,,,PMC:Query2
188,10.1093/bioinformatics/btq231,20427517,PMC2887046,,,,"Baitaluk, Michael; Ponomarenko, Julia",Semantic integration of data on transcriptional regulation,2010,Bioinformatics,,"Motivation: Experimental and predicted data concerning gene transcriptional regulation are distributed among many heterogeneous sources. However, there are no resources to integrate these data automatically or to provide a ‘one-stop shop’ experience for users seeking information essential for deciphering and modeling gene regulatory networks., Results: IntegromeDB, a semantic graph-based ‘deep-web’ data integration system that automatically captures, integrates and manages publicly available data concerning transcriptional regulation, as well as other relevant biological information, is proposed in this article. The problems associated with data integration are addressed by ontology-driven data mapping, multiple data annotation and heterogeneous data querying, also enabling integration of the user's data. IntegromeDB integrates over 100 experimental and computational data sources relating to genomics, transcriptomics, genetics, and functional and interaction data concerning gene transcriptional regulation in eukaryotes and prokaryotes., Availability: IntegromeDB is accessible through the integrated research environment BiologicalNetworks at http://www.BiologicalNetworks.org, Contact: baitaluk@sdsc.edu, Supplementary information: Supplementary data are available at Bioinformatics online.",2010-07-01,2021-06-05 21:13:27,1651-1661,13,26,Bioinformatics,,PubMed Central,PMID: 20427517 PMCID: PMC2887046,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2887046/,,,,PMC:Query2
189,10.1093/bioinformatics/btr203,21685064,PMC3117351,,,,"Gülsoy, Günhan; Kahveci, Tamer",RINQ: Reference-based Indexing for Network Queries,2011,Bioinformatics,,"We consider the problem of similarity queries in biological network databases. Given a database of networks, similarity query returns all the database networks whose similarity (i.e. alignment score) to a given query network is at least a specified similarity cutoff value. Alignment of two networks is a very costly operation, which makes exhaustive comparison of all the database networks with a query impractical. To tackle this problem, we develop a novel indexing method, named RINQ (Reference-based Indexing for Biological Network Queries). Our method uses a set of reference networks to eliminate a large portion of the database quickly for each query. A reference network is a small biological network. We precompute and store the alignments of all the references with all the database networks. When our database is queried, we align the query network with all the reference networks. Using these alignments, we calculate a lower bound and an approximate upper bound to the alignment score of each database network with the query network. With the help of upper and lower bounds, we eliminate the majority of the database networks without aligning them to the query network. We also quickly identify a small portion of these as guaranteed to be similar to the query. We perform pairwise alignment only for the remaining networks. We also propose a supervised method to pick references that have a large chance of filtering the unpromising database networks. Extensive experimental evaluation suggests that (i) our method reduced the running time of a single query on a database of around 300 networks from over 2 days to only 8 h; (ii) our method outperformed the state of the art method Closure Tree and SAGA by a factor of three or more; and (iii) our method successfully identified statistically and biologically significant relationships across networks and organisms., Contact: ggulsoy@cise.ufl.edu; tamer@cise.ufl.edu, Supplementary information: Supplementary data are available at Bioinformatics online.",2011-07-01,2021-06-05 21:13:27,i149-i158,13,27,Bioinformatics,RINQ,PubMed Central,PMID: 21685064 PMCID: PMC3117351,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3117351/,,,,PMC:Query2
190,10.1093/bioinformatics/btr395,21743062,PMC3157922,A,AllegroGraph,AllegroGraph,"Jeong, Euna; Nagasaki, Masao; Ikeda, Emi; Sekiya, Yayoi; Saito, Ayumu; Miyano, Satoru",CSO validator: improving manual curation workflow for biological pathways,2011,Bioinformatics,,"Summary: Manual curation and validation of large-scale biological pathways are required to obtain high-quality pathway databases. In a typical curation process, model validation and model update based on appropriate feedback are repeated and requires considerable cooperation of scientists. We have developed a CSO (Cell System Ontology) validator to reduce the repetition and time during the curation process. This tool assists in quickly obtaining agreement among curators and domain experts and in providing a consistent and accurate pathway database., Availability: The tool is available on http://csovalidator.csml.org., Contact: masao@hgc.jp",2011-09-01,2021-06-05 21:13:27; 2021-06-06 06:38:41; 2021-06-05 20:56:20,2471-2472,17,27,Bioinformatics,CSO validator,PubMed Central,PMID: 21743062 PMCID: PMC3157922,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3157922/,,AllegroGraph,AllegroGraph,PMC:Query3; PMC:AllegroGraph; PMC:Query2
191,10.1093/bioinformatics/bts463,22829625,,A,,,"Boeva, Valentina; Lermine, Alban; Barette, Camille; Guillouf, Christel; Barillot, Emmanuel",Nebula--a web-server for advanced ChIP-seq data analysis,2012,"Bioinformatics (Oxford, England)",,"MOTIVATION: ChIP-seq consists of chromatin immunoprecipitation and deep sequencing of the extracted DNA fragments. It is the technique of choice for accurate characterization of the binding sites of transcription factors and other DNA-associated proteins. We present a web service, Nebula, which allows inexperienced users to perform a complete bioinformatics analysis of ChIP-seq data. RESULTS: Nebula was designed for both bioinformaticians and biologists. It is based on the Galaxy open source framework. Galaxy already includes a large number of functionalities for mapping reads and peak calling. We added the following to Galaxy: (i) peak calling with FindPeaks and a module for immunoprecipitation quality control, (ii) de novo motif discovery with ChIPMunk, (iii) calculation of the density and the cumulative distribution of peak locations relative to gene transcription start sites, (iv) annotation of peaks with genomic features and (v) annotation of genes with peak information. Nebula generates the graphs and the enrichment statistics at each step of the process. During Steps 3-5, Nebula optionally repeats the analysis on a control dataset and compares these results with those from the main dataset. Nebula can also incorporate gene expression (or gene modulation) data during these steps. In summary, Nebula is an innovative web service that provides an advanced ChIP-seq analysis pipeline providing ready-to-publish results. AVAILABILITY: Nebula is available at http://nebula.curie.fr/ SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.",2012-10-01,2021-06-05 21:24:28; 2021-06-05 21:06:22,2517-2519,19,28,Bioinformatics,,PubMed,PMID: 22829625,http://www.ncbi.nlm.nih.gov/pubmed/22829625,Binding Sites; Chromatin Immunoprecipitation; Computational Biology; High-Throughput Nucleotide Sequencing; Internet; Software,,,PubMed:Query3; PubMed:Query2
192,10.1093/bioinformatics/btt141,23595662,PMC3654710,A,AllegroGraph,AllegroGraph,"Robbins, David E.; Grüneberg, Alexander; Deus, Helena F.; Tanik, Murat M.; Almeida, Jonas S.",A self-updating road map of The Cancer Genome Atlas,2013,Bioinformatics,,"Motivation: Since 2011, The Cancer Genome Atlas’ (TCGA) files have been accessible through HTTP from a public site, creating entirely new possibilities for cancer informatics by enhancing data discovery and retrieval. Significantly, these enhancements enable the reporting of analysis results that can be fully traced to and reproduced using their source data. However, to realize this possibility, a continually updated road map of files in the TCGA is required. Creation of such a road map represents a significant data modeling challenge, due to the size and fluidity of this resource: each of the 33 cancer types is instantiated in only partially overlapping sets of analytical platforms, while the number of data files available doubles approximately every 7 months., Results: We developed an engine to index and annotate the TCGA files, relying exclusively on third-generation web technologies (Web 3.0). Specifically, this engine uses JavaScript in conjunction with the World Wide Web Consortium’s (W3C) Resource Description Framework (RDF), and SPARQL, the query language for RDF, to capture metadata of files in the TCGA open-access HTTP directory. The resulting index may be queried using SPARQL, and enables file-level provenance annotations as well as discovery of arbitrary subsets of files, based on their metadata, using web standard languages. In turn, these abilities enhance the reproducibility and distribution of novel results delivered as elements of a web-based computational ecosystem. The development of the TCGA Roadmap engine was found to provide specific clues about how biomedical big data initiatives should be exposed as public resources for exploratory analysis, data mining and reproducible research. These specific design elements align with the concept of knowledge reengineering and represent a sharp departure from top-down approaches in grid initiatives such as CaBIG. They also present a much more interoperable and reproducible alternative to the still pervasive use of data portals., Availability: A prepared dashboard, including links to source code and a SPARQL endpoint, is available at http://bit.ly/TCGARoadmap. A video tutorial is available at http://bit.ly/TCGARoadmapTutorial., Contact: robbinsd@uab.edu",2013-05-15,2021-06-05 21:13:27; 2021-06-06 06:38:41; 2021-06-05 20:56:20,1333-1340,10,29,Bioinformatics,,PubMed Central,PMID: 23595662 PMCID: PMC3654710,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3654710/,,AllegroGraph,AllegroGraph,PMC:Query3; PMC:AllegroGraph; PMC:Query2
193,10.1093/bioinformatics/btt396,23846746,PMC3753571,,,,"LeGault, Laura H.; Dewey, Colin N.",Inference of alternative splicing from RNA-Seq data with probabilistic splice graphs,2013,Bioinformatics,,"Motivation: Alternative splicing and other processes that allow for different transcripts to be derived from the same gene are significant forces in the eukaryotic cell. RNA-Seq is a promising technology for analyzing alternative transcripts, as it does not require prior knowledge of transcript structures or genome sequences. However, analysis of RNA-Seq data in the presence of genes with large numbers of alternative transcripts is currently challenging due to efficiency, identifiability and representation issues., Results: We present RNA-Seq models and associated inference algorithms based on the concept of probabilistic splice graphs, which alleviate these issues. We prove that our models are often identifiable and demonstrate that our inference methods for quantification and differential processing detection are efficient and accurate., Availability: Software implementing our methods is available at http://deweylab.biostat.wisc.edu/psginfer., Contact: cdewey@biostat.wisc.edu, Supplementary information: Supplementary data are available at Bioinformatics online.",2013-09-15,2021-06-05 21:13:27,2300-2310,18,29,Bioinformatics,,PubMed Central,PMID: 23846746 PMCID: PMC3753571,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3753571/,,,,PMC:Query2
194,10.1093/bioinformatics/btt549,24135261,PMC3842757,A,Virtuoso; Neo4j; AllegroGraph,Virtuoso; Neo4j; AllegroGraph,"Have, Christian Theil; Jensen, Lars Juhl",Are graph databases ready for bioinformatics?,2013,"Bioinformatics; Bioinformatics (Oxford, England)",,Contact: Lars.Juhl.Jensen@gmail.com,2013-12-15,2021-06-05 21:13:27; 2021-06-06 06:38:41; 2021-06-05 21:06:22; 2021-06-05 20:59:14; 2021-06-05 20:37:08; 2021-06-05 20:56:20,3107-3108,24,29,Bioinformatics,,PubMed; PubMed Central,PMID: 24135261 PMCID: PMC3842757,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3842757/; http://www.ncbi.nlm.nih.gov/pubmed/24135261,"Computational Biology; Computer Graphics; Databases, Factual",Virtuoso; Neo4j; AllegroGraph,Virtuoso; Neo4j; AllegroGraph,PMC:AllegroGraph; PMC:Query2; PMC:Query3; PMC:Neo4j; PMC:Virtuoso; PubMed:Query2
195,10.1093/bioinformatics/btv276,25940563,PMC4547614,A,Neo4j,Neo4j,"McTavish, Emily Jane; Hinchliff, Cody E.; Allman, James F.; Brown, Joseph W.; Cranston, Karen A.; Holder, Mark T.; Rees, Jonathan A.; Smith, Stephen A.",Phylesystem: a git-based data store for community-curated phylogenetic estimates,2015,Bioinformatics,,"Motivation: Phylogenetic estimates from published studies can be archived using general platforms like Dryad (Vision, 2010) or TreeBASE (Sanderson et al., 1994). Such services fulfill a crucial role in ensuring transparency and reproducibility in phylogenetic research. However, digital tree data files often require some editing (e.g. rerooting) to improve the accuracy and reusability of the phylogenetic statements. Furthermore, establishing the mapping between tip labels used in a tree and taxa in a single common taxonomy dramatically improves the ability of other researchers to reuse phylogenetic estimates. As the process of curating a published phylogenetic estimate is not error-free, retaining a full record of the provenance of edits to a tree is crucial for openness, allowing editors to receive credit for their work and making errors introduced during curation easier to correct., Results: Here, we report the development of software infrastructure to support the open curation of phylogenetic data by the community of biologists. The backend of the system provides an interface for the standard database operations of creating, reading, updating and deleting records by making commits to a git repository. The record of the history of edits to a tree is preserved by git’s version control features. Hosting this data store on GitHub (http://github.com/) provides open access to the data store using tools familiar to many developers. We have deployed a server running the ‘phylesystem-api’, which wraps the interactions with git and GitHub. The Open Tree of Life project has also developed and deployed a JavaScript application that uses the phylesystem-api and other web services to enable input and curation of published phylogenetic statements., Availability and implementation: Source code for the web service layer is available at https://github.com/OpenTreeOfLife/phylesystem-api. The data store can be cloned from: https://github.com/OpenTreeOfLife/phylesystem. A web application that uses the phylesystem web services is deployed at http://tree.opentreeoflife.org/curator. Code for that tool is available from https://github.com/OpenTreeOfLife/opentree., Contact: mtholder@gmail.com",2015-09-01,2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-05 20:37:08,2794-2800,17,31,Bioinformatics,Phylesystem,PubMed Central,PMID: 25940563 PMCID: PMC4547614,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4547614/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
196,10.1093/bioinformatics/btv460,26272981,PMC4653389,A,Neo4j,Neo4j,"Summer, Georg; Kelder, Thomas; Ono, Keiichiro; Radonjic, Marijana; Heymans, Stephane; Demchak, Barry",cyNeo4j: connecting Neo4j and Cytoscape,2015,"Bioinformatics; Bioinformatics (Oxford, England)",,"Summary: We developed cyNeo4j, a Cytoscape App to link Cytoscape and Neo4j databases to utilize the performance and storage capacities Neo4j offers. We implemented a Neo4j NetworkAnalyzer, ForceAtlas2 layout and Cypher component to demonstrate the possibilities a distributed setup of Cytoscape and Neo4j have., Availability and implementation: The app is available from the Cytoscape App Store at http://apps.cytoscape.org/apps/cyneo4j, the Neo4j plugins at www.github.com/gsummer/cyneo4j-parent and the community and commercial editions of Neo4j can be found at http://www.neo4j.com., Contact: georg.summer@gmail.com; We developed cyNeo4j, a Cytoscape App to link Cytoscape and Neo4j databases to utilize the performance and storage capacities Neo4j offers. We implemented a Neo4j NetworkAnalyzer, ForceAtlas2 layout and Cypher component to demonstrate the possibilities a distributed setup of Cytoscape and Neo4j have. AVAILABILITY AND IMPLEMENTATION: The app is available from the Cytoscape App Store at http://apps.cytoscape.org/apps/cyneo4j, the Neo4j plugins at www.github.com/gsummer/cyneo4j-parent and the community and commercial editions of Neo4j can be found at http://www.neo4j.com. CONTACT: georg.summer@gmail.com.",2015-12-01,2021-06-05 21:06:22; 2021-06-05 21:12:40; 2021-06-05 21:16:51; 2021-06-05 20:37:08; 2021-06-05 20:56:20; 2021-06-05 21:24:28,3868-3869,23,31,Bioinformatics,cyNeo4j,PubMed; PubMed Central,PMID: 26272981 PMCID: PMC4653389,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4653389/; http://www.ncbi.nlm.nih.gov/pubmed/26272981,"Algorithms; Databases, Factual; Software",Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
197,10.1093/bioinformatics/btv593,26545824,PMC4803387,,,,"Komiyama, Yusuke; Banno, Masaki; Ueki, Kokoro; Saad, Gul; Shimizu, Kentaro",Automatic generation of bioinformatics tools for predicting protein–ligand binding sites,2016,Bioinformatics,,"Motivation: Predictive tools that model protein–ligand binding on demand are needed to promote ligand research in an innovative drug-design environment. However, it takes considerable time and effort to develop predictive tools that can be applied to individual ligands. An automated production pipeline that can rapidly and efficiently develop user-friendly protein–ligand binding predictive tools would be useful., Results: We developed a system for automatically generating protein–ligand binding predictions. Implementation of this system in a pipeline of Semantic Web technique-based web tools will allow users to specify a ligand and receive the tool within 0.5–1 day. We demonstrated high prediction accuracy for three machine learning algorithms and eight ligands., Availability and implementation: The source code and web application are freely available for download at http://utprot.net. They are implemented in Python and supported on Linux., Contact: shimizu@bi.a.u-tokyo.ac.jp, Supplementary information: Supplementary data are available at Bioinformatics online.",2016-03-15,2021-06-05 21:12:40,901-907,6,32,Bioinformatics,,PubMed Central,PMID: 26545824 PMCID: PMC4803387,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4803387/,,,,PMC:Query2
198,10.1093/bioinformatics/btv739,26708334,PMC4824131,A,Neo4j,Neo4j,"Bottomly, Daniel; McWeeney, Shannon K.; Wilmot, Beth",HitWalker2: visual analytics for precision medicine and beyond,2016,"Bioinformatics; Bioinformatics (Oxford, England)",,"Summary: The lack of visualization frameworks to guide interpretation and facilitate discovery is a potential bottleneck for precision medicine, systems genetics and other studies. To address this we have developed an interactive, reproducible, web-based prioritization approach that builds on our earlier work. HitWalker2 is highly flexible and can utilize many data types and prioritization methods based upon available data and desired questions, allowing it to be utilized in a diverse range of studies such as cancer, infectious disease and psychiatric disorders., Availability and implementation: Source code is freely available at https://github.com/biodev/HitWalker2 and implemented using Python/Django, Neo4j and Javascript (D3.js and jQuery). We support major open source browsers (e.g. Firefox and Chromium/Chrome)., Contact: wilmotb@ohsu.edu, Supplementary information: Supplementary data are available at Bioinformatics online. Additional information/instructions are available at https://github.com/biodev/HitWalker2/wiki; The lack of visualization frameworks to guide interpretation and facilitate discovery is a potential bottleneck for precision medicine, systems genetics and other studies. To address this we have developed an interactive, reproducible, web-based prioritization approach that builds on our earlier work. HitWalker2 is highly flexible and can utilize many data types and prioritization methods based upon available data and desired questions, allowing it to be utilized in a diverse range of studies such as cancer, infectious disease and psychiatric disorders. AVAILABILITY AND IMPLEMENTATION: Source code is freely available at https://github.com/biodev/HitWalker2 and implemented using Python/Django, Neo4j and Javascript (D3.js and jQuery). We support major open source browsers (e.g. Firefox and Chromium/Chrome). CONTACT: wilmotb@ohsu.edu SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online. Additional information/instructions are available at https://github.com/biodev/HitWalker2/wiki.",2016-04-15,2021-06-05 21:06:22; 2021-06-05 21:12:40; 2021-06-05 21:16:51; 2021-06-05 20:37:08; 2021-06-05 20:55:40; 2021-06-05 21:24:28,1253-1255,8,32,Bioinformatics,HitWalker2,PubMed; PubMed Central,PMID: 26708334 PMCID: PMC4824131,http://www.ncbi.nlm.nih.gov/pubmed/26708334; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4824131/,Humans; Precision Medicine; Programming Languages; Software,Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
199,10.1093/bioinformatics/btw214,27153650,PMC4937199,A,Virtuoso,Virtuoso,"Queralt-Rosinach, Núria; Piñero, Janet; Bravo, Àlex; Sanz, Ferran; Furlong, Laura I.",DisGeNET-RDF: harnessing the innovative power of the Semantic Web to explore the genetic basis of diseases,2016,Bioinformatics,,"Motivation: DisGeNET-RDF makes available knowledge on the genetic basis of human diseases in the Semantic Web. Gene-disease associations (GDAs) and their provenance metadata are published as human-readable and machine-processable web resources. The information on GDAs included in DisGeNET-RDF is interlinked to other biomedical databases to support the development of bioinformatics approaches for translational research through evidence-based exploitation of a rich and fully interconnected linked open data., Availability and implementation: http://rdf.disgenet.org/, Contact: support@disgenet.org",2016-07-15,2021-06-05 20:55:40; 2021-06-05 21:12:40; 2021-06-05 20:59:14,2236-2238,14,32,Bioinformatics,DisGeNET-RDF,PubMed Central,PMID: 27153650 PMCID: PMC4937199,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4937199/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
200,10.1093/bioinformatics/btw455,27587666,,A,Neo4j,Neo4j,"Sheikhizadeh, Siavash; Schranz, M. Eric; Akdel, Mehmet; de Ridder, Dick; Smit, Sandra","PanTools: representation, storage and exploration of pan-genomic data",2016,"Bioinformatics (Oxford, England)",,"MOTIVATION: Next-generation sequencing technology is generating a wealth of highly similar genome sequences for many species, paving the way for a transition from single-genome to pan-genome analyses. Accordingly, genomics research is going to switch from reference-centric to pan-genomic approaches. We define the pan-genome as a comprehensive representation of multiple annotated genomes, facilitating analyses on the similarity and divergence of the constituent genomes at the nucleotide, gene and genome structure level. Current pan-genomic approaches do not thoroughly address scalability, functionality and usability. RESULTS: We introduce a generalized De Bruijn graph as a pan-genome representation, as well as an online algorithm to construct it. This representation is stored in a Neo4j graph database, which makes our approach scalable to large eukaryotic genomes. Besides the construction algorithm, our software package, called PanTools, currently provides functionality for annotating pan-genomes, adding sequences, grouping genes, retrieving gene sequences or genomic regions, reconstructing genomes and comparing and querying pan-genomes. We demonstrate the performance of the tool using datasets of 62 E. coli genomes, 93 yeast genomes and 19 Arabidopsis thaliana genomes. AVAILABILITY AND IMPLEMENTATION: The Java implementation of PanTools is publicly available at http://www.bif.wur.nl CONTACT: sandra.smit@wur.nl.",2016-09-01,2021-06-05 21:24:28; 2021-06-05 21:06:22; 2021-06-05 21:16:51,i487-i493,17,32,Bioinformatics,PanTools,PubMed,PMID: 27587666,http://www.ncbi.nlm.nih.gov/pubmed/27587666,"Algorithms; Arabidopsis; Computational Biology; Escherichia coli; Genome; Genome, Bacterial; Genomics; High-Throughput Nucleotide Sequencing; Humans; Software",Neo4j,Neo4j,PubMed:Neo4j; PubMed:Query3; PubMed:Query2
201,10.1093/bioinformatics/btw652,27797761,PMC6041975,A,AllegroGraph,AllegroGraph,"Penha, Emanuel Diego S; Iriabho, Egiebade; Dussaq, Alex; de Oliveira, Diana Magalhães; Almeida, Jonas S",Isomorphic semantic mapping of variant call format (VCF2RDF),2017,Bioinformatics,,"Summary The move of computational genomics workflows to Cloud Computing platforms is associated with a new level of integration and interoperability that challenges existing data representation formats. The Variant Calling Format (VCF) is in a particularly sensitive position in that regard, with both clinical and consumer-facing analysis tools relying on this self-contained description of genomic variation in Next Generation Sequencing (NGS) results. In this report we identify an isomorphic map between VCF and the reference Resource Description Framework. RDF is advanced by the World Wide Web Consortium (W3C) to enable representations of linked data that are both distributed and discoverable. The resulting ability to decompose VCF reports of genomic variation without loss of context addresses the need to modularize and govern NGS pipelines for Precision Medicine. Specifically, it provides the flexibility (i.e. the indexing) needed to support the wide variety of clinical scenarios and patient-facing governance where only part of the VCF data is fitting. Availability and Implementation Software libraries with a claim to be both domain-facing and consumer-facing have to pass the test of portability across the variety of devices that those consumers in fact adopt. That is, ideally the implementation should itself take place within the space defined by web technologies. Consequently, the isomorphic mapping function was implemented in JavaScript, and was tested in a variety of environments and devices, client and server side alike. These range from web browsers in mobile phones to the most popular micro service platform, NodeJS. The code is publicly available at https://github.com/ibl/VCFr, with a live deployment at: http://ibl.github.io/VCFr/.",2017-02-15,2021-06-05 20:55:40; 2021-06-06 06:38:41; 2021-06-05 21:12:01,547-548,4,33,Bioinformatics,,PubMed Central,PMID: 27797761 PMCID: PMC6041975,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6041975/,,AllegroGraph,AllegroGraph,PMC:Query3; PMC:AllegroGraph; PMC:Query2
202,10.1093/bioinformatics/btw731,27993779,PMC5408918,A,Neo4j,Neo4j,"Balaur, Irina; Mazein, Alexander; Saqi, Mansoor; Lysenko, Artem; Rawlings, Christopher J; Auffray, Charles; Balaur, Irina; Mazein, Alexander; Saqi, Mansoor; Lysenko, Artem; Rawlings, Christopher J.; Auffray, Charles",Recon2Neo4j: applying graph database technologies for managing comprehensive genome-scale networks,2017,"Bioinformatics; Bioinformatics (Oxford, England)",,"Summary The goal of this work is to offer a computational framework for exploring data from the Recon2 human metabolic reconstruction model. Advanced user access features have been developed using the Neo4j graph database technology and this paper describes key features such as efficient management of the network data, examples of the network querying for addressing particular tasks, and how query results are converted back to the Systems Biology Markup Language (SBML) standard format. The Neo4j-based metabolic framework facilitates exploration of highly connected and comprehensive human metabolic data and identification of metabolic subnetworks of interest. A Java-based parser component has been developed to convert query results (available in the JSON format) into SBML and SIF formats in order to facilitate further results exploration, enhancement or network sharing. Availability and Implementation The Neo4j-based metabolic framework is freely available from: https://diseaseknowledgebase.etriks.org/metabolic/browser/. The java code files developed for this work are available from the following url: https://github.com/ibalaur/MetabolicFramework. Supplementary information  are available at Bioinformatics online.; Summary: The goal of this work is to offer a computational framework for exploring data from the Recon2 human metabolic reconstruction model. Advanced user access features have been developed using the Neo4j graph database technology and this paper describes key features such as efficient management of the network data, examples of the network querying for addressing particular tasks, and how query results are converted back to the Systems Biology Markup Language (SBML) standard format. The Neo4j-based metabolic framework facilitates exploration of highly connected and comprehensive human metabolic data and identification of metabolic subnetworks of interest. A Java-based parser component has been developed to convert query results (available in the JSON format) into SBML and SIF formats in order to facilitate further results exploration, enhancement or network sharing. Availability and Implementation: The Neo4j-based metabolic framework is freely available from: https://diseaseknowledgebase.etriks.org/metabolic/browser/ . The java code files developed for this work are available from the following url: https://github.com/ibalaur/MetabolicFramework . Contact: ibalaur@eisbm.org. Supplementary information: Supplementary data are available at Bioinformatics online.",2017-04-01,2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 20:37:08; 2021-06-05 21:12:01; 2021-06-05 20:55:40; 2021-06-05 21:24:28,1096-1098,7,33,Bioinformatics,Recon2Neo4j,PubMed; PubMed Central,PMID: 27993779 PMCID: PMC5408918,http://www.ncbi.nlm.nih.gov/pubmed/27993779; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5408918/,"Computer Graphics; Database Management Systems; Databases, Factual; Genome; Humans; Metabolic Networks and Pathways; Models, Biological; Software",Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
203,10.1093/bioinformatics/btx397,28633344,,A,,,"Mughal, Sajid; Moghul, Ismail; Yu, Jing; UKIRDC; Clark, Tristan; Gregory, David S.; Pontikos, Nikolas",Pheno4J: a gene to phenotype graph database,2017,"Bioinformatics (Oxford, England)",,"Summary: Efficient storage and querying of large amounts of genetic and phenotypic data is crucial to contemporary clinical genetic research. This introduces computational challenges for classical relational databases, due to the sparsity and sheer volume of the data. Our Java based solution loads annotated genetic variants and well phenotyped patients into a graph database to allow fast efficient storage and querying of large volumes of structured genetic and phenotypic data. This abstracts technical problems away and lets researchers focus on the science rather than the implementation. We have also developed an accompanying webserver with end-points to facilitate querying of the database. Availability and implementation: The Java and Python code are available at https://github.com/phenopolis/pheno4j. Contact: n.pontikos@ucl.ac.uk. Supplementary information: Supplementary data are available at Bioinformatics online.",2017-10-15,2021-06-05 21:06:22,3317-3319,20,33,Bioinformatics,Pheno4J,PubMed,PMID: 28633344,http://www.ncbi.nlm.nih.gov/pubmed/28633344,"Computational Biology; Databases, Genetic; Genetic Variation; Humans; Phenotype; Software",,,PubMed:Query2
204,10.1093/bioinformatics/btx441,29077811,PMC5860170,,,,"Sidiropoulos, Konstantinos; Viteri, Guilherme; Sevilla, Cristoffer; Jupe, Steve; Webber, Marissa; Orlic-Milacic, Marija; Jassal, Bijay; May, Bruce; Shamovsky, Veronica; Duenas, Corina; Rothfels, Karen; Matthews, Lisa; Song, Heeyeon; Stein, Lincoln; Haw, Robin; D’Eustachio, Peter; Ping, Peipei; Hermjakob, Henning; Fabregat, Antonio",Reactome enhanced pathway visualization,2017,Bioinformatics,,"Motivation Reactome is a free, open-source, open-data, curated and peer-reviewed knowledge base of biomolecular pathways. Pathways are arranged in a hierarchical structure that largely corresponds to the GO biological process hierarchy, allowing the user to navigate from high level concepts like immune system to detailed pathway diagrams showing biomolecular events like membrane transport or phosphorylation. Here, we present new developments in the Reactome visualization system that facilitate navigation through the pathway hierarchy and enable efficient reuse of Reactome visualizations for users’ own research presentations and publications. Results For the higher levels of the hierarchy, Reactome now provides scalable, interactive textbook-style diagrams in SVG format, which are also freely downloadable and editable. Repeated diagram elements like ‘mitochondrion’ or ‘receptor’ are available as a library of graphic elements. Detailed lower-level diagrams are now downloadable in editable PPTX format as sets of interconnected objects. Availability and implementation http://reactome.org",2017-11-01,2021-06-05 21:12:01,3461-3467,21,33,Bioinformatics,,PubMed Central,PMID: 29077811 PMCID: PMC5860170,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5860170/,,,,PMC:Query2
205,10.1093/bioinformatics/btx660,29048466,PMC5860616,A,Neo4j,Neo4j,"Hoyt, Charles Tapley; Konotopez, Andrej; Ebeling, Christian",PyBEL: a computational framework for Biological Expression Language,2018,Bioinformatics,,"Summary Biological Expression Language (BEL) assembles knowledge networks from biological relations across multiple modes and scales. Here, we present PyBEL; a software package for parsing, validating, converting, storing, querying, and visualizing networks encoded in BEL. Availability and implementation PyBEL is implemented in platform-independent, universal Python code. Its source is distributed under the Apache 2.0 License at https://github.com/pybel. Supplementary information  are available at Bioinformatics online.",2018-02-15,2021-06-05 20:55:40; 2021-06-05 21:11:16; 2021-06-05 20:36:32,703-704,4,34,Bioinformatics,PyBEL,PubMed Central,PMID: 29048466 PMCID: PMC5860616,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5860616/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
206,10.1093/bioinformatics/btx738,29186384,PMC5860622,A,Neo4j,Neo4j,"Castillo-Lara, S.; Abril, J. F.; Castillo-Lara, S; Abril, J F",PlanNET: homology-based predicted interactome for multiple planarian transcriptomes,2018,"Bioinformatics; Bioinformatics (Oxford, England)",,"Motivation Planarians are emerging as a model organism to study regeneration in animals. However, the little available data of protein–protein interactions hinders the advances in understanding the mechanisms underlying its regenerating capabilities. Results We have developed a protocol to predict protein–protein interactions using sequence homology data and a reference Human interactome. This methodology was applied on 11 Schmidtea mediterranea transcriptomic sequence datasets. Then, using Neo4j as our database manager, we developed PlanNET, a web application to explore the multiplicity of networks and the associated sequence annotations. By mapping RNA-seq expression experiments onto the predicted networks, and allowing a transcript-centric exploration of the planarian interactome, we provide researchers with a useful tool to analyse possible pathways and to design new experiments, as well as a reproducible methodology to predict, store, and explore protein interaction networks for non-model organisms. Availability and implementation The web application PlanNET is available at https://compgen.bio.ub.edu/PlanNET. The source code used is available at https://compgen.bio.ub.edu/PlanNET/downloads. Supplementary information  are available at Bioinformatics online.; Motivation: Planarians are emerging as a model organism to study regeneration in animals. However, the little available data of protein-protein interactions hinders the advances in understanding the mechanisms underlying its regenerating capabilities. Results: We have developed a protocol to predict protein-protein interactions using sequence homology data and a reference Human interactome. This methodology was applied on 11 Schmidtea mediterranea transcriptomic sequence datasets. Then, using Neo4j as our database manager, we developed PlanNET, a web application to explore the multiplicity of networks and the associated sequence annotations. By mapping RNA-seq expression experiments onto the predicted networks, and allowing a transcript-centric exploration of the planarian interactome, we provide researchers with a useful tool to analyse possible pathways and to design new experiments, as well as a reproducible methodology to predict, store, and explore protein interaction networks for non-model organisms. Availability and implementation: The web application PlanNET is available at https://compgen.bio.ub.edu/PlanNET. The source code used is available at https://compgen.bio.ub.edu/PlanNET/downloads. Contact: jabril@ub.edu. Supplementary information: Supplementary data are available at Bioinformatics online.",2018-03-15,2021-06-05 21:11:16; 2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 20:55:40; 2021-06-05 21:24:28; 2021-06-05 20:36:32,1016-1023,6,34,Bioinformatics,PlanNET,PubMed; PubMed Central,PMID: 29186384 PMCID: PMC5860622,http://www.ncbi.nlm.nih.gov/pubmed/29186384; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5860622/,"Animals; Gene Expression Profiling; Humans; Internet; Planarians; Protein Interaction Maps; Regeneration; Sequence Analysis, RNA; Software",Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
207,10.1093/bioinformatics/btx739,29186292,PMC6031061,A,Neo4j,Neo4j,"Lekschas, Fritz; Gehlenborg, Nils",SATORI: a system for ontology-guided visual exploration of biomedical data repositories,2018,Bioinformatics,,"Motivation The ever-increasing number of biomedical datasets provides tremendous opportunities for re-use but current data repositories provide limited means of exploration apart from text-based search. Ontological metadata annotations provide context by semantically relating datasets. Visualizing this rich network of relationships can improve the explorability of large data repositories and help researchers find datasets of interest. Results We developed SATORI—an integrative search and visual exploration interface for the exploration of biomedical data repositories. The design is informed by a requirements analysis through a series of semi-structured interviews. We evaluated the implementation of SATORI in a field study on a real-world data collection. SATORI enables researchers to seamlessly search, browse and semantically query data repositories via two visualizations that are highly interconnected with a powerful search interface. Availability and implementation SATORI is an open-source web application, which is freely available at http://satori.refinery-platform.org and integrated into the Refinery Platform. Supplementary information  are available at Bioinformatics online.",2018-04-01,2021-06-05 20:55:40; 2021-06-05 21:11:16; 2021-06-05 20:36:32,1200-1207,7,34,Bioinformatics,SATORI,PubMed Central,PMID: 29186292 PMCID: PMC6031061,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6031061/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
208,10.1093/bioinformatics/btx767,29186322,PMC5905645,,,,"Koehorst, Jasper J; van Dam, Jesse C J; Saccenti, Edoardo; Martins dos Santos, Vitor A P; Suarez-Diez, Maria; Schaap, Peter J",SAPP: functional genome annotation and analysis through a semantic framework using FAIR principles,2018,Bioinformatics,,"Summary To unlock the full potential of genome data and to enhance data interoperability and reusability of genome annotations we have developed SAPP, a Semantic Annotation Platform with Provenance. SAPP is designed as an infrastructure supporting FAIR de novo computational genomics but can also be used to process and analyze existing genome annotations. SAPP automatically predicts, tracks and stores structural and functional annotations and associated dataset- and element-wise provenance in a Linked Data format, thereby enabling information mining and retrieval with Semantic Web technologies. This greatly reduces the administrative burden of handling multiple analysis tools and versions thereof and facilitates multi-level large scale comparative analysis. Availability and implementation SAPP is written in JAVA and freely available at https://gitlab.com/sapp and runs on Unix-like operating systems. The documentation, examples and a tutorial are available at https://sapp.gitlab.io.",2018-04-15,2021-06-05 21:11:16,1401-1403,8,34,Bioinformatics,SAPP,PubMed Central,PMID: 29186322 PMCID: PMC5905645,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5905645/,,,,PMC:Query2
209,10.1093/bioinformatics/bty845,30304355,PMC6499247,A,Neo4j,Neo4j,"Pyysalo, Sampo; Baker, Simon; Ali, Imran; Haselwimmer, Stefan; Shah, Tejas; Young, Andrew; Guo, Yufan; Högberg, Johan; Stenius, Ulla; Narita, Masashi; Korhonen, Anna",LION LBD: a literature-based discovery system for cancer biology,2019,Bioinformatics,,"Motivation The overwhelming size and rapid growth of the biomedical literature make it impossible for scientists to read all studies related to their work, potentially leading to missed connections and wasted time and resources. Literature-based discovery (LBD) aims to alleviate these issues by identifying implicit links between disjoint parts of the literature. While LBD has been studied in depth since its introduction three decades ago, there has been limited work making use of recent advances in biomedical text processing methods in LBD. Results We present LION LBD, a literature-based discovery system that enables researchers to navigate published information and supports hypothesis generation and testing. The system is built with a particular focus on the molecular biology of cancer using state-of-the-art machine learning and natural language processing methods, including named entity recognition and grounding to domain ontologies covering a wide range of entity types and a novel approach to detecting references to the hallmarks of cancer in text. LION LBD implements a broad selection of co-occurrence based metrics for analyzing the strength of entity associations, and its design allows real-time search to discover indirect associations between entities in a database of tens of millions of publications while preserving the ability of users to explore each mention in its original context in the literature. Evaluations of the system demonstrate its ability to identify undiscovered links and rank relevant concepts highly among potential connections. Availability and implementation The LION LBD system is available via a web-based user interface and a programmable API, and all components of the system are made available under open licenses from the project home page http://lbd.lionproject.net. Supplementary information  are available at Bioinformatics online.",2019-05-01,2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:36:32,1553-1561,9,35,Bioinformatics,LION LBD,PubMed Central,PMID: 30304355 PMCID: PMC6499247,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6499247/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
210,10.1093/bioinformatics/btz050,30689784,,A,Neo4j,Neo4j,"Maiers, Martin; Halagan, Michael; Gragert, Loren; Bashyal, Pradeep; Brelsford, Jason; Schneider, Joel; Lutsker, Polina; Louzoun, Yoram",GRIMM: GRaph IMputation and matching for HLA genotypes,2019,"Bioinformatics (Oxford, England)",,"MOTIVATION: For over 10 years allele-level HLA matching for bone marrow registries has been performed in a probabilistic context. HLA typing technologies provide ambiguous results in that they could not distinguish among all known HLA alleles equences; therefore registries have implemented matching algorithms that provide lists of donor and cord blood units ordered in terms of the likelihood of allele-level matching at specific HLA loci. With the growth of registry sizes, current match algorithm implementations are unable to provide match results in real time. RESULTS: We present here a novel computationally-efficient open source implementation of an HLA imputation and match algorithm using a graph database platform. Using graph traversal, the matching algorithm runtime is practically not affected by registry size. This implementation generates results that agree with consensus output on a publicly-available match algorithm cross-validation dataset. AVAILABILITY AND IMPLEMENTATION: The Python, Perl and Neo4j code is available at https://github.com/nmdp-bioinformatics/grimm. SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.",2019-09-15,2021-06-05 21:24:28; 2021-06-05 21:06:22; 2021-06-05 21:16:51,3520-3523,18,35,Bioinformatics,GRIMM,PubMed,PMID: 30689784,http://www.ncbi.nlm.nih.gov/pubmed/30689784,Genotype; Histocompatibility Testing; HLA Antigens; Humans; Tissue Donors,Neo4j,Neo4j,PubMed:Neo4j; PubMed:Query3; PubMed:Query2
211,10.1093/bioinformatics/btz260,30994884,,A,,,"Aguilera-Mendoza, Longendri; Marrero-Ponce, Yovani; Beltran, Jesus A.; Tellez Ibarra, Roberto; Guillen-Ramirez, Hugo A.; Brizuela, Carlos A.",Graph-based data integration from bioactive peptide databases of pharmaceutical interest: toward an organized collection enabling visual network analysis,2019,"Bioinformatics (Oxford, England)",,"MOTIVATION: Bioactive peptides have gained great attention in the academy and pharmaceutical industry since they play an important role in human health. However, the increasing number of bioactive peptide databases is causing the problem of data redundancy and duplicated efforts. Even worse is the fact that the available data is non-standardized and often dirty with data entry errors. Therefore, there is a need for a unified view that enables a more comprehensive analysis of the information on this topic residing at different sites. RESULTS: After collecting web pages from a large variety of bioactive peptide databases, we organized the web content into an integrated graph database (starPepDB) that holds a total of 71 310 nodes and 348 505 relationships. In this graph structure, there are 45 120 nodes representing peptides, and the rest of the nodes are connected to peptides for describing metadata. Additionally, to facilitate a better understanding of the integrated data, a software tool (starPep toolbox) has been developed for supporting visual network analysis in a user-friendly way; providing several functionalities such as peptide retrieval and filtering, network construction and visualization, interactive exploration and exporting data options. AVAILABILITY AND IMPLEMENTATION: Both starPepDB and starPep toolbox are freely available at http://mobiosd-hub.com/starpep/. SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.",2019-11-01,2021-06-05 21:06:22,4739-4747,22,35,Bioinformatics,Graph-based data integration from bioactive peptide databases of pharmaceutical interest,PubMed,PMID: 30994884,http://www.ncbi.nlm.nih.gov/pubmed/30994884,"Databases, Factual; Humans; Metadata; Peptides; Pharmaceutical Preparations; Software",,,PubMed:Query2
212,10.1093/bioinformatics/btz604,31410449,PMC6954664,A,Neo4j,Neo4j,"Morton, Kenneth; Wang, Patrick; Bizon, Chris; Cox, Steven; Balhoff, James; Kebede, Yaphet; Fecho, Karamarie; Tropsha, Alexander",ROBOKOP: an abstraction layer and user interface for knowledge graphs to support question answering,2019,"Bioinformatics; Bioinformatics (Oxford, England)",,"Summary Knowledge graphs (KGs) are quickly becoming a common-place tool for storing relationships between entities from which higher-level reasoning can be conducted. KGs are typically stored in a graph-database format, and graph-database queries can be used to answer questions of interest that have been posed by users such as biomedical researchers. For simple queries, the inclusion of direct connections in the KG and the storage and analysis of query results are straightforward; however, for complex queries, these capabilities become exponentially more challenging with each increase in complexity of the query. For instance, one relatively complex query can yield a KG with hundreds of thousands of query results. Thus, the ability to efficiently query, store, rank and explore sub-graphs of a complex KG represents a major challenge to any effort designed to exploit the use of KGs for applications in biomedical research and other domains. We present Reasoning Over Biomedical Objects linked in Knowledge Oriented Pathways as an abstraction layer and user interface to more easily query KGs and store, rank and explore query results. Availability and implementation An instance of the ROBOKOP UI for exploration of the ROBOKOP Knowledge Graph can be found at http://robokop.renci.org. The ROBOKOP Knowledge Graph can be accessed at http://robokopkg.renci.org. Code and instructions for building and deploying ROBOKOP are available under the MIT open software license from https://github.com/NCATS-Gamma/robokop. Supplementary information  are available at Bioinformatics online.; SUMMARY: Knowledge graphs (KGs) are quickly becoming a common-place tool for storing relationships between entities from which higher-level reasoning can be conducted. KGs are typically stored in a graph-database format, and graph-database queries can be used to answer questions of interest that have been posed by users such as biomedical researchers. For simple queries, the inclusion of direct connections in the KG and the storage and analysis of query results are straightforward; however, for complex queries, these capabilities become exponentially more challenging with each increase in complexity of the query. For instance, one relatively complex query can yield a KG with hundreds of thousands of query results. Thus, the ability to efficiently query, store, rank and explore sub-graphs of a complex KG represents a major challenge to any effort designed to exploit the use of KGs for applications in biomedical research and other domains. We present Reasoning Over Biomedical Objects linked in Knowledge Oriented Pathways as an abstraction layer and user interface to more easily query KGs and store, rank and explore query results. AVAILABILITY AND IMPLEMENTATION: An instance of the ROBOKOP UI for exploration of the ROBOKOP Knowledge Graph can be found at http://robokop.renci.org. The ROBOKOP Knowledge Graph can be accessed at http://robokopkg.renci.org. Code and instructions for building and deploying ROBOKOP are available under the MIT open software license from https://github.com/NCATS-Gamma/robokop. SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.",2019-12-15,2021-06-05 20:55:01; 2021-06-05 21:06:22; 2021-06-05 20:36:32; 2021-06-05 21:10:37,5382-5384,24,35,Bioinformatics,ROBOKOP,PubMed; PubMed Central,PMID: 31410449 PMCID: PMC6954664,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6954664/; http://www.ncbi.nlm.nih.gov/pubmed/31410449,"Databases, Factual; Pattern Recognition, Automated; Software",Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PubMed:Query2; PMC:Query2
213,10.1093/bioinformatics/btz658,31504165,,A,Neo4j,Neo4j,"Lose, Thoba; van Heusden, Peter; Christoffels, Alan",COMBAT-TB-NeoDB: fostering tuberculosis research through integrative analysis using graph database technologies,2020,"Bioinformatics (Oxford, England)",,"MOTIVATION: Recent advancements in genomic technologies have enabled high throughput cost-effective generation of 'omics' data from M.tuberculosis (M.tb) isolates, which then gets shared via a number of heterogeneous publicly available biological databases. Albeit useful, fragmented curation negatively impacts the researcher's ability to leverage the data via federated queries. RESULTS: We present Combat-TB-NeoDB, an integrated M.tb 'omics' knowledge-base. Combat-TB-NeoDB is based on Neo4j and was created by binding the labeled property graph model to a suitable ontology namely Chado. Combat-TB-NeoDB enables researchers to execute complex federated queries by linking prominent biological databases, and supplementary M.tb variants data from published literature. AVAILABILITY AND IMPLEMENTATION: The Combat-TB-NeoDB (https://neodb.sanbi.ac.za) repository and all tools mentioned in this manuscript are freely available at https://github.com/COMBAT-TB. SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.",2020-02-01,2021-06-05 21:24:28; 2021-06-05 21:06:22; 2021-06-05 21:16:51,982-983,3,36,Bioinformatics,COMBAT-TB-NeoDB,PubMed,PMID: 31504165,http://www.ncbi.nlm.nih.gov/pubmed/31504165,"Databases, Factual; Genome; Genomics; Humans; Mycobacterium tuberculosis; Software; Tuberculosis",Neo4j,Neo4j,PubMed:Neo4j; PubMed:Query3; PubMed:Query2
214,10.1093/brain/awz248,31501903,PMC6763744,,,,"Efthymiou, Stephanie; Salpietro, Vincenzo; Malintan, Nancy; Poncelet, Mallory; Kriouile, Yamna; Fortuna, Sara; De Zorzi, Rita; Payne, Katelyn; Henderson, Lindsay B; Cortese, Andrea; Maddirevula, Sateesh; Alhashmi, Nadia; Wiethoff, Sarah; Ryten, Mina; Botia, Juan A; Provitera, Vincenzo; Schuelke, Markus; Vandrovcova, Jana; Walsh, Laurence; Torti, Erin; Iodice, Valeria; Najafi, Maryam; Karimiani, Ehsan Ghayoor; Maroofian, Reza; Siquier-Pernet, Karine; Boddaert, Nathalie; De Lonlay, Pascale; Cantagrel, Vincent; Aguennouz, Mhammed; El Khorassani, Mohamed; Schmidts, Miriam; Alkuraya, Fowzan S; Edvardson, Simon; Nolano, Maria; Devaux, Jérôme; Houlden, Henry",Biallelic mutations in neurofascin cause neurodevelopmental impairment and peripheral demyelination,2019,Brain,,"See Karakaya and Wirth (doi:10.1093/brain/awz273) for a scientific commentary on this article., Neurofascin (NFASC) isoforms are immunoglobulin cell adhesion molecules involved in node of Ranvier assembly. Efthymiou et al. identify biallelic NFASC variants in ten unrelated patients with a neurodevelopmental disorder characterized by variable degrees of central and peripheral involvement. Abnormal expression of Nfasc155 is accompanied by severe loss of myelinated fibres., Axon pathfinding and synapse formation are essential processes for nervous system development and function. The assembly of myelinated fibres and nodes of Ranvier is mediated by a number of cell adhesion molecules of the immunoglobulin superfamily including neurofascin, encoded by the NFASC gene, and its alternative isoforms Nfasc186 and Nfasc140 (located in the axonal membrane at the node of Ranvier) and Nfasc155 (a glial component of the paranodal axoglial junction). We identified 10 individuals from six unrelated families, exhibiting a neurodevelopmental disorder characterized with a spectrum of central (intellectual disability, developmental delay, motor impairment, speech difficulties) and peripheral (early onset demyelinating neuropathy) neurological involvement, who were found by exome or genome sequencing to carry one frameshift and four different homozygous non-synonymous variants in NFASC. Expression studies using immunostaining-based techniques identified absent expression of the Nfasc155 isoform as a consequence of the frameshift variant and a significant reduction of expression was also observed in association with two non-synonymous variants affecting the fibronectin type III domain. Cell aggregation studies revealed a severely impaired Nfasc155-CNTN1/CASPR1 complex interaction as a result of the identified variants. Immunofluorescence staining of myelinated fibres from two affected individuals showed a severe loss of myelinated fibres and abnormalities in the paranodal junction morphology. Our results establish that recessive variants affecting the Nfasc155 isoform can affect the formation of paranodal axoglial junctions at the nodes of Ranvier. The genetic disease caused by biallelic NFASC variants includes neurodevelopmental impairment and a spectrum of central and peripheral demyelination as part of its core clinical phenotype. Our findings support possible overlapping molecular mechanisms of paranodal damage at peripheral nerves in both the immune-mediated and the genetic disease, but the observation of prominent central neurological involvement in NFASC biallelic variant carriers highlights the importance of this gene in human brain development and function.",2019-10,2021-06-05 21:10:37,2948-2964,10,142,Brain,,PubMed Central,PMID: 31501903 PMCID: PMC6763744,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6763744/,,,,PMC:Query2
215,10.1093/database/baaa015,32283553,PMC7153956,A,Neo4j,Neo4j,"Queralt-Rosinach, Núria; Stupp, Gregory S; Li, Tong Shu; Mayers, Michael; Hoatlin, Maureen E; Might, Matthew; Good, Benjamin M; Su, Andrew I; Queralt-Rosinach, Núria; Stupp, Gregory S.; Li, Tong Shu; Mayers, Michael; Hoatlin, Maureen E.; Might, Matthew; Good, Benjamin M.; Su, Andrew I.",Structured reviews for data and knowledge-driven research,2020,Database: The Journal of Biological Databases and Curation,,"Hypothesis generation is a critical step in research and a cornerstone in the rare disease field. Research is most efficient when those hypotheses are based on the entirety of knowledge known to date. Systematic review articles are commonly used in biomedicine to summarize existing knowledge and contextualize experimental data. But the information contained within review articles is typically only expressed as free-text, which is difficult to use computationally. Researchers struggle to navigate, collect and remix prior knowledge as it is scattered in several silos without seamless integration and access. This lack of a structured information framework hinders research by both experimental and computational scientists. To better organize knowledge and data, we built a structured review article that is specifically focused on NGLY1 Deficiency, an ultra-rare genetic disease first reported in 2012. We represented this structured review as a knowledge graph and then stored this knowledge graph in a Neo4j database to simplify dissemination, querying and visualization of the network. Relative to free-text, this structured review better promotes the principles of findability, accessibility, interoperability and reusability (FAIR). In collaboration with domain experts in NGLY1 Deficiency, we demonstrate how this resource can improve the efficiency and comprehensiveness of hypothesis generation. We also developed a read-write interface that allows domain experts to contribute FAIR structured knowledge to this community resource. In contrast to traditional free-text review articles, this structured review exists as a living knowledge graph that is curated by humans and accessible to computational analyses. Finally, we have generalized this workflow into modular and repurposable components that can be applied to other domain areas. This NGLY1 Deficiency-focused network is publicly available at http://ngly1graph.org/. AVAILABILITY AND IMPLEMENTATION: Database URL: http://ngly1graph.org/. Network data files are at: https://github.com/SuLab/ngly1-graph and source code at: https://github.com/SuLab/bioknowledge-reviewer. CONTACT: asu@scripps.edu.; Hypothesis generation is a critical step in research and a cornerstone in the rare disease field. Research is most efficient when those hypotheses are based on the entirety of knowledge known to date. Systematic review articles are commonly used in biomedicine to summarize existing knowledge and contextualize experimental data. But the information contained within review articles is typically only expressed as free-text, which is difficult to use computationally. Researchers struggle to navigate, collect and remix prior knowledge as it is scattered in several silos without seamless integration and access. This lack of a structured information framework hinders research by both experimental and computational scientists. To better organize knowledge and data, we built a structured review article that is specifically focused on NGLY1 Deficiency, an ultra-rare genetic disease first reported in 2012. We represented this structured review as a knowledge graph and then stored this knowledge graph in a Neo4j database to simplify dissemination, querying and visualization of the network. Relative to free-text, this structured review better promotes the principles of findability, accessibility, interoperability and reusability (FAIR). In collaboration with domain experts in NGLY1 Deficiency, we demonstrate how this resource can improve the efficiency and comprehensiveness of hypothesis generation. We also developed a read–write interface that allows domain experts to contribute FAIR structured knowledge to this community resource. In contrast to traditional free-text review articles, this structured review exists as a living knowledge graph that is curated by humans and accessible to computational analyses. Finally, we have generalized this workflow into modular and repurposable components that can be applied to other domain areas. This NGLY1 Deficiency-focused network is publicly available at http://ngly1graph.org/. Availability and implementation Database URL: http://ngly1graph.org/. Network data files are at: https://github.com/SuLab/ngly1-graph and source code at: https://github.com/SuLab/bioknowledge-reviewer. Contact asu@scripps.edu",2020-04-11; 2020-01-01,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08; 2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 21:24:28,,,2020,Database (Oxford),,PubMed; PubMed Central,PMID: 32283553 PMCID: PMC7153956,http://www.ncbi.nlm.nih.gov/pubmed/32283553; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7153956/,"Animals; Biomedical Research; Computational Biology; Congenital Disorders of Glycosylation; Data Curation; Data Mining; Databases, Factual; Humans; Internet; Knowledge Bases; Peptide-N4-(N-acetyl-beta-glucosaminyl) Asparagine Amidase; Systematic Reviews as Topic",Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
216,10.1093/database/baaa018,32294194,PMC7158887,A,Neo4j,Neo4j,"Cowman, Tyler; Coşkun, Mustafa; Grama, Ananth; Koyutürk, Mehmet",Integrated querying and version control of context-specific biological networks,2020,Database: The Journal of Biological Databases and Curation,,"Motivation Biomolecular data stored in public databases is increasingly specialized to organisms, context/pathology and tissue type, potentially resulting in significant overhead for analyses. These networks are often specializations of generic interaction sets, presenting opportunities for reducing storage and computational cost. Therefore, it is desirable to develop effective compression and storage techniques, along with efficient algorithms and a flexible query interface capable of operating on compressed data structures. Current graph databases offer varying levels of support for network integration. However, these solutions do not provide efficient methods for the storage and querying of versioned networks. Results We present VerTIoN, a framework consisting of novel data structures and associated query mechanisms for integrated querying of versioned context-specific biological networks. As a use case for our framework, we study network proximity queries in which the user can select and compose a combination of tissue-specific and generic networks. Using our compressed version tree data structure, in conjunction with state-of-the-art numerical techniques, we demonstrate real-time querying of large network databases. Conclusion Our results show that it is possible to support flexible queries defined on heterogeneous networks composed at query time while drastically reducing response time for multiple simultaneous queries. The flexibility offered by VerTIoN in composing integrated network versions opens significant new avenues for the utilization of ever increasing volume of context-specific network data in a broad range of biomedical applications. Availability and Implementation VerTIoN is implemented as a C++ library and is available at http://compbio.case.edu/omics/software/vertion and https://github.com/tjcowman/vertion Contact tyler.cowman@case.edu; MOTIVATION: Biomolecular data stored in public databases is increasingly specialized to organisms, context/pathology and tissue type, potentially resulting in significant overhead for analyses. These networks are often specializations of generic interaction sets, presenting opportunities for reducing storage and computational cost. Therefore, it is desirable to develop effective compression and storage techniques, along with efficient algorithms and a flexible query interface capable of operating on compressed data structures. Current graph databases offer varying levels of support for network integration. However, these solutions do not provide efficient methods for the storage and querying of versioned networks. RESULTS: We present VerTIoN, a framework consisting of novel data structures and associated query mechanisms for integrated querying of versioned context-specific biological networks. As a use case for our framework, we study network proximity queries in which the user can select and compose a combination of tissue-specific and generic networks. Using our compressed version tree data structure, in conjunction with state-of-the-art numerical techniques, we demonstrate real-time querying of large network databases. CONCLUSION: Our results show that it is possible to support flexible queries defined on heterogeneous networks composed at query time while drastically reducing response time for multiple simultaneous queries. The flexibility offered by VerTIoN in composing integrated network versions opens significant new avenues for the utilization of ever increasing volume of context-specific network data in a broad range of biomedical applications. AVAILABILITY AND IMPLEMENTATION: VerTIoN is implemented as a C++ library and is available at http://compbio.case.edu/omics/software/vertion and https://github.com/tjcowman/vertion. CONTACT: tyler.cowman@case.edu.",2020-04-15; 2020-01-01,2021-06-05 20:35:57; 2021-06-05 21:06:22; 2021-06-05 20:54:31; 2021-06-05 21:10:08,,,2020,Database (Oxford),,PubMed; PubMed Central,PMID: 32294194 PMCID: PMC7158887,http://www.ncbi.nlm.nih.gov/pubmed/32294194; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7158887/,"Algorithms; Computational Biology; Data Curation; Data Mining; Databases, Factual; Gene Regulatory Networks; Humans; Internet; Protein Interaction Maps; User-Computer Interface",Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PubMed:Query2; PMC:Query2
217,10.1093/database/baaa034,32449511,PMC7246345,,,,"Holliday, Gemma L; Brown, Shoshana D; Mischel, David; Polacco, Benjamin J; Babbitt, Patricia C",A strategy for large-scale comparison of evolutionary- and reaction-based classifications of enzyme function,2020,Database: The Journal of Biological Databases and Curation,,"Determining the molecular function of enzymes discovered by genome sequencing represents a primary foundation for understanding many aspects of biology. Historically, classification of enzyme reactions has used the enzyme nomenclature system developed to describe the overall reactions performed by biochemically characterized enzymes, irrespective of their associated sequences. In contrast, functional classification and assignment for the millions of protein sequences of unknown function now available is largely done in two computational steps, first by similarity-based assignment of newly obtained sequences to homologous groups, followed by transferring to them the known functions of similar biochemically characterized homologs. Due to the fundamental differences in their etiologies and practice, `how’ these chemistry- and evolution-centric functional classification systems relate to each other has been difficult to explore on a large scale. To investigate this issue in a new way, we integrated two published ontologies that had previously described each of these classification systems independently. The resulting infrastructure was then used to compare the functional assignments obtained from each classification system for the well-studied and functionally diverse enolase superfamily. Mapping these function assignments to protein structure and reaction similarity networks shows a profound and complex disconnect between the homology- and chemistry-based classification systems. This conclusion mirrors previous observations suggesting that except for closely related sequences, facile annotation transfer from small numbers of characterized enzymes to the huge number uncharacterized homologs to which they are related is problematic. Our extension of these comparisons to large enzyme superfamilies in a computationally intelligent manner provides a foundation for new directions in protein function prediction for the huge proportion of sequences of unknown function represented in major databases. Interactive sequence, reaction, substrate and product similarity networks computed for this work for the enolase and two other superfamilies are freely available for download from the Structure Function Linkage Database Archive (http://sfld.rbvi.ucsf.edu).",2020-05-25,2021-06-05 21:10:08,,,2020,Database (Oxford),,PubMed Central,PMID: 32449511 PMCID: PMC7246345,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7246345/,,,,PMC:Query2
218,10.1093/database/baaa087,33216895,PMC7678784,,,,"Begum, Khodeza; Mohl, Jonathon E; Ayivor, Fredrick; Perez, Eder E; Leung, Ming-Ying",GPCR-PEnDB: a database of protein sequences and derived features to facilitate prediction and classification of G protein-coupled receptors,2020,Database: The Journal of Biological Databases and Curation,,"G protein-coupled receptors (GPCRs) constitute the largest group of membrane receptor proteins in eukaryotes. Due to their significant roles in various physiological processes such as vision, smell and inflammation, GPCRs are the targets of many prescription drugs. However, the functional and sequence diversity of GPCRs has kept their prediction and classification based on amino acid sequence data as a challenging bioinformatics problem. There are existing computational approaches, mainly using machine learning and statistical methods, to predict and classify GPCRs based on amino acid sequence and sequence derived features. In this paper, we describe a searchable MySQL database, named GPCR-PEnDB (GPCR Prediction Ensemble Database), of confirmed GPCRs and non-GPCRs. It was constructed with the goal of allowing users to conveniently access useful information of GPCRs in a wide range of organisms and to compile reliable training and testing datasets for different combinations of computational tools. This database currently contains 3129 confirmed GPCR and 3575 non-GPCR sequences collected from the UniProtKB/Swiss-Prot protein database, encompassing over 1200 species. The non-GPCR entries include transmembrane proteins for evaluating various prediction programs’ abilities to distinguish GPCRs from other transmembrane proteins. Each protein is linked to information about its source organism, classification, sequence lengths and composition, and other derived sequence features. We present examples of using this database along with its graphical user interface, to query for GPCRs with specific sequence properties and to compare the accuracies of five tools for GPCR prediction. This initial version of GPCR-PEnDB will provide a framework for future extensions to include additional sequence and feature data to facilitate the design and assessment of software tools and experimental studies to help understand the functional roles of GPCRs.,  Database URL: gpcr.utep.edu/database",2020-11-20,2021-06-05 21:09:36,,,2020,Database (Oxford),GPCR-PEnDB,PubMed Central,PMID: 33216895 PMCID: PMC7678784,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7678784/,,,,PMC:Query2
219,10.1093/database/baaa110,33306799,PMC7731929,A,Neo4j,Neo4j,"Simpson, Claire M; Gnad, Florian; Simpson, Claire M.; Gnad, Florian",Applying graph database technology for analyzing perturbed co-expression networks in cancer,2020,Database: The Journal of Biological Databases and Curation,,"Graph representations provide an elegant solution to capture and analyze complex molecular mechanisms in the cell. Co-expression networks are undirected graph representations of transcriptional co-behavior indicating (co-)regulations, functional modules or even physical interactions between the corresponding gene products. The growing avalanche of available RNA sequencing (RNAseq) data fuels the construction of such networks, which are usually stored in relational databases like most other biological data. Inferring linkage by recursive multiple-join statements, however, is computationally expensive and complex to design in relational databases. In contrast, graph databases store and represent complex interconnected data as nodes, edges and properties, making it fast and intuitive to query and analyze relationships. While graph-based database technologies are on their way from a fringe domain to going mainstream, there are only a few studies reporting their application to biological data. We used the graph database management system Neo4j to store and analyze co-expression networks derived from RNAseq data from The Cancer Genome Atlas. Comparing co-expression in tumors versus healthy tissues in six cancer types revealed significant perturbation tracing back to erroneous or rewired gene regulation. Applying centrality, community detection and pathfinding graph algorithms uncovered the destruction or creation of central nodes, modules and relationships in co-expression networks of tumors. Given the speed, accuracy and straightforwardness of managing these densely connected networks, we conclude that graph databases are ready for entering the arena of biological data.",2020-12-11,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36; 2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 21:24:28,,,2020,Database (Oxford),,PubMed; PubMed Central,PMID: 33306799 PMCID: PMC7731929,http://www.ncbi.nlm.nih.gov/pubmed/33306799; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7731929/,,Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
220,10.1093/database/baab016,33864455,PMC8052916,A,Neo4j,Neo4j,"Fadlelmola, Faisal M; Ghedira, Kais; Hamdi, Yosr; Hanachi, Mariem; Radouani, Fouzia; Allali, Imane; Kiran, Anmol; Zass, Lyndon; Alsayed, Nihad; Fassatoui, Meriem; Samtal, Chaimae; Ahmed, Samah; Da Rocha, Jorge; Chaqsare, Souad; Sallam, Reem M; Chaouch, Melek; Farahat, Mohammed; Ssekagiri, Alfred; Parker, Ziyaad; Adil, Mai; Turkson, Michael; Benchaalia, Aymen; Benkahla, Alia; Panji, Sumir; Kassim, Samar; Souiai, Oussema; Mulder, Nicola",H3ABioNet genomic medicine and microbiome data portals hackathon proceedings,2021,Database: The Journal of Biological Databases and Curation,,"African genomic medicine and microbiome datasets are usually not well characterized in terms of their origin, making it difficult to find and extract data for specific African ethnic groups or even countries. The Pan-African H3Africa Bioinformatics Network (H3ABioNet) recognized the need for developing data portals for African genomic medicine and African microbiomes to address this and ran a hackathon to initiate their development. The two portals were designed and significant progress was made in their development during the hackathon. All the participants worked in a very synergistic and collaborative atmosphere in order to achieve the hackathon's goals. The participants were divided into content and technical teams and worked over a period of 6 days. In response to one of the survey questions of what the participants liked the most during the hackathon, 55% of the hackathon participants highlighted the familial and friendly atmosphere, the team work and the diversity of team members and their expertise. This paper describes the preparations for the portals hackathon and the interaction between the participants and reflects upon the lessons learned about its impact on successfully developing the two data portals as well as building scientific expertise of younger African researchers.,  Database URL: The code for developing the two portals was made publicly available in GitHub repositories: [https://github.com/codemeleon/Database; https://github.com/codemeleon/AfricanMicrobiomePortal].",2021-04-17,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,,2021,Database (Oxford),,PubMed Central,PMID: 33864455 PMCID: PMC8052916,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8052916/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
221,10.1093/database/baab026,34003247,PMC8130509,A,Fauna; Neo4j; GraphDB; ArangoDB; JanusGraph; Dgraph; OrientDB; AllegroGraph,Fauna; Neo4j; GraphDB; ArangoDB; JanusGraph; Dgraph; OrientDB; AllegroGraph,"Timón-Reina, Santiago; Rincón, Mariano; Martínez-Tomás, Rafael",An overview of graph databases and their applications in the biomedical domain,2021,Database: The Journal of Biological Databases and Curation,,"Over the past couple of decades, the explosion of densely interconnected data has stimulated the research, development and adoption of graph database technologies. From early graph models to more recent native graph databases, the landscape of implementations has evolved to cover enterprise-ready requirements. Because of the interconnected nature of its data, the biomedical domain has been one of the early adopters of graph databases, enabling more natural representation models and better data integration workflows, exploration and analysis facilities. In this work, we survey the literature to explore the evolution, performance and how the most recent graph database solutions are applied in the biomedical domain, compiling a great variety of use cases. With this evidence, we conclude that the available graph database management systems are fit to support data-intensive, integrative applications, targeted at both basic research and exploratory tasks closer to the clinic.",2021-05-18,2021-06-05 20:35:57; 2021-06-06 07:33:06; 2021-06-05 20:54:31; 2021-06-06 06:42:51; 2021-06-05 21:09:36; 2021-06-06 06:49:06; 2021-06-06 06:38:41; 2021-06-05 21:06:22; 2021-06-06 07:06:30; 2021-06-06 07:26:31; 2021-06-06 06:54:16,,,2021,Database (Oxford),,PubMed; PubMed Central,PMID: 34003247 PMCID: PMC8130509,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8130509/; http://www.ncbi.nlm.nih.gov/pubmed/34003247,,Fauna; Neo4j; GraphDB; ArangoDB; JanusGraph; Dgraph; OrientDB; AllegroGraph,Fauna; Neo4j; GraphDB; ArangoDB; JanusGraph; Dgraph; OrientDB; AllegroGraph,PMC:Dgraph; PMC:AllegroGraph; PMC:Query2; PMC:OrientDB; PMC:Fauna; PMC:Query3; PMC:Neo4j; PMC:GraphDB; PubMed:Query2; PMC:JanusGraph; PMC:ArangoDB
222,10.1093/database/bat056,23894185,PMC3724366,,,,"Wiley, Laura K.; Sivley, R. Michael; Bush, William S.",Rapid storage and retrieval of genomic intervals from a relational database system using nested containment lists,2013,Database: The Journal of Biological Databases and Curation,,"Efficient storage and retrieval of genomic annotations based on range intervals is necessary, given the amount of data produced by next-generation sequencing studies. The indexing strategies of relational database systems (such as MySQL) greatly inhibit their use in genomic annotation tasks. This has led to the development of stand-alone applications that are dependent on flat-file libraries. In this work, we introduce MyNCList, an implementation of the NCList data structure within a MySQL database. MyNCList enables the storage, update and rapid retrieval of genomic annotations from the convenience of a relational database system. Range-based annotations of 1 million variants are retrieved in under a minute, making this approach feasible for whole-genome annotation tasks., Database URL: https://github.com/bushlab/mynclist",2013-07-26,2021-06-05 21:13:27,,,2013,Database (Oxford),,PubMed Central,PMID: 23894185 PMCID: PMC3724366,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3724366/,,,,PMC:Query2
223,10.1093/database/bau130,25754863,PMC4352687,A,Neo4j,Neo4j,"Henkel, Ron; Wolkenhauer, Olaf; Waltemath, Dagmar","Combining computational models, semantic annotations and simulation experiments in a graph database",2015,Database: The Journal of Biological Databases and Curation,,"Model repositories such as the BioModels Database, the CellML Model Repository or JWS Online are frequently accessed to retrieve computational models of biological systems. However, their storage concepts support only restricted types of queries and not all data inside the repositories can be retrieved. In this article we present a storage concept that meets this challenge. It grounds on a graph database, reflects the models' structure, incorporates semantic annotations and simulation descriptions and ultimately connects different types of model-related data. The connections between heterogeneous model-related data and bio-ontologies enable efficient search via biological facts and grant access to new model features. The introduced concept notably improves the access of computational models and associated simulations in a model repository. This has positive effects on tasks such as model search, retrieval, ranking, matching and filtering. Furthermore, our work for the first time enables CellML- and Systems Biology Markup Language-encoded models to be effectively maintained in one database. We show how these models can be linked via annotations and queried. Database URL: https://sems.uni-rostock.de/projects/masymos/; Model repositories such as the BioModels Database, the CellML Model Repository or JWS Online are frequently accessed to retrieve computational models of biological systems. However, their storage concepts support only restricted types of queries and not all data inside the repositories can be retrieved. In this article we present a storage concept that meets this challenge. It grounds on a graph database, reflects the models’ structure, incorporates semantic annotations and simulation descriptions and ultimately connects different types of model-related data. The connections between heterogeneous model-related data and bio-ontologies enable efficient search via biological facts and grant access to new model features. The introduced concept notably improves the access of computational models and associated simulations in a model repository. This has positive effects on tasks such as model search, retrieval, ranking, matching and filtering. Furthermore, our work for the first time enables CellML- and Systems Biology Markup Language-encoded models to be effectively maintained in one database. We show how these models can be linked via annotations and queried., Database URL: https://sems.uni-rostock.de/projects/masymos/",2015; 2015-03-08,2021-06-05 21:12:40; 2021-06-05 21:06:22; 2021-06-05 20:37:08; 2021-06-05 20:56:20,,,2015,Database (Oxford),,PubMed; PubMed Central,PMID: 25754863 PMCID: PMC4352687,http://www.ncbi.nlm.nih.gov/pubmed/25754863; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4352687/,"Biological Ontologies; Data Curation; Databases, Factual; Models, Biological; Systems Biology",Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PubMed:Query2; PMC:Query2
224,10.1093/database/bav049,26055098,PMC4460400,A,Virtuoso,Virtuoso,"Kamdar, Maulik R.; Dumontier, Michel",An Ebola virus-centered knowledge base,2015,Database: The Journal of Biological Databases and Curation,,"Ebola virus (EBOV), of the family Filoviridae viruses, is a NIAID category A, lethal human pathogen. It is responsible for causing Ebola virus disease (EVD) that is a severe hemorrhagic fever and has a cumulative death rate of 41% in the ongoing epidemic in West Africa. There is an ever-increasing need to consolidate and make available all the knowledge that we possess on EBOV, even if it is conflicting or incomplete. This would enable biomedical researchers to understand the molecular mechanisms underlying this disease and help develop tools for efficient diagnosis and effective treatment. In this article, we present our approach for the development of an Ebola virus-centered Knowledge Base (Ebola-KB) using Linked Data and Semantic Web Technologies. We retrieve and aggregate knowledge from several open data sources, web services and biomedical ontologies. This knowledge is transformed to RDF, linked to the Bio2RDF datasets and made available through a SPARQL 1.1 Endpoint. Ebola-KB can also be explored using an interactive Dashboard visualizing the different perspectives of this integrated knowledge. We showcase how different competency questions, asked by domain users researching the druggability of EBOV, can be formulated as SPARQL Queries or answered using the Ebola-KB Dashboard., Database URL: http://ebola.semanticscience.org.",2015-06-08,2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-05 20:59:14,,,2015,Database (Oxford),,PubMed Central,PMID: 26055098 PMCID: PMC4460400,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4460400/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
225,10.1093/database/baw028,27022157,PMC4822648,,,,"Putman, Tim E.; Burgstaller-Muehlbacher, Sebastian; Waagmeester, Andra; Wu, Chunlei; Su, Andrew I.; Good, Benjamin M.",Centralizing content and distributing labor: a community model for curating the very long tail of microbial genomes,2016,Database: The Journal of Biological Databases and Curation,,"The last 20 years of advancement in sequencing technologies have led to sequencing thousands of microbial genomes, creating mountains of genetic data. While efficiency in generating the data improves almost daily, applying meaningful relationships between taxonomic and genetic entities on this scale requires a structured and integrative approach. Currently, knowledge is distributed across a fragmented landscape of resources from government-funded institutions such as National Center for Biotechnology Information (NCBI) and UniProt to topic-focused databases like the ODB3 database of prokaryotic operons, to the supplemental table of a primary publication. A major drawback to large scale, expert-curated databases is the expense of maintaining and extending them over time. No entity apart from a major institution with stable long-term funding can consider this, and their scope is limited considering the magnitude of microbial data being generated daily. Wikidata is an openly editable, semantic web compatible framework for knowledge representation. It is a project of the Wikimedia Foundation and offers knowledge integration capabilities ideally suited to the challenge of representing the exploding body of information about microbial genomics. We are developing a microbial specific data model, based on Wikidata’s semantic web compatibility, which represents bacterial species, strains and the gene and gene products that define them. Currently, we have loaded 43 694 gene and 37 966 protein items for 21 species of bacteria, including the human pathogenic bacteria Chlamydia trachomatis. Using this pathogen as an example, we explore complex interactions between the pathogen, its host, associated genes, other microbes, disease and drugs using the Wikidata SPARQL endpoint. In our next phase of development, we will add another 99 bacterial genomes and their gene and gene products, totaling ∼900,000 additional entities. This aggregation of knowledge will be a platform for community-driven collaboration, allowing the networking of microbial genetic data through the sharing of knowledge by both the data and domain expert.",2016-03-28,2021-06-05 21:12:40,,,2016,Database (Oxford),Centralizing content and distributing labor,PubMed Central,PMID: 27022157 PMCID: PMC4822648,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4822648/,,,,PMC:Query2
226,10.1093/database/baw046,27081155,PMC4831722,,,,"Pons, Ewoud; Becker, Benedikt F. H.; Akhondi, Saber A.; Afzal, Zubair; van Mulligen, Erik M.; Kors, Jan A.; Pons, Ewoud; Becker, Benedikt F.H.; Akhondi, Saber A.; Afzal, Zubair; van Mulligen, Erik M.; Kors, Jan A.",Extraction of chemical-induced diseases using prior knowledge and textual information,2016,Database: The Journal of Biological Databases and Curation,,"We describe our approach to the chemical-disease relation (CDR) task in the BioCreative V challenge. The CDR task consists of two subtasks: automatic disease-named entity recognition and normalization (DNER), and extraction of chemical-induced diseases (CIDs) from Medline abstracts. For the DNER subtask, we used our concept recognition tool Peregrine, in combination with several optimization steps. For the CID subtask, our system, which we named RELigator, was trained on a rich feature set, comprising features derived from a graph database containing prior knowledge about chemicals and diseases, and linguistic and statistical features derived from the abstracts in the CDR training corpus. We describe the systems that were developed and present evaluation results for both subtasks on the CDR test set. For DNER, our Peregrine system reached anF-score of 0.757. For CID, the system achieved anF-score of 0.526, which ranked second among 18 participating teams. Several post-challenge modifications of the systems resulted in substantially improvedF-scores (0.828 for DNER and 0.602 for CID). RELigator is available as a web service athttp://biosemantics.org/index.php/software/religator.; We describe our approach to the chemical–disease relation (CDR) task in the BioCreative V challenge. The CDR task consists of two subtasks: automatic disease-named entity recognition and normalization (DNER), and extraction of chemical-induced diseases (CIDs) from Medline abstracts. For the DNER subtask, we used our concept recognition tool Peregrine, in combination with several optimization steps. For the CID subtask, our system, which we named RELigator, was trained on a rich feature set, comprising features derived from a graph database containing prior knowledge about chemicals and diseases, and linguistic and statistical features derived from the abstracts in the CDR training corpus. We describe the systems that were developed and present evaluation results for both subtasks on the CDR test set. For DNER, our Peregrine system reached an F-score of 0.757. For CID, the system achieved an F-score of 0.526, which ranked second among 18 participating teams. Several post-challenge modifications of the systems resulted in substantially improved F-scores (0.828 for DNER and 0.602 for CID). RELigator is available as a web service at http://biosemantics.org/index.php/software/religator.",2016; 2016-04-14,2021-06-05 21:06:22; 2021-06-05 21:12:40,,,2016,Database (Oxford),,PubMed; PubMed Central,PMID: 27081155 PMCID: PMC4831722,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4831722/; http://www.ncbi.nlm.nih.gov/pubmed/27081155,"Computational Biology; Data Mining; Databases, Factual; Disease; Hazardous Substances; Humans; Toxicogenetics",,,PubMed:Query2; PMC:Query2
227,10.1093/database/bax025,28365742,PMC5467579,,,,"Putman, Tim E.; Lelong, Sebastien; Burgstaller-Muehlbacher, Sebastian; Waagmeester, Andra; Diesh, Colin; Dunn, Nathan; Munoz-Torres, Monica; Stupp, Gregory S.; Wu, Chunlei; Su, Andrew I.; Good, Benjamin M.",WikiGenomes: an open web application for community consumption and curation of gene annotation data in Wikidata,2017,Database: The Journal of Biological Databases and Curation,,"With the advancement of genome-sequencing technologies, new genomes are being sequenced daily. Although these sequences are deposited in publicly available data warehouses, their functional and genomic annotations (beyond genes which are predicted automatically) mostly reside in the text of primary publications. Professional curators are hard at work extracting those annotations from the literature for the most studied organisms and depositing them in structured databases. However, the resources don’t exist to fund the comprehensive curation of the thousands of newly sequenced organisms in this manner. Here, we describe WikiGenomes (wikigenomes.org), a web application that facilitates the consumption and curation of genomic data by the entire scientific community. WikiGenomes is based on Wikidata, an openly editable knowledge graph with the goal of aggregating published knowledge into a free and open database. WikiGenomes empowers the individual genomic researcher to contribute their expertise to the curation effort and integrates the knowledge into Wikidata, enabling it to be accessed by anyone without restriction.,  Database URL: www.wikigenomes.org",2017-03-24,2021-06-05 21:12:01,,,2017,Database (Oxford),WikiGenomes,PubMed Central,PMID: 28365742 PMCID: PMC5467579,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5467579/,,,,PMC:Query2
228,10.1093/database/bax059,29220451,PMC5569678,A,Virtuoso,Virtuoso,"Hu, Wei; Qiu, Honglei; Huang, Jiacheng; Dumontier, Michel",BioSearch: a semantic search engine for Bio2RDF,2017,Database: The Journal of Biological Databases and Curation,,"Biomedical data are growing at an incredible pace and require substantial expertise to organize data in a manner that makes them easily findable, accessible, interoperable and reusable. Massive effort has been devoted to using Semantic Web standards and technologies to create a network of Linked Data for the life sciences, among others. However, while these data are accessible through programmatic means, effective user interfaces for non-experts to SPARQL endpoints are few and far between. Contributing to user frustrations is that data are not necessarily described using common vocabularies, thereby making it difficult to aggregate results, especially when distributed across multiple SPARQL endpoints. We propose BioSearch — a semantic search engine that uses ontologies to enhance federated query construction and organize search results. BioSearch also features a simplified query interface that allows users to optionally filter their keywords according to classes, properties and datasets. User evaluation demonstrated that BioSearch is more effective and usable than two state of the art search and browsing solutions.,  Database URL: http://ws.nju.edu.cn/biosearch/",2017-08-08,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:59:14,,,2017,Database (Oxford),BioSearch,PubMed Central,PMID: 29220451 PMCID: PMC5569678,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5569678/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
229,10.1093/database/bax065,29220467,PMC5737054,A,Neo4j,Neo4j,"Wright, Theodore B; Ball, David; Hersh, William",Query expansion using MeSH terms for dataset retrieval: OHSU at the bioCADDIE 2016 dataset retrieval challenge,2017,Database: The Journal of Biological Databases and Curation,,"Scientific data are being generated at an ever-increasing rate. The Biomedical and Healthcare Data Discovery Index Ecosystem (bioCADDIE) is an NIH-funded Data Discovery Index that aims to provide a platform for researchers to locate, retrieve, and share research datasets. The bioCADDIE 2016 Dataset Retrieval Challenge was held to identify the most effective dataset retrieval methods. We aimed to assess the value of Medical Subject Heading (MeSH) term-based query expansion to improve retrieval. Our system, based on the open-source search engine, Elasticsearch, expands queries by identifying synonyms from the MeSH vocabulary and adding these to the original query. The number and relative weighting of MeSH terms is variable. The top 1000 search results for the 15 challenge queries were submitted for evaluation. After the challenge, we performed additional runs to determine the optimal number of MeSH terms and weighting. Our best overall score used five MeSH terms with a 1:5 terms:words weighting ratio, achieving an inferred normalized distributed cumulative gain (infNDCG) of 0.445, which was the third highest score among the 10 research groups who participated in the challenge. Further testing revealed our initial combination of MeSH terms and weighting yielded the best overall performance. Scores varied considerably between queries as well as with different variations of MeSH terms and weights. Query expansion using MeSH terms can enhance search relevance of biomedical datasets. High variability between queries and system variables suggest room for improvement and directions for further research.,  Database URL: https://biocaddie.org/benchmark-data",2017-10-20,2021-06-05 20:55:40; 2021-06-05 21:11:16; 2021-06-05 20:36:32,,,2017,Database (Oxford),Query expansion using MeSH terms for dataset retrieval,PubMed Central,PMID: 29220467 PMCID: PMC5737054,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5737054/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
230,10.1093/database/bay014,29688361,PMC5824778,,,,"Adetunji, Modupeore O; Lamont, Susan J; Schmidt, Carl J","TransAtlasDB: an integrated database connecting expression data, metadata and variants",2018,Database: The Journal of Biological Databases and Curation,,"High-throughput transcriptome sequencing (RNAseq) is the universally applied method for target-free transcript identification and gene expression quantification, generating huge amounts of data. The constraint of accessing such data and interpreting results can be a major impediment in postulating suitable hypothesis, thus an innovative storage solution that addresses these limitations, such as hard disk storage requirements, efficiency and reproducibility are paramount. By offering a uniform data storage and retrieval mechanism, various data can be compared and easily investigated. We present a sophisticated system, TransAtlasDB, which incorporates a hybrid architecture of both relational and NoSQL databases for fast and efficient data storage, processing and querying of large datasets from transcript expression analysis with corresponding metadata, as well as gene-associated variants (such as SNPs) and their predicted gene effects. TransAtlasDB provides the data model of accurate storage of the large amount of data derived from RNAseq analysis and also methods of interacting with the database, either via the command-line data management workflows, written in Perl, with useful functionalities that simplifies the complexity of data storage and possibly manipulation of the massive amounts of data generated from RNAseq analysis or through the web interface. The database application is currently modeled to handle analyses data from agricultural species, and will be expanded to include more species groups. Overall TransAtlasDB aims to serve as an accessible repository for the large complex results data files derived from RNAseq gene expression profiling and variant analysis.,  Database URL: https://modupeore.github.io/TransAtlasDB/",2018-02-23,2021-06-05 21:11:16,,,2018,Database (Oxford),TransAtlasDB,PubMed Central,PMID: 29688361 PMCID: PMC5824778,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5824778/,,,,PMC:Query2
231,10.1093/database/bay051,29992320,PMC6030809,A,Neo4j,Neo4j,"Lambusch, Fabienne; Waltemath, Dagmar; Wolkenhauer, Olaf; Sandkuhl, Kurt; Rosenke, Christian; Henkel, Ron",Identifying frequent patterns in biochemical reaction networks: a workflow,2018,Database: The Journal of Biological Databases and Curation,,"Computational models in biology encode molecular and cell biological processes. Many of these models can be represented as biochemical reaction networks. Studying such networks, one is mostly interested in systems that share similar reactions and mechanisms. Typical goals of an investigation thus include understanding of model parts, identification of reoccurring patterns and recognition of biologically relevant motifs. The large number and size of available models, however, require automated methods to support researchers in achieving their goals. Specifically for the problem of finding patterns in large networks only partial solutions exist. We propose a workflow that identifies frequent structural patterns in biochemical reaction networks encoded in the Systems Biology Markup Language. The workflow utilizes a subgraph mining algorithm to detect the network patterns. Once patterns are identified, the textual pattern description can automatically be converted into a graphical representation. Furthermore, information about the distribution of patterns among a selected set of models can be retrieved. The workflow was validated with 575 models from the curated branch of BioModels. In this paper, we highlight interesting and frequent structural patterns. Furthermore, we provide exemplary patterns that incorporate terms from the Systems Biology Ontology. Our workflow can be applied to a custom set of models or to models already existing in our graph database MaSyMoS. The occurrences of frequent patterns may give insight into the encoding of central biological processes, evaluate postulated biological motifs or serve as a similarity measure for models that share common structures., Database URL: https://github.com/FabienneL/BioNet-Mining; Computational models in biology encode molecular and cell biological processes. Many of these models can be represented as biochemical reaction networks. Studying such networks, one is mostly interested in systems that share similar reactions and mechanisms. Typical goals of an investigation thus include understanding of model parts, identification of reoccurring patterns and recognition of biologically relevant motifs. The large number and size of available models, however, require automated methods to support researchers in achieving their goals. Specifically for the problem of finding patterns in large networks only partial solutions exist. We propose a workflow that identifies frequent structural patterns in biochemical reaction networks encoded in the Systems Biology Markup Language. The workflow utilizes a subgraph mining algorithm to detect the network patterns. Once patterns are identified, the textual pattern description can automatically be converted into a graphical representation. Furthermore, information about the distribution of patterns among a selected set of models can be retrieved. The workflow was validated with 575 models from the curated branch of BioModels. In this paper, we highlight interesting and frequent structural patterns. Furthermore, we provide exemplary patterns that incorporate terms from the Systems Biology Ontology. Our workflow can be applied to a custom set of models or to models already existing in our graph database MaSyMoS. The occurrences of frequent patterns may give insight into the encoding of central biological processes, evaluate postulated biological motifs or serve as a similarity measure for models that share common structures.Database URL: https://github.com/FabienneL/BioNet-Mining.",2018-01-01; 2018-07-03,2021-06-05 20:55:01; 2021-06-05 21:06:22; 2021-06-05 21:11:16; 2021-06-05 20:36:32,,,2018,Database (Oxford),Identifying frequent patterns in biochemical reaction networks,PubMed; PubMed Central,PMID: 29992320 PMCID: PMC6030809,http://www.ncbi.nlm.nih.gov/pubmed/29992320; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6030809/,"Algorithms; Biochemical Phenomena; Data Mining; Databases as Topic; Pattern Recognition, Automated; Peptides; Phosphorylation; Protein Biosynthesis; RNA Stability; RNA, Messenger; Transcription, Genetic; Workflow",Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PubMed:Query2; PMC:Query2
232,10.1093/database/bay086,30212910,PMC6146121,,,,"Le, Kevin K; Whiteside, Matthew D; Hopkins, James E; Gannon, Victor P J; Laing, Chad R; Le, Kevin K.; Whiteside, Matthew D.; Hopkins, James E.; Gannon, Victor P. J.; Laing, Chad R.",Spfy: an integrated graph database for real-time prediction of bacterial phenotypes and downstream comparative analyses,2018,Database: The Journal of Biological Databases and Curation,,"Public health laboratories are currently moving to whole-genome sequence (WGS)-based analyses, and require the rapid prediction of standard reference laboratory methods based solely on genomic data. Currently, these predictive genomics tasks rely on workflows that chain together multiple programs for the requisite analyses. While useful, these systems do not store the analyses in a genome-centric way, meaning the same analyses are often re-computed for the same genomes. To solve this problem, we created Spfy, a platform that rapidly performs the common reference laboratory tests, uses a graph database to store and retrieve the results from the computational workflows and links data to individual genomes using standardized ontologies. The Spfy platform facilitates rapid phenotype identification, as well as the efficient storage and downstream comparative analysis of tens of thousands of genome sequences. Though generally applicable to bacterial genome sequences, Spfy currently contains 10 243 Escherichia coli genomes, for which in-silico serotype and Shiga-toxin subtype, as well as the presence of known virulence factors and antimicrobial resistance determinants have been computed. Additionally, the presence/absence of the entire E. coli pan-genome was computed and linked to each genome. Owing to its database of diverse pre-computed results, and the ability to easily incorporate user data, Spfy facilitates hypothesis testing in fields ranging from population genomics to epidemiology, while mitigating the re-computation of analyses. The graph approach of Spfy is flexible, and can accommodate new analysis software modules as they are developed, easily linking new results to those already stored. Spfy provides a database and analyses approach for E. coli that is able to match the rapid accumulation of WGS data in public databases.",2018-01-01; 2018-09-13,2021-06-05 21:06:22; 2021-06-05 21:11:16,1-10,,2018,Database (Oxford),Spfy,PubMed; PubMed Central,PMID: 30212910 PMCID: PMC6146121,http://www.ncbi.nlm.nih.gov/pubmed/30212910; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6146121/,"Computational Biology; Databases as Topic; Escherichia coli; Genome, Bacterial; Internet; Phenotype; Software; Virulence Factors",,,PubMed:Query2; PMC:Query2
233,10.1093/database/bay088,30239679,PMC6146126,A,Neo4j,Neo4j,"Harper, Lisa; Campbell, Jacqueline; Cannon, Ethalinda K S; Jung, Sook; Poelchau, Monica; Walls, Ramona; Andorf, Carson; Arnaud, Elizabeth; Berardini, Tanya Z; Birkett, Clayton; Cannon, Steve; Carson, James; Condon, Bradford; Cooper, Laurel; Dunn, Nathan; Elsik, Christine G; Farmer, Andrew; Ficklin, Stephen P; Grant, David; Grau, Emily; Herndon, Nic; Hu, Zhi-Liang; Humann, Jodi; Jaiswal, Pankaj; Jonquet, Clement; Laporte, Marie-Angélique; Larmande, Pierre; Lazo, Gerard; McCarthy, Fiona; Menda, Naama; Mungall, Christopher J; Munoz-Torres, Monica C; Naithani, Sushma; Nelson, Rex; Nesdill, Daureen; Park, Carissa; Reecy, James; Reiser, Leonore; Sanderson, Lacey-Anne; Sen, Taner Z; Staton, Margaret; Subramaniam, Sabarinath; Tello-Ruiz, Marcela Karey; Unda, Victor; Unni, Deepak; Wang, Liya; Ware, Doreen; Wegrzyn, Jill; Williams, Jason; Woodhouse, Margaret; Yu, Jing; Main, Doreen",AgBioData consortium recommendations for sustainable genomics and genetics databases for agriculture,2018,Database: The Journal of Biological Databases and Curation,,"The future of agricultural research depends on data. The sheer volume of agricultural biological data being produced today makes excellent data management essential. Governmental agencies, publishers and science funders require data management plans for publicly funded research. Furthermore, the value of data increases exponentially when they are properly stored, described, integrated and shared, so that they can be easily utilized in future analyses. AgBioData (https://www.agbiodata.org) is a consortium of people working at agricultural biological databases, data archives and knowledgbases who strive to identify common issues in database development, curation and management, with the goal of creating database products that are more Findable, Accessible, Interoperable and Reusable. We strive to promote authentic, detailed, accurate and explicit communication between all parties involved in scientific data. As a step toward this goal, we present the current state of biocuration, ontologies, metadata and persistence, database platforms, programmatic (machine) access to data, communication and sustainability with regard to data curation. Each section describes challenges and opportunities for these topics, along with recommendations and best practices.",2018-09-18,2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:36:32,,,2018,Database (Oxford),,PubMed Central,PMID: 30239679 PMCID: PMC6146126,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6146126/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
234,10.1093/database/bay108,30346607,PMC6196310,,,,"Warikoo, Neha; Chang, Yung-Chun; Hsu, Wen-Lian",LPTK: a linguistic pattern-aware dependency tree kernel approach for the BioCreative VI CHEMPROT task,2018,Database: The Journal of Biological Databases and Curation,,"Identifying the interactions between chemical compounds and genes from biomedical literatures is one of the frequently discussed topics of text mining in the life science field. In this paper, we describe Linguistic Pattern-Aware Dependency Tree Kernel, a linguistic interaction pattern learning method developed for CHEMPROT task–BioCreative VI, to capture chemical–protein interaction (CPI) patterns within biomedical literatures. We also introduce a framework to integrate these linguistic patterns with smooth partial tree kernel to extract the CPIs. This new method of feature representation models aspects of linguistic probability in geometric representation, which not only optimizes the sufficiency of feature dimension for classification, but also defines features as interpretable contexts rather than long vectors of numbers. In order to test the robustness and efficiency of our system in identifying different kinds of biological interactions, we evaluated our framework on three separate data sets, i.e. CHEMPROT corpus, Chemical–Disease Relation corpus and Protein–Protein Interaction corpus. Corresponding experiment results demonstrate that our method is effective and outperforms several compared systems for each data set.",2018-10-22,2021-06-05 21:11:16,,,2018,Database (Oxford),LPTK,PubMed Central,PMID: 30346607 PMCID: PMC6196310,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6196310/,,,,PMC:Query2
235,10.1093/database/bay123,30576482,PMC6301334,A,Virtuoso,Virtuoso,"Kawashima, Shuichi; Katayama, Toshiaki; Hatanaka, Hideki; Kushida, Tatsuya; Takagi, Toshihisa",NBDC RDF portal: a comprehensive repository for semantic data in life sciences,2018,Database: The Journal of Biological Databases and Curation,,"In the life sciences, researchers increasingly want to access multiple databases in an integrated way. However, different databases currently use different formats and vocabularies, hindering the proper integration of heterogeneous life science data. Adopting the Resource Description Framework (RDF) has the potential to address such issues by improving database interoperability, leading to advances in automatic data processing. Based on this idea, we have advised many Japanese database development groups to expose their databases in RDF. To further promote such activities, we have developed an RDF-based life science dataset repository called the National Bioscience Database Center (NBDC) RDF portal. All the datasets in this repository have been reviewed by the NBDC to ensure interoperability and queryability. As of July 2018, the service includes 21 RDF datasets, comprising over 45.5 billion triples. It provides SPARQL endpoints for all datasets, useful metadata and the ability to download RDF files. The NBDC RDF portal can be accessed at https://integbio.jp/rdf/.",2018-12-14,2021-06-05 20:55:01; 2021-06-05 20:59:14; 2021-06-05 21:10:37,,,2018,Database (Oxford),NBDC RDF portal,PubMed Central,PMID: 30576482 PMCID: PMC6301334,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6301334/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
236,10.1093/database/bay146,30649295,PMC6334007,,,,"Naithani, Sushma; Gupta, Parul; Preece, Justin; Garg, Priyanka; Fraser, Valerie; Padgitt-Cobb, Lillian K; Martin, Matthew; Vining, Kelly; Jaiswal, Pankaj",Involving community in genes and pathway curation,2019,Database: The Journal of Biological Databases and Curation,,"Biocuration plays a crucial role in building databases and complex systems-level platforms required for processing, annotating and analyzing ‘Big Data’ in biology. However, biocuration efforts cannot keep pace with a dramatic increase in the production of omics data; this presents one of the bottlenecks in genomics. In two pathway curation jamborees, Plant Reactome curators tested strategies for introducing researchers to pathway curation tools, harnessing biologists’ expertise in curating plant pathways and developing a network of community biocurators. We summarize the strategy, workflow and outcomes of these exercises, and discuss the role of community biocuration in advancing databases and genomic resources.",2019-01-16,2021-06-05 21:10:37,,,2019,Database (Oxford),,PubMed Central,PMID: 30649295 PMCID: PMC6334007,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6334007/,,,,PMC:Query2
237,10.1093/database/baz004,30698777,PMC6352757,,,,"Grand, Alberto; Geda, Emanuele; Mignone, Andrea; Bertotti, Andrea; Fiori, Alessandro",One tool to find them all: a case of data integration and querying in a distributed LIMS platform,2019,Database: The Journal of Biological Databases and Curation,,"In the last years, Laboratory Information Management Systems (LIMS) have been growing from mere inventory systems into increasingly comprehensive software platforms, spanning functionalities as diverse as data search, annotation and analysis. Our institution started in 2011 a LIMS project named the Laboratory Assistant Suite with the purpose of assisting researchers throughout all of their laboratory activities, providing graphical tools to support decision-making tasks and building complex analyses on integrated data. The modular architecture of the system exploits multiple databases with different technologies. To provide an efficient and easy tool for retrieving information of interest, we developed the Multi-Dimensional Data Manager (MDDM). By means of intuitive interfaces, scientists can execute complex queries without any knowledge of query languages or database structures, and easily integrate heterogeneous data stored in multiple databases. Together with the other software modules making up the platform, the MDDM has helped improve the overall quality of the data, substantially reduced the time spent with manual data entry and retrieval and ultimately broadened the spectrum of interconnections among the data, offering novel perspectives to the biomedical analysts.",2019-01-30,2021-06-05 21:10:37,,,2019,Database (Oxford),One tool to find them all,PubMed Central,PMID: 30698777 PMCID: PMC6352757,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6352757/,,,,PMC:Query2
238,10.1093/database/baz067,31392324,PMC6686081,,,,"Vogt, Lars; Baum, Roman; Bhatty, Philipp; Köhler, Christian; Meid, Sandra; Quast, Björn; Grobe, Peter",SOCCOMAS: a FAIR web content management system that uses knowledge graphs and that is based on semantic programming,2019,Database: The Journal of Biological Databases and Curation,,"We introduce Semantic Ontology-Controlled application for web Content Management Systems (SOCCOMAS), a development framework for FAIR (‘findable’, ‘accessible’, ‘interoperable’, ‘reusable’) Semantic Web Content Management Systems (S-WCMSs). Each S-WCMS run by SOCCOMAS has its contents managed through a corresponding knowledge base that stores all data and metadata in the form of semantic knowledge graphs in a Jena tuple store. Automated procedures track provenance, user contributions and detailed change history. Each S-WCMS is accessible via both a graphical user interface (GUI), utilizing the JavaScript framework AngularJS, and a SPARQL endpoint. As a consequence, all data and metadata are maximally findable, accessible, interoperable and reusable and comply with the FAIR Guiding Principles. The source code of SOCCOMAS is written using the Semantic Programming Ontology (SPrO). SPrO consists of commands, attributes and variables, with which one can describe an S-WCMS. We used SPrO to describe all the features and workflows typically required by any S-WCMS and documented these descriptions in a SOCCOMAS source code ontology (SC-Basic). SC-Basic specifies a set of default features, such as provenance tracking and publication life cycle with versioning, which will be available in all S-WCMS run by SOCCOMAS. All features and workflows specific to a particular S-WCMS, however, must be described within an instance source code ontology (INST-SCO), defining, e.g. the function and composition of the GUI, with all its user interactions, the underlying data schemes and representations and all its workflow processes. The combination of descriptions in SC-Basic and a given INST-SCO specify the behavior of an S-WCMS. SOCCOMAS controls this S-WCMS through the Java-based middleware that accompanies SPrO, which functions as an interpreter. Because of the ontology-controlled design, SOCCOMAS allows easy customization with a minimum of technical programming background required, thereby seamlessly integrating conventional web page technologies with semantic web technologies. SOCCOMAS and the Java Interpreter are available from (https://github.com/SemanticProgramming).",2019-08-08,2021-06-05 21:10:37,,,2019,Database (Oxford),SOCCOMAS,PubMed Central,PMID: 31392324 PMCID: PMC6686081,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6686081/,,,,PMC:Query2
239,10.1093/database/baz073,31236561,PMC6591535,,,,"Hu, Geng-Ming; Secario, M K; Chen, Chi-Ming; Hu, Geng-Ming; Secario, M. K.; Chen, Chi-Ming",SeQuery: an interactive graph database for visualizing the GPCR superfamily,2019,Database: The Journal of Biological Databases and Curation,,"The rate at which new protein and gene sequences are being discovered has grown explosively in the omics era, which has increasingly complicated the efficient characterization and analysis of their biological properties. In this study, we propose a web-based graphical database tool, SeQuery, for intuitively visualizing proteome/genome networks by integrating the sequential, structural and functional information of sequences. As a demonstration of our tool’s effectiveness, we constructed a graph database of G protein-coupled receptor (GPCR) sequences by integrating data from the UniProt, GPCRdb and RCSB PDB databases. Our tool attempts to achieve two goals: (i) given the sequence of a query protein, correctly and efficiently identify whether the protein is a GPCR, and, if so, define its sequential and functional roles in the GPCR superfamily; and (ii) present a panoramic view of the GPCR superfamily and its network centralities that allows users to explore the superfamily at various resolutions. Such a bottom-up-to-top-down view can provide the users with a comprehensive understanding of the GPCR superfamily through interactive navigation of the graph database. A test of SeQuery with the GPCR2841 dataset shows that it correctly identifies 99 out of 100 queried protein sequences. The developed tool is readily applicable to other biological networks, and we aim to expand SeQuery by including additional biological databases in the near future.; The rate at which new protein and gene sequences are being discovered has grown explosively in the omics era, which has increasingly complicated the efficient characterization and analysis of their biological properties. In this study, we propose a web-based graphical database tool, SeQuery, for intuitively visualizing proteome/genome networks by integrating the sequential, structural and functional information of sequences. As a demonstration of our tool's effectiveness, we constructed a graph database of G protein-coupled receptor (GPCR) sequences by integrating data from the UniProt, GPCRdb and RCSB PDB databases. Our tool attempts to achieve two goals: (i) given the sequence of a query protein, correctly and efficiently identify whether the protein is a GPCR, and, if so, define its sequential and functional roles in the GPCR superfamily; and (ii) present a panoramic view of the GPCR superfamily and its network centralities that allows users to explore the superfamily at various resolutions. Such a bottom-up-to-top-down view can provide the users with a comprehensive understanding of the GPCR superfamily through interactive navigation of the graph database. A test of SeQuery with the GPCR2841 dataset shows that it correctly identifies 99 out of 100 queried protein sequences. The developed tool is readily applicable to other biological networks, and we aim to expand SeQuery by including additional biological databases in the near future.",2019-06-25; 2019-01-01,2021-06-05 21:10:37; 2021-06-05 21:06:22,,,2019,Database (Oxford),SeQuery,PubMed; PubMed Central,PMID: 31236561 PMCID: PMC6591535,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6591535/; http://www.ncbi.nlm.nih.gov/pubmed/31236561,"Amino Acid Sequence; Animals; Databases, Protein; Humans; Receptors, G-Protein-Coupled; Sequence Alignment; Software",,,PubMed:Query2; PMC:Query2
240,10.1093/database/baz077,31328773,PMC6643302,,,,"Spoor, Shawna; Cheng, Chun-Huai; Sanderson, Lacey-Anne; Condon, Bradford; Almsaeed, Abdullah; Chen, Ming; Bretaudeau, Anthony; Rasche, Helena; Jung, Sook; Main, Dorrie; Bett, Kirstin; Staton, Margaret; Wegrzyn, Jill L; Feltus, F Alex; Ficklin, Stephen P",Tripal v3: an ontology-based toolkit for construction of FAIR biological community databases,2019,Database: The Journal of Biological Databases and Curation,,"Community biological databases provide an important online resource for both public and private data, analysis tools and community engagement. These sites house genomic, transcriptomic, genetic, breeding and ancillary data for specific species, families or clades. Due to the complexity and increasing quantities of these data, construction of online resources is increasingly difficult especially with limited funding and access to technical expertise. Furthermore, online repositories are expected to promote FAIR data principles (findable, accessible, interoperable and reusable) that presents additional challenges. The open-source Tripal database toolkit seeks to mitigate these challenges by creating both the software and an interactive community of developers for construction of online community databases. Additionally, through coordinated, distributed co-development, Tripal sites encourage community-wide sustainability. Here, we report the release of Tripal version 3 that improves data accessibility and data sharing through systematic use of controlled vocabularies (CVs). Tripal uses the community-developed Chado database as a default data store, but now provides tools to support other data stores, while ensuring that CVs remain the central organizational structure for the data. A new site developer can use Tripal to develop a basic site with little to no programming, with the ability to integrate other data types using extension modules and the Tripal application programming interface. A thorough online User’s Guide and Developer’s Handbook are available at http://tripal.info, providing download, installation and step-by-step setup instructions.",2019-07-22,2021-06-05 21:10:37,,,2019,Database (Oxford),Tripal v3,PubMed Central,PMID: 31328773 PMCID: PMC6643302,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6643302/,,,,PMC:Query2
241,10.1093/database/baz080,31287543,PMC6615453,A,GraphDB; Neo4j,GraphDB; Neo4j,"Mignone, Andrea; Grand, Alberto; Fiori, Alessandro; Medico, Enzo; Bertotti, Andrea",Semalytics: a semantic analytics platform for the exploration of distributed and heterogeneous cancer data in translational research,2019,Database: The Journal of Biological Databases and Curation,,"Each cancer is a complex system with unique molecular features determining its dynamics, such as its prognosis and response to therapies. Understanding the role of these biological traits is fundamental in order to personalize cancer clinical care according to the characteristics of each patient’s disease. To achieve this, translational researchers propagate patients’ samples through in vivo and in vitro cultures to test different therapies on the same tumor and to compare their outcomes with the molecular profile of the disease. This in turn generates information that can be subsequently translated into the development of predictive biomarkers for clinical use. These large-scale experiments generate huge collections of hierarchical data (i.e. experimental trees) with relative annotations that are extremely difficult to analyze. To address such issues in data analyses, we came up with the Semalytics data framework, the core of an analytical platform that processes experimental information through Semantic Web technologies. Semalytics allows (i) the efficient exploration of experimental trees with irregular structures together with their annotations. Moreover, (ii) the platform links its data to a wider open knowledge base (i.e. Wikidata) to add an extended knowledge layer without the need to manage and curate those data locally. Altogether, Semalytics provides augmented perspectives on experimental data, allowing the generation of new hypotheses, which were not anticipated by the user a priori., In this work, we present the data core we created for Semalytics, focusing on its semantic nucleus and on how it exploits semantic reasoning and data integration to tackle issues of this kind of analyses. Finally, we describe a proof-of-concept study based on the examination of several dozen cases of metastatic colorectal cancer in order to illustrate how Semalytics can help researchers generate hypotheses about the role of genes alterations in causing resistance or sensitivity of cancer cells to specific drugs.",2019-07-09,2021-06-05 20:55:01; 2021-06-06 06:54:16; 2021-06-05 20:36:32; 2021-06-05 21:10:37,,,2019,Database (Oxford),Semalytics,PubMed Central,PMID: 31287543 PMCID: PMC6615453,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6615453/,,GraphDB; Neo4j,GraphDB; Neo4j,PMC:Query3; PMC:Neo4j; PMC:GraphDB; PMC:Query2
242,10.1093/database/baz106,31697362,PMC6836710,,,,"Sima, Ana Claudia; Mendes de Farias, Tarcisio; Zbinden, Erich; Anisimova, Maria; Gil, Manuel; Stockinger, Heinz; Stockinger, Kurt; Robinson-Rechavi, Marc; Dessimoz, Christophe",Enabling semantic queries across federated bioinformatics databases,2019,Database: The Journal of Biological Databases and Curation,,"Motivation: Data integration promises to be one of the main catalysts in enabling new insights to be drawn from the wealth of biological data available publicly. However, the heterogeneity of the different data sources, both at the syntactic and the semantic level, still poses significant challenges for achieving interoperability among biological databases., Results: We introduce an ontology-based federated approach for data integration. We applied this approach to three heterogeneous data stores that span different areas of biological knowledge: (i) Bgee, a gene expression relational database; (ii) Orthologous Matrix (OMA), a Hierarchical Data Format 5 orthology DS; and (iii) UniProtKB, a Resource Description Framework (RDF) store containing protein sequence and functional information. To enable federated queries across these sources, we first defined a new semantic model for gene expression called GenEx. We then show how the relational data in Bgee can be expressed as a virtual RDF graph, instantiating GenEx, through dedicated relational-to-RDF mappings. By applying these mappings, Bgee data are now accessible through a public SPARQL endpoint. Similarly, the materialized RDF data of OMA, expressed in terms of the Orthology ontology, is made available in a public SPARQL endpoint. We identified and formally described intersection points (i.e. virtual links) among the three data sources. These allow performing joint queries across the data stores. Finally, we lay the groundwork to enable nontechnical users to benefit from the integrated data, by providing a natural language template-based search interface.",2019-11-07,2021-06-05 21:10:37,,,2019,Database (Oxford),,PubMed Central,PMID: 31697362 PMCID: PMC6836710,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6836710/,,,,PMC:Query2
243,10.1093/database/baz120,31712826,PMC6846243,A,Neo4j,Neo4j,"Arenas-Galnares, Rodrigo; Castillo-Lara, Sergio; Toulis, Vasileios; Boloc, Daniel; Gonzàlez-Duarte, Roser; Marfany, Gemma; Abril, Josep F; Arenas-Galnares, Rodrigo; Castillo-Lara, Sergio; Toulis, Vasileios; Boloc, Daniel; Gonzàlez-Duarte, Roser; Marfany, Gemma; Abril, Josep F.",RPGeNet v2.0: expanding the universe of retinal disease gene interactions network,2019,Database: The Journal of Biological Databases and Curation,,"RPGeNet offers researchers a user-friendly queriable tool to visualize the interactome network of visual disorder genes, thus enabling the identification of new potential causative genes and the assignment of novel candidates to specific retinal or cellular pathways. This can be highly relevant for clinical applications as retinal dystrophies affect 1:3000 people worldwide, and the causative genes are still unknown for 30% of the patients. RPGeNet is a refined interaction network interface that limits its skeleton network to the shortest paths between each and every known causative gene of inherited syndromic and non-syndromic retinal dystrophies. RPGeNet integrates interaction information from STRING, BioGRID and PPaxe, along with retina-specific expression data and associated genetic variants, over a Cytoscape.js web interface. For the new version, RPGeNet v2.0, the database engine was migrated to Neo4j graph database manager, which speeds up the initial queries and can handle whole interactome data for new ways to query the network. Further, user facilities have been introduced as the capability of saving and restoring a researcher customized network layout or as novel features to facilitate navigation and data projection on the network explorer interface. Responsiveness has been further improved by transferring some functionality to the client side.",2019-11-11; 2019-01-01,2021-06-05 20:35:57; 2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 21:10:37; 2021-06-05 20:55:01; 2021-06-05 21:24:28,,,2019,Database (Oxford),RPGeNet v2.0,PubMed; PubMed Central,PMID: 31712826 PMCID: PMC6846243,http://www.ncbi.nlm.nih.gov/pubmed/31712826; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6846243/,"Databases, Genetic; Epistasis, Genetic; Humans; Retinal Diseases; Software; User-Computer Interface",Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
244,10.1093/database/baz130,31796964,PMC6891001,A,Neo4j,Neo4j,"Panzade, Ganesh; Gangwar, Indu; Awasthi, Supriya; Sharma, Nitesh; Shankar, Ravi",Plant Regulomics Portal (PRP): a comprehensive integrated regulatory information and analysis portal for plant genomes,2019,Database: The Journal of Biological Databases and Curation,,"Gene regulation is a highly complex and networked phenomenon where multiple tiers of control determine the cell state in a spatio-temporal manner. Among these, the transcription factors, DNA and histone modifications, and post-transcriptional control by small RNAs like miRNAs serve as major regulators. An understanding of the integrative and spatio-temporal impact of these regulatory factors can provide better insights into the state of a ‘cell system’. Yet, there are limited resources available to this effect. Therefore, we hereby report an integrative information portal (Plant Regulomics Portal; PRP) for plants for the first time. The portal has been developed by integrating a huge amount of curated data from published sources, RNA-, methylome- and sRNA/miRNA sequencing, histone modifications and repeats, gene ontology, digital gene expression and characterized pathways. The key features of the portal include a regulatory search engine for fetching numerous analytical outputs and tracks of the abovementioned regulators and also a genome browser for integrated visualization of the search results. It also has numerous analytical features for analyses of transcription factors (TFs) and sRNA/miRNA, spot-specific methylation, gene expression and interactions and details of pathways for any given genomic element. It can also provide information on potential RdDM regulation, while facilitating enrichment analysis, generation of visually rich plots and downloading of data in a selective manner. Visualization of intricate biological networks is an important feature which utilizes the Neo4j Graph database making analysis of relationships and long-range system viewing possible. Till date, PRP hosts 571-GB processed data for four plant species namely Arabidopsis thaliana, Oryza sativa subsp. japonica, Zea mays and Glycine max., Database URL: https://scbb.ihbt.res.in/PRP; Gene regulation is a highly complex and networked phenomenon where multiple tiers of control determine the cell state in a spatio-temporal manner. Among these, the transcription factors, DNA and histone modifications, and post-transcriptional control by small RNAs like miRNAs serve as major regulators. An understanding of the integrative and spatio-temporal impact of these regulatory factors can provide better insights into the state of a 'cell system'. Yet, there are limited resources available to this effect. Therefore, we hereby report an integrative information portal (Plant Regulomics Portal; PRP) for plants for the first time. The portal has been developed by integrating a huge amount of curated data from published sources, RNA-, methylome- and sRNA/miRNA sequencing, histone modifications and repeats, gene ontology, digital gene expression and characterized pathways. The key features of the portal include a regulatory search engine for fetching numerous analytical outputs and tracks of the abovementioned regulators and also a genome browser for integrated visualization of the search results. It also has numerous analytical features for analyses of transcription factors (TFs) and sRNA/miRNA, spot-specific methylation, gene expression and interactions and details of pathways for any given genomic element. It can also provide information on potential RdDM regulation, while facilitating enrichment analysis, generation of visually rich plots and downloading of data in a selective manner. Visualization of intricate biological networks is an important feature which utilizes the Neo4j Graph database making analysis of relationships and long-range system viewing possible. Till date, PRP hosts 571-GB processed data for four plant species namely Arabidopsis thaliana, Oryza sativa subsp. japonica, Zea mays and Glycine max. Database URL: https://scbb.ihbt.res.in/PRP.",2019-12-03; 2019-01-01,2021-06-05 20:35:57; 2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 21:10:37; 2021-06-05 20:55:01; 2021-06-05 21:24:28,,,2019,Database (Oxford),Plant Regulomics Portal (PRP),PubMed; PubMed Central,PMID: 31796964 PMCID: PMC6891001,http://www.ncbi.nlm.nih.gov/pubmed/31796964; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6891001/,"Binding Sites; Databases, Genetic; DNA Methylation; Gene Expression Regulation, Plant; Genome, Plant; MicroRNAs; Protein Binding; RNA, Plant; Transcription Factors",Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
245,10.1093/database/baz162,32055858,PMC7018612,A,Neo4j,Neo4j,"Mei, Songqing; Huang, Xiaowei; Xie, Chengshu; Mora, Antonio",GREG—studying transcriptional regulation using integrative graph databases; GREG-studying transcriptional regulation using integrative graph databases,2020,Database: The Journal of Biological Databases and Curation,,"A gene regulatory process is the result of the concerted action of transcription factors, co-factors, regulatory non-coding RNAs (ncRNAs) and chromatin interactions. Therefore, the combination of protein-DNA, protein-protein, ncRNA-DNA, ncRNA-protein and DNA-DNA data in a single graph database offers new possibilities regarding generation of biological hypotheses. GREG (The Gene Regulation Graph Database) is an integrative database and web resource that allows the user to visualize and explore the network of all above-mentioned interactions for a query transcription factor, long non-coding RNA, genomic range or DNA annotation, as well as extracting node and interaction information, identifying connected nodes and performing advanced graphical queries directly on the regulatory network, in a simple and efficient way. In this article, we introduce GREG together with some application examples (including exploratory research of Nanog's regulatory landscape and the etiology of chronic obstructive pulmonary disease), which we use as a demonstration of the advantages of using graph databases in biomedical research. Database URL: https://mora-lab.github.io/projects/greg.html, www.moralab.science/GREG/.; A gene regulatory process is the result of the concerted action of transcription factors, co-factors, regulatory non-coding RNAs (ncRNAs) and chromatin interactions. Therefore, the combination of protein–DNA, protein–protein, ncRNA–DNA, ncRNA–protein and DNA–DNA data in a single graph database offers new possibilities regarding generation of biological hypotheses. GREG (The Gene Regulation Graph Database) is an integrative database and web resource that allows the user to visualize and explore the network of all above-mentioned interactions for a query transcription factor, long non-coding RNA, genomic range or DNA annotation, as well as extracting node and interaction information, identifying connected nodes and performing advanced graphical queries directly on the regulatory network, in a simple and efficient way. In this article, we introduce GREG together with some application examples (including exploratory research of Nanog’s regulatory landscape and the etiology of chronic obstructive pulmonary disease), which we use as a demonstration of the advantages of using graph databases in biomedical research.,  Database URL: https://mora-lab.github.io/projects/greg.html, www.moralab.science/GREG/",2020-01-01; 2020-02-13,2021-06-05 20:35:57; 2021-06-05 20:55:01; 2021-06-05 21:06:22; 2021-06-05 21:10:08,,,2020,Database (Oxford),,PubMed; PubMed Central,PMID: 32055858 PMCID: PMC7018612,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7018612/; http://www.ncbi.nlm.nih.gov/pubmed/32055858,"Cell Line, Tumor; Database Management Systems; Databases, Genetic; Gene Expression Regulation; Genomics; Humans; Molecular Sequence Annotation; Pulmonary Disease, Chronic Obstructive; RNA, Long Noncoding; Transcription Factors",Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PubMed:Query2; PMC:Query2
246,10.1093/g3journal/jkaa028,33561251,PMC8022729,,,,"Evans, Cory J; Olson, John M; Mondal, Bama Charan; Kandimalla, Pratyush; Abbasi, Ariano; Abdusamad, Mai M; Acosta, Osvaldo; Ainsworth, Julia A; Akram, Haris M; Albert, Ralph B; Alegria-Leal, Elitzander; Alexander, Kai Y; Ayala, Angelica C; Balashova, Nataliya S; Barber, Rebecca M; Bassi, Harmanjit; Bennion, Sean P; Beyder, Miriam; Bhatt, Kush V; Bhoot, Chinmay; Bradshaw, Aaron W; Brannigan, Tierney G; Cao, Boyu; Cashell, Yancey Y; Chai, Timothy; Chan, Alex W; Chan, Carissa; Chang, Inho; Chang, Jonathan; Chang, Michael T; Chang, Patrick W; Chang, Stephen; Chari, Neel; Chassiakos, Alexander J; Chen, Iris E; Chen, Vivian K; Chen, Zheying; Cheng, Marsha R; Chiang, Mimi; Chiu, Vivian; Choi, Sharon; Chung, Jun Ho; Contreras, Liset; Corona, Edgar; Cruz, Courtney J; Cruz, Renae L; Dang, Jefferson M; Dasari, Suhas P; De La Fuente, Justin R O; Del Rio, Oscar M A; Dennis, Emily R; Dertsakyan, Petros S; Dey, Ipsita; Distler, Rachel S; Dong, Zhiqiao; Dorman, Leah C; Douglass, Mark A; Ehresman, Allysen B; Fu, Ivy H; Fua, Andrea; Full, Sean M; Ghaffari-Rafi, Arash; Ghani, Asmar Abdul; Giap, Bosco; Gill, Sonia; Gill, Zafar S; Gills, Nicholas J; Godavarthi, Sindhuja; Golnazarian, Talin; Goyal, Raghav; Gray, Ricardo; Grunfeld, Alexander M; Gu, Kelly M; Gutierrez, Natalia C; Ha, An N; Hamid, Iman; Hanson, Ashley; Hao, Celesti; He, Chongbin; He, Mengshi; Hedtke, Joshua P; Hernandez, Ysrael K; Hlaing, Hnin; Hobby, Faith A; Hoi, Karen; Hope, Ashley C; Hosseinian, Sahra M; Hsu, Alice; Hsueh, Jennifer; Hu, Eileen; Hu, Spencer S; Huang, Stephanie; Huang, Wilson; Huynh, Melanie; Javier, Carmen; Jeon, Na Eun; Ji, Sunjong; Johal, Jasmin; John, Amala; Johnson, Lauren; Kadakia, Saurin; Kakade, Namrata; Kamel, Sarah; Kaur, Ravinder; Khatra, Jagteshwar S; Kho, Jeffrey A; Kim, Caleb; Kim, Emily Jin-Kyung; Kim, Hee Jong; Kim, Hyun Wook; Kim, Jin Hee; Kim, Seong Ah; Kim, Woo Kyeom; Kit, Brian; La, Cindy; Lai, Jonathan; Lam, Vivian; Le, Nguyen Khoi; Lee, Chi Ju; Lee, Dana; Lee, Dong Yeon; Lee, James; Lee, Jason; Lee, Jessica; Lee, Ju-Yeon; Lee, Sharon; Lee, Terrence C; Lee, Victoria; Li, Amber J; Li, Jialing; Libro, Alexandra M; Lien, Irvin C; Lim, Mia; Lin, Jeffrey M; Liu, Connie Y; Liu, Steven C; Louie, Irene; Lu, Shijia W; Luo, William Y; Luu, Tiffany; Madrigal, Josef T; Mai, Yishan; Miya, Darron I; Mohammadi, Mina; Mohanta, Sayonika; Mokwena, Tebogo; Montoya, Tonatiuh; Mould, Dallas L; Murata, Mark R; Muthaiya, Janani; Naicker, Seethim; Neebe, Mallory R; Ngo, Amy; Ngo, Duy Q; Ngo, Jamie A; Nguyen, Anh T; Nguyen, Huy C X; Nguyen, Rina H; Nguyen, Thao T T; Nguyen, Vincent T; Nishida, Kevin; Oh, Seo-Kyung; Omi, Kristen M; Onglatco, Mary C; Almazan, Guadalupe Ortega; Paguntalan, Jahzeel; Panchal, Maharshi; Pang, Stephanie; Parikh, Harin B; Patel, Purvi D; Patel, Trisha H; Petersen, Julia E; Pham, Steven; Phan-Everson, Tien M; Pokhriyal, Megha; Popovich, Davis W; Quaal, Adam T; Querubin, Karl; Resendiz, Anabel; Riabkova, Nadezhda; Rong, Fred; Salarkia, Sarah; Sama, Nateli; Sang, Elaine; Sanville, David A; Schoen, Emily R; Shen, Zhouyang; Siangchin, Ken; Sibal, Gabrielle; Sin, Garuem; Sjarif, Jasmine; Smith, Christopher J; Soeboer, Annisa N; Sosa, Cristian; Spitters, Derek; Stender, Bryan; Su, Chloe C; Summapund, Jenny; Sun, Beatrice J; Sutanto, Christine; Tan, Jaime S; Tan, Nguon L; Tangmatitam, Parich; Trac, Cindy K; Tran, Conny; Tran, Daniel; Tran, Duy; Tran, Vina; Truong, Patrick A; Tsai, Brandon L; Tsai, Pei-Hua; Tsui, C Kimberly; Uriu, Jackson K; Venkatesh, Sanan; Vo, Maique; Vo, Nhat-Thi; Vo, Phuong; Voros, Timothy C; Wan, Yuan; Wang, Eric; Wang, Jeffrey; Wang, Michael K; Wang, Yuxuan; Wei, Siman; Wilson, Matthew N; Wong, Daniel; Wu, Elliott; Xing, Hanning; Xu, Jason P; Yaftaly, Sahar; Yan, Kimberly; Yang, Evan; Yang, Rebecca; Yao, Tony; Yeo, Patricia; Yip, Vivian; Yogi, Puja; Young, Gloria Chin; Yung, Maggie M; Zai, Alexander; Zhang, Christine; Zhang, Xiao X; Zhao, Zijun; Zhou, Raymond; Zhou, Ziqi; Abutouk, Mona; Aguirre, Brian; Ao, Chon; Baranoff, Alexis; Beniwal, Angad; Cai, Zijie; Chan, Ryan; Chien, Kenneth Chang; Chaudhary, Umar; Chin, Patrick; Chowdhury, Praptee; Dalie, Jamlah; Du, Eric Y; Estrada, Alec; Feng, Erwin; Ghaly, Monica; Graf, Rose; Hernandez, Eduardo; Herrera, Kevin; Ho, Vivien W; Honeychurch, Kaitlyn; Hou, Yurianna; Huang, Jo M; Ishii, Momoko; James, Nicholas; Jang, Gah-Eun; Jin, Daphne; Juarez, Jesse; Kesaf, Ayse Elif; Khalsa, Sat Kartar; Kim, Hannah; Kovsky, Jenna; Kuang, Chak Lon; Kumar, Shraddha; Lam, Gloria; Lee, Ceejay; Lee, Grace; Li, Li; Lin, Joshua; Liu, Josephine; Ly, Janice; Ma, Austin; Markovic, Hannah; Medina, Cristian; Mungcal, Jonelle; Naranbaatar, Bilguudei; Patel, Kayla; Petersen, Lauren; Phan, Amanda; Phung, Malcolm; Priasti, Nadiyah; Ruano, Nancy; Salim, Tanveer; Schnell, Kristen; Shah, Paras; Shen, Jinhua; Stutzman, Nathan; Sukhina, Alisa; Tian, Rayna; Vega-Loza, Andrea; Wang, Joyce; Wang, Jun; Watanabe, Rina; Wei, Brandon; Xie, Lillian; Ye, Jessica; Zhao, Jeffrey; Zimmerman, Jill; Bracken, Colton; Capili, Jason; Char, Andrew; Chen, Michel; Huang, Pingdi; Ji, Sena; Kim, Emily; Kim, Kenneth; Ko, Julie; Laput, Sean Louise G; Law, Sam; Lee, Sang Kuk; Lee, Olivia; Lim, David; Lin, Eric; Marik, Kyle; Mytych, Josh; O'Laughlin, Andie; Pak, Jensen; Park, Claire; Ryu, Ruth; Shinde, Ashwin; Sosa, Manny; Waite, Nick; Williams, Mane; Wong, Richard; Woo, Jocelyn; Woo, Jonathan; Yepuri, Vishaal; Yim, Dorothy; Huynh, Dan; Wijiewarnasurya, Dinali; Shapiro, Casey; Levis-Fitzgerald, Marc; Jaworski, Leslie; Lopatto, David; Clark, Ira E; Johnson, Tracy; Banerjee, Utpal",A functional genomics screen identifying blood cell development genes in Drosophila by undergraduates participating in a course-based research experience,2021,G3: Genes|Genomes|Genetics,,"Undergraduate students participating in the UCLA Undergraduate Research Consortium for Functional Genomics (URCFG) have conducted a two-phased screen using RNA interference (RNAi) in combination with fluorescent reporter proteins to identify genes important for hematopoiesis in Drosophila. This screen disrupted the function of approximately 3500 genes and identified 137 candidate genes for which loss of function leads to observable changes in the hematopoietic development. Targeting RNAi to maturing, progenitor, and regulatory cell types identified key subsets that either limit or promote blood cell maturation. Bioinformatic analysis reveals gene enrichment in several previously uncharacterized areas, including RNA processing and export and vesicular trafficking. Lastly, the participation of students in this course-based undergraduate research experience (CURE) correlated with increased learning gains across several areas, as well as increased STEM retention, indicating that authentic, student-driven research in the form of a CURE represents an impactful and enriching pedagogical approach.",2021-01-30,2021-06-05 21:09:36,,1,11,G3 (Bethesda),,PubMed Central,PMID: 33561251 PMCID: PMC8022729,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8022729/,,,,PMC:Query2
247,10.1093/gigascience/giaa039,32391910,PMC7213554,A,Neo4j,Neo4j,"Escamilla Molgora, Juan M; Sedda, Luigi; Atkinson, Peter M; Escamilla Molgora, Juan M.; Sedda, Luigi; Atkinson, Peter M.",Biospytial: spatial graph-based computing for ecological Big Data,2020,GigaScience,,"BACKGROUND: The exponential accumulation of environmental and ecological data together with the adoption of open data initiatives bring opportunities and challenges for integrating and synthesising relevant knowledge that need to be addressed, given the ongoing environmental crises. FINDINGS: Here we present Biospytial, a modular open source knowledge engine designed to import, organise, analyse and visualise big spatial ecological datasets using the power of graph theory. The engine uses a hybrid graph-relational approach to store and access information. A graph data structure uses linkage relationships to build semantic structures represented as complex data structures stored in a graph database, while tabular and geospatial data are stored in an efficient spatial relational database system. We provide an application using information on species occurrences, their taxonomic classification and climatic datasets. We built a knowledge graph of the Tree of Life embedded in an environmental and geographical grid to perform an analysis on threatened species co-occurring with jaguars (Panthera onca). CONCLUSIONS: The Biospytial approach reduces the complexity of joining datasets using multiple tabular relations, while its scalable design eases the problem of merging datasets from different sources. Its modular design makes it possible to distribute several instances simultaneously, allowing fast and efficient handling of big ecological datasets. The provided example demonstrates the engine's capabilities in performing basic graph manipulation, analysis and visualizations of taxonomic groups co-occurring in space. The example shows potential avenues for performing novel ecological analyses, biodiversity syntheses and species distribution models aided by a network of taxonomic and spatial relationships.; Background The exponential accumulation of environmental and ecological data together with the adoption of open data initiatives bring opportunities and challenges for integrating and synthesising relevant knowledge that need to be addressed, given the ongoing environmental crises. Findings Here we present Biospytial, a modular open source knowledge engine designed to import, organise, analyse and visualise big spatial ecological datasets using the power of graph theory. The engine uses a hybrid graph-relational approach to store and access information. A graph data structure uses linkage relationships to build semantic structures represented as complex data structures stored in a graph database, while tabular and geospatial data are stored in an efficient spatial relational database system. We provide an application using information on species occurrences, their taxonomic classification and climatic datasets. We built a knowledge graph of the Tree of Life embedded in an environmental and geographical grid to perform an analysis on threatened species co-occurring with jaguars (Panthera onca). Conclusions The Biospytial approach reduces the complexity of joining datasets using multiple tabular relations, while its scalable design eases the problem of merging datasets from different sources. Its modular design makes it possible to distribute several instances simultaneously, allowing fast and efficient handling of big ecological datasets. The provided example demonstrates the engine’s capabilities in performing basic graph manipulation, analysis and visualizations of taxonomic groups co-occurring in space. The example shows potential avenues for performing novel ecological analyses, biodiversity syntheses and species distribution models aided by a network of taxonomic and spatial relationships.",2020-05-11; 2020-05-01,2021-06-05 20:35:57; 2021-06-05 21:06:22; 2021-06-05 20:54:31; 2021-06-05 21:10:08,,5,9,Gigascience,Biospytial,PubMed; PubMed Central,PMID: 32391910 PMCID: PMC7213554,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7213554/; http://www.ncbi.nlm.nih.gov/pubmed/32391910,big ecological data; biodiversity informatics; ecological knowledge engine; open science; spatial data infrastructure,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PubMed:Query2; PMC:Query2
248,10.1093/gigascience/giy062,29860514,PMC6207142,A,Neo4j,Neo4j,"Gioiosa, Silvia; Bolis, Marco; Flati, Tiziano; Massini, Annalisa; Garattini, Enrico; Chillemi, Giovanni; Fratelli, Maddalena; Castrignanò, Tiziana",Massive NGS data analysis reveals hundreds of potential novel gene fusions in human cell lines,2018,GigaScience,,"Background Gene fusions derive from chromosomal rearrangements. The resulting chimeric transcripts are often endowed with oncogenic potential. Furthermore, they serve as diagnostic tools for the clinical classification of cancer subgroups with different prognosis and, in some cases, they can provide specific drug targets. To date, many efforts have been carried out to study gene fusion events occurring in tumor samples. In recent years, the availability of a comprehensive next-generation sequencing dataset for all existing human tumor cell lines has provided the opportunity to further investigate these data in order to identify novel and still uncharacterized gene fusion events. Results In our work, we have extensively reanalyzed 935 paired-end RNA-sequencing experiments downloaded from the Cancer Cell Line Encyclopedia repository, aiming at addressing novel putative cell-line specific gene fusion events in human malignancies. The bioinformatics analysis has been performed by the execution of four gene fusion detection algorithms. The results have been further prioritized by running a Bayesian classifier that makes an in silico validation. The collection of fusion events supported by all of the predictive software results in a robust set of ∼1,700 in silico predicted novel candidates suitable for downstream analyses. Given the huge amount of data and information produced, computational results have been systematized in a database named LiGeA. The database can be browsed through a dynamic and interactive web portal, further integrated with validated data from other well-known repositories. Taking advantage of the intuitive query forms, the users can easily access, navigate, filter, and select the putative gene fusions for further validations and studies. They can also find suitable experimental models for a given fusion of interest. Conclusions We believe that the LiGeA resource can represent not only the first compendium of both known and putative novel gene fusion events in the catalog of all of the human malignant cell lines but it can also become a handy starting point for wet-lab biologists who wish to investigate novel cancer biomarkers and specific drug targets.",2018-06-01,2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:36:32,,10,7,Gigascience,,PubMed Central,PMID: 29860514 PMCID: PMC6207142,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6207142/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
249,10.1093/gigascience/giz088,31363752,PMC6667378,A,Neo4j,Neo4j,"Sánchez, Luis Francisco Hernández; Burger, Bram; Horro, Carlos; Fabregat, Antonio; Johansson, Stefan; Njølstad, Pål Rasmus; Barsnes, Harald; Hermjakob, Henning; Vaudel, Marc",PathwayMatcher: proteoform-centric network construction enables fine-granularity multiomics pathway mapping,2019,GigaScience,,"Background Mapping biomedical data to functional knowledge is an essential task in bioinformatics and can be achieved by querying identifiers (e.g., gene sets) in pathway knowledge bases. However, the isoform and posttranslational modification states of proteins are lost when converting input and pathways into gene-centric lists. Findings Based on the Reactome knowledge base, we built a network of protein-protein interactions accounting for the documented isoform and modification statuses of proteins. We then implemented a command line application called PathwayMatcher (github.com/PathwayAnalysisPlatform/PathwayMatcher) to query this network. PathwayMatcher supports multiple types of omics data as input and outputs the possibly affected biochemical reactions, subnetworks, and pathways. Conclusions PathwayMatcher enables refining the network representation of pathways by including proteoforms defined as protein isoforms with posttranslational modifications. The specificity of pathway analyses is hence adapted to different levels of granularity, and it becomes possible to distinguish interactions between different forms of the same protein.",2019-07-30,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,,8,8,Gigascience,PathwayMatcher,PubMed Central,PMID: 31363752 PMCID: PMC6667378,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6667378/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
250,10.1093/hmg/ddy163,29771313,PMC6061876,,,,"Hemani, Gibran; Bowden, Jack; Davey Smith, George",Evaluating the potential role of pleiotropy in Mendelian randomization studies,2018,Human Molecular Genetics,,"Pleiotropy, the phenomenon of a single genetic variant influencing multiple traits, is likely widespread in the human genome. If pleiotropy arises because the single nucleotide polymorphism (SNP) influences one trait, which in turn influences another (‘vertical pleiotropy’), then Mendelian randomization (MR) can be used to estimate the causal influence between the traits. Of prime focus among the many limitations to MR is the unprovable assumption that apparent pleiotropic associations are mediated by the exposure (i.e. reflect vertical pleiotropy), and do not arise due to SNPs influencing the two traits through independent pathways (‘horizontal pleiotropy’). The burgeoning treasure trove of genetic associations yielded through genome wide association studies makes for a tantalizing prospect of phenome-wide causal inference. Recent years have seen substantial attention devoted to the problem of horizontal pleiotropy, and in this review we outline how newly developed methods can be used together to improve the reliability of MR.",2018-08-01,2021-06-05 21:11:16,R195-R208,R2,27,Hum Mol Genet,,PubMed Central,PMID: 29771313 PMCID: PMC6061876,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6061876/,,,,PMC:Query2
251,10.1093/ije/dyx251,29342271,PMC5913624,A,Neo4j,Neo4j,"Elsworth, Benjamin; Dawe, Karen; Vincent, Emma E; Langdon, Ryan; Lynch, Brigid M; Martin, Richard M; Relton, Caroline; Higgins, Julian P T; Gaunt, Tom R",MELODI: Mining Enriched Literature Objects to Derive Intermediates,2018,International Journal of Epidemiology,,"Background The scientific literature contains a wealth of information from different fields on potential disease mechanisms. However, identifying and prioritizing mechanisms for further analytical evaluation presents enormous challenges in terms of the quantity and diversity of published research. The application of data mining approaches to the literature offers the potential to identify and prioritize mechanisms for more focused and detailed analysis. Methods Here we present MELODI, a literature mining platform that can identify mechanistic pathways between any two biomedical concepts. Results Two case studies demonstrate the potential uses of MELODI and how it can generate hypotheses for further investigation. First, an analysis of ETS-related gene ERG and prostate cancer derives the intermediate transcription factor SP1, recently confirmed to be physically interacting with ERG. Second, examining the relationship between a new potential risk factor for pancreatic cancer identifies possible mechanistic insights which can be studied in vitro. Conclusions We have demonstrated the possible applications of MELODI, including two case studies. MELODI has been implemented as a Python/Django web application, and is freely available to use at [www.melodi.biocompute.org.uk].",2018-04,2021-06-05 20:55:40; 2021-06-05 21:11:16; 2021-06-05 20:36:32,369-379,2,47,Int J Epidemiol,MELODI,PubMed Central,PMID: 29342271 PMCID: PMC5913624,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5913624/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
252,10.1093/jamia/ocab078,33895839,PMC8135317,,,,"Du, Jingcheng; Wang, Qing; Wang, Jingqi; Ramesh, Prerana; Xiang, Yang; Jiang, Xiaoqian; Tao, Cui",COVID-19 Trial Graph: A Linked Graph for COVID-19 Clinical Trials,2021,Journal of the American Medical Informatics Association : JAMIA; Journal of the American Medical Informatics Association: JAMIA,,"OBJECTIVE: Clinical trials are an essential part of the effort to find safe and effective prevention and treatment for COVID-19. Given the rapid growth of COVID-19 clinical trials, there is an urgent need for a better clinical trial information retrieval that supports searching by specifying criteria including both eligibility criteria and structured trial information. MATERIALS AND METHODS: We built a linked graph for registered COVID-19 clinical trials: the COVID-19 Trial Graph, to facilitate retrieval of clinical trials. Natural language processing (NLP) tools were leveraged to extract and normalize the clinical trial information from both their eligibility criteria free texts and structured information from ClinicalTrials.gov. We linked the extracted data using the COVID-19 Trial Graph and imported it to a graph database, which supports both query and visualization. We evaluated trial graph using case queries and graph embedding. RESULTS: The graph currently (as of 10-05-2020) contains 3,392 registered COVID-19 clinical trials, with 17,480 nodes and 65,236 relationships. Manual evaluation of case queries found high-precision and recall scores on retrieving relevant clinical trials searching from both eligibility criteria and trial-structured information. We observed clustering in clinical trials via graph embedding, which also showed superiority over the baseline (0.8704 vs. 0.8199) in evaluating whether a trial can complete its recruitment successfully. CONCLUSIONS: The COVID-19 Trial Graph is a novel representation of clinical trials that allows diverse search queries and provides a graph-based visualization of COVID-19 clinical trials. High-dimensional vectors mapped by graph embedding for clinical trials would be potentially beneficial for many downstream applications, such as trial end recruitment status prediction, and trial similarity comparison. Our methodology also is generalizable to other clinical trials, such as cancer clinical trials.; Objective Clinical trials are an essential part of the effort to find safe and effective prevention and treatment for COVID-19. Given the rapid growth of COVID-19 clinical trials, there is an urgent need for a better clinical trial information retrieval that supports searching by specifying criteria including both eligibility criteria and structured trial information. Materials and Methods We built a linked graph for registered COVID-19 clinical trials: the COVID-19 Trial Graph, to facilitate retrieval of clinical trials. Natural language processing (NLP) tools were leveraged to extract and normalize the clinical trial information from both their eligibility criteria free texts and structured information from ClinicalTrials.gov. We linked the extracted data using the COVID-19 Trial Graph and imported it to a graph database, which supports both query and visualization. We evaluated trial graph using case queries and graph embedding. Results The graph currently (as of 10-05-2020) contains 3,392 registered COVID-19 clinical trials, with 17,480 nodes and 65,236 relationships. Manual evaluation of case queries found high-precision and recall scores on retrieving relevant clinical trials searching from both eligibility criteria and trial-structured information. We observed clustering in clinical trials via graph embedding, which also showed superiority over the baseline (0.8704 vs. 0.8199) in evaluating whether a trial can complete its recruitment successfully. Conclusions The COVID-19 Trial Graph is a novel representation of clinical trials that allows diverse search queries and provides a graph-based visualization of COVID-19 clinical trials. High-dimensional vectors mapped by graph embedding for clinical trials would be potentially beneficial for many downstream applications, such as trial end recruitment status prediction, and trial similarity comparison. Our methodology also is generalizable to other clinical trials, such as cancer clinical trials.",2021-04-24,2021-06-05 21:06:22; 2021-06-05 21:09:36,,,,J Am Med Inform Assoc,COVID-19 Trial Graph,PubMed; PubMed Central,PMID: 33895839 PMCID: PMC8135317,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8135317/; http://www.ncbi.nlm.nih.gov/pubmed/33895839,clinical trial; covid-19; eligibility criteria; graph representation,,,PubMed:Query2; PMC:Query2
253,10.1093/jamia/ocu017,25710558,PMC4394967,A,Neo4j,Neo4j,"Soulakis, Nicholas D.; Carson, Matthew B.; Lee, Young Ji; Schneider, Daniel H.; Skeehan, Connor T.; Scholtens, Denise M.; Soulakis, Nicholas D; Carson, Matthew B; Lee, Young Ji; Schneider, Daniel H; Skeehan, Connor T; Scholtens, Denise M",Visualizing collaborative electronic health record usage for hospitalized patients with heart failure,2015,Journal of the American Medical Informatics Association : JAMIA; Journal of the American Medical Informatics Association: JAMIA,,"OBJECTIVE: To visualize and describe collaborative electronic health record (EHR) usage for hospitalized patients with heart failure. MATERIALS AND METHODS: We identified records of patients with heart failure and all associated healthcare provider record usage through queries of the Northwestern Medicine Enterprise Data Warehouse. We constructed a network by equating access and updates of a patient's EHR to a provider-patient interaction. We then considered shared patient record access as the basis for a second network that we termed the provider collaboration network. We calculated network statistics, the modularity of provider interactions, and provider cliques. RESULTS: We identified 548 patient records accessed by 5113 healthcare providers in 2012. The provider collaboration network had 1504 nodes and 83 998 edges. We identified 7 major provider collaboration modules. Average clique size was 87.9 providers. We used a graph database to demonstrate an ad hoc query of our provider-patient network. DISCUSSION: Our analysis suggests a large number of healthcare providers across a wide variety of professions access records of patients with heart failure during their hospital stay. This shared record access tends to take place not only in a pairwise manner but also among large groups of providers. CONCLUSION: EHRs encode valuable interactions, implicitly or explicitly, between patients and providers. Network analysis provided strong evidence of multidisciplinary record access of patients with heart failure across teams of 100+ providers. Further investigation may lead to clearer understanding of how record access information can be used to strategically guide care coordination for patients hospitalized for heart failure.; Objective To visualize and describe collaborative electronic health record (EHR) usage for hospitalized patients with heart failure., Materials and methods We identified records of patients with heart failure and all associated healthcare provider record usage through queries of the Northwestern Medicine Enterprise Data Warehouse. We constructed a network by equating access and updates of a patient’s EHR to a provider-patient interaction. We then considered shared patient record access as the basis for a second network that we termed the provider collaboration network. We calculated network statistics, the modularity of provider interactions, and provider cliques., Results We identified 548 patient records accessed by 5113 healthcare providers in 2012. The provider collaboration network had 1504 nodes and 83 998 edges. We identified 7 major provider collaboration modules. Average clique size was 87.9 providers. We used a graph database to demonstrate an ad hoc query of our provider-patient network., Discussion Our analysis suggests a large number of healthcare providers across a wide variety of professions access records of patients with heart failure during their hospital stay. This shared record access tends to take place not only in a pairwise manner but also among large groups of providers., Conclusion EHRs encode valuable interactions, implicitly or explicitly, between patients and providers. Network analysis provided strong evidence of multidisciplinary record access of patients with heart failure across teams of 100+ providers. Further investigation may lead to clearer understanding of how record access information can be used to strategically guide care coordination for patients hospitalized for heart failure.",2015-03,2021-06-05 21:12:40; 2021-06-05 21:06:22; 2021-06-05 20:37:08; 2021-06-05 20:56:20,299-311,2,22,J Am Med Inform Assoc,,PubMed; PubMed Central,PMID: 25710558 PMCID: PMC4394967,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4394967/; http://www.ncbi.nlm.nih.gov/pubmed/25710558,"Care collaboration; Data Display; Data Mining; electronic health records; Electronic Health Records; Health Personnel; heart failure; Heart Failure; Hospitalization; Humans; network analysis; Pattern Recognition, Automated; User-Computer Interface",Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PubMed:Query2; PMC:Query2
254,10.1093/jamia/ocv137,26911823,PMC6375118,A,ArangoDB,ArangoDB,"Lin, Ching-Heng; Fann, Yang-Cheng; Liou, Der-Ming",An exploratory study using an openEHR 2-level modeling approach to represent common data elements,2016,Journal of the American Medical Informatics Association : JAMIA,,"Background and Objective In order to facilitate clinical research across multiple institutions, data harmonization is a critical requirement. Common data elements (CDEs) collect data uniformly, allowing data interoperability between research studies. However, structural limitations have hindered the application of CDEs. An advanced modeling structure is needed to rectify such limitations. The openEHR 2-level modeling approach has been widely implemented in the medical informatics domain. The aim of our study is to explore the feasibility of applying an openEHR approach to model the CDE concept. ,  Materials and Methods Using the National Institute of Neurological Disorders and Stroke General CDEs as material, we developed a semiautomatic mapping tool to assist domain experts mapping CDEs to existing openEHR archetypes in order to evaluate their coverage and to allow further analysis. In addition, we modeled a set of CDEs using the openEHR approach to evaluate the ability of archetypes to structurally represent any type of CDE content. ,  Results Among 184 CDEs, 28% (51) of the archetypes could be directly used to represent CDEs, while 53% (98) of the archetypes required further development (extension or specialization). A comprehensive comparison between CDEs and openEHR archetypes was conducted based on the lessons learnt from the practical modeling. ,  Discussion CDEs and archetypes have dissimilar modeling approaches, but the data structure of both models are essentially similar. This study proposes to develop a comprehensive structure to model CDE concepts instead of improving the structure of CED. ,  Conclusion The findings from this research show that the openEHR archetype has structural coverage for the CDEs, namely the openEHR archetype is able to represent the CDEs and meet the functional expectations of the CDEs. This work can be used as a reference when improving CDE structure using an advanced modeling approach.",2016-09,2021-06-05 20:55:40; 2021-06-05 21:12:40; 2021-06-06 06:42:51,956-967,5,23,J Am Med Inform Assoc,,PubMed Central,PMID: 26911823 PMCID: PMC6375118,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6375118/,,ArangoDB,ArangoDB,PMC:Query3; PMC:Query2; PMC:ArangoDB
255,10.1093/jamia/ocx121,29346583,PMC7378878,A,Neo4j,Neo4j,"Chen, Xiaoling; Gururaj, Anupama E; Ozyurt, Burak; Liu, Ruiling; Soysal, Ergin; Cohen, Trevor; Tiryaki, Firat; Li, Yueling; Zong, Nansu; Jiang, Min; Rogith, Deevakar; Salimi, Mandana; Kim, Hyeon-eui; Rocca-Serra, Philippe; Gonzalez-Beltran, Alejandra; Farcas, Claudiu; Johnson, Todd; Margolis, Ron; Alter, George; Sansone, Susanna-Assunta; Fore, Ian M; Ohno-Machado, Lucila; Grethe, Jeffrey S; Xu, Hua",DataMed – an open source discovery index for finding biomedical datasets,2018,Journal of the American Medical Informatics Association : JAMIA,,"Objective Finding relevant datasets is important for promoting data reuse in the biomedical domain, but it is challenging given the volume and complexity of biomedical data. Here we describe the development of an open source biomedical data discovery system called DataMed, with the goal of promoting the building of additional data indexes in the biomedical domain. Materials and Methods DataMed, which can efficiently index and search diverse types of biomedical datasets across repositories, is developed through the National Institutes of Health–funded biomedical and healthCAre Data Discovery Index Ecosystem (bioCADDIE) consortium. It consists of 2 main components: (1) a data ingestion pipeline that collects and transforms original metadata information to a unified metadata model, called DatA Tag Suite (DATS), and (2) a search engine that finds relevant datasets based on user-entered queries. In addition to describing its architecture and techniques, we evaluated individual components within DataMed, including the accuracy of the ingestion pipeline, the prevalence of the DATS model across repositories, and the overall performance of the dataset retrieval engine. Results and Conclusion Our manual review shows that the ingestion pipeline could achieve an accuracy of 90% and core elements of DATS had varied frequency across repositories. On a manually curated benchmark dataset, the DataMed search engine achieved an inferred average precision of 0.2033 and a precision at 10 (P@10, the number of relevant results in the top 10 search results) of 0.6022, by implementing advanced natural language processing and terminology services. Currently, we have made the DataMed system publically available as an open source package for the biomedical community.",2018-01-13,2021-06-05 20:55:40; 2021-06-05 21:11:16; 2021-06-05 20:36:32,300-308,3,25,J Am Med Inform Assoc,,PubMed Central,PMID: 29346583 PMCID: PMC7378878,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7378878/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
256,10.1093/jamia/ocz216,32068839,PMC7075538,A,Neo4j,Neo4j,"Rizvi, Rubina F; Vasilakes, Jake; Adam, Terrence J; Melton, Genevieve B; Bishop, Jeffrey R; Bian, Jiang; Tao, Cui; Zhang, Rui",iDISK: the integrated DIetary Supplements Knowledge base,2020,Journal of the American Medical Informatics Association : JAMIA,,"Objective To build a knowledge base of dietary supplement (DS) information, called the integrated DIetary Supplement Knowledge base (iDISK), which integrates and standardizes DS-related information from 4 existing resources. Materials and Methods iDISK was built through an iterative process comprising 3 phases: 1) establishment of the content scope, 2) development of the data model, and 3) integration of existing resources. Four well-regarded DS resources were integrated into iDISK: The Natural Medicines Comprehensive Database, the “About Herbs” page on the Memorial Sloan Kettering Cancer Center website, the Dietary Supplement Label Database, and the Natural Health Products Database. We evaluated the iDISK build process by manually checking that the data elements associated with 50 randomly selected ingredients were correctly extracted and integrated from their respective sources. Results iDISK encompasses a terminology of 4208 DS ingredient concepts, which are linked via 6 relationship types to 495 drugs, 776 diseases, 985 symptoms, 605 therapeutic classes, 17 system organ classes, and 137 568 DS products. iDISK also contains 7 concept attribute types and 3 relationship attribute types. Evaluation of the data extraction and integration process showed average errors of 0.3%, 2.6%, and 0.4% for concepts, relationships and attributes, respectively. Conclusion We developed iDISK, a publicly available standardized DS knowledge base that can facilitate more efficient and meaningful dissemination of DS knowledge.",2020-02-18,2021-06-05 20:35:57; 2021-06-05 20:55:01; 2021-06-05 21:10:08,539-548,4,27,J Am Med Inform Assoc,iDISK,PubMed Central,PMID: 32068839 PMCID: PMC7075538,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7075538/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
257,10.1093/jamiaopen/ooz064,32607484,PMC7309238,,,,"Singh, Harpreet; Kaur, Ravneet; Saluja, Satish; Cho, Su Jin; Kaur, Avneet; Pandey, Ashish Kumar; Gupta, Shubham; Das, Ritu; Kumar, Praveen; Palma, Jonathan; Yadav, Gautam; Sun, Yao",Development of data dictionary for neonatal intensive care unit: advancement towards a better critical care unit,2019,JAMIA Open,,"Background Critical care units (CCUs) with extensive use of various monitoring devices generate massive data. To utilize the valuable information of these devices; data are collected and stored using systems like clinical information system and laboratory information management system. These systems are proprietary, allow limited access to their database and, have the vendor-specific clinical implementation. In this study, we focus on developing an open-source web-based meta-data repository for CCU representing stay of the patient with relevant details. Methods After developing the web-based open-source repository named data dictionary (DD), we analyzed prospective data from 2 sites for 4 months for data quality dimensions (completeness, timeliness, validity, accuracy, and consistency), morbidity, and clinical outcomes. We used a regression model to highlight the significance of practice variations linked with various quality indicators. Results DD with 1555 fields (89.6% categorical and 11.4% text fields) is presented to cover the clinical workflow of a CCU. The overall quality of 1795 patient days data with respect to standard quality dimensions is 87%. The data exhibit 88% completeness, 97% accuracy, 91% timeliness, and 94% validity in terms of representing CCU processes. The data scores only 67% in terms of consistency. Furthermore, quality indicators and practice variations are strongly correlated (P < 0.05). Conclusion This study documents DD for standardized data collection in CCU. DD provides robust data and insights for audit purposes and pathways for CCU to target practice improvements leading to specific quality improvements.",2019-11-25,2021-06-05 21:10:37,21-30,1,3,JAMIA Open,Development of data dictionary for neonatal intensive care unit,PubMed Central,PMID: 32607484 PMCID: PMC7309238,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7309238/,,,,PMC:Query2
258,10.1093/jrr/rrz032,31135901,PMC6640903,,,,"Bravatà, Valentina; Cammarata, Francesco P; Minafra, Luigi; Pisciotta, Pietro; Scazzone, Concetta; Manti, Lorenzo; Savoca, Gaetano; Petringa, Giada; Cirrone, Giuseppe A P; Cuttone, Giacomo; Gilardi, Maria C; Forte, Giusi I; Russo, Giorgio",Proton-irradiated breast cells: molecular points of view,2019,Journal of Radiation Research,,"Breast cancer (BC) is the most common cancer in women, highly heterogeneous at both the clinical and molecular level. Radiation therapy (RT) represents an efficient modality to treat localized tumor in BC care, although the choice of a unique treatment plan for all BC patients, including RT, may not be the best option. Technological advances in RT are evolving with the use of charged particle beams (i.e. protons) which, due to a more localized delivery of the radiation dose, reduce the dose administered to the heart compared with conventional RT. However, few data regarding proton-induced molecular changes are currently available. The aim of this study was to investigate and describe the production of immunological molecules and gene expression profiles induced by proton irradiation. We performed Luminex assay and cDNA microarray analyses to study the biological processes activated following irradiation with proton beams, both in the non-tumorigenic MCF10A cell line and in two tumorigenic BC cell lines, MCF7 and MDA-MB-231. The immunological signatures were dose dependent in MCF10A and MCF7 cell lines, whereas MDA-MB-231 cells show a strong pro-inflammatory profile regardless of the dose delivered. Clonogenic assay revealed different surviving fractions according to the breast cell lines analyzed. We found the involvement of genes related to cell response to proton irradiation and reported specific cell line- and dose-dependent gene signatures, able to drive cell fate after radiation exposure. Our data could represent a useful tool to better understand the molecular mechanisms elicited by proton irradiation and to predict treatment outcome",2019-07,2021-06-05 21:10:37,451-465,4,60,J Radiat Res,Proton-irradiated breast cells,PubMed Central,PMID: 31135901 PMCID: PMC6640903,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6640903/,,,,PMC:Query2
259,10.1093/nar/gkl884,17108355,PMC1669709,,,,"Kim, Namshin; Alekseyenko, Alexander V.; Roy, Meenakshi; Lee, Christopher",The ASAP II database: analysis and comparative genomics of alternative splicing in 15 animal species,2007,Nucleic Acids Research,,"We have greatly expanded the Alternative Splicing Annotation Project (ASAP) database: (i) its human alternative splicing data are expanded approximately 3-fold over the previous ASAP database, to nearly 90,000 distinct alternative splicing events; (ii) it now provides genome-wide alternative splicing analyses for 15 vertebrate, insect and other animal species; (iii) it provides comprehensive comparative genomics information for comparing alternative splicing and splice site conservation across 17 aligned genomes, based on UCSC multigenome alignments; (iv) it provides an approximately 2- to 3-fold expansion in detection of tissue-specific alternative splicing events, and of cancer versus normal specific alternative splicing events. We have also constructed a novel database linking orthologous exons and orthologous introns between genomes, based on multigenome alignment of 17 animal species. It can be a valuable resource for studies of gene structure evolution. ASAP II provides a new web interface enabling more detailed exploration of the data, and integrating comparative genomics information with alternative splicing data. We provide a set of tools for advanced data-mining of ASAP II with Pygr (the Python Graph Database Framework for Bioinformatics) including powerful features such as graph query, multigenome alignment query, etc. ASAP II is available at http://www.bioinformatics.ucla.edu/ASAP2.; We have greatly expanded the Alternative Splicing Annotation Project (ASAP) database: (i) its human alternative splicing data are expanded ∼3-fold over the previous ASAP database, to nearly 90 000 distinct alternative splicing events; (ii) it now provides genome-wide alternative splicing analyses for 15 vertebrate, insect and other animal species; (iii) it provides comprehensive comparative genomics information for comparing alternative splicing and splice site conservation across 17 aligned genomes, based on UCSC multigenome alignments; (iv) it provides an ∼2- to 3-fold expansion in detection of tissue-specific alternative splicing events, and of cancer versus normal specific alternative splicing events. We have also constructed a novel database linking orthologous exons and orthologous introns between genomes, based on multigenome alignment of 17 animal species. It can be a valuable resource for studies of gene structure evolution. ASAP II provides a new web interface enabling more detailed exploration of the data, and integrating comparative genomics information with alternative splicing data. We provide a set of tools for advanced data-mining of ASAP II with Pygr (the Python Graph Database Framework for Bioinformatics) including powerful features such as graph query, multigenome alignment query, etc. ASAP II is available at .",2007-01,2021-06-05 21:06:22; 2021-06-05 21:14:07,D93-D98; D93-98,Database issue,35,Nucleic Acids Res,The ASAP II database,PubMed; PubMed Central,PMID: 17108355 PMCID: PMC1669709,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1669709/; http://www.ncbi.nlm.nih.gov/pubmed/17108355,"Alternative Splicing; Animals; Databases, Nucleic Acid; Exons; Genomics; Humans; Internet; Introns; RNA Splice Sites; Sequence Alignment; User-Computer Interface",,,PubMed:Query2; PMC:Query2
260,10.1093/nar/gkr972,22080554,PMC3245088,A,Neo4j,Neo4j,"Schriml, Lynn Marie; Arze, Cesar; Nadendla, Suvarna; Chang, Yu-Wei Wayne; Mazaitis, Mark; Felix, Victor; Feng, Gang; Kibbe, Warren Alden",Disease Ontology: a backbone for disease semantic integration,2012,Nucleic Acids Research,,"The Disease Ontology (DO) database (http://disease-ontology.org) represents a comprehensive knowledge base of 8043 inherited, developmental and acquired human diseases (DO version 3, revision 2510). The DO web browser has been designed for speed, efficiency and robustness through the use of a graph database. Full-text contextual searching functionality using Lucene allows the querying of name, synonym, definition, DOID and cross-reference (xrefs) with complex Boolean search strings. The DO semantically integrates disease and medical vocabularies through extensive cross mapping and integration of MeSH, ICD, NCI's thesaurus, SNOMED CT and OMIM disease-specific terms and identifiers. The DO is utilized for disease annotation by major biomedical databases (e.g. Array Express, NIF, IEDB), as a standard representation of human disease in biomedical ontologies (e.g. IDO, Cell line ontology, NIFSTD ontology, Experimental Factor Ontology, Influenza Ontology), and as an ontological cross mappings resource between DO, MeSH and OMIM (e.g. GeneWiki). The DO project (http://diseaseontology.sf.net) has been incorporated into open source tools (e.g. Gene Answers, FunDO) to connect gene and disease biomedical data through the lens of human disease. The next iteration of the DO web browser will integrate DO's extended relations and logical definition representation along with these biomedical resource cross-mappings.",2012-01,2021-06-05 21:13:27; 2021-06-05 21:06:22; 2021-06-05 20:37:08; 2021-06-05 20:56:20,D940-946; D940-D946,Database issue,40,Nucleic Acids Res,Disease Ontology,PubMed; PubMed Central,PMID: 22080554 PMCID: PMC3245088,http://www.ncbi.nlm.nih.gov/pubmed/22080554; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3245088/,"Computer Graphics; Databases, Factual; Disease; Humans; Semantics; Software; Terminology as Topic; User-Computer Interface; Vocabulary, Controlled",Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PubMed:Query2; PMC:Query2
261,10.1093/nar/gkt1192,24271398,PMC3965056,A,Neo4j,Neo4j,"Dutkowski, Janusz; Ono, Keiichiro; Kramer, Michael; Yu, Michael; Pratt, Dexter; Demchak, Barry; Ideker, Trey",NeXO Web: the NeXO ontology database and visualization platform,2014,Nucleic Acids Research,,"The Network-extracted Ontology (NeXO) is a gene ontology inferred directly from large-scale molecular networks. While most ontologies are constructed through manual expert curation, NeXO uses a principled computational approach which integrates evidence from hundreds of thousands of individual gene and protein interactions to construct a global hierarchy of cellular components and processes. Here, we describe the development of the NeXO Web platform (http://www.nexontology.org)—an online database and graphical user interface for visualizing, browsing and performing term enrichment analysis using NeXO and the gene ontology. The platform applies state-of-the-art web technology and visualization techniques to provide an intuitive framework for investigating biological machinery captured by both data-driven and manually curated ontologies.",2014-01-01,2021-06-05 21:13:27; 2021-06-05 20:56:20; 2021-06-05 20:37:08,D1269-D1274,Database issue,42,Nucleic Acids Res,NeXO Web,PubMed Central,PMID: 24271398 PMCID: PMC3965056,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3965056/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
262,10.1093/nar/gku1011,25348409,PMC4383880,A,Neo4j,Neo4j,"Kibbe, Warren A.; Arze, Cesar; Felix, Victor; Mitraka, Elvira; Bolton, Evan; Fu, Gang; Mungall, Christopher J.; Binder, Janos X.; Malone, James; Vasant, Drashtti; Parkinson, Helen; Schriml, Lynn M.",Disease Ontology 2015 update: an expanded and updated database of human diseases for linking biomedical knowledge through disease data,2015,Nucleic Acids Research,,"The current version of the Human Disease Ontology (DO) (http://www.disease-ontology.org) database expands the utility of the ontology for the examination and comparison of genetic variation, phenotype, protein, drug and epitope data through the lens of human disease. DO is a biomedical resource of standardized common and rare disease concepts with stable identifiers organized by disease etiology. The content of DO has had 192 revisions since 2012, including the addition of 760 terms. Thirty-two percent of all terms now include definitions. DO has expanded the number and diversity of research communities and community members by 50+ during the past two years. These community members actively submit term requests, coordinate biomedical resource disease representation and provide expert curation guidance. Since the DO 2012 NAR paper, there have been hundreds of term requests and a steady increase in the number of DO listserv members, twitter followers and DO website usage. DO is moving to a multi-editor model utilizing Protégé to curate DO in web ontology language. This will enable closer collaboration with the Human Phenotype Ontology, EBI's Ontology Working Group, Mouse Genome Informatics and the Monarch Initiative among others, and enhance DO's current asserted view and multiple inferred views through reasoning.",2015-01-28,2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-05 20:37:08,D1071-D1078,Database issue,43,Nucleic Acids Res,Disease Ontology 2015 update,PubMed Central,PMID: 25348409 PMCID: PMC4383880,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4383880/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
263,10.1093/nar/gku1181,25414348,PMC4383975,A,Virtuoso,Virtuoso,"Chelliah, Vijayalakshmi; Juty, Nick; Ajmera, Ishan; Ali, Raza; Dumousseau, Marine; Glont, Mihai; Hucka, Michael; Jalowicki, Gaël; Keating, Sarah; Knight-Schrijver, Vincent; Lloret-Villas, Audald; Natarajan, Kedar Nath; Pettit, Jean-Baptiste; Rodriguez, Nicolas; Schubert, Michael; Wimalaratne, Sarala M.; Zhao, Yangyang; Hermjakob, Henning; Le Novère, Nicolas; Laibe, Camille",BioModels: ten-year anniversary,2015,Nucleic Acids Research,,"BioModels (http://www.ebi.ac.uk/biomodels/) is a repository of mathematical models of biological processes. A large set of models is curated to verify both correspondence to the biological process that the model seeks to represent, and reproducibility of the simulation results as described in the corresponding peer-reviewed publication. Many models submitted to the database are annotated, cross-referencing its components to external resources such as database records, and terms from controlled vocabularies and ontologies. BioModels comprises two main branches: one is composed of models derived from literature, while the second is generated through automated processes. BioModels currently hosts over 1200 models derived directly from the literature, as well as in excess of 140 000 models automatically generated from pathway resources. This represents an approximate 60-fold growth for literature-based model numbers alone, since BioModels’ first release a decade ago. This article describes updates to the resource over this period, which include changes to the user interface, the annotation profiles of models in the curation pipeline, major infrastructure changes, ability to perform online simulations and the availability of model content in Linked Data form. We also outline planned improvements to cope with a diverse array of new challenges.",2015-01-28,2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-05 20:59:14,D542-D548,Database issue,43,Nucleic Acids Res,BioModels,PubMed Central,PMID: 25414348 PMCID: PMC4383975,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4383975/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
264,10.1093/nar/gku169,24589583,PMC4005636,A,Neo4j,Neo4j,"Luo, Chengwei; Rodriguez-R, Luis M.; Konstantinidis, Konstantinos T.",MyTaxa: an advanced taxonomic classifier for genomic and metagenomic sequences,2014,Nucleic Acids Research,,"Determining the taxonomic affiliation of sequences assembled from metagenomes remains a major bottleneck that affects research across the fields of environmental, clinical and evolutionary microbiology. Here, we introduce MyTaxa, a homology-based bioinformatics framework to classify metagenomic and genomic sequences with unprecedented accuracy. The distinguishing aspect of MyTaxa is that it employs all genes present in an unknown sequence as classifiers, weighting each gene based on its (predetermined) classifying power at a given taxonomic level and frequency of horizontal gene transfer. MyTaxa also implements a novel classification scheme based on the genome-aggregate average amino acid identity concept to determine the degree of novelty of sequences representing uncharacterized taxa, i.e. whether they represent novel species, genera or phyla. Application of MyTaxa on in silico generated (mock) and real metagenomes of varied read length (100–2000 bp) revealed that it correctly classified at least 5% more sequences than any other tool. The analysis also showed that ∼10% of the assembled sequences from human gut metagenomes represent novel species with no sequenced representatives, several of which were highly abundant in situ such as members of the Prevotella genus. Thus, MyTaxa can find several important applications in microbial identification and diversity studies.",2014-04,2021-06-05 21:13:27; 2021-06-05 20:56:20; 2021-06-05 20:37:08,e73,8,42,Nucleic Acids Res,MyTaxa,PubMed Central,PMID: 24589583 PMCID: PMC4005636,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4005636/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
265,10.1093/nar/gku443,24861621,PMC4086107,A,Neo4j,Neo4j,"Xia, Jianguo; Benner, Maia J.; Hancock, Robert E. W.",NetworkAnalyst - integrative approaches for protein–protein interaction network analysis and visual exploration,2014,Nucleic Acids Research,,"Biological network analysis is a powerful approach to gain systems-level understanding of patterns of gene expression in different cell types, disease states and other biological/experimental conditions. Three consecutive steps are required - identification of genes or proteins of interest, network construction and network analysis and visualization. To date, researchers have to learn to use a combination of several tools to accomplish this task. In addition, interactive visualization of large networks has been primarily restricted to locally installed programs. To address these challenges, we have developed NetworkAnalyst, taking advantage of state-of-the-art web technologies, to enable high performance network analysis with rich user experience. NetworkAnalyst integrates all three steps and presents the results via a powerful online network visualization framework. Users can upload gene or protein lists, single or multiple gene expression datasets to perform comprehensive gene annotation and differential expression analysis. Significant genes are mapped to our manually curated protein-protein interaction database to construct relevant networks. The results are presented through standard web browsers for network analysis and interactive exploration. NetworkAnalyst supports common functions for network topology and module analyses. Users can easily search, zoom and highlight nodes or modules, as well as perform functional enrichment analysis on these selections. The networks can be customized with different layouts, colors or node sizes, and exported as PNG, PDF or GraphML files. Comprehensive FAQs, tutorials and context-based tips and instructions are provided. NetworkAnalyst currently supports protein-protein interaction network analysis for human and mouse and is freely available at http://www.networkanalyst.ca.",2014-07-01,2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-05 20:37:08,W167-W174,Web Server issue,42,Nucleic Acids Res,,PubMed Central,PMID: 24861621 PMCID: PMC4086107,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4086107/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
266,10.1093/nar/gkv1012,26442528,PMC4787774,,,,"Skinnider, Michael A.; Dejong, Chris A.; Rees, Philip N.; Johnston, Chad W.; Li, Haoxin; Webster, Andrew L. H.; Wyatt, Morgan A.; Magarvey, Nathan A.",Genomes to natural products PRediction Informatics for Secondary Metabolomes (PRISM),2015,Nucleic Acids Research,,"Microbial natural products are an invaluable source of evolved bioactive small molecules and pharmaceutical agents. Next-generation and metagenomic sequencing indicates untapped genomic potential, yet high rediscovery rates of known metabolites increasingly frustrate conventional natural product screening programs. New methods to connect biosynthetic gene clusters to novel chemical scaffolds are therefore critical to enable the targeted discovery of genetically encoded natural products. Here, we present PRISM, a computational resource for the identification of biosynthetic gene clusters, prediction of genetically encoded nonribosomal peptides and type I and II polyketides, and bio- and cheminformatic dereplication of known natural products. PRISM implements novel algorithms which render it uniquely capable of predicting type II polyketides, deoxygenated sugars, and starter units, making it a comprehensive genome-guided chemical structure prediction engine. A library of 57 tailoring reactions is leveraged for combinatorial scaffold library generation when multiple potential substrates are consistent with biosynthetic logic. We compare the accuracy of PRISM to existing genomic analysis platforms. PRISM is an open-source, user-friendly web application available at http://magarveylab.ca/prism/.",2015-11-16,2021-06-05 21:12:40,9645-9662,20,43,Nucleic Acids Res,,PubMed Central,PMID: 26442528 PMCID: PMC4787774,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4787774/,,,,PMC:Query2
267,10.1093/nar/gkv1247,26578555,PMC4702881,A,Virtuoso,Virtuoso,"Mariethoz, Julien; Khatib, Khaled; Alocci, Davide; Campbell, Matthew P.; Karlsson, Niclas G.; Packer, Nicolle H.; Mullen, Elaine H.; Lisacek, Frederique","SugarBindDB, a resource of glycan-mediated host–pathogen interactions",2016,Nucleic Acids Research,,"The SugarBind Database (SugarBindDB) covers knowledge of glycan binding of human pathogen lectins and adhesins. It is a curated database; each glycan–protein binding pair is associated with at least one published reference. The core data element of SugarBindDB is a set of three inseparable components: the pathogenic agent, a lectin/adhesin and a glycan ligand. Each entity (agent, lectin or ligand) is described by a range of properties that are summarized in an entity-dedicated page. Several search, navigation and visualisation tools are implemented to investigate the functional role of glycans in pathogen binding. The database is cross-linked to protein and glycan-relaled resources such as UniProtKB and UniCarbKB. It is tightly bound to the latter via a substructure search tool that maps each ligand to full structures where it occurs. Thus, a glycan–lectin binding pair of SugarBindDB can lead to the identification of a glycan-mediated protein–protein interaction, that is, a lectin–glycoprotein interaction, via substructure search and the knowledge of site-specific glycosylation stored in UniCarbKB. SugarBindDB is accessible at: http://sugarbind.expasy.org.",2016-01-04,2021-06-05 20:55:40; 2021-06-05 21:12:40; 2021-06-05 20:59:14,D1243-D1250,Database issue,44,Nucleic Acids Res,,PubMed Central,PMID: 26578555 PMCID: PMC4702881,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4702881/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
268,10.1093/nar/gkv951,26400175,PMC4702940,A,Virtuoso; Neo4j,Virtuoso; Neo4j,"Kim, Sunghwan; Thiessen, Paul A.; Bolton, Evan E.; Chen, Jie; Fu, Gang; Gindulyte, Asta; Han, Lianyi; He, Jane; He, Siqian; Shoemaker, Benjamin A.; Wang, Jiyao; Yu, Bo; Zhang, Jian; Bryant, Stephen H.",PubChem Substance and Compound databases,2016,Nucleic Acids Research,,"PubChem (https://pubchem.ncbi.nlm.nih.gov) is a public repository for information on chemical substances and their biological activities, launched in 2004 as a component of the Molecular Libraries Roadmap Initiatives of the US National Institutes of Health (NIH). For the past 11 years, PubChem has grown to a sizable system, serving as a chemical information resource for the scientific research community. PubChem consists of three inter-linked databases, Substance, Compound and BioAssay. The Substance database contains chemical information deposited by individual data contributors to PubChem, and the Compound database stores unique chemical structures extracted from the Substance database. Biological activity data of chemical substances tested in assay experiments are contained in the BioAssay database. This paper provides an overview of the PubChem Substance and Compound databases, including data sources and contents, data organization, data submission using PubChem Upload, chemical structure standardization, web-based interfaces for textual and non-textual searches, and programmatic access. It also gives a brief description of PubChem3D, a resource derived from theoretical three-dimensional structures of compounds in PubChem, as well as PubChemRDF, Resource Description Framework (RDF)-formatted PubChem data for data sharing, analysis and integration with information contained in other databases.",2016-01-04,2021-06-05 20:55:40; 2021-06-05 21:12:40; 2021-06-05 20:59:14; 2021-06-05 20:37:08,D1202-D1213,Database issue,44,Nucleic Acids Res,,PubMed Central,PMID: 26400175 PMCID: PMC4702940,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4702940/,,Virtuoso; Neo4j,Virtuoso; Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2; PMC:Virtuoso
269,10.1093/nar/gkw1075,27899649,PMC5210558,A,Virtuoso,Virtuoso,"Natale, Darren A.; Arighi, Cecilia N.; Blake, Judith A.; Bona, Jonathan; Chen, Chuming; Chen, Sheng-Chih; Christie, Karen R.; Cowart, Julie; D'Eustachio, Peter; Diehl, Alexander D.; Drabkin, Harold J.; Duncan, William D.; Huang, Hongzhan; Ren, Jia; Ross, Karen; Ruttenberg, Alan; Shamovsky, Veronica; Smith, Barry; Wang, Qinghua; Zhang, Jian; El-Sayed, Abdelrahman; Wu, Cathy H.",Protein Ontology (PRO): enhancing and scaling up the representation of protein entities,2017,Nucleic Acids Research,,"The Protein Ontology (PRO; http://purl.obolibrary.org/obo/pr) formally defines and describes taxon-specific and taxon-neutral protein-related entities in three major areas: proteins related by evolution; proteins produced from a given gene; and protein-containing complexes. PRO thus serves as a tool for referencing protein entities at any level of specificity. To enhance this ability, and to facilitate the comparison of such entities described in different resources, we developed a standardized representation of proteoforms using UniProtKB as a sequence reference and PSI-MOD as a post-translational modification reference. We illustrate its use in facilitating an alignment between PRO and Reactome protein entities. We also address issues of scalability, describing our first steps into the use of text mining to identify protein-related entities, the large-scale import of proteoform information from expert curated resources, and our ability to dynamically generate PRO terms. Web views for individual terms are now more informative about closely-related terms, including for example an interactive multiple sequence alignment. Finally, we describe recent improvement in semantic utility, with PRO now represented in OWL and as a SPARQL endpoint. These developments will further support the anticipated growth of PRO and facilitate discoverability of and allow aggregation of data relating to protein entities.",2017-01-04,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:59:14,D339-D346,Database issue,45,Nucleic Acids Res,Protein Ontology (PRO),PubMed Central,PMID: 27899649 PMCID: PMC5210558,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5210558/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
270,10.1093/nar/gkw1128,27899636,PMC5210586,A,Neo4j,Neo4j,"Mungall, Christopher J.; McMurry, Julie A.; Köhler, Sebastian; Balhoff, James P.; Borromeo, Charles; Brush, Matthew; Carbon, Seth; Conlin, Tom; Dunn, Nathan; Engelstad, Mark; Foster, Erin; Gourdine, J.P.; Jacobsen, Julius O.B.; Keith, Dan; Laraway, Bryan; Lewis, Suzanna E.; NguyenXuan, Jeremy; Shefchek, Kent; Vasilevsky, Nicole; Yuan, Zhou; Washington, Nicole; Hochheiser, Harry; Groza, Tudor; Smedley, Damian; Robinson, Peter N.; Haendel, Melissa A.",The Monarch Initiative: an integrative data and analytic platform connecting phenotypes to genotypes across species,2017,Nucleic Acids Research,,"The correlation of phenotypic outcomes with genetic variation and environmental factors is a core pursuit in biology and biomedicine. Numerous challenges impede our progress: patient phenotypes may not match known diseases, candidate variants may be in genes that have not been characterized, model organisms may not recapitulate human or veterinary diseases, filling evolutionary gaps is difficult, and many resources must be queried to find potentially significant genotype–phenotype associations. Non-human organisms have proven instrumental in revealing biological mechanisms. Advanced informatics tools can identify phenotypically relevant disease models in research and diagnostic contexts. Large-scale integration of model organism and clinical research data can provide a breadth of knowledge not available from individual sources and can provide contextualization of data back to these sources. The Monarch Initiative (monarchinitiative.org) is a collaborative, open science effort that aims to semantically integrate genotype–phenotype data from many species and sources in order to support precision medicine, disease modeling, and mechanistic exploration. Our integrated knowledge graph, analytic tools, and web services enable diverse users to explore relationships between phenotypes and genotypes across species.",2017-01-04,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:37:08,D712-D722,Database issue,45,Nucleic Acids Res,The Monarch Initiative,PubMed Central,PMID: 27899636 PMCID: PMC5210586,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5210586/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
271,10.1093/nar/gkw1226,28007941,PMC5388403,A,Neo4j,Neo4j,"Woodruff, Lauren B. A.; Gorochowski, Thomas E.; Roehner, Nicholas; Mikkelsen, Tarjei S.; Densmore, Douglas; Gordon, D. Benjamin; Nicol, Robert; Voigt, Christopher A.",Registry in a tube: multiplexed pools of retrievable parts for genetic design space exploration,2017,Nucleic Acids Research,,"Genetic designs can consist of dozens of genes and hundreds of genetic parts. After evaluating a design, it is desirable to implement changes without the cost and burden of starting the construction process from scratch. Here, we report a two-step process where a large design space is divided into deep pools of composite parts, from which individuals are retrieved and assembled to build a final construct. The pools are built via multiplexed assembly and sequenced using next-generation sequencing. Each pool consists of ∼20 Mb of up to 5000 unique and sequence-verified composite parts that are barcoded for retrieval by PCR. This approach is applied to a 16-gene nitrogen fixation pathway, which is broken into pools containing a total of 55 848 composite parts (71.0 Mb). The pools encompass an enormous design space (1043 possible 23 kb constructs), from which an algorithm-guided 192-member 4.5 Mb library is built. Next, all 1030 possible genetic circuits based on 10 repressors (NOR/NOT gates) are encoded in pools where each repressor is fused to all permutations of input promoters. These demonstrate that multiplexing can be applied to encompass entire design spaces from which individuals can be accessed and evaluated.",2017-02-17,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:37:08,1553-1565,3,45,Nucleic Acids Res,Registry in a tube,PubMed Central,PMID: 28007941 PMCID: PMC5388403,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5388403/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
272,10.1093/nar/gkx1132,29145629,PMC5753187,A,Neo4j,Neo4j,"Fabregat, Antonio; Jupe, Steven; Matthews, Lisa; Sidiropoulos, Konstantinos; Gillespie, Marc; Garapati, Phani; Haw, Robin; Jassal, Bijay; Korninger, Florian; May, Bruce; Milacic, Marija; Roca, Corina Duenas; Rothfels, Karen; Sevilla, Cristoffer; Shamovsky, Veronica; Shorser, Solomon; Varusai, Thawfeek; Viteri, Guilherme; Weiser, Joel; Wu, Guanming; Stein, Lincoln; Hermjakob, Henning; D'Eustachio, Peter; Fabregat, Antonio; Jupe, Steven; Matthews, Lisa; Sidiropoulos, Konstantinos; Gillespie, Marc; Garapati, Phani; Haw, Robin; Jassal, Bijay; Korninger, Florian; May, Bruce; Milacic, Marija; Roca, Corina Duenas; Rothfels, Karen; Sevilla, Cristoffer; Shamovsky, Veronica; Shorser, Solomon; Varusai, Thawfeek; Viteri, Guilherme; Weiser, Joel; Wu, Guanming; Stein, Lincoln; Hermjakob, Henning; D’Eustachio, Peter",The Reactome Pathway Knowledgebase,2018,Nucleic Acids Research,,"The Reactome Knowledgebase (https://reactome.org) provides molecular details of signal transduction, transport, DNA replication, metabolism, and other cellular processes as an ordered network of molecular transformations—an extended version of a classic metabolic map, in a single consistent data model. Reactome functions both as an archive of biological processes and as a tool for discovering unexpected functional relationships in data such as gene expression profiles or somatic mutation catalogues from tumor cells. To support the continued brisk growth in the size and complexity of Reactome, we have implemented a graph database, improved performance of data analysis tools, and designed new data structures and strategies to boost diagram viewer performance. To make our website more accessible to human users, we have improved pathway display and navigation by implementing interactive Enhanced High Level Diagrams (EHLDs) with an associated icon library, and subpathway highlighting and zooming, in a simplified and reorganized web site with adaptive design. To encourage re-use of our content, we have enabled export of pathway diagrams as ‘PowerPoint’ files.; The Reactome Knowledgebase (https://reactome.org) provides molecular details of signal transduction, transport, DNA replication, metabolism, and other cellular processes as an ordered network of molecular transformations-an extended version of a classic metabolic map, in a single consistent data model. Reactome functions both as an archive of biological processes and as a tool for discovering unexpected functional relationships in data such as gene expression profiles or somatic mutation catalogues from tumor cells. To support the continued brisk growth in the size and complexity of Reactome, we have implemented a graph database, improved performance of data analysis tools, and designed new data structures and strategies to boost diagram viewer performance. To make our website more accessible to human users, we have improved pathway display and navigation by implementing interactive Enhanced High Level Diagrams (EHLDs) with an associated icon library, and subpathway highlighting and zooming, in a simplified and reorganized web site with adaptive design. To encourage re-use of our content, we have enabled export of pathway diagrams as 'PowerPoint' files.",2018-01-04,2021-06-05 20:55:40; 2021-06-05 21:06:22; 2021-06-05 21:11:16; 2021-06-05 20:36:32,D649-D655,Database issue; D1,46,Nucleic Acids Res,,PubMed; PubMed Central,PMID: 29145629 PMCID: PMC5753187,http://www.ncbi.nlm.nih.gov/pubmed/29145629; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5753187/,"Computer Graphics; Databases, Chemical; Databases, Protein; Humans; Internet; Knowledge Bases; Metabolic Networks and Pathways; Molecular Sequence Annotation; Signal Transduction; User-Computer Interface",Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PubMed:Query2; PMC:Query2
273,10.1093/nar/gkx237,28383659,PMC5570157,A,Neo4j,Neo4j,"Nightingale, Andrew; Antunes, Ricardo; Alpi, Emanuele; Bursteinas, Borisas; Gonzales, Leonardo; Liu, Wudong; Luo, Jie; Qi, Guoying; Turner, Edd; Martin, Maria",The Proteins API: accessing key integrated protein and genome information,2017,Nucleic Acids Research,,"The Proteins API provides searching and programmatic access to protein and associated genomics data such as curated protein sequence positional annotations from UniProtKB, as well as mapped variation and proteomics data from large scale data sources (LSS). Using the coordinates service, researchers are able to retrieve the genomic sequence coordinates for proteins in UniProtKB. This, the LSS genomics and proteomics data for UniProt proteins is programmatically only available through this service. A Swagger UI has been implemented to provide documentation, an interface for users, with little or no programming experience, to ‘talk’ to the services to quickly and easily formulate queries with the services and obtain dynamically generated source code for popular programming languages, such as Java, Perl, Python and Ruby. Search results are returned as standard JSON, XML or GFF data objects. The Proteins API is a scalable, reliable, fast, easy to use RESTful services that provides a broad protein information resource for users to ask questions based upon their field of expertise and allowing them to gain an integrated overview of protein annotations available to aid their knowledge gain on proteins in biological processes. The Proteins API is available at (http://www.ebi.ac.uk/proteins/api/doc).",2017-07-03,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:36:32,W539-W544,Web Server issue,45,Nucleic Acids Res,The Proteins API,PubMed Central,PMID: 28383659 PMCID: PMC5570157,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5570157/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
274,10.1093/nar/gkx807,28981707,PMC5753345,A,Neo4j,Neo4j,"Brenes, Alejandro; Afzal, Vackar; Kent, Robert; Lamond, Angus I",The Encyclopedia of Proteome Dynamics: a big data ecosystem for (prote)omics,2018,Nucleic Acids Research,,"Driven by improvements in speed and resolution of mass spectrometers (MS), the field of proteomics, which involves the large-scale detection and analysis of proteins in cells, tissues and organisms, continues to expand in scale and complexity. There is a resulting growth in datasets of both raw MS files and processed peptide and protein identifications. MS-based proteomics technology is also used increasingly to measure additional protein properties affecting cellular function and disease mechanisms, including post-translational modifications, protein–protein interactions, subcellular and tissue distributions. Consequently, biologists and clinicians need innovative tools to conveniently analyse, visualize and explore such large, complex proteomics data and to integrate it with genomics and other related large-scale datasets. We have created the Encyclopedia of Proteome Dynamics (EPD) to meet this need (https://peptracker.com/epd/). The EPD combines a polyglot persistent database and web-application that provides open access to integrated proteomics data for >30 000 proteins from published studies on human cells and model organisms. It is designed to provide a user-friendly interface, featuring graphical navigation with interactive visualizations that facilitate powerful data exploration in an intuitive manner. The EPD offers a flexible and scalable ecosystem to integrate proteomics data with genomics information, RNA expression and other related, large-scale datasets.",2018-01-04,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:36:32,D1202-D1209,Database issue,46,Nucleic Acids Res,The Encyclopedia of Proteome Dynamics,PubMed Central,PMID: 28981707 PMCID: PMC5753345,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5753345/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
275,10.1093/nar/gkx918,29040751,PMC5753195,A,Neo4j,Neo4j,"Mao, Fengbiao; Liu, Qi; Zhao, Xiaolu; Yang, Haonan; Guo, Sen; Xiao, Luoyuan; Li, Xianfeng; Teng, Huajing; Sun, Zhongsheng; Dou, Yali",EpiDenovo: a platform for linking regulatory de novo mutations to developmental epigenetics and diseases,2018,Nucleic Acids Research,,"De novo mutations (DNMs) have been shown to be a major cause of severe early-onset genetic disorders such as autism spectrum disorder and intellectual disability. Over one million DNMs have been identified in developmental disorders by next generation sequencing, but linking these DNMs to the genes that they impact remains a challenge, as the majority of them are embedded in non-coding regions. As most developmental diseases occur in the early stages of development or during childhood, it is crucial to clarify the details of epigenetic regulation in early development in order to interpret the mechanisms underlying developmental disorders. Here, we develop EpiDenovo, a database that is freely available at http://www.epidenovo.biols.ac.cn/, and which provides the associations between embryonic epigenomes and DNMs in developmental disorders, including several neuropsychiatric disorders and congenital heart disease. EpiDenovo provides an easy-to-use web interface allowing users rapidly to find the epigenetic signatures of DNMs and the expression patterns of the genes that they regulate during embryonic development. In summary, EpiDenovo is a useful resource for selecting candidate genes for further functional studies in embryonic development, and for investigating regulatory DNMs as well as other genetic variants causing or underlying developmental disorders.",2018-01-04,2021-06-05 20:55:40; 2021-06-05 21:11:16; 2021-06-05 20:36:32,D92-D99,Database issue,46,Nucleic Acids Res,EpiDenovo,PubMed Central,PMID: 29040751 PMCID: PMC5753195,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5753195/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
276,10.1093/nar/gkx930,29040688,PMC5753264,A,Neo4j,Neo4j,"Gupta, Surya; Turan, Demet; Tavernier, Jan; Martens, Lennart",The online Tabloid Proteome: an annotated database of protein associations,2018,Nucleic Acids Research,,"A complete knowledge of the proteome can only be attained by determining the associations between proteins, along with the nature of these associations (e.g. physical contact in protein–protein interactions, participation in complex formation or different roles in the same pathway). Despite extensive efforts in elucidating direct protein interactions, our knowledge on the complete spectrum of protein associations remains limited. We therefore developed a new approach that detects protein associations from identifications obtained after re-processing of large-scale, public mass spectrometry-based proteomics data. Our approach infers protein association based on the co-occurrence of proteins across many different proteomics experiments, and provides information that is almost completely complementary to traditional direct protein interaction studies. We here present a web interface to query and explore the associations derived from this method, called the online Tabloid Proteome. The online Tabloid Proteome also integrates biological knowledge from several existing resources to annotate our derived protein associations. The online Tabloid Proteome is freely available through a user-friendly web interface, which provides intuitive navigation and data exploration options for the user at http://iomics.ugent.be/tabloidproteome.",2018-01-04,2021-06-05 20:55:40; 2021-06-05 21:11:16; 2021-06-05 20:36:32,D581-D585,Database issue,46,Nucleic Acids Res,The online Tabloid Proteome,PubMed Central,PMID: 29040688 PMCID: PMC5753264,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5753264/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
277,10.1093/nar/gky136,29529268,PMC5887897,A,Neo4j,Neo4j,"Wagner, Justin; Chelaru, Florin; Kancherla, Jayaram; Paulson, Joseph N; Zhang, Alexander; Felix, Victor; Mahurkar, Anup; Elmqvist, Niklas; Corrada Bravo, Héctor",Metaviz: interactive statistical and visual analysis of metagenomic data,2018,Nucleic Acids Research,,"Large studies profiling microbial communities and their association with healthy or disease phenotypes are now commonplace. Processed data from many of these studies are publicly available but significant effort is required for users to effectively organize, explore and integrate it, limiting the utility of these rich data resources. Effective integrative and interactive visual and statistical tools to analyze many metagenomic samples can greatly increase the value of these data for researchers. We present Metaviz, a tool for interactive exploratory data analysis of annotated microbiome taxonomic community profiles derived from marker gene or whole metagenome shotgun sequencing. Metaviz is uniquely designed to address the challenge of browsing the hierarchical structure of metagenomic data features while rendering visualizations of data values that are dynamically updated in response to user navigation. We use Metaviz to provide the UMD Metagenome Browser web service, allowing users to browse and explore data for more than 7000 microbiomes from published studies. Users can also deploy Metaviz as a web service, or use it to analyze data through the metavizr package to interoperate with state-of-the-art analysis tools available through Bioconductor. Metaviz is free and open source with the code, documentation and tutorials publicly accessible.",2018-04-06,2021-06-05 20:55:40; 2021-06-05 21:11:16; 2021-06-05 20:36:32,2777-2787,6,46,Nucleic Acids Res,Metaviz,PubMed Central,PMID: 29529268 PMCID: PMC5887897,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5887897/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
278,10.1093/nar/gky984,30535239,PMC6323912,A,Neo4j,Neo4j,"Conte, Nathalie; Mason, Jeremy C; Halmagyi, Csaba; Neuhauser, Steven; Mosaku, Abayomi; Yordanova, Galabina; Chatzipli, Aikaterini; Begley, Dale A; Krupke, Debra M; Parkinson, Helen; Meehan, Terrence F; Bult, Carol C",PDX Finder: A portal for patient-derived tumor xenograft model discovery,2019,Nucleic Acids Research,,"Patient-derived tumor xenograft (PDX) mouse models are a versatile oncology research platform for studying tumor biology and for testing chemotherapeutic approaches tailored to genomic characteristics of individual patients’ tumors. PDX models are generated and distributed by a diverse group of academic labs, multi-institution consortia and contract research organizations. The distributed nature of PDX repositories and the use of different metadata standards for describing model characteristics presents a significant challenge to identifying PDX models relevant to specific cancer research questions. The Jackson Laboratory and EMBL-EBI are addressing these challenges by co-developing PDX Finder, a comprehensive open global catalog of PDX models and their associated datasets. Within PDX Finder, model attributes are harmonized and integrated using a previously developed community minimal information standard to support consistent searching across the originating resources. Links to repositories are provided from the PDX Finder search results to facilitate model acquisition and/or collaboration. The PDX Finder resource currently contains information for 1985 PDX models of diverse cancers including those from large resources such as the Patient-Derived Models Repository, PDXNet and EurOPDX. Individuals or organizations that generate and distribute PDXs are invited to increase the ‘findability’ of their models by participating in the PDX Finder initiative at www.pdxfinder.org.",2019-01-08,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,D1073-D1079,Database issue,47,Nucleic Acids Res,PDX Finder,PubMed Central,PMID: 30535239 PMCID: PMC6323912,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6323912/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
279,10.1093/nar/gkz813,31552413,PMC6943066,A,Neo4j,Neo4j,,Alliance of Genome Resources Portal: unified model organism research platform,2020,Nucleic Acids Research,,"The Alliance of Genome Resources (Alliance) is a consortium of the major model organism databases and the Gene Ontology that is guided by the vision of facilitating exploration of related genes in human and well-studied model organisms by providing a highly integrated and comprehensive platform that enables researchers to leverage the extensive body of genetic and genomic studies in these organisms. Initiated in 2016, the Alliance is building a central portal (www.alliancegenome.org) for access to data for the primary model organisms along with gene ontology data and human data. All data types represented in the Alliance portal (e.g. genomic data and phenotype descriptions) have common data models and workflows for curation. All data are open and freely available via a variety of mechanisms. Long-term plans for the Alliance project include a focus on coverage of additional model organisms including those without dedicated curation communities, and the inclusion of new data types with a particular focus on providing data and tools for the non-model-organism researcher that support enhanced discovery about human health and disease. Here we review current progress and present immediate plans for this new bioinformatics resource.",2020-01-08,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,D650-D658,D1,48,Nucleic Acids Res,Alliance of Genome Resources Portal,PubMed Central,PMID: 31552413 PMCID: PMC6943066,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6943066/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
280,10.1093/nar/gkz853,31584092,PMC6943075,A,Neo4j,Neo4j,,PDBe-KB: a community-driven resource for structural and functional annotations,2020,Nucleic Acids Research,,"The Protein Data Bank in Europe-Knowledge Base (PDBe-KB, https://pdbe-kb.org) is a community-driven, collaborative resource for literature-derived, manually curated and computationally predicted structural and functional annotations of macromolecular structure data, contained in the Protein Data Bank (PDB). The goal of PDBe-KB is two-fold: (i) to increase the visibility and reduce the fragmentation of annotations contributed by specialist data resources, and to make these data more findable, accessible, interoperable and reusable (FAIR) and (ii) to place macromolecular structure data in their biological context, thus facilitating their use by the broader scientific community in fundamental and applied research. Here, we describe the guidelines of this collaborative effort, the current status of contributed data, and the PDBe-KB infrastructure, which includes the data exchange format, the deposition system for added value annotations, the distributable database containing the assembled data, and programmatic access endpoints. We also describe a series of novel web-pages—the PDBe-KB aggregated views of structure data—which combine information on macromolecular structures from many PDB entries. We have recently released the first set of pages in this series, which provide an overview of available structural and functional information for a protein of interest, referenced by a UniProtKB accession.",2020-01-08,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,D344-D353,D1,48,Nucleic Acids Res,PDBe-KB,PubMed Central,PMID: 31584092 PMCID: PMC6943075,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6943075/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
281,10.1093/nar/gkz869,31598718,PMC6943056,A,Neo4j,Neo4j,"Rahman, Raza-Ur; Liebhoff, Anna-Maria; Bansal, Vikas; Fiosins, Maksims; Rajput, Ashish; Sattar, Abdul; Magruder, Daniel S; Madan, Sumit; Sun, Ting; Gautam, Abhivyakti; Heins, Sven; Liwinski, Timur; Bethune, Jörn; Trenkwalder, Claudia; Fluck, Juliane; Mollenhauer, Brit; Bonn, Stefan",SEAweb: the small RNA Expression Atlas web application,2020,Nucleic Acids Research,,"We present the Small RNA Expression Atlas (SEAweb), a web application that allows for the interactive querying, visualization and analysis of known and novel small RNAs across 10 organisms. It contains sRNA and pathogen expression information for over 4200 published samples with standardized search terms and ontologies. In addition, SEAweb allows for the interactive visualization and re-analysis of 879 differential expression and 514 classification comparisons. SEAweb's user model enables sRNA researchers to compare and re-analyze user-specific and published datasets, highlighting common and distinct sRNA expression patterns. We provide evidence for SEAweb's fidelity by (i) generating a set of 591 tissue specific miRNAs across 29 tissues, (ii) finding known and novel bacterial and viral infections across diseases and (iii) determining a Parkinson's disease-specific blood biomarker signature using novel data. We believe that SEAweb's simple semantic search interface, the flexible interactive reports and the user model with rich analysis capabilities will enable researchers to better understand the potential function and diagnostic value of sRNAs or pathogens across tissues, diseases and organisms.",2020-01-08,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,D204-D219,D1,48,Nucleic Acids Res,SEAweb,PubMed Central,PMID: 31598718 PMCID: PMC6943056,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6943056/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
282,10.1093/nar/gkz895,31612961,PMC7145571,A,Neo4j,Neo4j,"Beck, Tim; Shorter, Tom; Brookes, Anthony J",GWAS Central: a comprehensive resource for the discovery and comparison of genotype and phenotype data from genome-wide association studies,2020,Nucleic Acids Research,,"The GWAS Central resource provides a toolkit for integrative access and visualization of a uniquely extensive collection of genome-wide association study data, while ensuring safe open access to prevent research participant identification. GWAS Central is the world's most comprehensive openly accessible repository of summary-level GWAS association information, providing over 70 million P-values for over 3800 studies investigating over 1400 unique phenotypes. The database content comprises direct submissions received from GWAS authors and consortia, in addition to actively gathered data sets from various public sources. GWAS data are discoverable from the perspective of genetic markers, genes, genome regions or phenotypes, via graphical visualizations and detailed downloadable data reports. Tested genetic markers and relevant genomic features can be visually interrogated across up to sixteen multiple association data sets in a single view using the integrated genome browser. The semantic standardization of phenotype descriptions with Medical Subject Headings and the Human Phenotype Ontology allows the precise identification of genetic variants associated with diseases, phenotypes and traits of interest. Harmonization of the phenotype descriptions used across several GWAS-related resources has extended the phenotype search capabilities to enable cross-database study discovery using a range of ontologies. GWAS Central is updated regularly and available at https://www.gwascentral.org.",2020-01-08,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,D933-D940,D1,48,Nucleic Acids Res,GWAS Central,PubMed Central,PMID: 31612961 PMCID: PMC7145571,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7145571/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
283,10.1093/nar/gkz904,31733065,PMC7145647,,,,"Urban, Martin; Cuzick, Alayne; Seager, James; Wood, Valerie; Rutherford, Kim; Venkatesh, Shilpa Yagwakote; De Silva, Nishadi; Martinez, Manuel Carbajo; Pedro, Helder; Yates, Andy D; Hassani-Pak, Keywan; Hammond-Kosack, Kim E",PHI-base: the pathogen–host interactions database,2020,Nucleic Acids Research,,"The pathogen–host interactions database (PHI-base) is available at www.phi-base.org. PHI-base contains expertly curated molecular and biological information on genes proven to affect the outcome of pathogen–host interactions reported in peer reviewed research articles. PHI-base also curates literature describing specific gene alterations that did not affect the disease interaction phenotype, in order to provide complete datasets for comparative purposes. Viruses are not included, due to their extensive coverage in other databases. In this article, we describe the increased data content of PHI-base, plus new database features and further integration with complementary databases. The release of PHI-base version 4.8 (September 2019) contains 3454 manually curated references, and provides information on 6780 genes from 268 pathogens, tested on 210 hosts in 13,801 interactions. Prokaryotic and eukaryotic pathogens are represented in almost equal numbers. Host species consist of approximately 60% plants (split 50:50 between cereal and non-cereal plants), and 40% other species of medical and/or environmental importance. The information available on pathogen effectors has risen by more than a third, and the entries for pathogens that infect crop species of global importance has dramatically increased in this release. We also briefly describe the future direction of the PHI-base project, and some existing problems with the PHI-base curation process.",2020-01-08,2021-06-05 21:10:37,D613-D620,D1,48,Nucleic Acids Res,PHI-base,PubMed Central,PMID: 31733065 PMCID: PMC7145647,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7145647/,,,,PMC:Query2
284,10.1093/nar/gkz996,31680153,PMC7145600,A,Neo4j,Neo4j,"Naithani, Sushma; Gupta, Parul; Preece, Justin; D’Eustachio, Peter; Elser, Justin L; Garg, Priyanka; Dikeman, Daemon A; Kiff, Jason; Cook, Justin; Olson, Andrew; Wei, Sharon; Tello-Ruiz, Marcela K; Mundo, Antonio Fabregat; Munoz-Pomer, Alfonso; Mohammed, Suhaib; Cheng, Tiejun; Bolton, Evan; Papatheodorou, Irene; Stein, Lincoln; Ware, Doreen; Jaiswal, Pankaj",Plant Reactome: a knowledgebase and resource for comparative pathway analysis,2020,Nucleic Acids Research,,"Plant Reactome (https://plantreactome.gramene.org) is an open-source, comparative plant pathway knowledgebase of the Gramene project. It uses Oryza sativa (rice) as a reference species for manual curation of pathways and extends pathway knowledge to another 82 plant species via gene-orthology projection using the Reactome data model and framework. It currently hosts 298 reference pathways, including metabolic and transport pathways, transcriptional networks, hormone signaling pathways, and plant developmental processes. In addition to browsing plant pathways, users can upload and analyze their omics data, such as the gene-expression data, and overlay curated or experimental gene-gene interaction data to extend pathway knowledge. The curation team actively engages researchers and students on gene and pathway curation by offering workshops and online tutorials. The Plant Reactome supports, implements and collaborates with the wider community to make data and tools related to genes, genomes, and pathways Findable, Accessible, Interoperable and Re-usable (FAIR).",2020-01-08,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,D1093-D1103,D1,48,Nucleic Acids Res,Plant Reactome,PubMed Central,PMID: 31680153 PMCID: PMC7145600,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7145600/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
285,10.1093/nar/gkz997,31701156,PMC7056945,A,Neo4j,Neo4j,"Shefchek, Kent A; Harris, Nomi L; Gargano, Michael; Matentzoglu, Nicolas; Unni, Deepak; Brush, Matthew; Keith, Daniel; Conlin, Tom; Vasilevsky, Nicole; Zhang, Xingmin Aaron; Balhoff, James P; Babb, Larry; Bello, Susan M; Blau, Hannah; Bradford, Yvonne; Carbon, Seth; Carmody, Leigh; Chan, Lauren E; Cipriani, Valentina; Cuzick, Alayne; Della Rocca, Maria; Dunn, Nathan; Essaid, Shahim; Fey, Petra; Grove, Chris; Gourdine, Jean-Phillipe; Hamosh, Ada; Harris, Midori; Helbig, Ingo; Hoatlin, Maureen; Joachimiak, Marcin; Jupp, Simon; Lett, Kenneth B; Lewis, Suzanna E; McNamara, Craig; Pendlington, Zoë M; Pilgrim, Clare; Putman, Tim; Ravanmehr, Vida; Reese, Justin; Riggs, Erin; Robb, Sofia; Roncaglia, Paola; Seager, James; Segerdell, Erik; Similuk, Morgan; Storm, Andrea L; Thaxon, Courtney; Thessen, Anne; Jacobsen, Julius O B; McMurry, Julie A; Groza, Tudor; Köhler, Sebastian; Smedley, Damian; Robinson, Peter N; Mungall, Christopher J; Haendel, Melissa A; Munoz-Torres, Monica C; Osumi-Sutherland, David",The Monarch Initiative in 2019: an integrative data and analytic platform connecting phenotypes to genotypes across species,2020,Nucleic Acids Research,,"In biology and biomedicine, relating phenotypic outcomes with genetic variation and environmental factors remains a challenge: patient phenotypes may not match known diseases, candidate variants may be in genes that haven’t been characterized, research organisms may not recapitulate human or veterinary diseases, environmental factors affecting disease outcomes are unknown or undocumented, and many resources must be queried to find potentially significant phenotypic associations. The Monarch Initiative (https://monarchinitiative.org) integrates information on genes, variants, genotypes, phenotypes and diseases in a variety of species, and allows powerful ontology-based search. We develop many widely adopted ontologies that together enable sophisticated computational analysis, mechanistic discovery and diagnostics of Mendelian diseases. Our algorithms and tools are widely used to identify animal models of human disease through phenotypic similarity, for differential diagnostics and to facilitate translational research. Launched in 2015, Monarch has grown with regards to data (new organisms, more sources, better modeling); new API and standards; ontologies (new Mondo unified disease ontology, improvements to ontologies such as HPO and uPheno); user interface (a redesigned website); and community development. Monarch data, algorithms and tools are being used and extended by resources such as GA4GH and NCATS Translator, among others, to aid mechanistic discovery and diagnostics.",2020-01-08,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,D704-D715,D1,48,Nucleic Acids Res,The Monarch Initiative in 2019,PubMed Central,PMID: 31701156 PMCID: PMC7056945,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7056945/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
286,10.1093/pcp/pcv200,26657893,PMC4722177,A,Neo4j,Neo4j,"Dai, Xinbin; Li, Jun; Liu, Tingsong; Zhao, Patrick Xuechun","HRGRN: A Graph Search-Empowered Integrative Database of Arabidopsis Signaling Transduction, Metabolism and Gene Regulation Networks",2016,Plant and Cell Physiology; Plant & Cell Physiology,,"The biological networks controlling plant signal transduction, metabolism and gene regulation are composed of not only tens of thousands of genes, compounds, proteins and RNAs but also the complicated interactions and co-ordination among them. These networks play critical roles in many fundamental mechanisms, such as plant growth, development and environmental response. Although much is known about these complex interactions, the knowledge and data are currently scattered throughout the published literature, publicly available high-throughput data sets and third-party databases. Many ‘unknown’ yet important interactions among genes need to be mined and established through extensive computational analysis. However, exploring these complex biological interactions at the network level from existing heterogeneous resources remains challenging and time-consuming for biologists. Here, we introduce HRGRN, a graph search-empowered integrative database of Arabidopsis signal transduction, metabolism and gene regulatory networks. HRGRN utilizes Neo4j, which is a highly scalable graph database management system, to host large-scale biological interactions among genes, proteins, compounds and small RNAs that were either validated experimentally or predicted computationally. The associated biological pathway information was also specially marked for the interactions that are involved in the pathway to facilitate the investigation of cross-talk between pathways. Furthermore, HRGRN integrates a series of graph path search algorithms to discover novel relationships among genes, compounds, RNAs and even pathways from heterogeneous biological interaction data that could be missed by traditional SQL database search methods. Users can also build subnetworks based on known interactions. The outcomes are visualized with rich text, figures and interactive network graphs on web pages. The HRGRN database is freely available at http://plantgrn.noble.org/hrgrn/.; The biological networks controlling plant signal transduction, metabolism and gene regulation are composed of not only tens of thousands of genes, compounds, proteins and RNAs but also the complicated interactions and co-ordination among them. These networks play critical roles in many fundamental mechanisms, such as plant growth, development and environmental response. Although much is known about these complex interactions, the knowledge and data are currently scattered throughout the published literature, publicly available high-throughput data sets and third-party databases. Many 'unknown' yet important interactions among genes need to be mined and established through extensive computational analysis. However, exploring these complex biological interactions at the network level from existing heterogeneous resources remains challenging and time-consuming for biologists. Here, we introduce HRGRN, a graph search-empowered integrative database of Arabidopsis signal transduction, metabolism and gene regulatory networks. HRGRN utilizes Neo4j, which is a highly scalable graph database management system, to host large-scale biological interactions among genes, proteins, compounds and small RNAs that were either validated experimentally or predicted computationally. The associated biological pathway information was also specially marked for the interactions that are involved in the pathway to facilitate the investigation of cross-talk between pathways. Furthermore, HRGRN integrates a series of graph path search algorithms to discover novel relationships among genes, compounds, RNAs and even pathways from heterogeneous biological interaction data that could be missed by traditional SQL database search methods. Users can also build subnetworks based on known interactions. The outcomes are visualized with rich text, figures and interactive network graphs on web pages. The HRGRN database is freely available at http://plantgrn.noble.org/hrgrn/.",2016-01,2021-06-05 21:06:22; 2021-06-05 21:12:40; 2021-06-05 21:16:51; 2021-06-05 20:37:08; 2021-06-05 20:55:40; 2021-06-05 21:24:28,e12,1,57,Plant Cell Physiol,HRGRN,PubMed; PubMed Central,PMID: 26657893 PMCID: PMC4722177,http://www.ncbi.nlm.nih.gov/pubmed/26657893; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4722177/,"Algorithms; Arabidopsis; Arabidopsis Proteins; Biological network; Databases, Genetic; Gene regulatory network; Gene Regulatory Networks; Graph database; Graph search; Internet; Metabolic pathway; Plant signal transduction; Signal Transduction; Software",Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
287,10.1093/schbul/sbaa030.483,,PMC7234452,A,Neo4j,Neo4j,"Hoon Jeong, Seong; Jung, Hee-Yeon; Won Chung, In; Sik Kim, Yong",M171. THE GENE-SHARING RELATIONSHIP OF SCHIZOPHRENIA WITH OTHER MENTAL OR SYSTEMIC DISORDERS: A DISEASE-SIMILARITY NETWORK ANALYSIS FOCUSED ON EGOCENTRIC NETWORK,2020,Schizophrenia Bulletin,,"Background Schizophrenia is an archetypal example that a psychiatric illness may not merely be a mental or a brain disorder but rather a systemic illness. It can be glimpsed from a wide range of biomarkers that span all the imaginable body systems, and from higher co-morbidity with other systemic illnesses. However, quantitative analysis of schizophrenia’s relationship with other diseases are not yet satisfactory. Genome-wide association studies have identified more than hundreds of genetic loci associated with schizophrenia. In turn, these loci are associated with a wide variety of other diseases. From this gene-disease relationship, a bipartite network can be built which, after appropriate projection, could help to map a complex disease-similarity network. In case of schizophrenia, it would reveal the position of schizophrenia among the broader categories of systemic illnesses. Methods DisGeNET is a discovery platform which contains one of the largest collections of gene-disease association data. The major source of the integrated data is the automatized curation from MEDLINE abstract. Therefore, it contains the timestamp of reported gene-disease association. Gene-disease-timestamp (year of publication) triplet was fed into a Neo4J graph database platform. From this, disease-disease relationships with shared gene count and Jaccard similarity score was extracted. The network structure of level 1.5 egocentric network centered upon schizophrenia was inspected. Louvain community detection algorithm was applied to expose underlying group structure among the 1st order alters. For comparison, similar ego-networks centered upon several major psychiatric illnesses were also inspected. Finally, the yearly variation of Jaccard score which reflected the accumulation of research data were monitored. Results The diseases which showed the highest Jaccard score (j) were bipolar disorder (j=0.203) and depressive disorder (j=0.190) as expected. Other diseases with meaningful similarity could be grouped into three communities: 1) psychiatric illness including bipolar/depressive disorder, 2) a variety of malignancies including neuroblastoma (j=0.083), stomach cancer (j=0.070) and pancreatic cancer (j=0.065) 3) other systemic illnesses including multiple sclerosis (j=0.088), metabolic syndrome (j=0.076), myocardial infarction (j=0.073), rheumatoid arthritis (j=0.070), lupus erythematosus (0.056). The gene-sharing relationship with systemic illnesses (malignancies and other) began to be revealed after 2005. Since then, more and more evidences were accumulated to solidify the schizophrenia’s link with systemic illnesses. Discussion Recently, a couple of large-scale epidemiological studies verified the significant correlation between prevalence of schizophrenia and cancer/autoimmune disorders. The present study results may augment these epidemiological data and thus strongly support the concept of schizophrenia as a systemic illness. Gene-sharing and its reflection in prevalence data would indicate deeper link at the level of pathogenesis with systemic illnesses. Recently, many authors contemplated the possible link between schizophrenia and cancer in terms of cell cycle regulation and control of apoptosis. Likewise, others suspected immunological disturbance as the fundamental mechanism of schizophrenia. In this vein, the need for extending the concept of mental disorders as a focused manifestation of systemic illness seems gaining impetus.",2020-05,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,S201-S202,Suppl 1,46,Schizophr Bull,M171. THE GENE-SHARING RELATIONSHIP OF SCHIZOPHRENIA WITH OTHER MENTAL OR SYSTEMIC DISORDERS,PubMed Central,PMID:  PMCID: PMC7234452,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7234452/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
288,10.1093/toxsci/kfaa025,32096866,PMC7261145,,,,"Wolffe, Taylor A M; Vidler, John; Halsall, Crispin; Hunt, Neil; Whaley, Paul",A Survey of Systematic Evidence Mapping Practice and the Case for Knowledge Graphs in Environmental Health and Toxicology,2020,Toxicological Sciences,,"Systematic evidence mapping offers a robust and transparent methodology for facilitating evidence-based approaches to decision-making in chemicals policy and wider environmental health (EH). Interest in the methodology is growing; however, its application in EH is still novel. To facilitate the production of effective systematic evidence maps for EH use cases, we survey the successful application of evidence mapping in other fields where the methodology is more established. Focusing on issues of “data storage technology,” “data integrity,” “data accessibility,” and “transparency,” we characterize current evidence mapping practice and critically review its potential value for EH contexts. We note that rigid, flat data tables and schema-first approaches dominate current mapping methods and highlight how this practice is ill-suited to the highly connected, heterogeneous, and complex nature of EH data. We propose this challenge is overcome by storing and structuring data as “knowledge graphs.” Knowledge graphs offer a flexible, schemaless, and scalable model for systematically mapping the EH literature. Associated technologies, such as ontologies, are well-suited to the long-term goals of systematic mapping methodology in promoting resource-efficient access to the wider EH evidence base. Several graph storage implementations are readily available, with a variety of proven use cases in other fields. Thus, developing and adapting systematic evidence mapping for EH should utilize these graph-based resources to ensure the production of scalable, interoperable, and robust maps to aid decision-making processes in chemicals policy and wider EH.",2020-05,2021-06-05 21:10:08,35-49,1,175,Toxicol Sci,,PubMed Central,PMID: 32096866 PMCID: PMC7261145,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7261145/,,,,PMC:Query2
289,10.1098/rsif.2018.0174,30045889,PMC6073642,,,,"Kandula, Sasikiran; Yamana, Teresa; Pei, Sen; Yang, Wan; Morita, Haruka; Shaman, Jeffrey",Evaluation of mechanistic and statistical methods in forecasting influenza-like illness,2018,Journal of the Royal Society Interface,,"A variety of mechanistic and statistical methods to forecast seasonal influenza have been proposed and are in use; however, the effects of various data issues and design choices (statistical versus mechanistic methods, for example) on the accuracy of these approaches have not been thoroughly assessed. Here, we compare the accuracy of three forecasting approaches—a mechanistic method, a weighted average of two statistical methods and a super-ensemble of eight statistical and mechanistic models—in predicting seven outbreak characteristics of seasonal influenza during the 2016–2017 season at the national and 10 regional levels in the USA. For each of these approaches, we report the effects of real time under- and over-reporting in surveillance systems, use of non-surveillance proxies of influenza activity and manual override of model predictions on forecast quality. Our results suggest that a meta-ensemble of statistical and mechanistic methods has better overall accuracy than the individual methods. Supplementing surveillance data with proxy estimates generally improves the quality of forecasts and transient reporting errors degrade the performance of all three approaches considerably. The improvement in quality from ad hoc and post-forecast changes suggests that domain experts continue to possess information that is not being sufficiently captured by current forecasting approaches.",2018-07,2021-06-05 21:11:16,,144,15,J R Soc Interface,,PubMed Central,PMID: 30045889 PMCID: PMC6073642,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6073642/,,,,PMC:Query2
290,10.1098/rsos.180298,30225017,PMC6124103,A,Neo4j,Neo4j,"McGinn, D.; McIlwraith, D.; Guo, Y.",Towards open data blockchain analytics: a Bitcoin perspective,2018,Royal Society Open Science,,"Bitcoin is the first implementation of a technology that has become known as a ‘public permissionless’ blockchain. Such systems allow public read/write access to an append-only blockchain database without the need for any mediating central authority. Instead, they guarantee access, security and protocol conformity through an elegant combination of cryptographic assurances and game theoretic economic incentives. Not until the advent of the Bitcoin blockchain has such a trusted, transparent, comprehensive and granular dataset of digital economic behaviours been available for public network analysis. In this article, by translating the cumbersome binary data structure of the Bitcoin blockchain into a high fidelity graph model, we demonstrate through various analyses the often overlooked social and econometric benefits of employing such a novel open data architecture. Specifically, we show: (i) how repeated patterns of transaction behaviours can be revealed to link user activity across the blockchain; (ii) how newly mined bitcoin can be associated to demonstrate individual accumulations of wealth; (iii) through application of the naïve quantity theory of money that Bitcoin's disinflationary properties can be revealed and measured; and (iv) how the user community can develop coordinated defences against repeated denial of service attacks on the network. Such public analyses of this open data are exemplary benefits unavailable to the closed data models of the ‘private permissioned’ distributed ledger architectures currently dominating enterprise-level blockchain development owing to existing issues of scalability, confidentiality and governance.; Bitcoin is the first implementation of a technology that has become known as a 'public permissionless' blockchain. Such systems allow public read/write access to an append-only blockchain database without the need for any mediating central authority. Instead, they guarantee access, security and protocol conformity through an elegant combination of cryptographic assurances and game theoretic economic incentives. Not until the advent of the Bitcoin blockchain has such a trusted, transparent, comprehensive and granular dataset of digital economic behaviours been available for public network analysis. In this article, by translating the cumbersome binary data structure of the Bitcoin blockchain into a high fidelity graph model, we demonstrate through various analyses the often overlooked social and econometric benefits of employing such a novel open data architecture. Specifically, we show: (i) how repeated patterns of transaction behaviours can be revealed to link user activity across the blockchain; (ii) how newly mined bitcoin can be associated to demonstrate individual accumulations of wealth; (iii) through application of the naïve quantity theory of money that Bitcoin's disinflationary properties can be revealed and measured; and (iv) how the user community can develop coordinated defences against repeated denial of service attacks on the network. Such public analyses of this open data are exemplary benefits unavailable to the closed data models of the 'private permissioned' distributed ledger architectures currently dominating enterprise-level blockchain development owing to existing issues of scalability, confidentiality and governance.",2018-08-08; 2018-08,2021-06-05 20:55:01; 2021-06-05 21:06:22; 2021-06-05 21:11:16; 2021-06-05 20:36:32,180298,8,5,R Soc Open Sci,Towards open data blockchain analytics,PubMed; PubMed Central,PMID: 30225017 PMCID: PMC6124103,http://www.ncbi.nlm.nih.gov/pubmed/30225017; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6124103/,bitcoin; blockchain; data mining; graph database; knowledge discovery; open data,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PubMed:Query2; PMC:Query2
291,10.1098/rstb.2014.0009,25561670,PMC4290423,A,Fauna,Fauna,"Owen, Christopher L.; Bracken-Grissom, Heather; Stern, David; Crandall, Keith A.",A synthetic phylogeny of freshwater crayfish: insights for conservation,2015,Philosophical Transactions of the Royal Society B: Biological Sciences,,"Phylogenetic systematics is heading for a renaissance where we shift from considering our phylogenetic estimates as a static image in a published paper and taxonomies as a hardcopy checklist to treating both the phylogenetic estimate and dynamic taxonomies as metadata for further analyses. The Open Tree of Life project (opentreeoflife.org) is developing synthesis tools for harnessing the power of phylogenetic inference and robust taxonomy to develop a synthetic tree of life. We capitalize on this approach to estimate a synthesis tree for the freshwater crayfish. The crayfish make an exceptional group to demonstrate the utility of the synthesis approach, as there recently have been a number of phylogenetic studies on the crayfishes along with a robust underlying taxonomic framework. Importantly, the crayfish have also been extensively assessed by an IUCN Red List team and therefore have accurate and up-to-date area and conservation status data available for analysis within a phylogenetic context. Here, we develop a synthesis phylogeny for the world's freshwater crayfish and examine the phylogenetic distribution of threat. We also estimate a molecular phylogeny based on all available GenBank crayfish sequences and use this tree to estimate divergence times and test for divergence rate variation. Finally, we conduct EDGE and HEDGE analyses and identify a number of species of freshwater crayfish of highest priority in conservation efforts.",2015-02-19,2021-06-05 21:12:40; 2021-06-05 20:56:20; 2021-06-06 07:33:06,,1662,370,Philos Trans R Soc Lond B Biol Sci,A synthetic phylogeny of freshwater crayfish,PubMed Central,PMID: 25561670 PMCID: PMC4290423,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4290423/,,Fauna,Fauna,PMC:Query3; PMC:Query2; PMC:Fauna
292,10.1098/rstb.2017.0380,30201843,PMC6158222,A,Neo4j,Neo4j,"Cantarelli, Matteo; Marin, Boris; Quintana, Adrian; Earnshaw, Matt; Court, Robert; Gleeson, Padraig; Dura-Bernal, Salvador; Silver, R. Angus; Idili, Giovanni",Geppetto: a reusable modular open platform for exploring neuroscience data and models,2018,Philosophical Transactions of the Royal Society B: Biological Sciences,,"Geppetto is an open-source platform that provides generic middleware infrastructure for building both online and desktop tools for visualizing neuroscience models and data and managing simulations. Geppetto underpins a number of neuroscience applications, including Open Source Brain (OSB), Virtual Fly Brain (VFB), NEURON-UI and NetPyNE-UI. OSB is used by researchers to create and visualize computational neuroscience models described in NeuroML and simulate them through the browser. VFB is the reference hub for Drosophila melanogaster neural anatomy and imaging data including neuropil, segmented neurons, microscopy stacks and gene expression pattern data. Geppetto is also being used to build a new user interface for NEURON, a widely used neuronal simulation environment, and for NetPyNE, a Python package for network modelling using NEURON. Geppetto defines domain agnostic abstractions used by all these applications to represent their models and data and offers a set of modules and components to integrate, visualize and control simulations in a highly accessible way. The platform comprises a backend which can connect to external data sources, model repositories and simulators together with a highly customizable frontend., This article is part of a discussion meeting issue ‘Connectome to behaviour: modelling C. elegans at cellular resolution’.",2018-10-19,2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:36:32,,1758,373,Philos Trans R Soc Lond B Biol Sci,Geppetto,PubMed Central,PMID: 30201843 PMCID: PMC6158222,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6158222/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
293,10.1098/rstb.2017.0382,30201845,PMC6158220,,,,"Sarma, Gopal P.; Lee, Chee Wai; Portegys, Tom; Ghayoomie, Vahid; Jacobs, Travis; Alicea, Bradly; Cantarelli, Matteo; Currie, Michael; Gerkin, Richard C.; Gingell, Shane; Gleeson, Padraig; Gordon, Richard; Hasani, Ramin M.; Idili, Giovanni; Khayrulin, Sergey; Lung, David; Palyanov, Andrey; Watts, Mark; Larson, Stephen D.",OpenWorm: overview and recent advances in integrative biological simulation of Caenorhabditis elegans,2018,Philosophical Transactions of the Royal Society B: Biological Sciences,,"The adoption of powerful software tools and computational methods from the software industry by the scientific research community has resulted in a renewed interest in integrative, large-scale biological simulations. These typically involve the development of computational platforms to combine diverse, process-specific models into a coherent whole. The OpenWorm Foundation is an independent research organization working towards an integrative simulation of the nematode Caenorhabditis elegans, with the aim of providing a powerful new tool to understand how the organism's behaviour arises from its fundamental biology. In this perspective, we give an overview of the history and philosophy of OpenWorm, descriptions of the constituent sub-projects and corresponding open-science management practices, and discuss current achievements of the project and future directions., This article is part of a discussion meeting issue ‘Connectome to behaviour: modelling C. elegans at cellular resolution’.",2018-10-19,2021-06-05 21:11:16,,1758,373,Philos Trans R Soc Lond B Biol Sci,OpenWorm,PubMed Central,PMID: 30201845 PMCID: PMC6158220,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6158220/,,,,PMC:Query2
294,10.1099/mgen.0.000376,32496181,PMC7371104,,,,"Wang, Lu Ya Ruth; Jokinen, Cassandra C.; Laing, Chad R.; Johnson, Roger P.; Ziebell, Kim; Gannon, Victor P. J.",Assessing the genomic relatedness and evolutionary rates of persistent verotoxigenic Escherichia coli serotypes within a closed beef herd in Canada,2020,Microbial Genomics,,"Verotoxigenic  Escherichia coli  (VTEC) are food- and water-borne pathogens associated with both sporadic illness and outbreaks of enteric disease. While it is known that cattle are reservoirs of VTEC, little is known about the genomic variation of VTEC in cattle, and whether the variation in genomes reported for human outbreak strains is consistent with individual animal or group/herd sources of infection. A previous study of VTEC prevalence identified serotypes carried persistently by three consecutive cohorts of heifers within a closed herd of cattle. This present study aimed to: (i) determine whether the genomic relatedness of bovine isolates is similar to that reported for human strains associated with single source outbreaks, (ii) estimate the rates of genome change among dominant serotypes over time within a cattle herd, and (iii) identify genomic features of serotypes associated with persistence in cattle. Illumina MiSeq genome sequencing and genotyping based on allelic and single nucleotide variations were completed, while genome change over time was measured using Bayesian evolutionary analysis sampling trees. The accessory genome, including the non-protein-encoding intergenic regions (IGRs), virulence factors, antimicrobial-resistance genes and plasmid gene content of representative persistent and sporadic cattle strains were compared using Fisher’s exact test corrected for multiple comparisons. Herd strains from serotypes O6:H34 (n=22), O22:H8 (n=30), O108:H8 (n=39), O139:H19 (n=44) and O157:H7 (n=106) were readily distinguishable from epidemiologically unrelated strains of the same serotype using a similarity threshold of 10 or fewer allele differences between adjacent nodes. Temporal-cohort clustering within each serotype was supported by date randomization analysis. Substitutions per site per year were consistent with previously reported values for  E. coli ; however, there was low branch support for these values. Acquisition of the phage-encoded Shiga toxin 2 gene in serotype O22:H8 was observed. Pan-genome analyses identified accessory regions that were more prevalent in persistent serotypes (P≤0.05) than in sporadic serotypes. These results suggest that VTEC serotypes from a specific cattle population are highly clonal with a similar level of relatedness as human single-source outbreak-associated strains, but changes in the genome occur gradually over time. Additionally, elements in the accessory genomes may provide a selective advantage for persistence of VTEC within cattle herds.",2020-06-04,2021-06-05 21:10:08,,6,6,Microb Genom,,PubMed Central,PMID: 32496181 PMCID: PMC7371104,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7371104/,,,,PMC:Query2
295,10.1101/2020.08.17.254839,32839776,PMC7444288,A,Neo4j; COVID19,Neo4j; COVID19,"Reese, Justin; Unni, Deepak; Callahan, Tiffany J.; Cappelletti, Luca; Ravanmehr, Vida; Carbon, Seth; Fontana, Tommaso; Blau, Hannah; Matentzoglu, Nicolas; Harris, Nomi L.; Munoz-Torres, Monica C.; Robinson, Peter N.; Joachimiak, Marcin P.; Mungall, Christopher J.",KG-COVID-19: a framework to produce customized knowledge graphs for COVID-19 response,2020,bioRxiv,,"Integrated, up-to-date data about SARS-CoV-2 and coronavirus disease 2019 (COVID-19) is crucial for the ongoing response to the COVID-19 pandemic by the biomedical research community. While rich biological knowledge exists for SARS-CoV-2 and related viruses (SARS-CoV, MERS-CoV), integrating this knowledge is difficult and time consuming, since much of it is in siloed databases or in textual format. Furthermore, the data required by the research community varies drastically for different tasks - the optimal data for a machine learning task, for example, is much different from the data used to populate a browsable user interface for clinicians. To address these challenges, we created KG-COVID-19, a flexible framework that ingests and integrates biomedical data to produce knowledge graphs (KGs) for COVID-19 response. This KG framework can also be applied to other problems in which siloed biomedical data must be quickly integrated for different research applications, including future pandemics., An effective response to the COVID-19 pandemic relies on integration of many different types of data available about SARS-CoV-2 and related viruses. KG-COVID-19 is a framework for producing knowledge graphs that can be customized for downstream applications including machine learning tasks, hypothesis-based querying, and browsable user interface to enable researchers to explore COVID-19 data and discover relationships.",2020-08-18,2021-06-05 20:35:57; 2021-06-05 21:35:36; 2021-06-05 20:54:31; 2021-06-05 21:10:08,,,,bioRxiv,KG-COVID-19,PubMed Central,PMID: 32839776 PMCID: PMC7444288,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7444288/,,Neo4j; COVID19,Neo4j; COVID19,PMC:Query3; PMC:Neo4j; PMC:COVID19; PMC:Query2
296,10.1101/2020.11.04.369041,33173863,PMC7654851,A,Neo4j; COVID19,Neo4j; COVID19,"Zahoránszky-Kőhalmi, Gergely; Siramshetty, Vishal B.; Kumar, Praveen; Gurumurthy, Manideep; Grillo, Busola; Mathew, Biju; Metaxatos, Dimitrios; Backus, Mark; Mierzwa, Tim; Simon, Reid; Grishagin, Ivan; Brovold, Laura; Mathé, Ewy A.; Hall, Matthew D.; Michael, Samuel G.; Godfrey, Alexander G.; Mestres, Jordi; Jensen, Lars J.; Oprea, Tudor I.",A Workflow of Integrated Resources to Catalyze Network Pharmacology Driven COVID-19 Research,2020,bioRxiv: The Preprint Server for Biology; bioRxiv,,"Motivation In the event of an outbreak due to an emerging pathogen, time is of the essence to contain or to mitigate the spread of the disease. Drug repositioning is one of the strategies that has the potential to deliver therapeutics relatively quickly. The SARS-CoV-2 pandemic has shown that integrating critical data resources to drive drug-repositioning studies, involving host-host, host-pathogen and drug-target interactions, remains a time-consuming effort that translates to a delay in the development and delivery of a life-saving therapy. Results Here, we describe a workflow we designed for a semi-automated integration of rapidly emerging datasets that can be generally adopted in a broad network pharmacology research setting. The workflow was used to construct a COVID-19 focused multimodal network that integrates 487 host-pathogen, 74,805 host-host protein and 1,265 drug-target interactions. The resultant Neo4j graph database named “Neo4COVID19” is accessible via a web interface and via API calls based on the Bolt protocol. We believe that our Neo4COVID19 database will be a valuable asset to the research community and will catalyze the discovery of therapeutics to fight COVID-19. Availability             https://neo4covid19.ncats.io; Motivation: In the event of an outbreak due to an emerging pathogen, time is of the essence to contain or to mitigate the spread of the disease. Drug repositioning is one of the strategies that has the potential to deliver therapeutics relatively quickly. The SARS-CoV-2 pandemic has shown that integrating critical data resources to drive drug-repositioning studies, involving host-host, hostpathogen and drug-target interactions, remains a time-consuming effort that translates to a delay in the development and delivery of a life-saving therapy. Results: Here, we describe a workflow we designed for a semi-automated integration of rapidly emerging datasets that can be generally adopted in a broad network pharmacology research setting. The workflow was used to construct a COVID-19 focused multimodal network that integrates 487 host-pathogen, 74,805 host-host protein and 1,265 drug-target interactions. The resultant Neo4j graph database named ""Neo4COVID19"" is accessible via a web interface and via API calls based on the Bolt protocol. We believe that our Neo4COVID19 database will be a valuable asset to the research community and will catalyze the discovery of therapeutics to fight COVID-19. Availability: https://neo4covid19.ncats.io.",2020-11-05,2021-06-05 20:35:57; 2021-06-05 21:35:36; 2021-06-05 20:54:31; 2021-06-05 21:09:36; 2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 21:24:28,,,,bioRxiv,,PubMed; PubMed Central,PMID: 33173863 PMCID: PMC7654851,http://www.ncbi.nlm.nih.gov/pubmed/33173863; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7654851/,,Neo4j; COVID19,Neo4j; COVID19,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PMC:COVID19; PubMed:Query2; PubMed:Query3
297,10.1101/gr.114272.110,21460061,PMC3083093,,,,"Brosch, Markus; Saunders, Gary I.; Frankish, Adam; Collins, Mark O.; Yu, Lu; Wright, James; Verstraten, Ruth; Adams, David J.; Harrow, Jennifer; Choudhary, Jyoti S.; Hubbard, Tim","Shotgun proteomics aids discovery of novel protein-coding genes, alternative splicing, and “resurrected” pseudogenes in the mouse genome",2011,Genome Research,,"Recent advances in proteomic mass spectrometry (MS) offer the chance to marry high-throughput peptide sequencing to transcript models, allowing the validation, refinement, and identification of new protein-coding loci. We present a novel pipeline that integrates highly sensitive and statistically robust peptide spectrum matching with genome-wide protein-coding predictions to perform large-scale gene validation and discovery in the mouse genome for the first time. In searching an excess of 10 million spectra, we have been able to validate 32%, 17%, and 7% of all protein-coding genes, exons, and splice boundaries, respectively. Moreover, we present strong evidence for the identification of multiple alternatively spliced translations from 53 genes and have uncovered 10 entirely novel protein-coding genes, which are not covered in any mouse annotation data sources. One such novel protein-coding gene is a fusion protein that spans the Ins2 and Igf2 loci to produce a transcript encoding the insulin II and the insulin-like growth factor 2–derived peptides. We also report nine processed pseudogenes that have unique peptide hits, demonstrating, for the first time, that they are not just transcribed but are translated and are therefore resurrected into new coding loci. This work not only highlights an important utility for MS data in genome annotation but also provides unique insights into the gene structure and propagation in the mouse genome. All these data have been subsequently used to improve the publicly available mouse annotation available in both the Vega and Ensembl genome browsers (http://vega.sanger.ac.uk).",2011-05,2021-06-05 21:13:27,756-767,5,21,Genome Res,,PubMed Central,PMID: 21460061 PMCID: PMC3083093,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3083093/,,,,PMC:Query2
298,10.1101/gr.5646507,17189379,PMC1781355,,,,"Tanner, Stephen; Shen, Zhouxin; Ng, Julio; Florea, Liliana; Guigó, Roderic; Briggs, Steven P.; Bafna, Vineet",Improving gene annotation using peptide mass spectrometry,2007,Genome Research,,"Annotation of protein-coding genes is a key goal of genome sequencing projects. In spite of tremendous recent advances in computational gene finding, comprehensive annotation remains a challenge. Peptide mass spectrometry is a powerful tool for researching the dynamic proteome and suggests an attractive approach to discover and validate protein-coding genes. We present algorithms to construct and efficiently search spectra against a genomic database, with no prior knowledge of encoded proteins. By searching a corpus of 18.5 million tandem mass spectra (MS/MS) from human proteomic samples, we validate 39,000 exons and 11,000 introns at the level of translation. We present translation-level evidence for novel or extended exons in 16 genes, confirm translation of 224 hypothetical proteins, and discover or confirm over 40 alternative splicing events. Polymorphisms are efficiently encoded in our database, allowing us to observe variant alleles for 308 coding SNPs. Finally, we demonstrate the use of mass spectrometry to improve automated gene prediction, adding 800 correct exons to our predictions using a simple rescoring strategy. Our results demonstrate that proteomic profiling should play a role in any genome sequencing project.",2007-02,2021-06-05 21:14:07,231-239,2,17,Genome Res,,PubMed Central,PMID: 17189379 PMCID: PMC1781355,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1781355/,,,,PMC:Query2
299,10.1107/S2059798319015730,31909740,PMC6939440,A,Neo4j,Neo4j,"Hatti, Kaushik S.; McCoy, Airlie J.; Oeffner, Robert D.; Sammito, Massimo D.; Read, Randy J.",Factors influencing estimates of coordinate error for molecular replacement,2020,"Acta Crystallographica. Section D, Structural Biology",,"Good prior estimates of the effective root-mean-square deviation (r.m.s.d.) between the atomic coordinates of the model and the target optimize the signal in molecular replacement, thereby increasing the success rate in difficult cases. Previous studies using protein structures solved by X-ray crystallography as models showed that optimal error estimates (refined after structure solution) were correlated with the sequence identity between the model and target, and with the number of residues in the model. Here, this work has been extended to find additional correlations between parameters of the model and the target and hence improved prior estimates of the coordinate error. Using a graph database, a curated set of 6030 molecular-replacement calculations using models that had been solved by X-ray crystallography was analysed to consider about 120 model and target parameters. Improved estimates were achieved by replacing the sequence identity with the Gonnet score for sequence similarity, as well as by considering the resolution of the target structure and the MolProbity score of the model. This approach was extended by analysing 12 610 additional molecular-replacement calculations where the model was determined by NMR. The median r.m.s.d. between pairs of models in an ensemble was found to be correlated with the estimated r.m.s.d. to the target. For models solved by NMR, the overall coordinate error estimates were larger than for structures determined by X-ray crystallography, and were more highly correlated with the number of residues.; Improved coordinate error estimates are proposed for the X-ray and NMR models used for maximum-likelihood-based molecular-replacement phasing., Good prior estimates of the effective root-mean-square deviation (r.m.s.d.) between the atomic coordinates of the model and the target optimize the signal in molecular replacement, thereby increasing the success rate in difficult cases. Previous studies using protein structures solved by X-ray crystallography as models showed that optimal error estimates (refined after structure solution) were correlated with the sequence identity between the model and target, and with the number of residues in the model. Here, this work has been extended to find additional correlations between parameters of the model and the target and hence improved prior estimates of the coordinate error. Using a graph database, a curated set of 6030 molecular-replacement calculations using models that had been solved by X-ray crystallography was analysed to consider about 120 model and target parameters. Improved estimates were achieved by replacing the sequence identity with the Gonnet score for sequence similarity, as well as by considering the resolution of the target structure and the MolProbity score of the model. This approach was extended by analysing 12 610 additional molecular-replacement calculations where the model was determined by NMR. The median r.m.s.d. between pairs of models in an ensemble was found to be correlated with the estimated r.m.s.d. to the target. For models solved by NMR, the overall coordinate error estimates were larger than for structures determined by X-ray crystallography, and were more highly correlated with the number of residues.",2020-01-01,2021-06-05 20:35:57; 2021-06-05 20:55:01; 2021-06-05 21:06:22; 2021-06-05 21:10:08,19-27,Pt 1,76,Acta Crystallogr D Struct Biol,,PubMed; PubMed Central,PMID: 31909740 PMCID: PMC6939440,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6939440/; http://www.ncbi.nlm.nih.gov/pubmed/31909740,"coordinate error; Crystallography, X-Ray; LLG; log-likelihood gain; Magnetic Resonance Spectroscopy; Models, Molecular; molecular replacement; NMR; Protein Conformation; Proteins; r.m.s.d.; root-mean-square deviation",Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PubMed:Query2; PMC:Query2
300,10.1107/S2059798320014515,33263322,PMC7709201,,,,"Sehnal, David; Svobodová, Radka; Berka, Karel; Rose, Alexander S.; Burley, Stephen K.; Velankar, Sameer; Koča, Jaroslav",High-performance macromolecular data delivery and visualization for the web,2020,"Acta Crystallographica. Section D, Structural Biology",,"This article provides a survey of available web services and tools for data delivery and visualization of macromolecular structures., Biomacromolecular structural data make up a vital and crucial scientific resource that has grown not only in terms of its amount but also in its size and complexity. Furthermore, these data are accompanied by large and increasing amounts of experimental data. Additionally, the macromolecular data are enriched with value-added annotations describing their biological, physicochemical and structural properties. Today, the scientific community requires fast and fully interactive web visualization to exploit this complex structural information. This article provides a survey of the available cutting-edge web services that address this challenge. Specifically, it focuses on data-delivery problems, discusses the visualization of a single structure, including experimental data and annotations, and concludes with a focus on the results of molecular-dynamics simulations and the visualization of structural ensembles.",2020-11-26,2021-06-05 21:09:36,1167-1173,Pt 12,76,Acta Crystallogr D Struct Biol,,PubMed Central,PMID: 33263322 PMCID: PMC7709201,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7709201/,,,,PMC:Query2
301,10.1107/S2059798320014746,33404520,PMC7787104,,,,"McCoy, Airlie J.; Stockwell, Duncan H.; Sammito, Massimo D.; Oeffner, Robert D.; Hatti, Kaushik S.; Croll, Tristan I.; Read, Randy J.",Phasertng: directed acyclic graphs for crystallographic phasing,2021,"Acta Crystallographica. Section D, Structural Biology",,"The employment of directed acyclic graphs to advance the tracking, control and appraisal of crystallographic phasing strategies is discussed., Crystallographic phasing strategies increasingly require the exploration and ranking of many hypotheses about the number, types and positions of atoms, molecules and/or molecular fragments in the unit cell, each with only a small chance of being correct. Accelerating this move has been improvements in phasing methods, which are now able to extract phase information from the placement of very small fragments of structure, from weak experimental phasing signal or from combinations of molecular replacement and experimental phasing information. Describing phasing in terms of a directed acyclic graph allows graph-management software to track and manage the path to structure solution. The crystallographic software supporting the graph data structure must be strictly modular so that nodes in the graph are efficiently generated by the encapsulated functionality. To this end, the development of new software, Phasertng, which uses directed acyclic graphs natively for input/output, has been initiated. In Phasertng, the codebase of Phaser has been rebuilt, with an emphasis on modularity, on scripting, on speed and on continuing algorithm development. As a first application of phasertng, its advantages are demonstrated in the context of phasertng.xtricorder, a tool to analyse and triage merged data in preparation for molecular replacement or experimental phasing. The description of the phasing strategy with directed acyclic graphs is a generalization that extends beyond the functionality of Phasertng, as it can incorporate results from bioinformatics and other crystallographic tools, and will facilitate multifaceted search strategies, dynamic ranking of alternative search pathways and the exploitation of machine learning to further improve phasing strategies.",2021-01-01,2021-06-05 21:09:36,1-10,Pt 1,77,Acta Crystallogr D Struct Biol,Phasertng,PubMed Central,PMID: 33404520 PMCID: PMC7787104,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7787104/,,,,PMC:Query2
302,10.1107/S2059798321001339,33559602,PMC7869900,,,,"Usón, Isabel; Ballard, Charles C.; Keegan, Ronan M.; Read, Randy J.","Integrated, rational molecular replacement",2021,"Acta Crystallographica. Section D, Structural Biology",,"Introducing the virtual special issue on the 2019 CCP4 Study Weekend on Integrated, rational molecular replacement at https://journals.iucr.org/special_issues/2020/CCP42019/.",2021-02-05,2021-06-05 21:09:36,129-130,Pt 2,77,Acta Crystallogr D Struct Biol,,PubMed Central,PMID: 33559602 PMCID: PMC7869900,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7869900/,,,,PMC:Query2
303,10.1109/ACCESS.2020.2995763,,PMC8098810,A,Neo4j; COVID19,Neo4j; COVID19,,Envisioning Insight-Driven Learning Based on Thick Data Analytics With Focus on Healthcare,2020,Ieee Access,,"Detecting and analyzing patient insights from social media enables healthcare givers to better understand what patients want and also to identify their pain points. Healthcare institutions cannot neglect the need to monitor and analyze popular social media outlets such as Twitter and Facebook. To have a study success, a healthcare giver needs to be able to engage with their patients and adapt to their preferences effectively. However, data-driven decision-making is no longer enough, as the best-in-class organizations struggle to realize tangible benefits from their data-driven analytics investments. Relying on simplistic textual analytics that use big data technologies to learn consumer/patient insights is no longer sufficient as most of these analytics utilize sort of bag-of-words counting algorithms. The majority of projects utilizing big data analytics have failed due to the obsession with metrics at the expense of capturing the customer’s perspective data, as well as the failure in turning consumer insights into actions. Most of the consumer insights can be captured with qualitative research methods that work with small, even statistically insignificant, sample sizes. Employing qualitative analytics provide some kind of actionable intelligence which acquires understanding to broad questions about the consumer needs in tandem with analytical power. Generating insight, on one hand, requires sound techniques to measure consumers’ engagement more precisely and offers depth analytics to the consumer data story. On the other hand, turning relevant insights into actions requires incorporating actionable intelligence across the business by verify hypotheses based on qualitative findings by using web analytics to see if these axioms apply to a large number of customers. The first component of our visionary approach is dedicated to identifying the relationships between constituents of the healthcare pain points as echoed by the social media conversation in terms of sociographic network where the elements composing these conversations are described as nodes and their interactions as links. In this part, conversation groups of nodes that are heavily connected will be identified representing what we call conversation communities. By identifying these conversation communities several consumer hidden insights can be inferred from using techniques such as visualizing conversation graphs relevant to given pain point, conversation learning from question answering, conversations summaries, conversation timelines, conversation anomalies and other conversation pattern learning techniques. These techniques will identify and learn the patient insights without forgetting from the context of conversation communities, are tagged as “thick data analytics”. Additionally machine learning methods can be used as assistive techniques to learn from the identified thick data and build models around identified thick data. With the use of transfer learning we also can fine tune these models with the arrival of new conversations. The author is currently experimenting with these seven insights driven learning methods described in this paper with massive geo-located Twitter data to infer the quality of care related to the current COVID-19 outbreak.",2020-06-01,2021-06-05 20:35:57; 2021-06-05 21:35:36; 2021-06-05 20:54:31; 2021-06-05 21:10:08,114998-115004,,8,IEEE Access,,PubMed Central,PMID:  PMCID: PMC8098810,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8098810/,,Neo4j; COVID19,Neo4j; COVID19,PMC:Query3; PMC:Neo4j; PMC:COVID19; PMC:Query2
304,10.1109/BIBE.2008.4696654,20428463,PMC2860184,,,,"Smalter, Aaron; Huan, Jun; Lushington, Gerald",GPM: A Graph Pattern Matching Kernel with Diffusion for Chemical Compound Classification,2008,Proceedings. IEEE International Symposium on Bioinformatics and Bioengineering; Proceedings / Annual IEEE International Symposium on Bioinformatics and Bioengineering (BIBE). IEEE International Symposium on Bioinformatics and Bioengineering,,"Classifying chemical compounds is an active topic in drug design and other cheminformatics applications. Graphs are general tools for organizing information from heterogenous sources and have been applied in modelling many kinds of biological data. With the fast accumulation of chemical structure data, building highly accurate predictive models for chemical graphs emerges as a new challenge.In this paper, we demonstrate a novel technique called Graph Pattern Matching kernel (GPM). Our idea is to leverage existing frequent pattern discovery methods and explore their application to kernel classifiers (e.g. support vector machine) for graph classification. In our method, we first identify all frequent patterns from a graph database. We then map subgraphs to graphs in the database and use a diffusion process to label nodes in the graphs. Finally the kernel is computed using a set matching algorithm. We performed experiments on 16 chemical structure data sets and have compared our methods to other major graph kernels. The experimental results demonstrate excellent performance of our method.; Classifying chemical compounds is an active topic in drug design and other cheminformatics applications. Graphs are general tools for organizing information from heterogenous sources and have been applied in modelling many kinds of biological data. With the fast accumulation of chemical structure data, building highly accurate predictive models for chemical graphs emerges as a new challenge., In this paper, we demonstrate a novel technique called Graph Pattern Matching kernel (GPM). Our idea is to leverage existing frequent pattern discovery methods and explore their application to kernel classifiers (e.g. support vector machine) for graph classification. In our method, we first identify all frequent patterns from a graph database. We then map subgraphs to graphs in the database and use a diffusion process to label nodes in the graphs. Finally the kernel is computed using a set matching algorithm. We performed experiments on 16 chemical structure data sets and have compared our methods to other major graph kernels. The experimental results demonstrate excellent performance of our method.",2008-12-08,2021-06-05 21:13:27; 2021-06-05 21:06:22,1-6,,2008,Proc IEEE Int Symp Bioinformatics Bioeng,GPM,PubMed; PubMed Central,PMID: 20428463 PMCID: PMC2860184,http://www.ncbi.nlm.nih.gov/pubmed/20428463; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2860184/,,,,PubMed:Query2; PMC:Query2
305,10.1109/BIBM.2017.8217845,29629236,PMC5889048,,,,"Lossio-Ventura, Juan Antonio; Hogan, William; Modave, François; Guo, Yi; He, Zhe; Hicks, Amanda; Bian, Jiang",OC-2-KB: A software pipeline to build an evidence-based obesity and cancer knowledge base,2017,Proceedings. IEEE International Conference on Bioinformatics and Biomedicine,,"Obesity has been linked to several types of cancer. Access to adequate health information activates people’s participation in managing their own health, which ultimately improves their health outcomes. Nevertheless, the existing online information about the relationship between obesity and cancer is heterogeneous and poorly organized. A formal knowledge representation can help better organize and deliver quality health information. Currently, there are several efforts in the biomedical domain to convert unstructured data to structured data and store them in Semantic Web knowledge bases (KB). In this demo paper, we present, OC-2-KB (Obesity and Cancer to Knowledge Base), a system that is tailored to guide the automatic KB construction for managing obesity and cancer knowledge from free-text scientific literature (i.e., PubMed abstracts) in a systematic way. OC-2-KB has two important modules which perform the acquisition of entities and the extraction then classification of relationships among these entities. We tested the OC-2-KB system on a data set with 23 manually annotated obesity and cancer PubMed abstracts and created a preliminary KB with 765 triples. We conducted a preliminary evaluation on this sample of triples and reported our evaluation results.",2017-11,2021-06-05 21:11:16,1284-1287,,2017,Proceedings (IEEE Int Conf Bioinformatics Biomed),OC-2-KB,PubMed Central,PMID: 29629236 PMCID: PMC5889048,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5889048/,,,,PMC:Query2
306,10.1109/BIBM.2018.8621340,31667004,PMC6821392,A,Neo4j,Neo4j,"He, Xing; Zhang, Rui; Rizvi, Rubina; Vasilakes, Jake; Yang, Xi; Guo, Yi; He, Zhe; Prosperi, Mattia; Bian, Jiang",Prototyping an Interactive Visualization of Dietary Supplement Knowledge Graph,2018,Proceedings. IEEE International Conference on Bioinformatics and Biomedicine,,"Dietary supplements (DS) are widely consumed. However, most people have limited knowledge about the safety and efficacy of DS. Even though there exists the well-curated integrated DIetary Supplement Knowledge base (iDISK) with a formal knowledge representation, it lacks a user-friendly interface for general consumers to query and retrieve DS information relevant to their needs. Following user-centered design principles, we prototyped a web application, ALOHA (i.e., dietAry suppLement knOwledge grapH visuAlization), with interactive graph-based visualization to facilitate consumers’ browsing of iDISK. We conducted a usability inspection and design session with a focus group and evaluated the usability of the prototype with a modified System Usability Scale (SUS). The SUS result was marginal (63.75 ± 7.2 with 1 outlier removed). Nevertheless, all participants agreed that such an application is urgently needed to address the gaps in how DS information (and health information in general) are currently organized and consumed online. These feedbacks are valuable to inform the next iteration of ALOHA.",2018-12,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,1649-1652,,2018,Proceedings (IEEE Int Conf Bioinformatics Biomed),,PubMed Central,PMID: 31667004 PMCID: PMC6821392,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6821392/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
307,10.1109/BigData.2014.7004278,25859565,PMC4388251,,,,"Pienta, Robert; Tamersoy, Acar; Tong, Hanghang; Chau, Duen Horng",MAGE: Matching Approximate Patterns in Richly-Attributed Graphs,2014,Proceedings : ... IEEE International Conference on Big Data. IEEE International Conference on Big Data,,"Given a large graph with millions of nodes and edges, say a social network where both its nodes and edges have multiple attributes (e.g., job titles, tie strengths), how to quickly find subgraphs of interest (e.g., a ring of businessmen with strong ties)? We present MAGE, a scalable, multicore subgraph matching approach that supports expressive queries over large, richly-attributed graphs. Our major contributions include: (1) MAGE supports graphs with both node and edge attributes (most existing approaches handle either one, but not both); (2) it supports expressive queries, allowing multiple attributes on an edge, wildcards as attribute values (i.e., match any permissible values), and attributes with continuous values; and (3) it is scalable, supporting graphs with several hundred million edges. We demonstrate MAGE's effectiveness and scalability via extensive experiments on large real and synthetic graphs, such as a Google+ social network with 460 million edges.",2014-10,2021-06-05 21:12:40,585-590,,2014,Proc IEEE Int Conf Big Data,MAGE,PubMed Central,PMID: 25859565 PMCID: PMC4388251,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4388251/,,,,PMC:Query2
308,10.1109/EMBC.2019.8857961,31945890,,A,Neo4j,Neo4j,"Nowak, Michael R.; Lee, Junseok; Choe, Yoonsuck",A Queryable Graph Representation of Vascular Connectivity in the Whole Mouse Brain,2019,Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference,,"We construct a graph representation for the topology and geometry of the vasculature presenting across the whole mouse brain (dataset: Knife-Edge Scanning Microscope Brain Atlas India Ink). We use our graph representation to calculate preliminary estimates of the average radius as 4:8 μm, total vascular volume as 1:1000 mm3, total vascular surface area as 6:5511 cm2, and total vascular length of 2866:6567 cm. We then isolate a posterior cerebral region, derive its graph representation, and then import that representation to a Neo4j graph database. We then detail how researchers can query this database online to isolate specific vascular networks for further analysis and reconstruction.",2019-07,2021-06-05 21:24:28; 2021-06-05 21:06:22; 2021-06-05 21:16:51,256-260,,2019,Annu Int Conf IEEE Eng Med Biol Soc,,PubMed,PMID: 31945890,http://www.ncbi.nlm.nih.gov/pubmed/31945890,"Animals; Brain; Databases, Factual; Mice; Microscopy; Records",Neo4j,Neo4j,PubMed:Neo4j; PubMed:Query3; PubMed:Query2
309,10.1109/ICDE.2016.7498243,27616876,PMC5015894,,,,"Xu, Shengzhi; Su, Sen; Xiong, Li; Cheng, Xiang; Xiao, Ke",Differentially Private Frequent Subgraph Mining,2016,Proceedings / International Conference on Data Engineering. International Conference on Data Engineering,,"Mining frequent subgraphs from a collection of input graphs is an important topic in data mining research. However, if the input graphs contain sensitive information, releasing frequent subgraphs may pose considerable threats to individual's privacy. In this paper, we study the problem of frequent subgraph mining (FGM) under the rigorous differential privacy model. We introduce a novel differentially private FGM algorithm, which is referred to as DFG. In this algorithm, we first privately identify frequent subgraphs from input graphs, and then compute the noisy support of each identified frequent subgraph. In particular, to privately identify frequent subgraphs, we present a frequent subgraph identification approach which can improve the utility of frequent subgraph identifications through candidates pruning. Moreover, to compute the noisy support of each identified frequent subgraph, we devise a lattice-based noisy support derivation approach, where a series of methods has been proposed to improve the accuracy of the noisy supports. Through formal privacy analysis, we prove that our DFG algorithm satisfies ε-differential privacy. Extensive experimental results on real datasets show that the DFG algorithm can privately find frequent subgraphs with high data utility.",2016-05,2021-06-05 21:12:01,229-240,,2016,Proc Int Conf Data Eng,,PubMed Central,PMID: 27616876 PMCID: PMC5015894,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5015894/,,,,PMC:Query2
310,10.1109/ICDM.2015.131,27034626,PMC4811603,,,,"Wang, Chenguang; Song, Yangqiu; Li, Haoran; Zhang, Ming; Han, Jiawei",KnowSim: A Document Similarity Measure on Structured Heterogeneous Information Networks,2015,Proceedings / IEEE International Conference on Data Mining. IEEE International Conference on Data Mining,,"As a fundamental task, document similarity measure has broad impact to document-based classification, clustering and ranking. Traditional approaches represent documents as bag-of-words and compute document similarities using measures like cosine, Jaccard, and dice. However, entity phrases rather than single words in documents can be critical for evaluating document relatedness. Moreover, types of entities and links between entities/words are also informative. We propose a method to represent a document as a typed heterogeneous information network (HIN), where the entities and relations are annotated with types. Multiple documents can be linked by the words and entities in the HIN. Consequently, we convert the document similarity problem to a graph distance problem. Intuitively, there could be multiple paths between a pair of documents. We propose to use the meta-path defined in HIN to compute distance between documents. Instead of burdening user to define meaningful meta-paths, an automatic method is proposed to rank the meta-paths. Given the meta-paths associated with ranking scores, an HIN-based similarity measure, KnowSim, is proposed to compute document similarities. Using Freebase, a well-known world knowledge base, to conduct semantic parsing and construct HIN for documents, our experiments on 20Newsgroups and RCV1 datasets show that KnowSim generates impressive high-quality document clustering.",2015-11,2021-06-05 21:12:40,1015-1020,,2015,Proc IEEE Int Conf Data Min,KnowSim,PubMed Central,PMID: 27034626 PMCID: PMC4811603,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4811603/,,,,PMC:Query2
311,10.1109/TCBB.2009.80,20431140,PMC3058227,,,,"Smalter, Aaron; Huan, Jun Luke; Jia, Yi; Lushington, Gerald; Smalter, Aaron; Huan, Jun (Luke); Jia, Yi; Lushington, Gerald",GPD: A Graph Pattern Diffusion Kernel for Accurate Graph Classification with Applications in Cheminformatics; GPD: a graph pattern diffusion kernel for accurate graph classification with applications in cheminformatics,2010,"IEEE/ACM transactions on computational biology and bioinformatics; IEEE/ACM transactions on computational biology and bioinformatics / IEEE, ACM",,"Graph data mining is an active research area. Graphs are general modeling tools to organize information from heterogeneous sources and have been applied in many scientific, engineering, and business fields. With the fast accumulation of graph data, building highly accurate predictive models for graph data emerges as a new challenge that has not been fully explored in the data mining community. In this paper, we demonstrate a novel technique called graph pattern diffusion (GPD) kernel. Our idea is to leverage existing frequent pattern discovery methods and to explore the application of kernel classifier (e.g., support vector machine) in building highly accurate graph classification. In our method, we first identify all frequent patterns from a graph database. We then map subgraphs to graphs in the graph database and use a process we call “pattern diffusion” to label nodes in the graphs. Finally, we designed a graph alignment algorithm to compute the inner product of two graphs. We have tested our algorithm using a number of chemical structure data. The experimental results demonstrate that our method is significantly better than competing methods such as those kernel functions based on paths, cycles, and subgraphs.; Graph data mining is an active research area. Graphs are general modeling tools to organize information from heterogeneous sources and have been applied in many scientific, engineering, and business fields. With the fast accumulation of graph data, building highly accurate predictive models for graph data emerges as a new challenge that has not been fully explored in the data mining community. In this paper, we demonstrate a novel technique called graph pattern diffusion (GPD) kernel. Our idea is to leverage existing frequent pattern discovery methods and to explore the application of kernel classifier (e.g., support vector machine) in building highly accurate graph classification. In our method, we first identify all frequent patterns from a graph database. We then map subgraphs to graphs in the graph database and use a process we call ""pattern diffusion"" to label nodes in the graphs. Finally, we designed a graph alignment algorithm to compute the inner product of two graphs. We have tested our algorithm using a number of chemical structure data. The experimental results demonstrate that our method is significantly better than competing methods such as those kernel functions based on paths, cycles, and subgraphs.",2010; 2010-06,2021-06-05 21:13:27; 2021-06-05 21:06:22,197-207,2,7,IEEE/ACM Trans Comput Biol Bioinform,GPD,PubMed; PubMed Central,PMID: 20431140 PMCID: PMC3058227,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3058227/; http://www.ncbi.nlm.nih.gov/pubmed/20431140,"Algorithms; Animals; Computational Biology; Computer Simulation; Data Mining; Databases, Factual; Enzyme Inhibitors; Female; Humans; Intestinal Mucosa; Male; Mice; Molecular Conformation; Pattern Recognition, Automated; Pharmaceutical Preparations; Pharmacokinetics; Rats",,,PubMed:Query2; PMC:Query2
312,10.1109/TCBB.2011.58,21422495,PMC4047992,,,,"Xiang, Yang; Payne, Philip R.O.; Huang, Kun",Transactional Database Transformation and Its Application in Prioritizing Human Disease Genes,2012,"IEEE/ACM transactions on computational biology and bioinformatics / IEEE, ACM",,"Binary (0,1) matrices, commonly known as transactional databases, can represent many application data, including gene-phenotype data where “1” represents a confirmed gene-phenotype relation and “0” represents an unknown relation. It is natural to ask what information is hidden behind these “0”s and “1”s. Unfortunately, recent matrix completion methods, though very effective in many cases, are less likely to infer something interesting from these (0,1)-matrices. To answer this challenge, we propose IndEvi, a very succinct and effective algorithm to perform independent-evidence-based transactional database transformation. Each entry of a (0,1)-matrix is evaluated by “independent evidence” (maximal supporting patterns) extracted from the whole matrix for this entry. The value of an entry, regardless of its value as 0 or 1, has completely no effect for its independent evidence. The experiment on a gene-phenotype database shows that our method is highly promising in ranking candidate genes and predicting unknown disease genes.",2012,2021-06-05 21:13:27,294-304,1,9,IEEE/ACM Trans Comput Biol Bioinform,,PubMed Central,PMID: 21422495 PMCID: PMC4047992,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4047992/,,,,PMC:Query2
313,10.1109/TCBB.2013.136,26355502,,A,,,"Liang Zhao, Hoi, Steven C. H.; Li, Zhenhua; Wong, Limsoon; Nguyen, Hung; Li, Jinyan","Coupling Graphs, Efficient Algorithms and B-Cell Epitope Prediction",2014,IEEE/ACM transactions on computational biology and bioinformatics,,"Coupling graphs are newly introduced in this paper to meet many application needs particularly in the field of bioinformatics. A coupling graph is a two-layer graph complex, in which each node from one layer of the graph complex has at least one connection with the nodes in the other layer, and vice versa. The coupling graph model is sufficiently powerful to capture strong and inherent associations between subgraph pairs in complicated applications. The focus of this paper is on mining algorithms of frequent coupling subgraphs and bioinformatics application. Although existing frequent subgraph mining algorithms are competent to identify frequent subgraphs from a graph database, they perform poorly on frequent coupling subgraph mining because they generate many irrelevant subgraphs. We propose a novel graph transformation technique to transform a coupling graph into a generic graph. Based on the transformed coupling graphs, existing graph mining methods are then utilized to discover frequent coupling subgraphs. We prove that the transformation is precise and complete and that the restoration is reversible. Experiments carried out on a database containing 10,511 coupling graphs show that our proposed algorithm reduces the mining time very much in comparison with the existing subgraph mining algorithms. Moreover, we demonstrate the usefulness of frequent coupling subgraphs by applying our algorithm to make accurate predictions of epitopes in antibody-antigen binding.",2014-02,2021-06-05 21:06:22,7-16,1,11,IEEE/ACM Trans Comput Biol Bioinform,,PubMed,PMID: 26355502,http://www.ncbi.nlm.nih.gov/pubmed/26355502,"Algorithms; Computational Biology; Data Mining; Databases, Protein; Epitopes, B-Lymphocyte; Models, Molecular; Models, Statistical",,,PubMed:Query2
314,10.1109/TKDE.2016.2515579,30867621,PMC6411071,A,Neo4j,Neo4j,"Wu, Yubao; Jin, Ruoming; Zhang, Xiang",Efficient and Exact Local Search for Random Walk Based Top-K Proximity Query in Large Graphs,2016,IEEE transactions on knowledge and data engineering,,"Top-k proximity query in large graphs is a fundamental problem with a wide range of applications. Various random walk based measures have been proposed to measure the proximity between different nodes. Although these measures are effective, efficiently computing them on large graphs is a challenging task. In this paper, we develop an efficient and exact local search method, FLoS (Fast Local Search), for top-k proximity query in large graphs. FLoS guarantees the exactness of the solution. Moreover, it can be applied to a variety of commonly used proximity measures. FLoS is based on the no local optimum property of proximity measures. We show that many measures have no local optimum. Utilizing this property, we introduce several operations to manipulate transition probabilities and develop tight lower and upper bounds on the proximity values. The lower and upper bounds monotonically converge to the exact proximity value when more nodes are visited. We further extend FLoS to measures having local optimum by utilizing relationship among different measures. We perform comprehensive experiments on real and synthetic large graphs to evaluate the efficiency and effectiveness of the proposed method.",2016-05,2021-06-05 20:55:40; 2021-06-05 21:12:40; 2021-06-05 20:37:08,1160-1174,5,28,IEEE Trans Knowl Data Eng,,PubMed Central,PMID: 30867621 PMCID: PMC6411071,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6411071/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
315,10.1109/TKDE.2017.2771762,30416320,PMC6221474,,,,"Ni, Jingchao; Cheng, Wei; Fan, Wei; Zhang, Xiang",ComClus: A Self-Grouping Framework for Multi-Network Clustering,2018,IEEE transactions on knowledge and data engineering,,"Joint clustering of multiple networks has been shown to be more accurate than performing clustering on individual networks separately. This is because multi-network clustering algorithms typically assume there is a common clustering structure shared by all networks, and different networks can provide compatible and complementary information for uncovering this underlying clustering structure. However, this assumption is too strict to hold in many emerging applications, where multiple networks usually have diverse data distributions. More popularly, the networks in consideration belong to different underlying groups. Only networks in the same underlying group share similar clustering structures. Better clustering performance can be achieved by considering such groups differently. As a result, an ideal method should be able to automatically detect network groups so that networks in the same group share a common clustering structure. To address this problem, we propose a new method, ComClus, to simultaneously group and cluster multiple networks. ComClus is novel in combining the clustering approach of non-negative matrix factorization (NMF) and the feature subspace learning approach of metric learning. Specifically, it treats node clusters as features of networks and learns proper subspaces from such features to differentiate different network groups. During the learning process, the two procedures of network grouping and clustering are coupled and mutually enhanced. Moreover, ComClus can effectively leverage prior knowledge on how to group networks such that network grouping can be conducted in a semi-supervised manner. This will enable users to guide the grouping process using domain knowledge so that network clustering accuracy can be further boosted. Extensive experimental evaluations on a variety of synthetic and real datasets demonstrate the effectiveness and scalability of the proposed method.",2018-03-01,2021-06-05 21:11:16,435-448,3,30,IEEE Trans Knowl Data Eng,ComClus,PubMed Central,PMID: 30416320 PMCID: PMC6221474,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6221474/,,,,PMC:Query2
316,10.1109/TVCG.2005.84,16144246,,A,,,"Magnor, Marcus; Kindlmann, Gordon; Hansen, Charles; Duric, Neb",Reconstruction and visualization of planetary nebulae,2005,IEEE transactions on visualization and computer graphics,,"From our terrestrially confined viewpoint, the actual three-dimensional shape of distant astronomical objects is, in general, very challenging to determine. For one class of astronomical objects, however, spatial structure can be recovered from conventional 2D images alone. So-called planetary nebulae (PNe) exhibit pronounced symmetry characteristics that come about due to fundamental physical processes. Making use of this symmetry constraint, we present a technique to automatically recover the axisymmetric structure of many planetary nebulae from photographs. With GPU-based volume rendering driving a nonlinear optimization, we estimate the nebula's local emission density as a function of its radial and axial coordinates and we recover the orientation of the nebula relative to Earth. The optimization refines the nebula model and its orientation by minimizing the differences between the rendered image and the original astronomical image. The resulting model allows creating realistic 3D visualizations of these nebulae, for example, for planetarium shows and other educational purposes. In addition, the recovered spatial distribution of the emissive gas can help astrophysicists gain deeper insight into the formation processes of planetary nebulae.",2005-10,2021-06-05 21:24:28; 2021-06-05 21:06:22,485-496,5,11,IEEE Trans Vis Comput Graph,,PubMed,PMID: 16144246,http://www.ncbi.nlm.nih.gov/pubmed/16144246,"Algorithms; Astronomy; Computer Graphics; Data Display; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Information Storage and Retrieval; Photography; Planets; Reproducibility of Results; Sensitivity and Specificity; User-Computer Interface",,,PubMed:Query3; PubMed:Query2
317,10.1109/TVCG.2009.108,19834159,,A,,,"van Ham, Frank; Perer, Adam","""Search, show context, expand on demand"": supporting large graph exploration with degree-of-interest",2009,IEEE transactions on visualization and computer graphics,,"A common goal in graph visualization research is the design of novel techniques for displaying an overview of an entire graph. However, there are many situations where such an overview is not relevant or practical for users, as analyzing the global structure may not be related to the main task of the users that have semi-specific information needs. Furthermore, users accessing large graph databases through an online connection or users running on less powerful (mobile) hardware simply do not have the resources needed to compute these overviews. In this paper, we advocate an interaction model that allows users to remotely browse the immediate context graph around a specific node of interest. We show how Furnas' original degree of interest function can be adapted from trees to graphs and how we can use this metric to extract useful contextual subgraphs, control the complexity of the generated visualization and direct users to interesting datapoints in the context. We demonstrate the effectiveness of our approach with an exploration of a dense online database containing over 3 million legal citations.",2009-12,2021-06-05 21:06:22,953-960,6,15,IEEE Trans Vis Comput Graph,"""Search, show context, expand on demand""",PubMed,PMID: 19834159,http://www.ncbi.nlm.nih.gov/pubmed/19834159,,,,PubMed:Query2
318,10.1109/TVCG.2012.281,26357126,,A,,,"Wenger, S.; Ament, M.; Guthe, S.; Lorenz, D.; Tillmann, A.; Weiskopf, D.; Magnor, M.",Visualization of Astronomical Nebulae via Distributed Multi-GPU Compressed Sensing Tomography,2012,IEEE transactions on visualization and computer graphics,,"The 3D visualization of astronomical nebulae is a challenging problem since only a single 2D projection is observable from our fixed vantage point on Earth. We attempt to generate plausible and realistic looking volumetric visualizations via a tomographic approach that exploits the spherical or axial symmetry prevalent in some relevant types of nebulae. Different types of symmetry can be implemented by using different randomized distributions of virtual cameras. Our approach is based on an iterative compressed sensing reconstruction algorithm that we extend with support for position-dependent volumetric regularization and linear equality constraints. We present a distributed multi-GPU implementation that is capable of reconstructing high-resolution datasets from arbitrary projections. Its robustness and scalability are demonstrated for astronomical imagery from the Hubble Space Telescope. The resulting volumetric data is visualized using direct volume rendering. Compared to previous approaches, our method preserves a much higher amount of detail and visual variety in the 3D visualization, especially for objects with only approximate symmetry.",2012-12,2021-06-05 21:24:28; 2021-06-05 21:06:22,2188-2197,12,18,IEEE Trans Vis Comput Graph,,PubMed,PMID: 26357126,http://www.ncbi.nlm.nih.gov/pubmed/26357126,,,,PubMed:Query3; PubMed:Query2
319,10.1109/TVCG.2017.2744898,28866563,,A,,,"Pienta, Robert; Hohman, Fred; Endert, Alex; Tamersoy, Acar; Roundy, Kevin; Gates, Chris; Navathe, Shamkant; Chau, Duen Horng",VIGOR: Interactive Visual Exploration of Graph Query Results,2018,IEEE transactions on visualization and computer graphics,,"Finding patterns in graphs has become a vital challenge in many domains from biological systems, network security, to finance (e.g., finding money laundering rings of bankers and business owners). While there is significant interest in graph databases and querying techniques, less research has focused on helping analysts make sense of underlying patterns within a group of subgraph results. Visualizing graph query results is challenging, requiring effective summarization of a large number of subgraphs, each having potentially shared node-values, rich node features, and flexible structure across queries. We present VIGOR, a novel interactive visual analytics system, for exploring and making sense of query results. VIGOR uses multiple coordinated views, leveraging different data representations and organizations to streamline analysts sensemaking process. VIGOR contributes: (1) an exemplar-based interaction technique, where an analyst starts with a specific result and relaxes constraints to find other similar results or starts with only the structure (i.e., without node value constraints), and adds constraints to narrow in on specific results; and (2) a novel feature-aware subgraph result summarization. Through a collaboration with Symantec, we demonstrate how VIGOR helps tackle real-world problems through the discovery of security blindspots in a cybersecurity dataset with over 11,000 incidents. We also evaluate VIGOR with a within-subjects study, demonstrating VIGOR's ease of use over a leading graph database management system, and its ability to help analysts understand their results at higher speed and make fewer errors.",2018-01,2021-06-05 21:06:22,215-225,1,24,IEEE Trans Vis Comput Graph,VIGOR,PubMed,PMID: 28866563,http://www.ncbi.nlm.nih.gov/pubmed/28866563,,,,PubMed:Query2
320,10.1109/TVCG.2018.2865149,30188828,PMC6785378,A,Neo4j,Neo4j,"Nobre, Carolina; Marc, Streit; Alexander, Lex",Juniper: A Tree+Table Approach to Multivariate Graph Visualization,2018,IEEE transactions on visualization and computer graphics,,"Analyzing large, multivariate graphs is an important problem in many domains, yet such graphs are challenging to visualize. In this paper, we introduce a novel, scalable, tree+table multivariate graph visualization technique, which makes many tasks related to multivariate graph analysis easier to achieve. The core principle we follow is to selectively query for nodes or subgraphs of interest and visualize these subgraphs as a spanning tree of the graph. The tree is laid out linearly, which enables us to juxtapose the nodes with a table visualization where diverse attributes can be shown. We also use this table as an adjacency matrix, so that the resulting technique is a hybrid node-link/adjacency matrix technique. We implement this concept in Juniper and complement it with a set of interaction techniques that enable analysts to dynamically grow, restructure, and aggregate the tree, as well as change the layout or show paths between nodes. We demonstrate the utility of our tool in usage scenarios for different multivariate networks: a bipartite network of scholars, papers, and citation metrics and a multitype network of story characters, places, books, etc.",2018-09-03,2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:36:32,,,,IEEE Trans Vis Comput Graph,Juniper,PubMed Central,PMID: 30188828 PMCID: PMC6785378,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6785378/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
321,10.1109/TVCG.2021.3076222,33909565,,A,,,"Chen, Ran; Shu, Xinhuan; Chen, Jiahui; Weng, Di; Tang, Junxiu; Fu, Siwei; Wu, Yingcai",Nebula: A Coordinating Grammar of Graphics,2021,IEEE transactions on visualization and computer graphics,,"In multiple coordinated views (MCVs), visualizations across views update their content in response to users interactions in other views. Interactive systems provide direct manipulation to create coordination between views, but are restricted to limited types of predefined templates. By contrast, textual specification languages enable flexible coordination but expose technical burden. To bridge the gap, we contribute Nebula, a grammar based on natural language for coordinating visualizations in MCVs. The grammar design is informed by a novel framework based on a systematic review of 176 coordinations from existing theories and applications, which describes coordination by demonstration, i.e., how coordination is performed by users. With the framework, Nebula specification formalizes coordination as a composition of user- and coordination-triggered interactions in origin and destination views, respectively, along with potential data transformation between the interactions. We evaluate Nebula by demonstrating its expressiveness with a gallery of diverse examples and analyzing its usability on cognitive dimensions.",2021-04-28,2021-06-05 21:24:28; 2021-06-05 21:06:22,,,PP,IEEE Trans Vis Comput Graph,Nebula,PubMed,PMID: 33909565,http://www.ncbi.nlm.nih.gov/pubmed/33909565,,,,PubMed:Query3; PubMed:Query2
322,10.1109/tkde.2018.2793862,33223776,PMC7678507,,,,"Cheng, Xiang; Su, Sen; Xu, Shengzhi; Xiong, Li; Xiao, Ke; Zhao, Mingxing",A Two-Phase Algorithm for Differentially Private Frequent Subgraph Mining,2018,IEEE transactions on knowledge and data engineering,,"Mining frequent subgraphs from a collection of input graphs is an important task for exploratory data analysis on graph data. However, if the input graphs contain sensitive information, releasing discovered frequent subgraphs may pose considerable threats to individual privacy. In this paper, we study the problem of frequent subgraph mining (FSM) under the rigorous differential privacy model. We present a two-phase differentially private FSM algorithm, which is referred to as DFG. In DFG, frequent subgraphs are privately identified in the first phase, and the noisy support of each identified frequent subgraph is calculated in the second phase. In particular, to privately identity frequent subgraphs, we propose a frequent subgraph identification approach, which can improve the accuracy of discovered frequent subgraphs through candidate pruning. Moreover, to compute the noisy support of each identified frequent subgraph, we devise a lattice-based noisy support computation approach, which leverages the inclusion relations between the discovered frequent subgraphs to improve the accuracy of the noisy supports. Through formal privacy analysis, we prove that DFG satisfies ϵ-differential privacy. Extensive experimental results on real datasets show that DFG can privately find frequent subgraphs while achieving high data utility.",2018-08-01,2021-06-05 21:11:16,1411-1425,8,30,IEEE Trans Knowl Data Eng,,PubMed Central,PMID: 33223776 PMCID: PMC7678507,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7678507/,,,,PMC:Query2
323,10.1109/tpami.2005.138,16013757,,A,,,"Gori, Marco; Maggini, Marco; Sarti, Lorenzo",Exact and approximate graph matching using random walks,2005,IEEE transactions on pattern analysis and machine intelligence,,"In this paper, we propose a general framework for graph matching which is suitable for different problems of pattern recognition. The pattern representation we assume is at the same time highly structured, like for classic syntactic and structural approaches, and of subsymbolic nature with real-valued features, like for connectionist and statistic approaches. We show that random walk based models, inspired by Google's PageRank, give rise to a spectral theory that nicely enhances the graph topological features at node level. As a straightforward consequence, we derive a polynomial algorithm for the classic graph isomorphism problem, under the restriction of dealing with Markovian spectrally distinguishable graphs (MSD), a class of graphs that does not seem to be easily reducible to others proposed in the literature. The experimental results that we found on different test-beds of the TC-15 graph database show that the defined MSD class ""almost always"" covers the database, and that the proposed algorithm is significantly more efficient than top scoring VF algorithm on the same data. Most interestingly, the proposed approach is very well-suited for dealing with partial and approximate graph matching problems, derived for instance from image retrieval tasks. We consider the objects of the COIL-100 visual collection and provide a graph-based representation, whose node's labels contain appropriate visual features. We show that the adoption of classic bipartite graph matching algorithms offers a straightforward generalization of the algorithm given for graph isomorphism and, finally, we report very promising experimental results on the COIL-100 visual collection.",2005-07,2021-06-05 21:06:22,1100-1111,7,27,IEEE Trans Pattern Anal Mach Intell,,PubMed,PMID: 16013757,http://www.ncbi.nlm.nih.gov/pubmed/16013757,"Algorithms; Artificial Intelligence; Cluster Analysis; Computer Simulation; Image Interpretation, Computer-Assisted; Information Storage and Retrieval; Models, Statistical; Numerical Analysis, Computer-Assisted; Pattern Recognition, Automated; Signal Processing, Computer-Assisted",,,PubMed:Query2
324,10.1111/cgf.12883,27942090,PMC5146994,A,Neo4j,Neo4j,"Partl, C.; Gratzl, S.; Streit, M.; Wassermann, A. M.; Pfister, H.; Schmalstieg, D.; Lex, A.",Pathfinder: Visual Analysis of Paths in Graphs,2016,Computer graphics forum : journal of the European Association for Computer Graphics,,"The analysis of paths in graphs is highly relevant in many domains. Typically, path-related tasks are performed in node-link layouts. Unfortunately, graph layouts often do not scale to the size of many real world networks. Also, many networks are multivariate, i.e., contain rich attribute sets associated with the nodes and edges. These attributes are often critical in judging paths, but directly visualizing attributes in a graph layout exacerbates the scalability problem. In this paper, we present visual analysis solutions dedicated to path-related tasks in large and highly multivariate graphs. We show that by focusing on paths, we can address the scalability problem of multivariate graph visualization, equipping analysts with a powerful tool to explore large graphs. We introduce Pathfinder (), a technique that provides visual methods to query paths, while considering various constraints. The resulting set of paths is visualized in both a ranked list and as a node-link diagram. For the paths in the list, we display rich attribute data associated with nodes and edges, and the node-link diagram provides topological context. The paths can be ranked based on topological properties, such as path length or average node degree, and scores derived from attribute data. Pathfinder is designed to scale to graphs with tens of thousands of nodes and edges by employing strategies such as incremental query results. We demonstrate Pathfinder's fitness for use in scenarios with data from a coauthor network and biological pathways.",2016-06,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:37:08,71-80,3,35,Comput Graph Forum,Pathfinder,PubMed Central,PMID: 27942090 PMCID: PMC5146994,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5146994/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
325,10.1111/cgf.13184,29479126,PMC5821473,A,Neo4j,Neo4j,"Kerzner, E.; Lex, A.; Sigulinsky, C.L.; Umess, T.; Jones, B.W.; Marc, R.E.; Meyer, M.",Graffinity: Visualizing Connectivity in Large Graphs,2017,Computer graphics forum : journal of the European Association for Computer Graphics,,"Multivariate graphs are prolific across many fields, including transportation and neuroscience. A key task in graph analysis is the exploration of connectivity, to, for example, analyze how signals flow through neurons, or to explore how well different cities are connected by flights. While standard node-link diagrams are helpful in judging connectivity, they do not scale to large networks. Adjacency matrices also do not scale to large networks and are only suitable to judge connectivity of adjacent nodes. A key approach to realize scalable graph visualization are queries: instead of displaying the whole network, only a relevant subset is shown. Query-based techniques for analyzing connectivity in graphs, however, can also easily suffer from cluttering if the query result is big enough. To remedy this, we introduce techniques that provide an overview of the connectivity and reveal details on demand. We have two main contributions: (1) two novel visualization techniques that work in concert for summarizing graph connectivity; and (2) Graffinity, an open-source implementation of these visualizations supplemented by detail views to enable a complete analysis workflow. Graffinity was designed in a close collaboration with neuroscientists and is optimized for connectomics data analysis, yet the technique is applicable across domains. We validate the connectivity overview and our open-source tool with illustrative examples using flight and connectomics data.",2017-06,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:36:32,251-260,3,36,Comput Graph Forum,Graffinity,PubMed Central,PMID: 29479126 PMCID: PMC5821473,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5821473/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
326,10.1111/mpp.12965,33245626,PMC7488465,A,Neo4j,Neo4j,"González‐Fuente, Manuel; Carrère, Sébastien; Monachello, Dario; Marsella, Benjamin G.; Cazalé, Anne‐Claire; Zischek, Claudine; Mitra, Raka M.; Rezé, Nathalie; Cottret, Ludovic; Mukhtar, M. Shahid; Lurin, Claire; Noël, Laurent D.; Peeters, Nemo","EffectorK, a comprehensive resource to mine for Ralstonia, Xanthomonas, and other published effector interactors in the Arabidopsis proteome",2020,Molecular Plant Pathology,,"Pathogens deploy effector proteins that interact with host proteins to manipulate the host physiology to the pathogen's own benefit. However, effectors can also be recognized by host immune proteins, leading to the activation of defence responses. Effectors are thus essential components in determining the outcome of plant–pathogen interactions. Despite major efforts to decipher effector functions, our current knowledge on effector biology is scattered and often limited. In this study, we conducted two systematic large‐scale yeast two‐hybrid screenings to detect interactions between Arabidopsis thaliana proteins and effectors from two vascular bacterial pathogens: Ralstonia pseudosolanacearum and Xanthomonas campestris. We then constructed an interactomic network focused on Arabidopsis and effector proteins from a wide variety of bacterial, oomycete, fungal, and invertebrate pathogens. This network contains our experimental data and protein–protein interactions from 2,035 peer‐reviewed publications (48,200 Arabidopsis–Arabidopsis and 1,300 Arabidopsis–effector protein interactions). Our results show that effectors from different species interact with both common and specific Arabidopsis interactors, suggesting dual roles as modulators of generic and adaptive host processes. Network analyses revealed that effector interactors, particularly “effector hubs” and bacterial core effector interactors, occupy important positions for network organization, as shown by their larger number of protein interactions and centrality. These interactomic data were incorporated in EffectorK, a new graph‐oriented knowledge database that allows users to navigate the network, search for homology, or find possible paths between host and/or effector proteins. EffectorK is available at www.effectork.org and allows users to submit their own interactomic data., EffectorK (www.effectorK.org) is an open database compiling newly generated and literature‐curated interactomic data from various Arabidopsis pathogen effectors.",2020-08-15,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,1257-1270,10,21,Mol Plant Pathol,,PubMed Central,PMID: 33245626 PMCID: PMC7488465,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7488465/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
327,10.1128/genomeA.00214-13,23704175,PMC3662815,,,,"Tobes, Raquel; Manrique, Marina; Brozynska, Marta; Stephan, Roger; Pareja, Eduardo; Johler, Sophia","Noncontiguous Finished Genome Sequence of Staphylococcus aureus KLT6, a Staphylococcal Enterotoxin B-Positive Strain Involved in a Food Poisoning Outbreak in Switzerland",2013,Genome Announcements,,"We present the first complete genome sequence of a Staphylococcus aureus strain assigned to clonal complex 12. The strain was isolated in a food poisoning outbreak due to contaminated potato salad in Switzerland in 2009, and it produces staphylococcal enterotoxin B.",2013-05-23,2021-06-05 21:13:27,,3,1,Genome Announc,,PubMed Central,PMID: 23704175 PMCID: PMC3662815,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3662815/,,,,PMC:Query2
328,10.1128/mBio.02248-18,30459201,PMC6247079,A,Neo4j,Neo4j,"Hannigan, Geoffrey D.; Duhaime, Melissa B.; Ruffin, Mack T.; Koumpouras, Charlie C.; Schloss, Patrick D.",Diagnostic Potential and Interactive Dynamics of the Colorectal Cancer Virome,2018,mBio,,"Colorectal cancer is a leading cause of cancer-related death in the United States and worldwide. Its risk and severity have been linked to colonic bacterial community composition. Although human-specific viruses have been linked to other cancers and diseases, little is known about colorectal cancer virus communities. We addressed this knowledge gap by identifying differences in colonic virus communities in the stool of colorectal cancer patients and how they compared to bacterial community differences. The results suggested an indirect role for the virome in impacting colorectal cancer by modulating the associated bacterial community. These findings both support the idea of a biological role for viruses in colorectal cancer and provide a new understanding of basic colorectal cancer etiology., Human viruses (those that infect human cells) have been associated with many cancers, largely due to their mutagenic and functionally manipulative abilities. Despite this, cancer microbiome studies have focused almost exclusively on bacteria instead of viruses. We began evaluating the cancer virome by focusing on colorectal cancer, a primary cause of morbidity and mortality throughout the world and a cancer linked to altered colonic bacterial community compositions but with an unknown association with the gut virome. We used 16S rRNA gene, whole shotgun metagenomic, and purified virus metagenomic sequencing of stool to evaluate the differences in human colorectal cancer virus and bacterial community composition. Through random forest modeling, we identified differences in the healthy and colorectal cancer viromes. The cancer-associated virome consisted primarily of temperate bacteriophages that were also predicted to be bacterium-virus community network hubs. These results provide foundational evidence that bacteriophage communities are associated with colorectal cancer and potentially impact cancer progression by altering the bacterial host communities.",2018-11-20,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,,6,9,mBio,,PubMed Central,PMID: 30459201 PMCID: PMC6247079,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6247079/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
329,10.1136/amiajnl-2011-000552,22101971,PMC3277628,,,,"Athey, Brian D; Cavalcoli, James D; Jagadish, H V; Omenn, Gilbert S; Mirel, Barbara; Kretzler, Matthias; Burant, Charles; Isokpehi, Raphael D; DeLisi, Charles",The NIH National Center for Integrative Biomedical Informatics (NCIBI),2012,Journal of the American Medical Informatics Association : JAMIA,,"The National Center for Integrative and Biomedical Informatics (NCIBI) is one of the eight NCBCs. NCIBI supports information access and data analysis for biomedical researchers, enabling them to build computational and knowledge models of biological systems to address the Driving Biological Problems (DBPs). The NCIBI DBPs have included prostate cancer progression, organ-specific complications of type 1 and 2 diabetes, bipolar disorder, and metabolic analysis of obesity syndrome. Collaborating with these and other partners, NCIBI has developed a series of software tools for exploratory analysis, concept visualization, and literature searches, as well as core database and web services resources. Many of our training and outreach initiatives have been in collaboration with the Research Centers at Minority Institutions (RCMI), integrating NCIBI and RCMI faculty and students, culminating each year in an annual workshop. Our future directions include focusing on the TranSMART data sharing and analysis initiative.",2012,2021-06-05 21:13:27,166-170,2,19,J Am Med Inform Assoc,,PubMed Central,PMID: 22101971 PMCID: PMC3277628,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3277628/,,,,PMC:Query2
330,10.1136/amiajnl-2011-000646,22859646,PMC3555311,,,,"Farley, Toni; Kiefer, Jeff; Lee, Preston; Von Hoff, Daniel; Trent, Jeffrey M; Colbourn, Charles; Mousses, Spyro",The BioIntelligence Framework: a new computational platform for biomedical knowledge computing,2013,Journal of the American Medical Informatics Association : JAMIA,,"Breakthroughs in molecular profiling technologies are enabling a new data-intensive approach to biomedical research, with the potential to revolutionize how we study, manage, and treat complex diseases. The next great challenge for clinical applications of these innovations will be to create scalable computational solutions for intelligently linking complex biomedical patient data to clinically actionable knowledge. Traditional database management systems (DBMS) are not well suited to representing complex syntactic and semantic relationships in unstructured biomedical information, introducing barriers to realizing such solutions. We propose a scalable computational framework for addressing this need, which leverages a hypergraph-based data model and query language that may be better suited for representing complex multi-lateral, multi-scalar, and multi-dimensional relationships. We also discuss how this framework can be used to create rapid learning knowledge base systems to intelligently capture and relate complex patient data to biomedical knowledge in order to automate the recovery of clinically actionable information.",2013,2021-06-05 21:13:27,128-133,1,20,J Am Med Inform Assoc,The BioIntelligence Framework,PubMed Central,PMID: 22859646 PMCID: PMC3555311,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3555311/,,,,PMC:Query2
331,10.1136/bmjhci-2020-100254,33419870,PMC7798427,,,,"Cernile, George; Heritage, Trevor; Sebire, Neil J; Gordon, Ben; Schwering, Taralyn; Kazemlou, Shana; Borecki, Yulia",Network graph representation of COVID-19 scientific publications to aid knowledge discovery,2021,BMJ Health & Care Informatics,,"Introduction Numerous scientific journal articles related to COVID-19 have been rapidly published, making navigation and understanding of relationships difficult. Methods A graph network was constructed from the publicly available COVID-19 Open Research Dataset (CORD-19) of COVID-19-related publications using an engine leveraging medical knowledge bases to identify discrete medical concepts and an open-source tool (Gephi) to visualise the network. Results The network shows connections between diseases, medications and procedures identified from the title and abstract of 195 958 COVID-19-related publications (CORD-19 Dataset). Connections between terms with few publications, those unconnected to the main network and those irrelevant were not displayed. Nodes were coloured by knowledge base and the size of the node related to the number of publications containing the term. The data set and visualisations were made publicly accessible via a webtool. Conclusion Knowledge management approaches (text mining and graph networks) can effectively allow rapid navigation and exploration of entity inter-relationships to improve understanding of diseases such as COVID-19.",2021-01-08,2021-06-05 21:09:36,,1,28,BMJ Health Care Inform,,PubMed Central,PMID: 33419870 PMCID: PMC7798427,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7798427/,,,,PMC:Query2
332,10.1137/1.9781611972832.10,25949925,PMC4418485,,,,"Kong, Xiangnan; Yu, Philip S.; Wang, Xue; Ragin, Ann B.",Discriminative Feature Selection for Uncertain Graph Classification,2013,Proceedings of the ... SIAM International Conference on Data Mining. SIAM International Conference on Data Mining,,"Mining discriminative features for graph data has attracted much attention in recent years due to its important role in constructing graph classifiers, generating graph indices, etc. Most measurement of interestingness of discriminative subgraph features are defined on certain graphs, where the structure of graph objects are certain, and the binary edges within each graph represent the “presence” of linkages among the nodes. In many real-world applications, however, the linkage structure of the graphs is inherently uncertain. Therefore, existing measurements of interestingness based upon certain graphs are unable to capture the structural uncertainty in these applications effectively. In this paper, we study the problem of discriminative subgraph feature selection from uncertain graphs. This problem is challenging and different from conventional subgraph mining problems because both the structure of the graph objects and the discrimination score of each subgraph feature are uncertain. To address these challenges, we propose a novel discriminative subgraph feature selection method, Dug, which can find discriminative subgraph features in uncertain graphs based upon different statistical measures including expectation, median, mode and φ-probability. We first compute the probability distribution of the discrimination scores for each subgraph feature based on dynamic programming. Then a branch-and-bound algorithm is proposed to search for discriminative subgraphs efficiently. Extensive experiments on various neuroimaging applications (i.e., Alzheimers Disease, ADHD and HIV) have been performed to analyze the gain in performance by taking into account structural uncertainties in identifying discriminative subgraph features for graph classification.",2013,2021-06-05 21:13:27,82-93,,2013,Proc SIAM Int Conf Data Min,,PubMed Central,PMID: 25949925 PMCID: PMC4418485,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4418485/,,,,PMC:Query2
333,10.1142/9789813207813_0038,27896993,PMC6029858,,,,"Durmaz, Arda; Henderson, Tim A. D.; Brubaker, Douglas; Bebek, Gurkan",FREQUENT SUBGRAPH MINING OF PERSONALIZED SIGNALING PATHWAY NETWORKS GROUPS PATIENTS WITH FREQUENTLY DYSREGULATED DISEASE PATHWAYS AND PREDICTS PROGNOSIS,2017,Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing,,"Motivation Large scale genomics studies have generated comprehensive molecular characterization of numerous cancer types. Subtypes for many tumor types have been established; however, these classifications are based on molecular characteristics of a small gene sets with limited power to detect dysregulation at the patient level. We hypothesize that frequent graph mining of pathways to gather pathways functionally relevant to tumors can characterize tumor types and provide opportunities for personalized therapies. Results In this study we present an integrative omics approach to group patients based on their altered pathway characteristics and show prognostic differences within breast cancer (p < 9.57E – 10) and glioblastoma multiforme (p < 0.05) patients. We were able validate this approach in secondary RNA-Seq datasets with p < 0.05 and p < 0.01 respectively. We also performed pathway enrichment analysis to further investigate the biological relevance of dysregulated pathways. We compared our approach with network-based classifier algorithms and showed that our unsupervised approach generates more robust and biologically relevant clustering whereas previous approaches failed to report specific functions for similar patient groups or classify patients into prognostic groups. Conclusions These results could serve as a means to improve prognosis for future cancer patients, and to provide opportunities for improved treatment options and personalized interventions. The proposed novel graph mining approach is able to integrate PPI networks with gene expression in a biologically sound approach and cluster patients in to clinically distinct groups. We have utilized breast cancer and glioblastoma multiforme datasets from microarray and RNA-Seq platforms and identified disease mechanisms differentiating samples.",2017,2021-06-05 21:12:01,402-413,,22,Pac Symp Biocomput,,PubMed Central,PMID: 27896993 PMCID: PMC6029858,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6029858/,,,,PMC:Query2
334,10.1145/1516360.1516416,20428322,PMC2860326,,,,"Wang, Xiaohong; Smalter, Aaron; Huan, Jun; Lushington, Gerald H.",G-Hash: Towards Fast Kernel-based Similarity Search in Large Graph Databases,2009,Advances in Database Technology: Proceedings. International Conference on Extending Database Technology; Advances in database technology : proceedings. International Conference on Extending Database Technology,,"Structured data including sets, sequences, trees and graphs, pose significant challenges to fundamental aspects of data management such as efficient storage, indexing, and similarity search. With the fast accumulation of graph databases, similarity search in graph databases has emerged as an important research topic. Graph similarity search has applications in a wide range of domains including cheminformatics, bioinformatics, sensor network management, social network management, and XML documents, among others.Most of the current graph indexing methods focus on subgraph query processing, i.e. determining the set of database graphs that contains the query graph and hence do not directly support similarity search. In data mining and machine learning, various graph kernel functions have been designed to capture the intrinsic similarity of graphs. Though successful in constructing accurate predictive and classification models for supervised learning, graph kernel functions have (i) high computational complexity and (ii) non-trivial difficulty to be indexed in a graph database.Our objective is to bridge graph kernel function and similarity search in graph databases by proposing (i) a novel kernel-based similarity measurement and (ii) an efficient indexing structure for graph data management. Our method of similarity measurement builds upon local features extracted from each node and their neighboring nodes in graphs. A hash table is utilized to support efficient storage and fast search of the extracted local features. Using the hash table, a graph kernel function is defined to capture the intrinsic similarity of graphs and for fast similarity query processing. We have implemented our method, which we have named G-hash, and have demonstrated its utility on large chemical graph databases. Our results show that the G-hash method achieves state-of-the-art performance for k-nearest neighbor (k-NN) classification. Most importantly, the new similarity measurement and the index structure is scalable to large database with smaller indexing size, faster indexing construction time, and faster query processing time as compared to state-of-the-art indexing methods such as C-tree, gIndex, and GraphGrep.; Structured data including sets, sequences, trees and graphs, pose significant challenges to fundamental aspects of data management such as efficient storage, indexing, and similarity search. With the fast accumulation of graph databases, similarity search in graph databases has emerged as an important research topic. Graph similarity search has applications in a wide range of domains including cheminformatics, bioinformatics, sensor network management, social network management, and XML documents, among others., Most of the current graph indexing methods focus on subgraph query processing, i.e. determining the set of database graphs that contains the query graph and hence do not directly support similarity search. In data mining and machine learning, various graph kernel functions have been designed to capture the intrinsic similarity of graphs. Though successful in constructing accurate predictive and classification models for supervised learning, graph kernel functions have (i) high computational complexity and (ii) non-trivial difficulty to be indexed in a graph database., Our objective is to bridge graph kernel function and similarity search in graph databases by proposing (i) a novel kernel-based similarity measurement and (ii) an efficient indexing structure for graph data management. Our method of similarity measurement builds upon local features extracted from each node and their neighboring nodes in graphs. A hash table is utilized to support efficient storage and fast search of the extracted local features. Using the hash table, a graph kernel function is defined to capture the intrinsic similarity of graphs and for fast similarity query processing. We have implemented our method, which we have named G-hash, and have demonstrated its utility on large chemical graph databases. Our results show that the G-hash method achieves state-of-the-art performance for k-nearest neighbor (k-NN) classification. Most importantly, the new similarity measurement and the index structure is scalable to large database with smaller indexing size, faster indexing construction time, and faster query processing time as compared to state-of-the-art indexing methods such as C-tree, gIndex, and GraphGrep.",2009,2021-06-05 21:13:27; 2021-06-05 21:06:22,472-480,,360,Adv Database Technol,G-Hash,PubMed; PubMed Central,PMID: 20428322 PMCID: PMC2860326,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2860326/; http://www.ncbi.nlm.nih.gov/pubmed/20428322,,,,PubMed:Query2; PMC:Query2
335,10.1145/2503210.2503225,24402052,PMC3881961,A,Neo4j,Neo4j,"Zheng, Da; Burns, Randal; Szalay, Alexander S.","Toward Millions of File System IOPS on Low-Cost, Commodity Hardware",2013,ICS ... : proceedings of the ... ACM International Conference on Supercomputing / sponsored by ACM/SIGARCH. International Conference on Supercomputing,,"We describe a storage system that removes I/O bottlenecks to achieve more than one million IOPS based on a user-space file abstraction for arrays of commodity SSDs. The file abstraction refactors I/O scheduling and placement for extreme parallelism and non-uniform memory and I/O. The system includes a set-associative, parallel page cache in the user space. We redesign page caching to eliminate CPU overhead and lock-contention in non-uniform memory architecture machines. We evaluate our design on a 32 core NUMA machine with four, eight-core processors. Experiments show that our design delivers 1.23 million 512-byte read IOPS. The page cache realizes the scalable IOPS of Linux asynchronous I/O (AIO) and increases user-perceived I/O performance linearly with cache hit rates. The parallel, set-associative cache matches the cache hit rates of the global Linux page cache under real workloads.",2013,2021-06-05 21:13:27; 2021-06-05 20:56:20; 2021-06-05 20:37:08,,,,ICS,,PubMed Central,PMID: 24402052 PMCID: PMC3881961,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3881961/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
336,10.1145/2732158.2732192,25859567,PMC4388241,,,,"Pienta, Robert; Tamersoy, Acar; Tong, Hanghang; Endert, Alex; Chau, Duen Horng","Interactive Querying over Large Network Data: Scalability, Visualization, and Interaction Design",2015,IUI / International Conference on Intelligent User Interfaces. International Conference on Intelligent User Interfaces,,"Given the explosive growth of modern graph data, new methods are needed that allow for the querying of complex graph structures without the need of a complicated querying languages; in short, interactive graph querying is desirable. We describe our work towards achieving our overall research goal of designing and developing an interactive querying system for large network data. We focus on three critical aspects: scalable data mining algorithms, graph visualization, and interaction design. We have already completed an approximate subgraph matching system called MAGE in our previous work that fulfills the algorithmic foundation allowing us to query a graph with hundreds of millions of edges. Our preliminary work on visual graph querying, Graphite, was the first step in the process to making an interactive graph querying system. We are in the process of designing the graph visualization and robust interaction needed to make truly interactive graph querying a reality.",2015,2021-06-05 21:12:40,61-64,Companion,2015,IUI,Interactive Querying over Large Network Data,PubMed Central,PMID: 25859567 PMCID: PMC4388241,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4388241/,,,,PMC:Query2
337,10.1145/2783258.2783362,26705503,PMC4688017,,,,"Ren, Xiang; El-Kishky, Ahmed; Wang, Chi; Tao, Fangbo; Voss, Clare R.; Ji, Heng; Han, Jiawei",ClusType: Effective Entity Recognition and Typing by Relation Phrase-Based Clustering,2015,KDD : proceedings / International Conference on Knowledge Discovery & Data Mining. International Conference on Knowledge Discovery & Data Mining,,"Entity recognition is an important but challenging research problem. In reality, many text collections are from specific, dynamic, or emerging domains, which poses significant new challenges for entity recognition with increase in name ambiguity and context sparsity, requiring entity detection without domain restriction. In this paper, we investigate entity recognition (ER) with distant-supervision and propose a novel relation phrase-based ER framework, called ClusType, that runs data-driven phrase mining to generate entity mention candidates and relation phrases, and enforces the principle that relation phrases should be softly clustered when propagating type information between their argument entities. Then we predict the type of each entity mention based on the type signatures of its co-occurring relation phrases and the type indicators of its surface name, as computed over the corpus. Specifically, we formulate a joint optimization problem for two tasks, type propagation with relation phrases and multi-view relation phrase clustering. Our experiments on multiple genres—news, Yelp reviews and tweets—demonstrate the effectiveness and robustness of ClusType, with an average of 37% improvement in F1 score over the best compared method.",2015-08,2021-06-05 21:12:40,995-1004,,2015,KDD,ClusType,PubMed Central,PMID: 26705503 PMCID: PMC4688017,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4688017/,,,,PMC:Query2
338,10.1145/2783258.2783374,26705504,PMC4688021,,,,"Wang, Chenguang; Song, Yangqiu; El-Kishky, Ahmed; Roth, Dan; Zhang, Ming; Han, Jiawei",Incorporating World Knowledge to Document Clustering via Heterogeneous Information Networks,2015,KDD : proceedings / International Conference on Knowledge Discovery & Data Mining. International Conference on Knowledge Discovery & Data Mining,,"One of the key obstacles in making learning protocols realistic in applications is the need to supervise them, a costly process that often requires hiring domain experts. We consider the framework to use the world knowledge as indirect supervision. World knowledge is general-purpose knowledge, which is not designed for any specific domain. Then the key challenges are how to adapt the world knowledge to domains and how to represent it for learning. In this paper, we provide an example of using world knowledge for domain dependent document clustering. We provide three ways to specify the world knowledge to domains by resolving the ambiguity of the entities and their types, and represent the data with world knowledge as a heterogeneous information network. Then we propose a clustering algorithm that can cluster multiple types and incorporate the sub-type information as constraints. In the experiments, we use two existing knowledge bases as our sources of world knowledge. One is Freebase, which is collaboratively collected knowledge about entities and their organizations. The other is YAGO2, a knowledge base automatically extracted from Wikipedia and maps knowledge to the linguistic knowledge base, Word-Net. Experimental results on two text benchmark datasets (20newsgroups and RCV1) show that incorporating world knowledge as indirect supervision can significantly outperform the state-of-the-art clustering algorithms as well as clustering algorithms enhanced with world knowledge features.",2015-08,2021-06-05 21:12:40,1215-1224,,2015,KDD,,PubMed Central,PMID: 26705504 PMCID: PMC4688021,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4688021/,,,,PMC:Query2
339,10.1145/2858036.2858368,28018995,PMC5176260,A,Neo4j,Neo4j,"Hogan, Bernie; Melville, Joshua R.; Philips, Gregory Lee; Janulis, Patrick; Contractor, Noshir; Mustanski, Brian S.; Birkett, Michelle",Evaluating the Paper-to-Screen Translation of Participant-Aided Sociograms with High-Risk Participants,2016,Proceedings of the SIGCHI conference on human factors in computing systems . CHI Conference,,"While much social network data exists online, key network metrics for high-risk populations must still be captured through self-report. This practice has suffered from numerous limitations in workflow and response burden. However, advances in technology, network drawing libraries and databases are making interactive network drawing increasingly feasible. We describe the translation of an analog-based technique for capturing personal networks into a digital framework termed netCanvas that addresses many existing shortcomings such as: 1) complex data entry; 2) extensive interviewer intervention and field setup; 3) difficulties in data reuse; and 4) a lack of dynamic visualizations., We test this implementation within a health behavior study of a high-risk and difficult-to-reach population. We provide a within–subjects comparison between paper and touchscreens. We assert that touchscreen-based social network capture is now a viable alternative for highly sensitive data and social network data entry tasks.",2016-05,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:37:08,5360-5371,,2016,Proc SIGCHI Conf Hum Factor Comput Syst,,PubMed Central,PMID: 28018995 PMCID: PMC5176260,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5176260/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
340,10.1145/2909132.2909246,28553670,PMC5444304,A,Neo4j,Neo4j,"Pienta, Robert; Navathe, Shamkant; Tamersoy, Acar; Tong, Hanghang; Endert, Alex; Chau, Duen Horng",VISAGE: Interactive Visual Graph Querying,2016,AVI : proceedings of the Workshop on Advanced Visual Interfaces. AVI (Conference),,"Extracting useful patterns from large network datasets has become a fundamental challenge in many domains. We present VISAGE, an interactive visual graph querying approach that empowers users to construct expressive queries, without writing complex code (e.g., finding money laundering rings of bankers and business owners). Our contributions are as follows: (1) we introduce graph autocomplete, an interactive approach that guides users to construct and refine queries, preventing over-specification; (2) VISAGE guides the construction of graph queries using a data-driven approach, enabling users to specify queries with varying levels of specificity, from concrete and detailed (e.g., query by example), to abstract (e.g., with “wildcard” nodes of any types), to purely structural matching; (3) a twelve-participant, within-subject user study demonstrates VISAGE’s ease of use and the ability to construct graph queries significantly faster than using a conventional query language; (4) VISAGE works on real graphs with over 468K edges, achieving sub-second response times for common queries.",2016-06,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:37:08,272-279,,2016,AVI,VISAGE,PubMed Central,PMID: 28553670 PMCID: PMC5444304,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5444304/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
341,10.1145/2939672.2939814,28203486,PMC5304908,,,,"Shi, Yu; Kim, Myunghwan; Chatterjee, Shaunak; Tiwari, Mitul; Ghosh, Souvik; Rosales, Rómer","Dynamics of Large Multi-View Social Networks: Synergy, Cannibalization and Cross-View Interplay",2016,KDD : proceedings. International Conference on Knowledge Discovery & Data Mining,,"Most social networking services support multiple types of relationships between users, such as getting connected, sending messages, and consuming feed updates. These users and relationships can be naturally represented as a dynamic multi-view network, which is a set of weighted graphs with shared common nodes but having their own respective edges. Different network views, representing structural relationship and interaction types, could have very distinctive properties individually and these properties may change due to interplay across views. Therefore, it is of interest to study how multiple views interact and affect network dynamics and, in addition, explore possible applications to social networking., In this paper, we propose approaches to capture and analyze multi-view network dynamics from various aspects. Through our proposed descriptors, we observe the synergy and cannibalization between different user groups and network views from LinkedIn dataset. We then develop models that consider the synergy and cannibalization per new relationship, and show the outperforming predictive capability of our models compared to baseline models. Finally, the proposed models allow us to understand the interplay among different views where they dynamically change over time.",2016-08,2021-06-05 21:12:01,1855-1864,,2016,KDD,Dynamics of Large Multi-View Social Networks,PubMed Central,PMID: 28203486 PMCID: PMC5304908,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5304908/,,,,PMC:Query2
342,10.1145/2983323.2983819,28758046,PMC5530755,,,,"Goodwin, Travis R.; Harabagiu, Sanda M.",Medical Question Answering for Clinical Decision Support,2016,Proceedings of the ... ACM International Conference on Information & Knowledge Management. ACM International Conference on Information and Knowledge Management,,"The goal of modern Clinical Decision Support (CDS) systems is to provide physicians with information relevant to their management of patient care. When faced with a medical case, a physician asks questions about the diagnosis, the tests, or treatments that should be administered. Recently, the TREC-CDS track has addressed this challenge by evaluating results of retrieving relevant scientific articles where the answers of medical questions in support of CDS can be found. Although retrieving relevant medical articles instead of identifying the answers was believed to be an easier task, state-of-the-art results are not yet sufficiently promising. In this paper, we present a novel framework for answering medical questions in the spirit of TREC-CDS by first discovering the answer and then selecting and ranking scientific articles that contain the answer. Answer discovery is the result of probabilistic inference which operates on a probabilistic knowledge graph, automatically generated by processing the medical language of large collections of electronic medical records (EMRs). The probabilistic inference of answers combines knowledge from medical practice (EMRs) with knowledge from medical research (scientific articles). It also takes into account the medical knowledge automatically discerned from the medical case description. We show that this novel form of medical question answering (Q/A) produces very promising results in (a) identifying accurately the answers and (b) it improves medical article ranking by 40%.",2016-10,2021-06-05 21:12:01,297-306,,2016,Proc ACM Int Conf Inf Knowl Manag,,PubMed Central,PMID: 28758046 PMCID: PMC5530755,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5530755/,,,,PMC:Query2
343,10.1145/3097983.3098057,29430330,PMC5804740,A,Neo4j,Neo4j,"Sybrandt, Justin; Shtutman, Michael; Safro, Ilya",MOLIERE: Automatic Biomedical Hypothesis Generation System,2017,KDD : proceedings. International Conference on Knowledge Discovery & Data Mining,,"Hypothesis generation is becoming a crucial time-saving technique which allows biomedical researchers to quickly discover implicit connections between important concepts. Typically, these systems operate on domain-specific fractions of public medical data.  MOLIERE, in contrast, utilizes information from over 24.5 million documents. At the heart of our approach lies a multi-modal and multi-relational network of biomedical objects extracted from several heterogeneous datasets from the National Center for Biotechnology Information (NCBI). These objects include but are not limited to scientific papers, keywords, genes, proteins, diseases, and diagnoses. We model hypotheses using Latent Dirichlet Allocation applied on abstracts found near shortest paths discovered within this network, and demonstrate the effectiveness of  MOLIERE by performing hypothesis generation on historical data. Our network, implementation, and resulting data are all publicly available for the broad scientific community.",2017-08,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:36:32,1633-1642,,2017,KDD,MOLIERE,PubMed Central,PMID: 29430330 PMCID: PMC5804740,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5804740/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
344,10.1145/3178876.3186115,30003197,PMC6037532,,,,"Yang, Xiaofeng; Nicholson, Patrick K.; Ajwani, Deepak; Riedewald, Mirek; Gatterbauer, Wolfgang; Sala, Alessandra",Any-k: Anytime Top-k Tree Pattern Retrieval in Labeled Graphs,2018,Proceedings of the ... International World-Wide Web Conference. International WWW Conference,,"Many problems in areas as diverse as recommendation systems, social network analysis, semantic search, and distributed root cause analysis can be modeled as pattern search on labeled graphs (also called “heterogeneous information networks” or HINs). Given a large graph and a query pattern with node and edge label constraints, a fundamental challenge is to find the top-k matches according to a ranking function over edge and node weights. For users, it is difficult to select value k. We therefore propose the novel notion of an any-k ranking algorithm: for a given time budget, return as many of the top-ranked results as possible. Then, given additional time, produce the next lower-ranked results quickly as well. It can be stopped anytime, but may have to continue until all results are returned. This paper focuses on acyclic patterns over arbitrary labeled graphs. We are interested in practical algorithms that effectively exploit (1) properties of heterogeneous networks, in particular selective constraints on labels, and (2) that the users often explore only a fraction of the top-ranked results. Our solution, KARPET, carefully integrates aggressive pruning that leverages the acyclic nature of the query, and incremental guided search. It enables us to prove strong non-trivial time and space guarantees, which is generally considered very hard for this type of graph search problem. Through experimental studies we show that KARPET achieves running times in the order of milliseconds for tree patterns on large networks with millions of nodes and edges.",2018-04,2021-06-05 21:11:16,489-498,,2018,Proc Int World Wide Web Conf,Any-k,PubMed Central,PMID: 30003197 PMCID: PMC6037532,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6037532/,,,,PMC:Query2
345,10.1145/3183713.3183729,29937618,PMC6013301,,,,"Wu, Sen; Hsiao, Luke; Cheng, Xiao; Hancock, Braden; Rekatsinas, Theodoros; Levis, Philip; Ré, Christopher",Fonduer: Knowledge Base Construction from Richly Formatted Data,2018,Proceedings. ACM-Sigmod International Conference on Management of Data,,"We focus on knowledge base construction (KBC) from richly formatted data. In contrast to KBC from text or tabular data, KBC from richly formatted data aims to extract relations conveyed jointly via textual, structural, tabular, and visual expressions. We introduce  Fonduer, a machine-learning-based KBC system for richly formatted data.  Fonduer presents a new data model that accounts for three challenging characteristics of richly formatted data: (1) prevalent document-level relations, (2) multimodality, and (3) data variety.  Fonduer uses a new deep-learning model to automatically capture the representation (i.e., features) needed to learn how to extract relations from richly formatted data. Finally,  Fonduer provides a new programming model that enables users to convert domain expertise, based on multiple modalities of information, to meaningful signals of supervision for training a KBC system.  Fonduer-based KBC systems are in production for a range of use cases, including at a major online retailer. We compare  Fonduer against state-of-the-art KBC approaches in four different domains. We show that  Fonduer achieves an average improvement of 41 F1 points on the quality of the output knowledge base—and in some cases produces up to 1.87× the number of correct entries—compared to expert-curated public knowledge bases. We also conduct a user study to assess the usability of  Fonduer’s new programming model. We show that after using  Fonduer for only 30 minutes, non-domain experts are able to design KBC systems that achieve on average 23 F1 points higher quality than traditional machine-learning-based KBC approaches.",2018-06,2021-06-05 21:11:16,1301-1316,,2018,Proc ACM SIGMOD Int Conf Manag Data,Fonduer,PubMed Central,PMID: 29937618 PMCID: PMC6013301,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6013301/,,,,PMC:Query2
346,10.1145/3183713.3193567,31289421,PMC6615054,A,Neo4j,Neo4j,"Kalmegh, Prajakta; Lundberg, Harrison; Xu, Frederick; Babu, Shivnath; Roy, Sudeepa",iQCAR: A Demonstration of an Inter-Query Contention Analyzer for Cluster Computing Frameworks,2018,Proceedings. ACM-Sigmod International Conference on Management of Data,,"Unpredictability in query runtimes can arise in a shared cluster as a result of resource contentions caused by inter-query interactions. iQCAR - inter Query Contention AnalyzeR is a system that formally models these interferences between concurrent queries and provides a framework to attribute blame for contentions. iQCAR leverages a multi-level directed acyclic graph called iQC-Graph to diagnose the aberrations in query schedules that lead to these resource contentions. The demonstration will enable users to perform a step-wise deep exploration of such resource contentions faced by a query at various stages of its execution. The interface will allow users to identify top-k victims and sources of contentions, diagnose high-contention nodes and resources in the cluster, and rank their impacts on the performance of a query. Users will also be able to navigate through a set of rules recommended by iQCAR to compare how application of each rule by the cluster scheduler resolves the contentions in subsequent executions.",2018-06,2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:36:32,1721-1724,,2018,Proc ACM SIGMOD Int Conf Manag Data,iQCAR,PubMed Central,PMID: 31289421 PMCID: PMC6615054,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6615054/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
347,10.1145/3299869.3319904,33840884,PMC8034287,A,Neo4j,Neo4j,"Kalmegh, Prajakta; Babu, Shivnath; Roy, Sudeepa",iQCAR: inter-Query Contention Analyzer for Data Analytics Frameworks,2019,Proceedings. ACM-Sigmod International Conference on Management of Data,,"Resource interferences caused by concurrent queries is one of the key reasons for unpredictable performance and missed workload SLAs in cluster computing systems. Analyzing these inter-query resource interactions is critical in order to answer time-sensitive questions like ‘who is creating resource conflicts to my query’. More importantly, diagnosing whether the resource blocked times of a ‘victim’ query are caused by other queries or some other external factor can help the database administrator narrow down the many possibilities of query performance degradation. We introduce iQCAR, an inter-Query Contention Analyzer, that attributes blame for the slowdown of a query to concurrent queries. iQCAR models the resource conflicts using a multi-level directed acyclic graph that can help administrators compare impacts from concurrent queries, identify most contentious queries, resources and hosts in an online execution for a selected time window. Our experiments using TPCDS queries on Apache Spark show that our approach is substantially more accurate than other methods based on overlap time between concurrent queries.",2019-06,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,918-935,,2019,Proc ACM SIGMOD Int Conf Manag Data,iQCAR,PubMed Central,PMID: 33840884 PMCID: PMC8034287,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8034287/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
348,10.1145/3318464.3389726,33132489,PMC7593834,A,Neo4j,Neo4j,"Zhang, Yi; Ives, Zachary G.",Finding Related Tables in Data Lakes for Interactive Data Science,2020,Proceedings. ACM-Sigmod International Conference on Management of Data,,"Many modern data science applications build on data lakes, schema-agnostic repositories of data files and data products that offer limited organization and management capabilities. There is a need to build data lake search capabilities into data science environments, so scientists and analysts can find tables, schemas, workflows, and datasets useful to their task at hand. We develop search and management solutions for the Jupyter Notebook data science platform, to enable scientists to augment training data, find potential features to extract, clean data, and find joinable or linkable tables. Our core methods also generalize to other settings where computational tasks involve execution of programs or scripts.",2020-06,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,1951-1966,,2020,Proc ACM SIGMOD Int Conf Manag Data,,PubMed Central,PMID: 33132489 PMCID: PMC7593834,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7593834/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
349,10.1146/annurev-biodatasci-010820-091627,33954284,PMC8095730,A,Neo4j,Neo4j,"Callahan, Tiffany J.; Tripodi, Ignacio J.; Pielke-Lombardo, Harrison; Hunter, Lawrence E.",Knowledge-Based Biomedical Data Science,2020,Annual review of biomedical data science,,"Knowledge-based biomedical data science involves the design and implementation of computer systems that act as if they knew about biomedicine. Such systems depend on formally represented knowledge in computer systems, often in the form of knowledge graphs. Here we survey recent progress in systems that use formally represented knowledge to address data science problems in both clinical and biological domains, as well as progress on approaches for creating knowledge graphs. Major themes include the relationships between knowledge graphs and machine learning, the use of natural language processing to construct knowledge graphs, and the expansion of novel knowledge-based approaches to clinical and biological domains.",2020-07,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,23-41,,3,Annu Rev Biomed Data Sci,,PubMed Central,PMID: 33954284 PMCID: PMC8095730,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8095730/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
350,10.1146/annurev-genom-120219-080406,32453966,PMC8006571,,,,"Eizenga, Jordan M; Novak, Adam M; Sibbesen, Jonas A; Heumos, Simon; Ghaffaari, Ali; Hickey, Glenn; Chang, Xian; Seaman, Josiah D; Rounthwaite, Robin; Ebler, Jana; Rautiainen, Mikko; Garg, Shilpa; Paten, Benedict; Marschall, Tobias; Sirén, Jouni; Garrison, Erik",Pangenome graphs,2020,Annual review of genomics and human genetics,,"Low-cost whole genome assembly has enabled the collection of haplotype-resolved pangenomes for numerous organisms. In turn, this technological change is encouraging the development of methods that can precisely address the sequence and variation described in large collections of related genomes. These approaches often use graphical models of the pangenome to support algorithms for sequence alignment, visualization, functional genomics, and association studies. The additional information provided to these methods by the pangenome allows them to achieve superior performance on a variety of bioinformatic tasks, including read alignment, variant calling, and genotyping. Pangenome graphs stand to become a ubiquitous tool in genomics. Although it is unclear if they will replace linear reference genomes, their ability to harmoniously relate multiple sequence and coordinate systems will make them useful irrespective of which pangenomic models become most common in the future.",2020-08-31,2021-06-05 21:10:08,139-162,,21,Annu Rev Genomics Hum Genet,,PubMed Central,PMID: 32453966 PMCID: PMC8006571,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8006571/,,,,PMC:Query2
351,10.1152/ajpheart.00175.2018,29775406,PMC6230912,,,,"Liem, David A.; Murali, Sanjana; Sigdel, Dibakar; Shi, Yu; Wang, Xuan; Shen, Jiaming; Choi, Howard; Caufield, John H.; Wang, Wei; Ping, Peipei; Han, JiaWei",Phrase mining of textual data to analyze extracellular matrix protein patterns across cardiovascular disease,2018,American Journal of Physiology - Heart and Circulatory Physiology,,"Extracellular matrix (ECM) proteins have been shown to play important roles regulating multiple biological processes in an array of organ systems, including the cardiovascular system. Using a novel bioinformatics text-mining tool, we studied six categories of cardiovascular disease (CVD), namely, ischemic heart disease, cardiomyopathies, cerebrovascular accident, congenital heart disease, arrhythmias, and valve disease, anticipating novel ECM protein-disease and protein-protein relationships hidden within vast quantities of textual data. We conducted a phrase-mining analysis, delineating the relationships of 709 ECM proteins with the 6 groups of CVDs reported in 1,099,254 abstracts. The technology pipeline known as Context-Aware Semantic Online Analytical Processing was applied to semantically rank the association of proteins to each CVD and all six CVDs, performing analyses to quantify each protein-disease relationship. We performed principal component analysis and hierarchical clustering of the data, where each protein was visualized as a six-dimensional vector. We found that ECM proteins display variable degrees of association with the six CVDs; certain CVDs share groups of associated proteins, whereas others have divergent protein associations. We identified 82 ECM proteins sharing associations with all 6 CVDs. Our bioinformatics analysis ascribed distinct ECM pathways (via Reactome) from this subset of proteins, namely, insulin-like growth factor regulation and interleukin-4 and interleukin-13 signaling, suggesting their contribution to the pathogenesis of all six CVDs. Finally, we performed hierarchical clustering analysis and identified protein clusters predominantly associated with a targeted CVD; analyses of these proteins revealed unexpected insights underlying the key ECM-related molecular pathogenesis of each CVD, including virus assembly and release in arrhythmias. , NEW & NOTEWORTHY The present study is the first application of a text-mining algorithm to characterize the relationships of 709 extracellular matrix-related proteins with 6 categories of cardiovascular disease described in 1,099,254 abstracts. Our analysis informed unexpected extracellular matrix functions, pathways, and molecular relationships implicated in the six cardiovascular diseases.",2018-10-01,2021-06-05 21:11:16,H910-H924,4,315,Am J Physiol Heart Circ Physiol,,PubMed Central,PMID: 29775406 PMCID: PMC6230912,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6230912/,,,,PMC:Query2
352,10.1152/ajplung.00139.2017,28798251,PMC5792185,A,Virtuoso,Virtuoso,"Ardini-Poleske, Maryanne E.; Clark, Robert F.; Ansong, Charles; Carson, James P.; Corley, Richard A.; Deutsch, Gail H.; Hagood, James S.; Kaminski, Naftali; Mariani, Thomas J.; Potter, Steven S.; Pryhuber, Gloria S.; Warburton, David; Whitsett, Jeffrey A.; Palmer, Scott M.; Ambalavanan, Namasivayam",LungMAP: The Molecular Atlas of Lung Development Program,2017,American Journal of Physiology - Lung Cellular and Molecular Physiology,,"The National Heart, Lung, and Blood Institute is funding an effort to create a molecular atlas of the developing lung (LungMAP) to serve as a research resource and public education tool. The lung is a complex organ with lengthy development time driven by interactive gene networks and dynamic cross talk among multiple cell types to control and coordinate lineage specification, cell proliferation, differentiation, migration, morphogenesis, and injury repair. A better understanding of the processes that regulate lung development, particularly alveologenesis, will have a significant impact on survival rates for premature infants born with incomplete lung development and will facilitate lung injury repair and regeneration in adults. A consortium of four research centers, a data coordinating center, and a human tissue repository provides high-quality molecular data of developing human and mouse lungs. LungMAP includes mouse and human data for cross correlation of developmental processes across species. LungMAP is generating foundational data and analysis, creating a web portal for presentation of results and public sharing of data sets, establishing a repository of young human lung tissues obtained through organ donor organizations, and developing a comprehensive lung ontology that incorporates the latest findings of the consortium. The LungMAP website (www.lungmap.net) currently contains more than 6,000 high-resolution lung images and transcriptomic, proteomic, and lipidomic human and mouse data and provides scientific information to stimulate interest in research careers for young audiences. This paper presents a brief description of research conducted by the consortium, database, and portal development and upcoming features that will enhance the LungMAP experience for a community of users.",2017-11-01,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:59:14,L733-L740,5,313,Am J Physiol Lung Cell Mol Physiol,LungMAP,PubMed Central,PMID: 28798251 PMCID: PMC5792185,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5792185/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
353,10.1155/2009/502527,20052387,PMC2801005,,,,"Yılmaz, Burcu; Göktürk, Mehmet",Interactive Data Mining for Molecular Graphs,2009,Journal of Automated Methods and Management in Chemistry,,"Designing new medical drugs for a specific disease requires extensive analysis of many molecules that have an activity for the disease. The main goal of these extensive analyses is to discover substructures (fragments) that account for the activity of these molecules. Once they are discovered, these fragments are used to understand the structure of new drugs and design new medicines for the disease. In this paper, we propose an interactive approach for visual molecule mining to discover fragments of molecules that are responsible for the desired activity with respect to a specific disease. Our approach visualizes molecular data in a form that can be interpreted by a human expert. Using a pipelining structure, it enables experts to contribute to the solution with their expertise at different levels. In order to derive desired fragments, it combines histogram-based filtering and clustering methods in a novel way. This combination enables a flexible determination of frequent fragments that repeat in molecules exactly or with some variations.",2009,2021-06-05 21:13:27,,,2009,J Autom Methods Manag Chem,,PubMed Central,PMID: 20052387 PMCID: PMC2801005,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2801005/,,,,PMC:Query2
354,10.1155/2009/928286,19920859,PMC2775910,,,,"Lund, A. W.; Bilgin, C. C.; Hasan, M. A.; McKeen, L. M.; Stegemann, J. P.; Yener, B.; Zaki, M. J.; Plopper, G. E.",Quantification of Spatial Parameters in 3D Cellular Constructs Using Graph Theory,2009,Journal of Biomedicine and Biotechnology,,"Multispectral three-dimensional (3D) imaging provides spatial information for biological structures that cannot be measured by traditional methods. This work presents a method of tracking 3D biological structures to quantify changes over time using graph theory. Cell-graphs were generated based on the pairwise distances, in 3D-Euclidean space, between nuclei during collagen I gel compaction. From these graphs quantitative features are extracted that measure both the global topography and the frequently occurring local structures of the “tissue constructs.” The feature trends can be controlled by manipulating compaction through cell density and are significant when compared to random graphs. This work presents a novel methodology to track a simple 3D biological event and quantitatively analyze the underlying structural change. Further application of this method will allow for the study of complex biological problems that require the quantification of temporal-spatial information in 3D and establish a new paradigm in understanding structure-function relationships.",2009,2021-06-05 21:13:27,,,2009,J Biomed Biotechnol,,PubMed Central,PMID: 19920859 PMCID: PMC2775910,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2775910/,,,,PMC:Query2
355,10.1155/2014/749028,25121135,PMC4121100,,,,"Chen, Yifan; Zhao, Xiang; Xiao, Chuan; Zhang, Weiming; Tang, Jiuyang",Efficient and Scalable Graph Similarity Joins in MapReduce,2014,The Scientific World Journal,,"Along with the emergence of massive graph-modeled data, it is of great importance to investigate graph similarity joins due to their wide applications for multiple purposes, including data cleaning, and near duplicate detection. This paper considers graph similarity joins with edit distance constraints, which return pairs of graphs such that their edit distances are no larger than a given threshold. Leveraging the MapReduce programming model, we propose MGSJoin, a scalable algorithm following the filtering-verification framework for efficient graph similarity joins. It relies on counting overlapping graph signatures for filtering out nonpromising candidates. With the potential issue of too many key-value pairs in the filtering phase, spectral Bloom filters are introduced to reduce the number of key-value pairs. Furthermore, we integrate the multiway join strategy to boost the verification, where a MapReduce-based method is proposed for GED calculation. The superior efficiency and scalability of the proposed algorithms are demonstrated by extensive experimental results.",2014,2021-06-05 21:12:40,,,2014,ScientificWorldJournal,,PubMed Central,PMID: 25121135 PMCID: PMC4121100,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4121100/,,,,PMC:Query2
356,10.1155/2014/901419,25937954,PMC4393075,A,Neo4j,Neo4j,"Valentini, Giorgio",Hierarchical Ensemble Methods for Protein Function Prediction,2014,ISRN Bioinformatics,,"Protein function prediction is a complex multiclass multilabel classification problem, characterized by multiple issues such as the incompleteness of the available annotations, the integration of multiple sources of high dimensional biomolecular data, the unbalance of several functional classes, and the difficulty of univocally determining negative examples. Moreover, the hierarchical relationships between functional classes that characterize both the Gene Ontology and FunCat taxonomies motivate the development of hierarchy-aware prediction methods that showed significantly better performances than hierarchical-unaware “flat” prediction methods. In this paper, we provide a comprehensive review of hierarchical methods for protein function prediction based on ensembles of learning machines. According to this general approach, a separate learning machine is trained to learn a specific functional term and then the resulting predictions are assembled in a “consensus” ensemble decision, taking into account the hierarchical relationships between classes. The main hierarchical ensemble methods proposed in the literature are discussed in the context of existing computational methods for protein function prediction, highlighting their characteristics, advantages, and limitations. Open problems of this exciting research area of computational biology are finally considered, outlining novel perspectives for future research.",2014-05-04,2021-06-05 21:13:27; 2021-06-05 20:56:20; 2021-06-05 20:37:08,,,2014,ISRN Bioinform,,PubMed Central,PMID: 25937954 PMCID: PMC4393075,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4393075/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
357,10.1155/2014/957231,24772189,PMC3989774,A,AllegroGraph,AllegroGraph,"Chen, Xi; Chen, Huajun; Bi, Xuan; Gu, Peiqin; Chen, Jiaoyan; Wu, Zhaohui",BioTCM-SE: A Semantic Search Engine for the Information Retrieval of Modern Biology and Traditional Chinese Medicine,2014,Computational and Mathematical Methods in Medicine,,"Understanding the functional mechanisms of the complex biological system as a whole is drawing more and more attention in global health care management. Traditional Chinese Medicine (TCM), essentially different from Western Medicine (WM), is gaining increasing attention due to its emphasis on individual wellness and natural herbal medicine, which satisfies the goal of integrative medicine. However, with the explosive growth of biomedical data on the Web, biomedical researchers are now confronted with the problem of large-scale data analysis and data query. Besides that, biomedical data also has a wide coverage which usually comes from multiple heterogeneous data sources and has different taxonomies, making it hard to integrate and query the big biomedical data. Embedded with domain knowledge from different disciplines all regarding human biological systems, the heterogeneous data repositories are implicitly connected by human expert knowledge. Traditional search engines cannot provide accurate and comprehensive search results for the semantically associated knowledge since they only support keywords-based searches. In this paper, we present BioTCM-SE, a semantic search engine for the information retrieval of modern biology and TCM, which provides biologists with a comprehensive and accurate associated knowledge query platform to greatly facilitate the implicit knowledge discovery between WM and TCM.",2014,2021-06-05 21:13:27; 2021-06-06 06:38:41; 2021-06-05 20:56:20,,,2014,Comput Math Methods Med,BioTCM-SE,PubMed Central,PMID: 24772189 PMCID: PMC3989774,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3989774/,,AllegroGraph,AllegroGraph,PMC:Query3; PMC:AllegroGraph; PMC:Query2
358,10.1155/2015/475410,26221624,PMC4496660,A,GraphDB,GraphDB,"Çelik, Duygu",FoodWiki: Ontology-Driven Mobile Safe Food Consumption System,2015,The Scientific World Journal,,"An ontology-driven safe food consumption mobile system is considered. Over 3,000 compounds are being added to processed food, with numerous effects on the food: to add color, stabilize, texturize, preserve, sweeten, thicken, add flavor, soften, emulsify, and so forth. According to World Health Organization, governments have lately focused on legislation to reduce such ingredients or compounds in manufactured foods as they may have side effects causing health risks such as heart disease, cancer, diabetes, allergens, and obesity. By supervising what and how much to eat as well as what not to eat, we can maximize a patient's life quality through avoidance of unhealthy ingredients. Smart e-health systems with powerful knowledge bases can provide suggestions of appropriate foods to individuals. Next-generation smart knowledgebase systems will not only include traditional syntactic-based search, which limits the utility of the search results, but will also provide semantics for rich searching. In this paper, performance of concept matching of food ingredients is semantic-based, meaning that it runs its own semantic based rule set to infer meaningful results through the proposed Ontology-Driven Mobile Safe Food Consumption System (FoodWiki).",2015,2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-06 06:54:16,,,2015,ScientificWorldJournal,FoodWiki,PubMed Central,PMID: 26221624 PMCID: PMC4496660,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4496660/,,GraphDB,GraphDB,PMC:Query3; PMC:GraphDB; PMC:Query2
359,10.1155/2015/502795,26558254,PMC4629038,,,,"Aniceto, Rodrigo; Xavier, Rene; Guimarães, Valeria; Hondo, Fernanda; Holanda, Maristela; Walter, Maria Emilia; Lifschitz, Sérgio",Evaluating the Cassandra NoSQL Database Approach for Genomic Data Persistency,2015,International Journal of Genomics,,"Rapid advances in high-throughput sequencing techniques have created interesting computational challenges in bioinformatics. One of them refers to management of massive amounts of data generated by automatic sequencers. We need to deal with the persistency of genomic data, particularly storing and analyzing these large-scale processed data. To find an alternative to the frequently considered relational database model becomes a compelling task. Other data models may be more effective when dealing with a very large amount of nonconventional data, especially for writing and retrieving operations. In this paper, we discuss the Cassandra NoSQL database approach for storing genomic data. We perform an analysis of persistency and I/O operations with real data, using the Cassandra database system. We also compare the results obtained with a classical relational database system and another NoSQL database approach, MongoDB.",2015,2021-06-05 21:12:40,,,2015,Int J Genomics,,PubMed Central,PMID: 26558254 PMCID: PMC4629038,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4629038/,,,,PMC:Query2
360,10.1155/2015/904541,26125026,PMC4466500,A,OrientDB; Neo4j,OrientDB; Neo4j,"de Brevern, Alexandre G.; Meyniel, Jean-Philippe; Fairhead, Cécile; Neuvéglise, Cécile; Malpertuy, Alain",Trends in IT Innovation to Build a Next Generation Bioinformatics Solution to Manage and Analyse Biological Big Data Produced by NGS Technologies,2015,BioMed Research International,,"Sequencing the human genome began in 1994, and 10 years of work were necessary in order to provide a nearly complete sequence. Nowadays, NGS technologies allow sequencing of a whole human genome in a few days. This deluge of data challenges scientists in many ways, as they are faced with data management issues and analysis and visualization drawbacks due to the limitations of current bioinformatics tools.  In this paper, we describe how the NGS Big Data revolution changes the way of managing and analysing data. We present how biologists are confronted with abundance of methods, tools, and data formats. To overcome these problems, focus on Big Data Information Technology innovations from web and business intelligence. We underline the interest of NoSQL databases, which are much more efficient than relational databases. Since Big Data leads to the loss of interactivity with data during analysis due to high processing time, we describe solutions from the Business Intelligence that allow one to regain interactivity whatever the volume of data is. We illustrate this point with a focus on the Amadea platform. Finally, we discuss visualization challenges posed by Big Data and present the latest innovations with JavaScript graphic libraries.",2015,2021-06-06 06:49:06; 2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-05 20:37:08,,,2015,Biomed Res Int,,PubMed Central,PMID: 26125026 PMCID: PMC4466500,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4466500/,,OrientDB; Neo4j,OrientDB; Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2; PMC:OrientDB
361,10.1155/2016/3506261,27698659,PMC5029052,,,,"Bi, Size; Liang, Xiao; Huang, Ting-lei",Fracture Mechanics Method for Word Embedding Generation of Neural Probabilistic Linguistic Model,2016,Computational Intelligence and Neuroscience,,"Word embedding, a lexical vector representation generated via the neural linguistic model (NLM), is empirically demonstrated to be appropriate for improvement of the performance of traditional language model. However, the supreme dimensionality that is inherent in NLM contributes to the problems of hyperparameters and long-time training in modeling. Here, we propose a force-directed method to improve such problems for simplifying the generation of word embedding. In this framework, each word is assumed as a point in the real world; thus it can approximately simulate the physical movement following certain mechanics. To simulate the variation of meaning in phrases, we use the fracture mechanics to do the formation and breakdown of meaning combined by a 2-gram word group. With the experiments on the natural linguistic tasks of part-of-speech tagging, named entity recognition and semantic role labeling, the result demonstrated that the 2-dimensional word embedding can rival the word embeddings generated by classic NLMs, in terms of accuracy, recall, and text visualization.",2016,2021-06-05 21:12:01,,,2016,Comput Intell Neurosci,,PubMed Central,PMID: 27698659 PMCID: PMC5029052,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5029052/,,,,PMC:Query2
362,10.1155/2017/4271273,29065602,PMC5591970,,,,"Arch-int, Ngamnij; Arch-int, Somjit; Sonsilphong, Suphachoke; Wanchai, Paweena",Graph-Based Semantic Web Service Composition for Healthcare Data Integration,2017,Journal of Healthcare Engineering,,"Within the numerous and heterogeneous web services offered through different sources, automatic web services composition is the most convenient method for building complex business processes that permit invocation of multiple existing atomic services. The current solutions in functional web services composition lack autonomous queries of semantic matches within the parameters of web services, which are necessary in the composition of large-scale related services. In this paper, we propose a graph-based Semantic Web Services composition system consisting of two subsystems: management time and run time. The management-time subsystem is responsible for dependency graph preparation in which a dependency graph of related services is generated automatically according to the proposed semantic matchmaking rules. The run-time subsystem is responsible for discovering the potential web services and nonredundant web services composition of a user's query using a graph-based searching algorithm. The proposed approach was applied to healthcare data integration in different health organizations and was evaluated according to two aspects: execution time measurement and correctness measurement.",2017,2021-06-05 21:12:01,,,2017,J Healthc Eng,,PubMed Central,PMID: 29065602 PMCID: PMC5591970,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5591970/,,,,PMC:Query2
363,10.1155/2020/4951251,33083467,PMC7556071,,,,"Yao, Xiaocong; Liu, Minbo; Jin, Fang; Zhu, Zhongxin",Comprehensive Analysis of Differentially Expressed Circular RNAs in Patients with Senile Osteoporotic Vertebral Compression Fracture,2020,BioMed Research International,,"Aim  Circular RNAs (circRNAs) have been found to contribute to the regulation of many diseases and are abundantly expressed in various organisms. The present study is aimed at systematically characterizing the circRNA expression profiles in patients with senile osteoporotic vertebral compression fracture (OVCF) and predicting the potential functions of the regulatory networks correlated with these differentially expressed circRNAs.  Methods  The circRNA expression profile in patients with senile OVCF was explored by using RNA sequencing. The prediction of the enriched signaling pathways and circRNA-miRNA networks was conducted by bioinformatics analysis. Real-time quantitative PCR was used to validate the selected differentially expressed circRNAs from 20 patients with senile OVCF relative to 20 matched healthy controls.  Results  A total of 884 differentially expressed circRNAs were identified, of which 554 were upregulated and 330 were downregulated. The top 15 signaling pathways associated with these differentially expressed circRNAs were predicted. The result of qRT-PCR of the selected circRNAs was consistent with RNA sequencing.  Conclusions  CircRNAs are differentially expressed in patients with senile OVCF, which might contribute to the pathophysiological mechanism of senile osteoporosis.",2020-10-01,2021-06-05 21:10:08,,,2020,Biomed Res Int,,PubMed Central,PMID: 33083467 PMCID: PMC7556071,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7556071/,,,,PMC:Query2
364,10.1155/2020/6473745,32382301,PMC7195658,,,,"Tao, Yan-gu; Huang, Xiu-Fang; Wang, Jun-yan; Kang, Meng-ru; Wang, Ling-jun; Xian, Shao-xiang",Exploring Molecular Mechanism of Huangqi in Treating Heart Failure Using Network Pharmacology,2020,Evidence-based Complementary and Alternative Medicine : eCAM,,"Heart failure (HF), a clinical syndrome with a high incidence due to various reasons, is the advanced stage of most cardiovascular diseases. Huangqi is an effective treatment for cardiovascular disease, which has multitarget, multipathway functions. Therefore, we used network pharmacology to explore the molecular mechanism of Huangqi in treating HF. In this study, 21 compounds of Huangqi, which involved 407 targets, were obtained and reconfirmed using TCMSP and PubChem databases. Moreover, we used Cytoscape 3.7.1 to construct compound-target network and screened the top 10 compounds. 378 targets related to HF were obtained from CTD and GeneCards databases and HF-target network was constructed by Cytoscape 3.7.1. The 46 overlapping targets of HF and Huangqi were gotten by Draw Venn Diagram. STRING database was used to set up a protein-protein interaction network, and MCODE module and the top 5 targets with the highest degree for overlapping targets were obtained. GO analysis performed by Metascape indicated that the overlapping targets were mainly enriched in blood vessel development, reactive oxygen species metabolic process, response to wounding, blood circulation, and so on. KEGG analysis analyzed by ClueGO revealed that overlapping targets were mainly enriched in AGE-RAGE signaling pathway in diabetic complications, IL-17 signaling pathway, HIF-1 signaling pathway, c-type lectin receptor signaling pathway, relaxin signaling pathway, and so on. Finally, molecular docking showed that top 10 compounds of Huangqi also had good binding activities to important targets compared with digoxin, which was carried out in CB-Dock molecular docking server. In conclusion, Huangqi has potential effect on regulating overlapping targets and GE-RAGE signaling pathway in diabetic complications, IL-17 signaling pathway, HIF-1 signaling pathway, and so on to be a latent multitarget, multipathway treatment for HF.",2020-04-23,2021-06-05 21:10:08,,,2020,Evid Based Complement Alternat Med,,PubMed Central,PMID: 32382301 PMCID: PMC7195658,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7195658/,,,,PMC:Query2
365,10.1155/2020/8865808,33489061,PMC7787845,A,Neo4j; ArangoDB; OrientDB; AllegroGraph,Neo4j; ArangoDB; OrientDB; AllegroGraph,"Hammad, Rafat; Barhoush, Malek; Abed-alguni, Bilal H.",A Semantic-Based Approach for Managing Healthcare Big Data: A Survey,2020,Journal of Healthcare Engineering,,"Healthcare information systems can reduce the expenses of treatment, foresee episodes of pestilences, help stay away from preventable illnesses, and improve personal life satisfaction. As of late, considerable volumes of heterogeneous and differing medicinal services data are being produced from different sources covering clinic records of patients, lab results, and wearable devices, making it hard for conventional data processing to handle and manage this amount of data. Confronted with the difficulties and challenges facing the process of managing healthcare big data such as volume, velocity, and variety, healthcare information systems need to use new methods and techniques for managing and processing such data to extract useful information and knowledge. In the recent few years, a large number of organizations and companies have shown enthusiasm for using semantic web technologies with healthcare big data to convert data into knowledge and intelligence. In this paper, we review the state of the art on the semantic web for the healthcare industry. Based on our literature review, we will discuss how different techniques, standards, and points of view created by the semantic web community can participate in addressing the challenges related to healthcare big data.",2020-11-23,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-06 06:42:51; 2021-06-05 21:09:36; 2021-06-06 06:49:06; 2021-06-06 06:38:41,,,2020,J Healthc Eng,A Semantic-Based Approach for Managing Healthcare Big Data,PubMed Central,PMID: 33489061 PMCID: PMC7787845,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7787845/,,Neo4j; ArangoDB; OrientDB; AllegroGraph,Neo4j; ArangoDB; OrientDB; AllegroGraph,PMC:AllegroGraph; PMC:Query2; PMC:OrientDB; PMC:Query3; PMC:Neo4j; PMC:ArangoDB
366,10.1155/2021/5531327,33833858,PMC8016585,,,,"Cheng, Binjie; Zhang, Jin; Liu, Hong; Cai, Meiling; Wang, Ying",Research on Medical Knowledge Graph for Stroke,2021,Journal of Healthcare Engineering,,"Knowledge graph can effectively analyze and construct the essential characteristics of data. At present, scholars have proposed many knowledge graph models from different perspectives, especially in the medical field, but there are still relatively few studies on stroke diseases using medical knowledge graphs. Therefore, this paper will build a medical knowledge graph model for stroke. Firstly, a stroke disease dictionary and an ontology database are built through the international standard medical term sets and semiautomatic extraction-based crowdsourcing website data. Secondly, the external data are linked to the nodes of the existing knowledge graph via the entity similarity measures and the knowledge representation is performed by the knowledge graph embedded model. Thirdly, the structure of the established knowledge graph is modified continuously through iterative updating. Finally, in the experimental part, the proposed stroke medical knowledge graph is applied to the real stroke data and the performance of the proposed knowledge graph approach on the series of Trans ∗ models is compared.",2021-03-24,2021-06-05 21:09:36,,,2021,J Healthc Eng,,PubMed Central,PMID: 33833858 PMCID: PMC8016585,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8016585/,,,,PMC:Query2
367,10.1155/2021/6689740,33688337,PMC7920719,,,,"Zhang, Xiao; Zhao, Guorui",Taking a Closed-Book Examination: Decoupling KB-Based Inference by Virtual Hypothesis for Answering Real-World Questions,2021,Computational Intelligence and Neuroscience,,"Complex question answering in real world is a comprehensive and challenging task due to its demand for deeper question understanding and deeper inference. Information retrieval is a common solution and easy to implement, but it cannot answer questions which need long-distance dependencies across multiple documents. Knowledge base (KB) organizes information as a graph, and KB-based inference can employ logic formulas or knowledge embeddings to capture such long-distance semantic associations. However, KB-based inference has not been applied to real-world question answering well, because there are gaps among natural language, complex semantic structure, and appropriate hypothesis for inference. We propose decoupling KB-based inference by transforming a question into a high-level triplet in the KB, which makes it possible to apply KB-based inference methods to answer complex questions. In addition, we create a specialized question answering dataset only for inference, and our method is proved to be effective by conducting experiments on both AI2 Science Questions dataset and ours.",2021-02-22,2021-06-05 21:09:36,,,2021,Comput Intell Neurosci,Taking a Closed-Book Examination,PubMed Central,PMID: 33688337 PMCID: PMC7920719,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7920719/,,,,PMC:Query2
368,10.1158/0008-5472.CAN-17-0615,29092954,PMC5690492,A,Neo4j,Neo4j,"Savova, Guergana K.; Tseytlin, Eugene; Finan, Sean P.; Castine, Melissa; Miller, Timothy A.; Medvedeva, Olga P.; Harris, David A.; Hochheiser, Harry S.; Lin, Chen; Chavan, Girish R.; Jacobson, Rebecca S.",DeepPhe - A Natural Language Processing System for Extracting Cancer Phenotypes from Clinical Records,2017,Cancer research,,"Precise phenotype information is needed to understand the effects of genetic and epigenetic changes on tumor behavior and responsiveness. Extraction and representation of cancer phenotypes is currently mostly performed manually making it difficult to correlate phenotypic data to genomic data. In addition, genomic data is being produced at an increasingly faster pace, exacerbating the problem. The DeepPhe software enables automated extraction of detailed phenotype information from Electronic Medical Records of cancer patients. The system implements advanced Natural Language Processing and knowledge engineering methods within a flexible modular architecture, and was evaluated using a manually-annotated dataset of the University of Pittsburgh Medical Center (UPMC) breast cancer patients. The resulting platform provides critical and missing computational methods for computational phenotyping. Working in tandem with advanced analysis of high-throughput sequencing, these approaches will further accelerate the transition to precision cancer treatment.",2017-11-01,2021-06-05 20:55:40; 2021-06-05 21:11:16; 2021-06-05 20:36:32,e115-e118,21,77,Cancer Res,,PubMed Central,PMID: 29092954 PMCID: PMC5690492,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5690492/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
369,10.1161/CIRCOUTCOMES.116.003041,28051772,PMC5217475,A,Neo4j,Neo4j,"Carson, Matthew B.; Scholtens, Denise M.; Frailey, Conor N.; Gravenor, Stephanie J.; Powell, Emilie S.; Wang, Amy Y.; Kricke, Gayle Shier; Ahmad, Faraz S.; Mutharasan, R. Kannan; Soulakis, Nicholas D.",Characterizing Teamwork in Cardiovascular Care Outcomes: A Network Analytics Approach,2016,Circulation. Cardiovascular quality and outcomes,,"Background The nature of teamwork in healthcare is complex and interdisciplinary, and provider collaboration based on shared patient encounters is crucial to its success. Characterizing the intensity of working relationships with risk adjusted patient outcomes supplies insight into provider interactions in a hospital environment. Methods and Results We extracted four years of patient, provider, and activity data for encounters in an inpatient cardiology unit from Northwestern Medicine’s Enterprise Data Warehouse. We then created a provider-patient network to identify healthcare providers who jointly participated in patient encounters and calculated satisfaction rates for provider-provider pairs. We demonstrated the application of a novel parameter, the Shared Positive Outcome Ratio (SPOR), an objective composite measure that quantifies a given pair’s concentration of positive outcomes over a set of shared patients. We compared an observed collaboration network of 334 providers and 3,453 relationships to 1,000 networks with SPOR scores based on randomized outcomes and found 188 collaborative relationships between pairs of providers that showed significantly higher than expected patient satisfaction ratings. A group of 22 providers performed exceptionally in terms of patient satisfaction. Our results indicate high variability in collaboration scores across the network and highlight our ability to identify relationships with both higher and lower than expected scores across a set of shared patient encounters. Conclusions Satisfaction rates appear to vary across different teams of providers. Team collaboration can be quantified using a composite measure of collaboration across provider pairs. Tracking provider pair outcomes over a sufficient set of shared encounters may inform quality improvement strategies, such as optimizing team staffing, identifying characteristics and practices of high-performing teams, developing evidence-based team guidelines, and redesigning inpatient care processes.",2016-11,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:37:08,670-678,6,9,Circ Cardiovasc Qual Outcomes,Characterizing Teamwork in Cardiovascular Care Outcomes,PubMed Central,PMID: 28051772 PMCID: PMC5217475,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5217475/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
370,10.1162/dint_a_00058,33103120,PMC7583433,A,Virtuoso; Neo4j,Virtuoso; Neo4j,"Rashid, Sabbir M.; McCusker, James P.; Pinheiro, Paulo; Bax, Marcello P.; Santos, Henrique; Stingone, Jeanette A.; Das, Amar K.; McGuinness, Deborah L.",The Semantic Data Dictionary – An Approach for Describing and Annotating Data,2020,Data intelligence,,"It is common practice for data providers to include text descriptions for each column when publishing datasets in the form of data dictionaries. While these documents are useful in helping an end-user properly interpret the meaning of a column in a dataset, existing data dictionaries typically are not machine-readable and do not follow a common specification standard. We introduce the Semantic Data Dictionary, a specification that formalizes the assignment of a semantic representation of data, enabling standardization and harmonization across diverse datasets. In this paper, we present our Semantic Data Dictionary work in the context of our work with biomedical data; however, the approach can and has been used in a wide range of domains. The rendition of data in this form helps promote improved discovery, interoperability, reuse, traceability, and reproducibility. We present the associated research and describe how the Semantic Data Dictionary can help address existing limitations in the related literature. We discuss our approach, present an example by annotating portions of the publicly available National Health and Nutrition Examination Survey dataset, present modeling challenges, and describe the use of this approach in sponsored research, including our work on a large NIH-funded exposure and health data portal and in the RPI-IBM collaborative Health Empowerment by Analytics, Learning, and Semantics project. We evaluate this work in comparison with traditional data dictionaries, mapping languages, and data integration tools.",2020,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 20:59:14; 2021-06-05 21:09:36,443-486,4,2,Data Intell,,PubMed Central,PMID: 33103120 PMCID: PMC7583433,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7583433/,,Virtuoso; Neo4j,Virtuoso; Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2; PMC:Virtuoso
371,10.1177/1176934319889974,31839702,PMC6896126,A,ArangoDB; OrientDB; Neo4j,ArangoDB; OrientDB; Neo4j,"Wercelens, Polyane; da Silva, Waldeyr; Hondo, Fernanda; Castro, Klayton; Walter, Maria Emília; Araújo, Aletéia; Lifschitz, Sergio; Holanda, Maristela",Bioinformatics Workflows With NoSQL Database in Cloud Computing,2019,Evolutionary Bioinformatics Online,,"Scientific workflows can be understood as arrangements of managed activities executed by different processing entities. It is a regular Bioinformatics approach applying workflows to solve problems in Molecular Biology, notably those related to sequence analyses. Due to the nature of the raw data and the in silico environment of Molecular Biology experiments, apart from the research subject, 2 practical and closely related problems have been studied: reproducibility and computational environment. When aiming to enhance the reproducibility of Bioinformatics experiments, various aspects should be considered. The reproducibility requirements comprise the data provenance, which enables the acquisition of knowledge about the trajectory of data over a defined workflow, the settings of the programs, and the entire computational environment. Cloud computing is a booming alternative that can provide this computational environment, hiding technical details, and delivering a more affordable, accessible, and configurable on-demand environment for researchers. Considering this specific scenario, we proposed a solution to improve the reproducibility of Bioinformatics workflows in a cloud computing environment using both Infrastructure as a Service (IaaS) and Not only SQL (NoSQL) database systems. To meet the goal, we have built 3 typical Bioinformatics workflows and ran them on 1 private and 2 public clouds, using different types of NoSQL database systems to persist the provenance data according to the Provenance Data Model (PROV-DM). We present here the results and a guide for the deployment of a cloud environment for Bioinformatics exploring the characteristics of various NoSQL database systems to persist provenance data.",2019-12-05,2021-06-05 20:35:57; 2021-06-06 06:42:51; 2021-06-06 06:49:06; 2021-06-05 21:10:37; 2021-06-05 20:55:01,,,15,Evol Bioinform Online,,PubMed Central,PMID: 31839702 PMCID: PMC6896126,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6896126/,,ArangoDB; OrientDB; Neo4j,ArangoDB; OrientDB; Neo4j,PMC:Query2; PMC:OrientDB; PMC:Query3; PMC:Neo4j; PMC:ArangoDB
372,10.1177/1535370216633795,26900164,PMC4950314,,,,"Nagahawatte, Panduka; Willis, Ethan; Sakauye, Mark; Jose, Rony; Chen, Hao; Davis, Robert L",Featured Article: Genotation: Actionable knowledge for the scientific reader,2016,Experimental Biology and Medicine,,"We present an article viewer application that allows a scientific reader to easily discover and share knowledge by linking genomics-related concepts to knowledge of disparate biomedical databases. High-throughput data streams generated by technical advancements have contributed to scientific knowledge discovery at an unprecedented rate. Biomedical Informaticists have created a diverse set of databases to store and retrieve the discovered knowledge. The diversity and abundance of such resources present biomedical researchers a challenge with knowledge discovery. These challenges highlight a need for a better informatics solution. We use a text mining algorithm, Genomine, to identify gene symbols from the text of a journal article. The identified symbols are supplemented with information from the GenoDB knowledgebase. Self-updating GenoDB contains information from NCBI Gene, Clinvar, Medgen, dbSNP, KEGG, PharmGKB, Uniprot, and Hugo Gene databases. The journal viewer is a web application accessible via a web browser. The features described herein are accessible on www.genotation.org. The Genomine algorithm identifies gene symbols with an accuracy shown by .65 F-Score. GenoDB currently contains information regarding 59,905 gene symbols, 5633 drug–gene relationships, 5981 gene–disease relationships, and 713 pathways. This application provides scientific readers with actionable knowledge related to concepts of a manuscript. The reader will be able to save and share supplements to be visualized in a graphical manner. This provides convenient access to details of complex biological phenomena, enabling biomedical researchers to generate novel hypothesis to further our knowledge in human health. This manuscript presents a novel application that integrates genomic, proteomic, and pharmacogenomic information to supplement content of a biomedical manuscript and enable readers to automatically discover actionable knowledge.",2016-06,2021-06-05 21:12:40,1202-1209,11,241,Exp Biol Med (Maywood),Featured Article,PubMed Central,PMID: 26900164 PMCID: PMC4950314,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4950314/,,,,PMC:Query2
373,10.1186/1471-2105-10-376,19917102,PMC2784781,,,,"Dogrusoz, Ugur; Cetintas, Ahmet; Demir, Emek; Babur, Ozgun",Algorithms for effective querying of compound graph-based pathway databases,2009,BMC Bioinformatics,,"Background Graph-based pathway ontologies and databases are widely used to represent data about cellular processes. This representation makes it possible to programmatically integrate cellular networks and to investigate them using the well-understood concepts of graph theory in order to predict their structural and dynamic properties. An extension of this graph representation, namely hierarchically structured or compound graphs, in which a member of a biological network may recursively contain a sub-network of a somehow logically similar group of biological objects, provides many additional benefits for analysis of biological pathways, including reduction of complexity by decomposition into distinct components or modules. In this regard, it is essential to effectively query such integrated large compound networks to extract the sub-networks of interest with the help of efficient algorithms and software tools. Results Towards this goal, we developed a querying framework, along with a number of graph-theoretic algorithms from simple neighborhood queries to shortest paths to feedback loops, that is applicable to all sorts of graph-based pathway databases, from PPIs (protein-protein interactions) to metabolic and signaling pathways. The framework is unique in that it can account for compound or nested structures and ubiquitous entities present in the pathway data. In addition, the queries may be related to each other through ""AND"" and ""OR"" operators, and can be recursively organized into a tree, in which the result of one query might be a source and/or target for another, to form more complex queries. The algorithms were implemented within the querying component of a new version of the software tool PATIKAweb (Pathway Analysis Tool for Integration and Knowledge Acquisition) and have proven useful for answering a number of biologically significant questions for large graph-based pathway databases. Conclusion The PATIKA Project Web site is http://www.patika.org. PATIKAweb version 2.1 is available at http://web.patika.org.",2009-11-16,2021-06-05 21:13:27,376,,10,BMC Bioinformatics,,PubMed Central,PMID: 19917102 PMCID: PMC2784781,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2784781/,,,,PMC:Query2
374,10.1186/1471-2105-10-S1-S46,19208148,PMC2648771,,,,"Jia, Yi; Huan, Jun; Buhr, Vincent; Zhang, Jintao; Carayannopoulos, Leonidas N; Jia, Yi; Huan, Jun; Buhr, Vincent; Zhang, Jintao; Carayannopoulos, Leonidas N.","Towards comprehensive structural motif mining for better fold annotation in the ""twilight zone"" of sequence dissimilarity",2009,BMC bioinformatics; BMC Bioinformatics,,"Background Automatic identification of structure fingerprints from a group of diverse protein structures is challenging, especially for proteins whose divergent amino acid sequences may fall into the ""twilight-"" or ""midnight-"" zones where pair-wise sequence identities to known sequences fall below 25% and sequence-based functional annotations often fail. Results Here we report a novel graph database mining method and demonstrate its application to protein structure pattern identification and structure classification. The biologic motivation of our study is to recognize common structure patterns in ""immunoevasins"", proteins mediating virus evasion of host immune defense. Our experimental study, using both viral and non-viral proteins, demonstrates the efficiency and efficacy of the proposed method. Conclusion We present a theoretic framework, offer a practical software implementation for incorporating prior domain knowledge, such as substitution matrices as studied here, and devise an efficient algorithm to identify approximate matched frequent subgraphs. By doing so, we significantly expanded the analytical power of sophisticated data mining algorithms in dealing with large volume of complicated and noisy protein structure data. And without loss of generality, choice of appropriate compatibility matrices allows our method to be easily employed in domains where subgraph labels have some uncertainty.; BACKGROUND: Automatic identification of structure fingerprints from a group of diverse protein structures is challenging, especially for proteins whose divergent amino acid sequences may fall into the ""twilight-"" or ""midnight-"" zones where pair-wise sequence identities to known sequences fall below 25% and sequence-based functional annotations often fail. RESULTS: Here we report a novel graph database mining method and demonstrate its application to protein structure pattern identification and structure classification. The biologic motivation of our study is to recognize common structure patterns in ""immunoevasins"", proteins mediating virus evasion of host immune defense. Our experimental study, using both viral and non-viral proteins, demonstrates the efficiency and efficacy of the proposed method. CONCLUSION: We present a theoretic framework, offer a practical software implementation for incorporating prior domain knowledge, such as substitution matrices as studied here, and devise an efficient algorithm to identify approximate matched frequent subgraphs. By doing so, we significantly expanded the analytical power of sophisticated data mining algorithms in dealing with large volume of complicated and noisy protein structure data. And without loss of generality, choice of appropriate compatibility matrices allows our method to be easily employed in domains where subgraph labels have some uncertainty.",2009-01-30,2021-06-05 21:13:27; 2021-06-05 21:06:22,S46,Suppl 1,10; 10 Suppl 1,BMC Bioinformatics,,PubMed; PubMed Central,PMID: 19208148 PMCID: PMC2648771,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2648771/; http://www.ncbi.nlm.nih.gov/pubmed/19208148,"Algorithms; Amino Acid Motifs; Amino Acid Sequence; Computational Biology; Databases, Protein; Models, Molecular; Molecular Sequence Data; Protein Folding; Protein Structure, Tertiary; Proteins",,,PubMed:Query2; PMC:Query2
375,10.1186/1471-2105-10-S10-S10,19796394,PMC2755818,A,Virtuoso; AllegroGraph,Virtuoso; AllegroGraph,"Cheung, Kei-Hoi; Frost, H Robert; Marshall, M Scott; Prud'hommeaux, Eric; Samwald, Matthias; Zhao, Jun; Paschke, Adrian",A journey to Semantic Web query federation in the life sciences,2009,BMC Bioinformatics,,"Background As interest in adopting the Semantic Web in the biomedical domain continues to grow, Semantic Web technology has been evolving and maturing. A variety of technological approaches including triplestore technologies, SPARQL endpoints, Linked Data, and Vocabulary of Interlinked Datasets have emerged in recent years. In addition to the data warehouse construction, these technological approaches can be used to support dynamic query federation. As a community effort, the BioRDF task force, within the Semantic Web for Health Care and Life Sciences Interest Group, is exploring how these emerging approaches can be utilized to execute distributed queries across different neuroscience data sources. Methods and results We have created two health care and life science knowledge bases. We have explored a variety of Semantic Web approaches to describe, map, and dynamically query multiple datasets. We have demonstrated several federation approaches that integrate diverse types of information about neurons and receptors that play an important role in basic, clinical, and translational neuroscience research. Particularly, we have created a prototype receptor explorer which uses OWL mappings to provide an integrated list of receptors and executes individual queries against different SPARQL endpoints. We have also employed the AIDA Toolkit, which is directed at groups of knowledge workers who cooperatively search, annotate, interpret, and enrich large collections of heterogeneous documents from diverse locations. We have explored a tool called ""FeDeRate"", which enables a global SPARQL query to be decomposed into subqueries against the remote databases offering either SPARQL or SQL query interfaces. Finally, we have explored how to use the vocabulary of interlinked Datasets (voiD) to create metadata for describing datasets exposed as Linked Data URIs or SPARQL endpoints. Conclusion We have demonstrated the use of a set of novel and state-of-the-art Semantic Web technologies in support of a neuroscience query federation scenario. We have identified both the strengths and weaknesses of these technologies. While Semantic Web offers a global data model including the use of Uniform Resource Identifiers (URI's), the proliferation of semantically-equivalent URI's hinders large scale data integration. Our work helps direct research and tool development, which will be of benefit to this community.",2009-10-01,2021-06-05 21:13:27; 2021-06-06 06:38:41; 2021-06-05 20:56:20; 2021-06-05 20:59:14,S10,Suppl 10,10,BMC Bioinformatics,,PubMed Central,PMID: 19796394 PMCID: PMC2755818,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2755818/,,Virtuoso; AllegroGraph,Virtuoso; AllegroGraph,PMC:Query3; PMC:AllegroGraph; PMC:Query2; PMC:Virtuoso
376,10.1186/1471-2105-10-S10-S11,19796395,PMC2755819,A,Virtuoso,Virtuoso,"Antezana, Erick; Blondé, Ward; Egaña, Mikel; Rutherford, Alistair; Stevens, Robert; De Baets, Bernard; Mironov, Vladimir; Kuiper, Martin",BioGateway: a semantic systems biology tool for the life sciences,2009,BMC Bioinformatics,,"Background Life scientists need help in coping with the plethora of fast growing and scattered knowledge resources. Ideally, this knowledge should be integrated in a form that allows them to pose complex questions that address the properties of biological systems, independently from the origin of the knowledge. Semantic Web technologies prove to be well suited for knowledge integration, knowledge production (hypothesis formulation), knowledge querying and knowledge maintenance. Results We implemented a semantically integrated resource named BioGateway, comprising the entire set of the OBO foundry candidate ontologies, the GO annotation files, the SWISS-PROT protein set, the NCBI taxonomy and several in-house ontologies. BioGateway provides a single entry point to query these resources through SPARQL. It constitutes a key component for a Semantic Systems Biology approach to generate new hypotheses concerning systems properties. In the course of developing BioGateway, we faced challenges that are common to other projects that involve large datasets in diverse representations. We present a detailed analysis of the obstacles that had to be overcome in creating BioGateway. We demonstrate the potential of a comprehensive application of Semantic Web technologies to global biomedical data. Conclusion The time is ripe for launching a community effort aimed at a wider acceptance and application of Semantic Web technologies in the life sciences. We call for the creation of a forum that strives to implement a truly semantic life science foundation for Semantic Systems Biology., Access to the system and supplementary information (such as a listing of the data sources in RDF, and sample queries) can be found at .",2009-10-01,2021-06-05 21:13:27; 2021-06-05 20:56:20; 2021-06-05 20:59:14,S11,Suppl 10,10,BMC Bioinformatics,BioGateway,PubMed Central,PMID: 19796395 PMCID: PMC2755819,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2755819/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
377,10.1186/1471-2105-10-S10-S5,19796402,PMC2755826,A,Virtuoso,Virtuoso,"Roldán-García, María del Mar; Navas-Delgado, Ismael; Kerzazi, Amine; Chniber, Othmane; Molina-Castro, Joaquín; Aldana-Montes, José F",KA-SB: from data integration to large scale reasoning,2009,BMC Bioinformatics,,"Background The analysis of information in the biological domain is usually focused on the analysis of data from single on-line data sources. Unfortunately, studying a biological process requires having access to disperse, heterogeneous, autonomous data sources. In this context, an analysis of the information is not possible without the integration of such data. Methods KA-SB is a querying and analysis system for final users based on combining a data integration solution with a reasoner. Thus, the tool has been created with a process divided into two steps: 1) KOMF, the Khaos Ontology-based Mediator Framework, is used to retrieve information from heterogeneous and distributed databases; 2) the integrated information is crystallized in a (persistent and high performance) reasoner (DBOWL). This information could be further analyzed later (by means of querying and reasoning). Results In this paper we present a novel system that combines the use of a mediation system with the reasoning capabilities of a large scale reasoner to provide a way of finding new knowledge and of analyzing the integrated information from different databases, which is retrieved as a set of ontology instances. This tool uses a graphical query interface to build user queries easily, which shows a graphical representation of the ontology and allows users o build queries by clicking on the ontology concepts. Conclusion These kinds of systems (based on KOMF) will provide users with very large amounts of information (interpreted as ontology instances once retrieved), which cannot be managed using traditional main memory-based reasoners. We propose a process for creating persistent and scalable knowledgebases from sets of OWL instances obtained by integrating heterogeneous data sources with KOMF. This process has been applied to develop a demo tool , which uses the BioPax Level 3 ontology as the integration schema, and integrates UNIPROT, KEGG, CHEBI, BRENDA and SABIORK databases.",2009-10-01,2021-06-05 21:13:27; 2021-06-05 20:56:20; 2021-06-05 20:59:14,S5,Suppl 10,10,BMC Bioinformatics,KA-SB,PubMed Central,PMID: 19796402 PMCID: PMC2755826,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2755826/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
378,10.1186/1471-2105-10-S10-S7,19796404,PMC2755828,,,,"Dietze, Heiko; Schroeder, Michael",GoWeb: a semantic search engine for the life science web,2009,BMC Bioinformatics,,"Background Current search engines are keyword-based. Semantic technologies promise a next generation of semantic search engines, which will be able to answer questions. Current approaches either apply natural language processing to unstructured text or they assume the existence of structured statements over which they can reason. Results Here, we introduce a third approach, GoWeb, which combines classical keyword-based Web search with text-mining and ontologies to navigate large results sets and facilitate question answering. We evaluate GoWeb on three benchmarks of questions on genes and functions, on symptoms and diseases, and on proteins and diseases. The first benchmark is based on the BioCreAtivE 1 Task 2 and links 457 gene names with 1352 functions. GoWeb finds 58% of the functional GeneOntology annotations. The second benchmark is based on 26 case reports and links symptoms with diseases. GoWeb achieves 77% success rate improving an existing approach by nearly 20%. The third benchmark is based on 28 questions in the TREC genomics challenge and links proteins to diseases. GoWeb achieves a success rate of 79%. Conclusion GoWeb's combination of classical Web search with text-mining and ontologies is a first step towards answering questions in the biomedical domain. GoWeb is online at:",2009-10-01,2021-06-05 21:13:27,S7,Suppl 10,10,BMC Bioinformatics,GoWeb,PubMed Central,PMID: 19796404 PMCID: PMC2755828,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2755828/,,,,PMC:Query2
379,10.1186/1471-2105-10-S10-S9,19796406,PMC2755830,A,AllegroGraph,AllegroGraph,"Roos, Marco; Marshall, M Scott; Gibson, Andrew P; Schuemie, Martijn; Meij, Edgar; Katrenko, Sophia; van Hage, Willem Robert; Krommydas, Konstantinos; Adriaans, Pieter W",Structuring and extracting knowledge for the support of hypothesis generation in molecular biology,2009,BMC Bioinformatics,,"Background Hypothesis generation in molecular and cellular biology is an empirical process in which knowledge derived from prior experiments is distilled into a comprehensible model. The requirement of automated support is exemplified by the difficulty of considering all relevant facts that are contained in the millions of documents available from PubMed. Semantic Web provides tools for sharing prior knowledge, while information retrieval and information extraction techniques enable its extraction from literature. Their combination makes prior knowledge available for computational analysis and inference. While some tools provide complete solutions that limit the control over the modeling and extraction processes, we seek a methodology that supports control by the experimenter over these critical processes. Results We describe progress towards automated support for the generation of biomolecular hypotheses. Semantic Web technologies are used to structure and store knowledge, while a workflow extracts knowledge from text. We designed minimal proto-ontologies in OWL for capturing different aspects of a text mining experiment: the biological hypothesis, text and documents, text mining, and workflow provenance. The models fit a methodology that allows focus on the requirements of a single experiment while supporting reuse and posterior analysis of extracted knowledge from multiple experiments. Our workflow is composed of services from the 'Adaptive Information Disclosure Application' (AIDA) toolkit as well as a few others. The output is a semantic model with putative biological relations, with each relation linked to the corresponding evidence. Conclusion We demonstrated a 'do-it-yourself' approach for structuring and extracting knowledge in the context of experimental research on biomolecular mechanisms. The methodology can be used to bootstrap the construction of semantically rich biological models using the results of knowledge extraction processes. Models specific to particular experiments can be constructed that, in turn, link with other semantic models, creating a web of knowledge that spans experiments. Mapping mechanisms can link to other knowledge resources such as OBO ontologies or SKOS vocabularies. AIDA Web Services can be used to design personalized knowledge extraction procedures. In our example experiment, we found three proteins (NF-Kappa B, p21, and Bax) potentially playing a role in the interplay between nutrients and epigenetic gene regulation.",2009-10-01,2021-06-05 21:13:27; 2021-06-06 06:38:41; 2021-06-05 20:56:20,S9,Suppl 10,10,BMC Bioinformatics,,PubMed Central,PMID: 19796406 PMCID: PMC2755830,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2755830/,,AllegroGraph,AllegroGraph,PMC:Query3; PMC:AllegroGraph; PMC:Query2
380,10.1186/1471-2105-11-244,20462403,PMC2882391,,,,"Liu, Qian; Li, Jinyan",Protein binding hot spots and the residue-residue pairing preference: a water exclusion perspective,2010,BMC Bioinformatics,,"Background A protein binding hot spot is a small cluster of residues tightly packed at the center of the interface between two interacting proteins. Though a hot spot constitutes a small fraction of the interface, it is vital to the stability of protein complexes. Recently, there are a series of hypotheses proposed to characterize binding hot spots, including the pioneering O-ring theory, the insightful 'coupling' and 'hot region' principle, and our 'double water exclusion' (DWE) hypothesis. As the perspective changes from the O-ring theory to the DWE hypothesis, we examine the physicochemical properties of the binding hot spots under the new hypothesis and compare with those under the O-ring theory. Results The requirements for a cluster of residues to form a hot spot under the DWE hypothesis can be mathematically satisfied by a biclique subgraph if a vertex is used to represent a residue, an edge to indicate a close distance between two residues, and a bipartite graph to represent a pair of interacting proteins. We term these hot spots as DWE bicliques. We identified DWE bicliques from crystal packing contacts, obligate and non-obligate interactions. Our comparative study revealed that there are abundant unique bicliques to the biological interactions, indicating specific biological binding behaviors in contrast to crystal packing. The two sub-types of biological interactions also have their own signature bicliques. In our analysis on residue compositions and residue pairing preferences in DWE bicliques, the focus was on interaction-preferred residues (ipRs) and interaction-preferred residue pairs (ipRPs). It is observed that hydrophobic residues are heavily involved in the ipRs and ipRPs of the obligate interactions; and that aromatic residues are in favor in the ipRs and ipRPs of the biological interactions, especially in those of the non-obligate interactions. In contrast, the ipRs and ipRPs in crystal packing are dominated by hydrophilic residues, and most of the anti-ipRs of crystal packing are the ipRs of the obligate or non-obligate interactions. Conclusions These ipRs and ipRPs in our DWE bicliques describe a diverse binding features among the three types of interactions. They also highlight the specific binding behaviors of the biological interactions, sharply differing from the artifact interfaces in the crystal packing. It can be noted that DWE bicliques, especially the unique bicliques, can capture deep insights into the binding characteristics of protein interfaces.",2010-05-12,2021-06-05 21:13:27,244,,11,BMC Bioinformatics,Protein binding hot spots and the residue-residue pairing preference,PubMed Central,PMID: 20462403 PMCID: PMC2882391,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2882391/,,,,PMC:Query2
381,10.1186/1471-2105-11-610,21190573,PMC3019228,,,,"Kozhenkov, Sergey; Dubinina, Yulia; Sedova, Mayya; Gupta, Amarnath; Ponomarenko, Julia; Baitaluk, Michael",BiologicalNetworks 2.0 - an integrative view of genome biology data,2010,BMC Bioinformatics,,"Background A significant problem in the study of mechanisms of an organism's development is the elucidation of interrelated factors which are making an impact on the different levels of the organism, such as genes, biological molecules, cells, and cell systems. Numerous sources of heterogeneous data which exist for these subsystems are still not integrated sufficiently enough to give researchers a straightforward opportunity to analyze them together in the same frame of study. Systematic application of data integration methods is also hampered by a multitude of such factors as the orthogonal nature of the integrated data and naming problems. Results Here we report on a new version of BiologicalNetworks, a research environment for the integral visualization and analysis of heterogeneous biological data. BiologicalNetworks can be queried for properties of thousands of different types of biological entities (genes/proteins, promoters, COGs, pathways, binding sites, and other) and their relations (interactions, co-expression, co-citations, and other). The system includes the build-pathways infrastructure for molecular interactions/relations and module discovery in high-throughput experiments. Also implemented in BiologicalNetworks are the Integrated Genome Viewer and Comparative Genomics Browser applications, which allow for the search and analysis of gene regulatory regions and their conservation in multiple species in conjunction with molecular pathways/networks, experimental data and functional annotations. Conclusions The new release of BiologicalNetworks together with its back-end database introduces extensive functionality for a more efficient integrated multi-level analysis of microarray, sequence, regulatory, and other data. BiologicalNetworks is freely available at http://www.biologicalnetworks.org.",2010-12-29,2021-06-05 21:13:27,610,,11,BMC Bioinformatics,,PubMed Central,PMID: 21190573 PMCID: PMC3019228,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3019228/,,,,PMC:Query2
382,10.1186/1471-2105-11-96,20170516,PMC2850364,,,,"Di Natale, Raffaele; Ferro, Alfredo; Giugno, Rosalba; Mongiovì, Misael; Pulvirenti, Alfredo; Shasha, Dennis",SING: subgraph search in non-homogeneous graphs; SING: Subgraph search In Non-homogeneous Graphs,2010,BMC bioinformatics; BMC Bioinformatics,,"Background Finding the subgraphs of a graph database that are isomorphic to a given query graph has practical applications in several fields, from cheminformatics to image understanding. Since subgraph isomorphism is a computationally hard problem, indexing techniques have been intensively exploited to speed up the process. Such systems filter out those graphs which cannot contain the query, and apply a subgraph isomorphism algorithm to each residual candidate graph. The applicability of such systems is limited to databases of small graphs, because their filtering power degrades on large graphs. Results In this paper, SING (Subgraph search In Non-homogeneous Graphs), a novel indexing system able to cope with large graphs, is presented. The method uses the notion of feature, which can be a small subgraph, subtree or path. Each graph in the database is annotated with the set of all its features. The key point is to make use of feature locality information. This idea is used to both improve the filtering performance and speed up the subgraph isomorphism task. Conclusions Extensive tests on chemical compounds, biological networks and synthetic graphs show that the proposed system outperforms the most popular systems in query time over databases of medium and large graphs. Other specific tests show that the proposed system is effective for single large graphs.; BACKGROUND: Finding the subgraphs of a graph database that are isomorphic to a given query graph has practical applications in several fields, from cheminformatics to image understanding. Since subgraph isomorphism is a computationally hard problem, indexing techniques have been intensively exploited to speed up the process. Such systems filter out those graphs which cannot contain the query, and apply a subgraph isomorphism algorithm to each residual candidate graph. The applicability of such systems is limited to databases of small graphs, because their filtering power degrades on large graphs. RESULTS: In this paper, SING (Subgraph search In Non-homogeneous Graphs), a novel indexing system able to cope with large graphs, is presented. The method uses the notion of feature, which can be a small subgraph, subtree or path. Each graph in the database is annotated with the set of all its features. The key point is to make use of feature locality information. This idea is used to both improve the filtering performance and speed up the subgraph isomorphism task. CONCLUSIONS: Extensive tests on chemical compounds, biological networks and synthetic graphs show that the proposed system outperforms the most popular systems in query time over databases of medium and large graphs. Other specific tests show that the proposed system is effective for single large graphs.",2010-02-19,2021-06-05 21:13:27; 2021-06-05 21:06:22,96,,11,BMC Bioinformatics,SING,PubMed; PubMed Central,PMID: 20170516 PMCID: PMC2850364,http://www.ncbi.nlm.nih.gov/pubmed/20170516; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2850364/,"Algorithms; Computational Biology; Computer Graphics; Databases, Factual; Databases, Protein; Information Storage and Retrieval; Software; User-Computer Interface",,,PubMed:Query2; PMC:Query2
383,10.1186/1471-2105-11-S3-S8,20438655,PMC2863067,,,,"Wang, Xiaohong; Huan, Jun; Smalter, Aaron; Lushington, Gerald H",Application of kernel functions for accurate similarity search in large chemical databases,2010,BMC Bioinformatics,,"Background Similaritysearch in chemical structure databases is an important problem with many applications in chemical genomics, drug design, and efficient chemical probe screening among others. It is widely believed that structure based methods provide an efficient way to do the query. Recently various graph kernel functions have been designed to capture the intrinsic similarity of graphs. Though successful in constructing accurate predictive and classification models, graph kernel functions can not be applied to large chemical compound database due to the high computational complexity and the difficulties in indexing similarity search for large databases.  Results To bridge graph kernel function and similarity search in chemical databases, we applied a novel kernel-based similarity measurement, developed in our team, to measure similarity of graph represented chemicals. In our method, we utilize a hash table to support new graph kernel function definition, efficient storage and fast search. We have applied our method, named G-hash, to large chemical databases. Our results show that the G-hash method achieves state-of-the-art performance for k-nearest neighbor (k-NN) classification. Moreover, the similarity measurement and the index structure is scalable to large chemical databases with smaller indexing size, and faster query processing time as compared to state-of-the-art indexing methods such as Daylight fingerprints, C-tree and GraphGrep. Conclusions Efficient similarity query processing method for large chemical databases is challenging since we need to balance running time efficiency and similarity search accuracy. Our previous similarity search method, G-hash, provides a new way to perform similarity search in chemical databases. Experimental study validates the utility of G-hash in chemical databases.",2010-04-29,2021-06-05 21:13:27,S8,Suppl 3,11,BMC Bioinformatics,,PubMed Central,PMID: 20438655 PMCID: PMC2863067,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2863067/,,,,PMC:Query2
384,10.1186/1471-2105-12-45,21288338,PMC3152790,,,,"Lemons, Nathan W; Hu, Bin; Hlavacek, William S",Hierarchical graphs for rule-based modeling of biochemical systems,2011,BMC Bioinformatics,,"Background In rule-based modeling, graphs are used to represent molecules: a colored vertex represents a component of a molecule, a vertex attribute represents the internal state of a component, and an edge represents a bond between components. Components of a molecule share the same color. Furthermore, graph-rewriting rules are used to represent molecular interactions. A rule that specifies addition (removal) of an edge represents a class of association (dissociation) reactions, and a rule that specifies a change of a vertex attribute represents a class of reactions that affect the internal state of a molecular component. A set of rules comprises an executable model that can be used to determine, through various means, the system-level dynamics of molecular interactions in a biochemical system. Results For purposes of model annotation, we propose the use of hierarchical graphs to represent structural relationships among components and subcomponents of molecules. We illustrate how hierarchical graphs can be used to naturally document the structural organization of the functional components and subcomponents of two proteins: the protein tyrosine kinase Lck and the T cell receptor (TCR) complex. We also show that computational methods developed for regular graphs can be applied to hierarchical graphs. In particular, we describe a generalization of Nauty, a graph isomorphism and canonical labeling algorithm. The generalized version of the Nauty procedure, which we call HNauty, can be used to assign canonical labels to hierarchical graphs or more generally to graphs with multiple edge types. The difference between the Nauty and HNauty procedures is minor, but for completeness, we provide an explanation of the entire HNauty algorithm. Conclusions Hierarchical graphs provide more intuitive formal representations of proteins and other structured molecules with multiple functional components than do the regular graphs of current languages for specifying rule-based models, such as the BioNetGen language (BNGL). Thus, the proposed use of hierarchical graphs should promote clarity and better understanding of rule-based models.",2011-02-02,2021-06-05 21:13:27,45,,12,BMC Bioinformatics,,PubMed Central,PMID: 21288338 PMCID: PMC3152790,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3152790/,,,,PMC:Query2
385,10.1186/1471-2105-12-461,22126369,PMC3298549,,,,"Sahoo, Satya S; Nguyen, Vinh; Bodenreider, Olivier; Parikh, Priti; Minning, Todd; Sheth, Amit P",A unified framework for managing provenance information in translational research,2011,BMC Bioinformatics,,"Background A critical aspect of the NIH Translational Research roadmap, which seeks to accelerate the delivery of ""bench-side"" discoveries to patient's ""bedside,"" is the management of the provenance metadata that keeps track of the origin and history of data resources as they traverse the path from the bench to the bedside and back. A comprehensive provenance framework is essential for researchers to verify the quality of data, reproduce scientific results published in peer-reviewed literature, validate scientific process, and associate trust value with data and results. Traditional approaches to provenance management have focused on only partial sections of the translational research life cycle and they do not incorporate ""domain semantics"", which is essential to support domain-specific querying and analysis by scientists. Results We identify a common set of challenges in managing provenance information across the pre-publication and post-publication phases of data in the translational research lifecycle. We define the semantic provenance framework (SPF), underpinned by the Provenir upper-level provenance ontology, to address these challenges in the four stages of provenance metadata:, (a) Provenance collection - during data generation, (b) Provenance representation - to support interoperability, reasoning, and incorporate domain semantics, (c) Provenance storage and propagation - to allow efficient storage and seamless propagation of provenance as the data is transferred across applications, (d) Provenance query - to support queries with increasing complexity over large data size and also support knowledge discovery applications, We apply the SPF to two exemplar translational research projects, namely the Semantic Problem Solving Environment for Trypanosoma cruzi (T.cruzi SPSE) and the Biomedical Knowledge Repository (BKR) project, to demonstrate its effectiveness. Conclusions The SPF provides a unified framework to effectively manage provenance of translational research data during pre and post-publication phases. This framework is underpinned by an upper-level provenance ontology called Provenir that is extended to create domain-specific provenance ontologies to facilitate provenance interoperability, seamless propagation of provenance, automated querying, and analysis.",2011-11-29,2021-06-05 21:13:27,461,,12,BMC Bioinformatics,,PubMed Central,PMID: 22126369 PMCID: PMC3298549,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3298549/,,,,PMC:Query2
386,10.1186/1471-2105-12-98,21496247,PMC3101187,A,AllegroGraph,AllegroGraph,"Chisham, Brandon; Wright, Ben; Le, Trung; Son, Tran Cao; Pontelli, Enrico",CDAO-Store: Ontology-driven Data Integration for Phylogenetic Analysis,2011,BMC Bioinformatics,,"Background The Comparative Data Analysis Ontology (CDAO) is an ontology developed, as part of the EvoInfo and EvoIO groups supported by the National Evolutionary Synthesis Center, to provide semantic descriptions of data and transformations commonly found in the domain of phylogenetic analysis. The core concepts of the ontology enable the description of phylogenetic trees and associated character data matrices. Results Using CDAO as the semantic back-end, we developed a triple-store, named CDAO-Store. CDAO-Store is a RDF-based store of phylogenetic data, including a complete import of TreeBASE. CDAO-Store provides a programmatic interface, in the form of web services, and a web-based front-end, to perform both user-defined as well as domain-specific queries; domain-specific queries include search for nearest common ancestors, minimum spanning clades, filter multiple trees in the store by size, author, taxa, tree identifier, algorithm or method. In addition, CDAO-Store provides a visualization front-end, called CDAO-Explorer, which can be used to view both character data matrices and trees extracted from the CDAO-Store. CDAO-Store provides import capabilities, enabling the addition of new data to the triple-store; files in PHYLIP, MEGA, nexml, and NEXUS formats can be imported and their CDAO representations added to the triple-store. Conclusions CDAO-Store is made up of a versatile and integrated set of tools to support phylogenetic analysis. To the best of our knowledge, CDAO-Store is the first semantically-aware repository of phylogenetic data with domain-specific querying capabilities. The portal to CDAO-Store is available at http://www.cs.nmsu.edu/~cdaostore.",2011-04-15,2021-06-05 21:13:27; 2021-06-06 06:38:41; 2021-06-05 20:56:20,98,,12,BMC Bioinformatics,CDAO-Store,PubMed Central,PMID: 21496247 PMCID: PMC3101187,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3101187/,,AllegroGraph,AllegroGraph,PMC:Query3; PMC:AllegroGraph; PMC:Query2
387,10.1186/1471-2105-12-S1-S8,21342591,PMC3044316,A,AllegroGraph,AllegroGraph,"Jeong, Euna; Nagasaki, Masao; Ueno, Kazuko; Miyano, Satoru",Ontology-based instance data validation for high-quality curated biological pathways,2011,BMC Bioinformatics,,"Background Modeling in systems biology is vital for understanding the complexity of biological systems across scales and predicting system-level behaviors. To obtain high-quality pathway databases, it is essential to improve the efficiency of model validation and model update based on appropriate feedback. Results We have developed a new method to guide creating novel high-quality biological pathways, using a rule-based validation. Rules are defined to correct models against biological semantics and improve models for dynamic simulation. In this work, we have defined 40 rules which constrain event-specific participants and the related features and adding missing processes based on biological events. This approach is applied to data in Cell System Ontology which is a comprehensive ontology that represents complex biological pathways with dynamics and visualization. The experimental results show that the relatively simple rules can efficiently detect errors made during curation, such as misassignment and misuse of ontology concepts and terms in curated models. Conclusions A new rule-based approach has been developed to facilitate model validation and model complementation. Our rule-based validation embedding biological semantics enables us to provide high-quality curated biological pathways. This approach can serve as a preprocessing step for model integration, exchange and extraction data, and simulation.",2011-02-15,2021-06-05 21:13:27; 2021-06-06 06:38:41; 2021-06-05 20:56:20,S8,Suppl 1,12,BMC Bioinformatics,,PubMed Central,PMID: 21342591 PMCID: PMC3044316,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3044316/,,AllegroGraph,AllegroGraph,PMC:Query3; PMC:AllegroGraph; PMC:Query2
388,10.1186/1471-2105-12-S10-S17,22165854,PMC3236839,A,AllegroGraph; OrientDB; Neo4j,AllegroGraph; OrientDB; Neo4j,"Griffith, Shelton D; Quest, Daniel J; Brettin, Thomas S; Cottingham, Robert W",Scenario driven data modelling: a method for integrating diverse sources of data and data streams,2011,BMC Bioinformatics,,"Background Biology is rapidly becoming a data intensive, data-driven science. It is essential that data is represented and connected in ways that best represent its full conceptual content and allows both automated integration and data driven decision-making. Recent advancements in distributed multi-relational directed graphs, implemented in the form of the Semantic Web make it possible to deal with complicated heterogeneous data in new and interesting ways. Results This paper presents a new approach, scenario driven data modelling (SDDM), that integrates multi-relational directed graphs with data streams. SDDM can be applied to virtually any data integration challenge with widely divergent types of data and data streams. In this work, we explored integrating genetics data with reports from traditional media. SDDM was applied to the New Delhi metallo-beta-lactamase gene (NDM-1), an emerging global health threat. The SDDM process constructed a scenario, created a RDF multi-relational directed graph that linked diverse types of data to the Semantic Web, implemented RDF conversion tools (RDFizers) to bring content into the Sematic Web, identified data streams and analytical routines to analyse those streams, and identified user requirements and graph traversals to meet end-user requirements. Conclusions We provided an example where SDDM was applied to a complex data integration challenge. The process created a model of the emerging NDM-1 health threat, identified and filled gaps in that model, and constructed reliable software that monitored data streams based on the scenario derived multi-relational directed graph. The SDDM process significantly reduced the software requirements phase by letting the scenario and resulting multi-relational directed graph define what is possible and then set the scope of the user requirements. Approaches like SDDM will be critical to the future of data intensive, data-driven science because they automate the process of converting massive data streams into usable knowledge.",2011-10-18,2021-06-05 21:13:27; 2021-06-06 06:49:06; 2021-06-06 06:38:41; 2021-06-05 20:37:08; 2021-06-05 20:56:20,S17,Suppl 10,12,BMC Bioinformatics,Scenario driven data modelling,PubMed Central,PMID: 22165854 PMCID: PMC3236839,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3236839/,,AllegroGraph; OrientDB; Neo4j,AllegroGraph; OrientDB; Neo4j,PMC:AllegroGraph; PMC:Query2; PMC:OrientDB; PMC:Query3; PMC:Neo4j
389,10.1186/1471-2105-13-119,22672646,PMC3505483,,,,"Eronen, Lauri; Toivonen, Hannu",Biomine: predicting links between biological entities using network models of heterogeneous databases,2012,BMC Bioinformatics,,"Background Biological databases contain large amounts of data concerning the functions and associations of genes and proteins. Integration of data from several such databases into a single repository can aid the discovery of previously unknown connections spanning multiple types of relationships and databases. Results Biomine is a system that integrates cross-references from several biological databases into a graph model with multiple types of edges, such as protein interactions, gene-disease associations and gene ontology annotations. Edges are weighted based on their type, reliability, and informativeness. We present Biomine and evaluate its performance in link prediction, where the goal is to predict pairs of nodes that will be connected in the future, based on current data. In particular, we formulate protein interaction prediction and disease gene prioritization tasks as instances of link prediction. The predictions are based on a proximity measure computed on the integrated graph. We consider and experiment with several such measures, and perform a parameter optimization procedure where different edge types are weighted to optimize link prediction accuracy. We also propose a novel method for disease-gene prioritization, defined as finding a subset of candidate genes that cluster together in the graph. We experimentally evaluate Biomine by predicting future annotations in the source databases and prioritizing lists of putative disease genes. Conclusions The experimental results show that Biomine has strong potential for predicting links when a set of selected candidate links is available. The predictions obtained using the entire Biomine dataset are shown to clearly outperform ones obtained using any single source of data alone, when different types of links are suitably weighted. In the gene prioritization task, an established reference set of disease-associated genes is useful, but the results show that under favorable conditions, Biomine can also perform well when no such information is available., The Biomine system is a proof of concept. Its current version contains 1.1 million entities and 8.1 million relations between them, with focus on human genetics. Some of its functionalities are available in a public query interface at http://biomine.cs.helsinki.fi, allowing searching for and visualizing connections between given biological entities.",2012-06-06,2021-06-05 21:13:27,119,,13,BMC Bioinformatics,Biomine,PubMed Central,PMID: 22672646 PMCID: PMC3505483,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3505483/,,,,PMC:Query2
390,10.1186/1471-2105-13-321,23198735,PMC3560104,,,,"Cadag, Eithon; Tarczy-Hornoch, Peter; Myler, Peter J",Learning virulent proteins from integrated query networks,2012,BMC Bioinformatics,,"Background Methods of weakening and attenuating pathogens’ abilities to infect and propagate in a host, thus allowing the natural immune system to more easily decimate invaders, have gained attention as alternatives to broad-spectrum targeting approaches. The following work describes a technique to identifying proteins involved in virulence by relying on latent information computationally gathered across biological repositories, applicable to both generic and specific virulence categories. Results A lightweight method for data integration is used, which links information regarding a protein via a path-based query graph. A method of weighting is then applied to query graphs that can serve as input to various statistical classification methods for discrimination, and the combined usage of both data integration and learning methods are tested against the problem of both generalized and specific virulence function prediction. Conclusions This approach improves coverage of functional data over a protein. Moreover, while depending largely on noisy and potentially non-curated data from public sources, we find it outperforms other techniques to identification of general virulence factors and baseline remote homology detection methods for specific virulence categories.",2012-12-02,2021-06-05 21:13:27,321,,13,BMC Bioinformatics,,PubMed Central,PMID: 23198735 PMCID: PMC3560104,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3560104/,,,,PMC:Query2
391,10.1186/1471-2105-13-S1-S3,22373359,PMC3471352,A,Virtuoso,Virtuoso,"Mironov, Vladimir; Seethappan, Nirmala; Blondé, Ward; Antezana, Erick; Splendiani, Andrea; Kuiper, Martin",Gauging triple stores with actual biological data,2012,BMC bioinformatics; BMC Bioinformatics,,"BACKGROUND: Semantic Web technologies have been developed to overcome the limitations of the current Web and conventional data integration solutions. The Semantic Web is expected to link all the data present on the Internet instead of linking just documents. One of the foundations of the Semantic Web technologies is the knowledge representation language Resource Description Framework (RDF). Knowledge expressed in RDF is typically stored in so-called triple stores (also known as RDF stores), from which it can be retrieved with SPARQL, a language designed for querying RDF-based models. The Semantic Web technologies should allow federated queries over multiple triple stores. In this paper we compare the efficiency of a set of biologically relevant queries as applied to a number of different triple store implementations. RESULTS: Previously we developed a library of queries to guide the use of our knowledge base Cell Cycle Ontology implemented as a triple store. We have now compared the performance of these queries on five non-commercial triple stores: OpenLink Virtuoso (Open-Source Edition), Jena SDB, Jena TDB, SwiftOWLIM and 4Store. We examined three performance aspects: the data uploading time, the query execution time and the scalability. The queries we had chosen addressed diverse ontological or biological questions, and we found that individual store performance was quite query-specific. We identified three groups of queries displaying similar behaviour across the different stores: 1) relatively short response time queries, 2) moderate response time queries and 3) relatively long response time queries. SwiftOWLIM proved to be a winner in the first group, 4Store in the second one and Virtuoso in the third one. CONCLUSIONS: Our analysis showed that some queries behaved idiosyncratically, in a triple store specific manner, mainly with SwiftOWLIM and 4Store. Virtuoso, as expected, displayed a very balanced performance - its load time and its response time for all the tested queries were better than average among the selected stores; it showed a very good scalability and a reasonable run-to-run reproducibility. Jena SDB and Jena TDB were consistently slower than the other three implementations. Our analysis demonstrated that most queries developed for Virtuoso could be successfully used for other implementations.; Background Semantic Web technologies have been developed to overcome the limitations of the current Web and conventional data integration solutions. The Semantic Web is expected to link all the data present on the Internet instead of linking just documents. One of the foundations of the Semantic Web technologies is the knowledge representation language Resource Description Framework (RDF). Knowledge expressed in RDF is typically stored in so-called triple stores (also known as RDF stores), from which it can be retrieved with SPARQL, a language designed for querying RDF-based models. The Semantic Web technologies should allow federated queries over multiple triple stores. In this paper we compare the efficiency of a set of biologically relevant queries as applied to a number of different triple store implementations. Results Previously we developed a library of queries to guide the use of our knowledge base Cell Cycle Ontology implemented as a triple store. We have now compared the performance of these queries on five non-commercial triple stores: OpenLink Virtuoso (Open-Source Edition), Jena SDB, Jena TDB, SwiftOWLIM and 4Store. We examined three performance aspects: the data uploading time, the query execution time and the scalability. The queries we had chosen addressed diverse ontological or biological questions, and we found that individual store performance was quite query-specific. We identified three groups of queries displaying similar behaviour across the different stores: 1) relatively short response time queries, 2) moderate response time queries and 3) relatively long response time queries. SwiftOWLIM proved to be a winner in the first group, 4Store in the second one and Virtuoso in the third one. Conclusions Our analysis showed that some queries behaved idiosyncratically, in a triple store specific manner, mainly with SwiftOWLIM and 4Store. Virtuoso, as expected, displayed a very balanced performance - its load time and its response time for all the tested queries were better than average among the selected stores; it showed a very good scalability and a reasonable run-to-run reproducibility. Jena SDB and Jena TDB were consistently slower than the other three implementations. Our analysis demonstrated that most queries developed for Virtuoso could be successfully used for other implementations.",2012-01-25,2021-06-05 21:13:27; 2021-06-05 21:18:16; 2021-06-05 21:06:22; 2021-06-05 20:59:14; 2021-06-05 20:56:20; 2021-06-05 21:24:28,S3,Suppl 1,13 Suppl 1; 13,BMC Bioinformatics,,PubMed; PubMed Central,PMID: 22373359 PMCID: PMC3471352,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3471352/; http://www.ncbi.nlm.nih.gov/pubmed/22373359,Biological Ontologies; Computational Biology; Data Mining; Internet; Reproducibility of Results; Semantics; Time Factors,Virtuoso,Virtuoso,PMC:Query2; PMC:Query3; PMC:Virtuoso; PubMed:Query2; PubMed:Virtuoso; PubMed:Query3
392,10.1186/1471-2105-13-S17-S20,23281855,PMC3521413,,,,"Zhao, Liang; Wong, Limsoon; Lu, Lanyuan; Hoi, Steven CH; Li, Jinyan",B-cell epitope prediction through a graph model,2012,BMC Bioinformatics,,"Background Prediction of B-cell epitopes from antigens is useful to understand the immune basis of antibody-antigen recognition, and is helpful in vaccine design and drug development. Tremendous efforts have been devoted to this long-studied problem, however, existing methods have at least two common limitations. One is that they only favor prediction of those epitopes with protrusive conformations, but show poor performance in dealing with planar epitopes. The other limit is that they predict all of the antigenic residues of an antigen as belonging to one single epitope even when multiple non-overlapping epitopes of an antigen exist. Results In this paper, we propose to divide an antigen surface graph into subgraphs by using a Markov Clustering algorithm, and then we construct a classifier to distinguish these subgraphs as epitope or non-epitope subgraphs. This classifier is then taken to predict epitopes for a test antigen. On a big data set comprising 92 antigen-antibody PDB complexes, our method significantly outperforms the state-of-the-art epitope prediction methods, achieving 24.7% higher averaged f-score than the best existing models. In particular, our method can successfully identify those epitopes with a non-planarity which is too small to be addressed by the other models. Our method can also detect multiple epitopes whenever they exist. Conclusions Various protrusive and planar patches at the surface of antigens can be distinguishable by using graphical models combined with unsupervised clustering and supervised learning ideas. The difficult problem of identifying multiple epitopes from an antigen can be made easied by using our subgraph approach. The outstanding residue combinations found in the supervised learning will be useful for us to form new hypothesis in future studies.",2012-12-07,2021-06-05 21:13:27,S20,Suppl 17,13,BMC Bioinformatics,,PubMed Central,PMID: 23281855 PMCID: PMC3521413,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3521413/,,,,PMC:Query2
393,10.1186/1471-2105-13-S4-S7,22536974,PMC3303732,A,AllegroGraph,AllegroGraph,"Zappa, Achille; Splendiani, Andrea; Romano, Paolo",Towards linked open gene mutations data,2012,BMC Bioinformatics,,"Background With the advent of high-throughput technologies, a great wealth of variation data is being produced. Such information may constitute the basis for correlation analyses between genotypes and phenotypes and, in the future, for personalized medicine. Several databases on gene variation exist, but this kind of information is still scarce in the Semantic Web framework., In this paper, we discuss issues related to the integration of mutation data in the Linked Open Data infrastructure, part of the Semantic Web framework. We present the development of a mapping from the IARC TP53 Mutation database to RDF and the implementation of servers publishing this data. Methods A version of the IARC TP53 Mutation database implemented in a relational database was used as first test set. Automatic mappings to RDF were first created by using D2RQ and later manually refined by introducing concepts and properties from domain vocabularies and ontologies, as well as links to Linked Open Data implementations of various systems of biomedical interest., Since D2RQ query performances are lower than those that can be achieved by using an RDF archive, generated data was also loaded into a dedicated system based on tools from the Jena software suite. Results We have implemented a D2RQ Server for TP53 mutation data, providing data on a subset of the IARC database, including gene variations, somatic mutations, and bibliographic references. The server allows to browse the RDF graph by using links both between classes and to external systems. An alternative interface offers improved performances for SPARQL queries. The resulting data can be explored by using any Semantic Web browser or application. Conclusions This has been the first case of a mutation database exposed as Linked Data. A revised version of our prototype, including further concepts and IARC TP53 Mutation database data sets, is under development., The publication of variation information as Linked Data opens new perspectives: the exploitation of SPARQL searches on mutation data and other biological databases may support data retrieval which is presently not possible. Moreover, reasoning on integrated variation data may support discoveries towards personalized medicine.",2012-03-28,2021-06-05 21:13:27; 2021-06-06 06:38:41; 2021-06-05 20:56:20,S7,Suppl 4,13,BMC Bioinformatics,,PubMed Central,PMID: 22536974 PMCID: PMC3303732,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3303732/,,AllegroGraph,AllegroGraph,PMC:Query3; PMC:AllegroGraph; PMC:Query2
394,10.1186/1471-2105-14-158,23668630,PMC3669619,A,Virtuoso,Virtuoso,"Stoltzfus, Arlin; Lapp, Hilmar; Matasci, Naim; Deus, Helena; Sidlauskas, Brian; Zmasek, Christian M; Vaidya, Gaurav; Pontelli, Enrico; Cranston, Karen; Vos, Rutger; Webb, Campbell O; Harmon, Luke J; Pirrung, Megan; O'Meara, Brian; Pennell, Matthew W; Mirarab, Siavash; Rosenberg, Michael S; Balhoff, James P; Bik, Holly M; Heath, Tracy A; Midford, Peter E; Brown, Joseph W; McTavish, Emily Jane; Sukumaran, Jeet; Westneat, Mark; Alfaro, Michael E; Steele, Aaron; Jordan, Greg","Phylotastic! Making tree-of-life knowledge accessible, reusable and convenient",2013,BMC Bioinformatics,,"Background Scientists rarely reuse expert knowledge of phylogeny, in spite of years of effort to assemble a great “Tree of Life” (ToL). A notable exception involves the use of Phylomatic, which provides tools to generate custom phylogenies from a large, pre-computed, expert phylogeny of plant taxa. This suggests great potential for a more generalized system that, starting with a query consisting of a list of any known species, would rectify non-standard names, identify expert phylogenies containing the implicated taxa, prune away unneeded parts, and supply branch lengths and annotations, resulting in a custom phylogeny suited to the user’s needs. Such a system could become a sustainable community resource if implemented as a distributed system of loosely coupled parts that interact through clearly defined interfaces. Results With the aim of building such a “phylotastic” system, the NESCent Hackathons, Interoperability, Phylogenies (HIP) working group recruited 2 dozen scientist-programmers to a weeklong programming hackathon in June 2012. During the hackathon (and a three-month follow-up period), 5 teams produced designs, implementations, documentation, presentations, and tests including: (1) a generalized scheme for integrating components; (2) proof-of-concept pruners and controllers; (3) a meta-API for taxonomic name resolution services; (4) a system for storing, finding, and retrieving phylogenies using semantic web technologies for data exchange, storage, and querying; (5) an innovative new service, DateLife.org, which synthesizes pre-computed, time-calibrated phylogenies to assign ages to nodes; and (6) demonstration projects. These outcomes are accessible via a public code repository (GitHub.com), a website (http://www.phylotastic.org), and a server image. Conclusions Approximately 9 person-months of effort (centered on a software development hackathon) resulted in the design and implementation of proof-of-concept software for 4 core phylotastic components, 3 controllers, and 3 end-user demonstration tools. While these products have substantial limitations, they suggest considerable potential for a distributed system that makes phylogenetic knowledge readily accessible in computable form. Widespread use of phylotastic systems will create an electronic marketplace for sharing phylogenetic knowledge that will spur innovation in other areas of the ToL enterprise, such as annotation of sources and methods and third-party methods of quality assessment.",2013-05-13,2021-06-05 21:13:27; 2021-06-05 20:56:20; 2021-06-05 20:59:14,158,,14,BMC Bioinformatics,,PubMed Central,PMID: 23668630 PMCID: PMC3669619,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3669619/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
395,10.1186/1471-2105-14-159,23672344,PMC3680968,,,,"Di Lena, Pietro; Wu, Gang; Martelli, Pier Luigi; Casadio, Rita; Nardini, Christine",MIMO: an efficient tool for molecular interaction maps overlap,2013,BMC bioinformatics; BMC Bioinformatics,,"Background Molecular pathways represent an ensemble of interactions occurring among molecules within the cell and between cells. The identification of similarities between molecular pathways across organisms and functions has a critical role in understanding complex biological processes. For the inference of such novel information, the comparison of molecular pathways requires to account for imperfect matches (flexibility) and to efficiently handle complex network topologies. To date, these characteristics are only partially available in tools designed to compare molecular interaction maps. Results Our approach MIMO (Molecular Interaction Maps Overlap) addresses the first problem by allowing the introduction of gaps and mismatches between query and template pathways and permits -when necessary- supervised queries incorporating a priori biological information. It then addresses the second issue by relying directly on the rich graph topology described in the Systems Biology Markup Language (SBML) standard, and uses multidigraphs to efficiently handle multiple queries on biological graph databases. The algorithm has been here successfully used to highlight the contact point between various human pathways in the Reactome database. Conclusions MIMO offers a flexible and efficient graph-matching tool for comparing complex biological pathways.; BACKGROUND: Molecular pathways represent an ensemble of interactions occurring among molecules within the cell and between cells. The identification of similarities between molecular pathways across organisms and functions has a critical role in understanding complex biological processes. For the inference of such novel information, the comparison of molecular pathways requires to account for imperfect matches (flexibility) and to efficiently handle complex network topologies. To date, these characteristics are only partially available in tools designed to compare molecular interaction maps. RESULTS: Our approach MIMO (Molecular Interaction Maps Overlap) addresses the first problem by allowing the introduction of gaps and mismatches between query and template pathways and permits -when necessary- supervised queries incorporating a priori biological information. It then addresses the second issue by relying directly on the rich graph topology described in the Systems Biology Markup Language (SBML) standard, and uses multidigraphs to efficiently handle multiple queries on biological graph databases. The algorithm has been here successfully used to highlight the contact point between various human pathways in the Reactome database. CONCLUSIONS: MIMO offers a flexible and efficient graph-matching tool for comparing complex biological pathways.",2013-05-15,2021-06-05 21:13:27; 2021-06-05 21:06:22,159,,14,BMC Bioinformatics,MIMO,PubMed; PubMed Central,PMID: 23672344 PMCID: PMC3680968,http://www.ncbi.nlm.nih.gov/pubmed/23672344; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3680968/,"Algorithms; Amino Acids; Citric Acid Cycle; Computer Graphics; Databases, Factual; Electron Transport; Humans; Metabolic Networks and Pathways; Mitosis; Signal Transduction; Software; Systems Biology; Wnt Signaling Pathway",,,PubMed:Query2; PMC:Query2
396,10.1186/1471-2105-14-S7-S13,23815292,PMC3633016,,,,"Bonnici, Vincenzo; Giugno, Rosalba; Pulvirenti, Alfredo; Shasha, Dennis; Ferro, Alfredo",A subgraph isomorphism algorithm and its application to biochemical data,2013,BMC Bioinformatics,,"Background Graphs can represent biological networks at the molecular, protein, or species level. An important query is to find all matches of a pattern graph to a target graph. Accomplishing this is inherently difficult (NP-complete) and the efficiency of heuristic algorithms for the problem may depend upon the input graphs. The common aim of existing algorithms is to eliminate unsuccessful mappings as early as and as inexpensively as possible. Results We propose a new subgraph isomorphism algorithm which applies a search strategy to significantly reduce the search space without using any complex pruning rules or domain reduction procedures. We compare our method with the most recent and efficient subgraph isomorphism algorithms (VFlib, LAD, and our C++ implementation of FocusSearch which was originally distributed in Modula2) on synthetic, molecules, and interaction networks data. We show a significant reduction in the running time of our approach compared with these other excellent methods and show that our algorithm scales well as memory demands increase. Conclusions Subgraph isomorphism algorithms are intensively used by biochemical tools. Our analysis gives a comprehensive comparison of different software approaches to subgraph isomorphism highlighting their weaknesses and strengths. This will help researchers make a rational choice among methods depending on their application. We also distribute an open-source package including our system and our own C++ implementation of FocusSearch together with all the used datasets (http://ferrolab.dmi.unict.it/ri.html). In future work, our findings may be extended to approximate subgraph isomorphism algorithms.",2013-04-22,2021-06-05 21:13:27,S13,Suppl 7,14,BMC Bioinformatics,,PubMed Central,PMID: 23815292 PMCID: PMC3633016,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3633016/,,,,PMC:Query2
397,10.1186/1471-2105-15-64,24593054,PMC3973995,A,Neo4j,Neo4j,"Kang, Ning; Singh, Bharat; Bui, Chinh; Afzal, Zubair; van Mulligen, Erik M; Kors, Jan A",Knowledge-based extraction of adverse drug events from biomedical text,2014,BMC Bioinformatics,,"Background Many biomedical relation extraction systems are machine-learning based and have to be trained on large annotated corpora that are expensive and cumbersome to construct. We developed a knowledge-based relation extraction system that requires minimal training data, and applied the system for the extraction of adverse drug events from biomedical text. The system consists of a concept recognition module that identifies drugs and adverse effects in sentences, and a knowledge-base module that establishes whether a relation exists between the recognized concepts. The knowledge base was filled with information from the Unified Medical Language System. The performance of the system was evaluated on the ADE corpus, consisting of 1644 abstracts with manually annotated adverse drug events. Fifty abstracts were used for training, the remaining abstracts were used for testing. Results The knowledge-based system obtained an F-score of 50.5%, which was 34.4 percentage points better than the co-occurrence baseline. Increasing the training set to 400 abstracts improved the F-score to 54.3%. When the system was compared with a machine-learning system, jSRE, on a subset of the sentences in the ADE corpus, our knowledge-based system achieved an F-score that is 7 percentage points higher than the F-score of jSRE trained on 50 abstracts, and still 2 percentage points higher than jSRE trained on 90% of the corpus. Conclusion A knowledge-based approach can be successfully used to extract adverse drug events from biomedical text without need for a large training set. Whether use of a knowledge base is equally advantageous for other biomedical relation-extraction tasks remains to be investigated.",2014-03-04,2021-06-05 21:13:27; 2021-06-05 20:56:20; 2021-06-05 20:37:08,64,,15,BMC Bioinformatics,,PubMed Central,PMID: 24593054 PMCID: PMC3973995,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3973995/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
398,10.1186/1471-2105-16-S17-S5,26679199,PMC4674855,,,,"Shabana, KM; Abdul Nazeer, KA; Pradhan, Meeta; Palakal, Mathew",A computational method for drug repositioning using publicly available gene expression data,2015,BMC Bioinformatics,,"Motivation The identification of new therapeutic uses of existing drugs, or drug repositioning, offers the possibility of faster drug development, reduced risk, lesser cost and shorter paths to approval. The advent of high throughput microarray technology has enabled comprehensive monitoring of transcriptional response associated with various disease states and drug treatments. This data can be used to characterize disease and drug effects and thereby give a measure of the association between a given drug and a disease. Several computational methods have been proposed in the literature that make use of publicly available transcriptional data to reposition drugs against diseases. Method In this work, we carry out a data mining process using publicly available gene expression data sets associated with a few diseases and drugs, to identify the existing drugs that can be used to treat genes causing lung cancer and breast cancer. Results Three strong candidates for repurposing have been identified- Letrozole and GDC-0941 against lung cancer, and Ribavirin against breast cancer. Letrozole and GDC-0941 are drugs currently used in breast cancer treatment and Ribavirin is used in the treatment of Hepatitis C.",2015-12-07,2021-06-05 21:12:40,S5,Suppl 17,16,BMC Bioinformatics,,PubMed Central,PMID: 26679199 PMCID: PMC4674855,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4674855/,,,,PMC:Query2
399,10.1186/1471-2105-7-21,16417636,PMC1382257,,,,"Durand, Patrick; Labarre, Laurent; Meil, Alain; Divo1, Jean-Louis; Vandenbrouck, Yves; Viari, Alain; Wojcik, Jérôme",GenoLink: a graph-based querying and browsing system for investigating the function of genes and proteins,2006,BMC Bioinformatics,,"Background A large variety of biological data can be represented by graphs. These graphs can be constructed from heterogeneous data coming from genomic and post-genomic technologies, but there is still need for tools aiming at exploring and analysing such graphs. This paper describes GenoLink, a software platform for the graphical querying and exploration of graphs. Results GenoLink provides a generic framework for representing and querying data graphs. This framework provides a graph data structure, a graph query engine, allowing to retrieve sub-graphs from the entire data graph, and several graphical interfaces to express such queries and to further explore their results. A query consists in a graph pattern with constraints attached to the vertices and edges. A query result is the set of all sub-graphs of the entire data graph that are isomorphic to the pattern and satisfy the constraints. The graph data structure does not rely upon any particular data model but can dynamically accommodate for any user-supplied data model. However, for genomic and post-genomic applications, we provide a default data model and several parsers for the most popular data sources. GenoLink does not require any programming skill since all operations on graphs and the analysis of the results can be carried out graphically through several dedicated graphical interfaces. Conclusion GenoLink is a generic and interactive tool allowing biologists to graphically explore various sources of information. GenoLink is distributed either as a standalone application or as a component of the Genostar/Iogma platform. Both distributions are free for academic research and teaching purposes and can be requested at academy@genostar.com. A commercial licence form can be obtained for profit company at info@genostar.com. See also .",2006-01-17,2021-06-05 21:14:07,21,,7,BMC Bioinformatics,GenoLink,PubMed Central,PMID: 16417636 PMCID: PMC1382257,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1382257/,,,,PMC:Query2
400,10.1186/1471-2105-8-S3-S5,17493288,PMC1892102,,,,"Smith, Andrew K; Cheung, Kei-Hoi; Yip, Kevin Y; Schultz, Martin; Gerstein, Mark B",LinkHub: a Semantic Web system that facilitates cross-database queries and information retrieval in proteomics,2007,BMC Bioinformatics,,"Background A key abstraction in representing proteomics knowledge is the notion of unique identifiers for individual entities (e.g. proteins) and the massive graph of relationships among them. These relationships are sometimes simple (e.g. synonyms) but are often more complex (e.g. one-to-many relationships in protein family membership). Results We have built a software system called LinkHub using Semantic Web RDF that manages the graph of identifier relationships and allows exploration with a variety of interfaces. For efficiency, we also provide relational-database access and translation between the relational and RDF versions. LinkHub is practically useful in creating small, local hubs on common topics and then connecting these to major portals in a federated architecture; we have used LinkHub to establish such a relationship between UniProt and the North East Structural Genomics Consortium. LinkHub also facilitates queries and access to information and documents related to identifiers spread across multiple databases, acting as ""connecting glue"" between different identifier spaces. We demonstrate this with example queries discovering ""interologs"" of yeast protein interactions in the worm and exploring the relationship between gene essentiality and pseudogene content. We also show how ""protein family based"" retrieval of documents can be achieved. LinkHub is available at hub.gersteinlab.org and hub.nesg.org with supplement, database models and full-source code. Conclusion LinkHub leverages Semantic Web standards-based integrated data to provide novel information retrieval to identifier-related documents through relational graph queries, simplifies and manages connections to major hubs such as UniProt, and provides useful interactive and query interfaces for exploring the integrated data.",2007-05-09,2021-06-05 21:14:07,S5,Suppl 3,8,BMC Bioinformatics,LinkHub,PubMed Central,PMID: 17493288 PMCID: PMC1892102,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1892102/,,,,PMC:Query2
401,10.1186/1471-2105-9-S1-S6,18315859,PMC2259407,A,AllegroGraph,AllegroGraph,"Xu, Qingwei; Shi, Yixiang; Lu, Qiang; Zhang, Guoqing; Luo, Qingming; Li, Yixue",GORouter: an RDF model for providing semantic query and inference services for Gene Ontology and its associations,2008,BMC Bioinformatics,,"Background The most renowned biological ontology, Gene Ontology (GO) is widely used for annotations of genes and gene products of different organisms. However, there are shortcomings in the Resource Description Framework (RDF) data file provided by the GO consortium: 1) Lack of sufficient semantic relationships between pairs of terms coming from the three independent GO sub-ontologies, that limit the power to provide complex semantic queries and inference services based on it. 2) The term-centric view of GO annotation data and the fact that all information is stored in a single file. This makes attempts to retrieve GO annotations based on big volume datasets unmanageable. 3) No support of GOSlim. Results We propose a RDF model, GORouter, which encodes heterogeneous original data in a uniform RDF format, creates additional ontology mappings between GO terms, and introduces a set of inference rulebases. Furthermore, we use the Oracle Network Data Model (NDM) as the native RDF data repository and the table function RDF_MATCH to seamlessly combine the result of RDF queries with traditional relational data. As a result, the scale of GORouter is minimized; information not directly involved in semantic inference is put into relational tables. Conclusion Our work demonstrates how to use multiple semantic web tools and techniques to provide a mixture of semantic query and inference solutions of GO and its associations. GORouter is licensed under Apache License Version 2.0, and is accessible via the website: .",2008-02-13,2021-06-06 06:38:41; 2021-06-05 20:56:20; 2021-06-05 21:14:07,S6,Suppl 1,9,BMC Bioinformatics,GORouter,PubMed Central,PMID: 18315859 PMCID: PMC2259407,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2259407/,,AllegroGraph,AllegroGraph,PMC:Query3; PMC:AllegroGraph; PMC:Query2
402,10.1186/1471-2105-9-S4-S10,18460171,PMC2367637,,,,"Ferro, Alfredo; Giugno, Rosalba; Mongiovì, Misael; Pulvirenti, Alfredo; Skripin, Dmitry; Shasha, Dennis",GraphFind: enhancing graph searching by low support data mining techniques,2008,BMC bioinformatics; BMC Bioinformatics,,"Background Biomedical and chemical databases are large and rapidly growing in size. Graphs naturally model such kinds of data. To fully exploit the wealth of information in these graph databases, a key role is played by systems that search for all exact or approximate occurrences of a query graph. To deal efficiently with graph searching, advanced methods for indexing, representation and matching of graphs have been proposed. Results This paper presents GraphFind. The system implements efficient graph searching algorithms together with advanced filtering techniques that allow approximate search. It allows users to select candidate subgraphs rather than entire graphs. It implements an effective data storage based also on low-support data mining. Conclusions GraphFind is compared with Frowns, GraphGrep and gIndex. Experiments show that GraphFind outperforms the compared systems on a very large collection of small graphs. The proposed low-support mining technique which applies to any searching system also allows a significant index space reduction.; BACKGROUND: Biomedical and chemical databases are large and rapidly growing in size. Graphs naturally model such kinds of data. To fully exploit the wealth of information in these graph databases, a key role is played by systems that search for all exact or approximate occurrences of a query graph. To deal efficiently with graph searching, advanced methods for indexing, representation and matching of graphs have been proposed. RESULTS: This paper presents GraphFind. The system implements efficient graph searching algorithms together with advanced filtering techniques that allow approximate search. It allows users to select candidate subgraphs rather than entire graphs. It implements an effective data storage based also on low-support data mining. CONCLUSIONS: GraphFind is compared with Frowns, GraphGrep and gIndex. Experiments show that GraphFind outperforms the compared systems on a very large collection of small graphs. The proposed low-support mining technique which applies to any searching system also allows a significant index space reduction.",2008-04-25,2021-06-05 21:06:22; 2021-06-05 21:14:07,S10,Suppl 4,9; 9 Suppl 4,BMC Bioinformatics,GraphFind,PubMed; PubMed Central,PMID: 18460171 PMCID: PMC2367637,http://www.ncbi.nlm.nih.gov/pubmed/18460171; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2367637/,"Computer Simulation; Database Management Systems; Databases, Factual; Information Storage and Retrieval; Models, Chemical; Models, Molecular; Software",,,PubMed:Query2; PMC:Query2
403,10.1186/1471-2164-12-S3-S6,22369294,PMC3333189,,,,"Ali, Jamshaid; Paila, Umadevi; Ranjan, Akash",ApicoAlign: an alignment and sequence search tool for apicomplexan proteins,2011,BMC Genomics,,"Background Over the recent years, a number of genomes have been successfully sequenced and this was followed by genome annotation projects to help understand the biological capabilities of newly sequenced genomes. To improve the annotation of Plasmodium falciparum proteins, we earlier developed parasite specific matrices (PfSSM) and demonstrated their (Smat80 and PfFSmat60) better performance over standard matrices (BLOSUM and PAM). Here we extend that study to nine apicomplexan species other than P. falciparum and develop a web application ApicoAlign for improving the annotation of apicomplexan proteins. Results The SMAT80 and PfFSmat60 matrices perform better for apicomplexan proteins compared to BLOSUM in detecting the orthologs and improving the alignment of these proteins with their potential orthologs respectively. Database searches against non-redundant (nr) database have shown that SMAT80 gives superior performance compared to BLOSUM series in terms of E-values, bit scores, percent identity, alignment length and mismatches for most of the apicomplexan proteins studied here. Using these matrices, we were able to find orthologs for rhomboid proteases of P. berghei, P. falciparum &P. vivax and large subunit of U2 snRNP auxiliary factor of Cryptosporidium parvum in Arabidopsis thaliana. We also show improved pairwise alignments of proteins from Apicomplexa viz. Cryptosporidium parvum and P. falciparum with their orthologs from other species using the PfFSmat60 matrix. Conclusions The SMAT80 and PfFSmat60 substitution matrices perform better for apicomplexan proteins compared to BLOSUM series. Since they can be helpful in improving the annotation of apicomplexan genomes and their functional characterization, we have developed a web server ApicoAlign for finding orthologs and aligning apicomplexan proteins.",2011-11-30,2021-06-05 21:13:27,S6,Suppl 3,12,BMC Genomics,ApicoAlign,PubMed Central,PMID: 22369294 PMCID: PMC3333189,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3333189/,,,,PMC:Query2
404,10.1186/1471-2164-14-866,24320622,PMC4046656,,,,"Parra, Ruben; Paredes, Miguel A; Sanchez-Calle, Isabel M; Gomez-Jimenez, Maria C",Comparative transcriptional profiling analysis of olive ripe-fruit pericarp and abscission zone tissues shows expression differences and distinct patterns of transcriptional regulation,2013,BMC Genomics,,"Background In fleshy fruit, abscission of fully ripe fruit is a process intimately linked to the ripening process. In many fruit-tree species, such as olive (Olea europaea L. cv. Picual), there is a coupling of the full ripening and the activation of the abscission-zone (AZ). Although fully ripe fruit have marked physiological differences with respect to their AZs, dissimilarities in gene expression have not been thoroughly investigated. The present study examines the transcriptome of olive fruit and their AZ tissues at the last stage of ripening, monitored using mRNA-Seq. Results Roche-454 massive parallel pyrosequencing enabled us to generate 397,457 high-quality EST sequences, among which 199,075 were from ripe-fruit pericarp and 198,382 from AZ tissues. We assembled these sequences into 19,062 contigs, grouped as 17,048 isotigs. Using the read amounts for each annotated isotig (from a total of 15,671), we identified 7,756 transcripts. A comparative analysis of the transcription profiles conducted in ripe-fruit pericarp and AZ evidenced that 4,391 genes were differentially expressed genes (DEGs) in fruit and AZ. Functional categorization of the DEGs revealed that AZ tissue has an apparently higher response to external stimuli than does that of ripe fruit, revealing a higher expression of auxin-signaling genes, as well as lignin catabolic and biosynthetic pathway, aromatic amino acid biosynthetic pathway, isoprenoid biosynthetic pathway, protein amino acid dephosphorylation, amino acid transport, and photosynthesis. By contrast, fruit-enriched transcripts are involved in ATP synthesis coupled proton transport, glycolysis, and cell-wall organization. Furthermore, over 150 transcripts encoding putative transcription-factors (TFs) were identified (37 fruit TFs and 113 AZ TFs), of which we randomly selected eight genes and we confirmed their expression patterns using quantitative RT-PCR. Conclusion We generated a set of EST sequences from olive fruit at full ripening, and DEGs between two different olive tissues, ripe fruit and their AZ, were also identified. Regarding the cross-talk between fruit and AZ, using qRT-PCR, we confirmed a set of TF genes that were differentially expressed, revealing profiles of expression that have not previously been reported, this offering a promising beginning for studies on the different transcription regulation in such tissues. Electronic supplementary material The online version of this article (doi:10.1186/1471-2164-14-866) contains supplementary material, which is available to authorized users.",2013-12-09,2021-06-05 21:13:27,,1,14,BMC Genomics,,PubMed Central,PMID: 24320622 PMCID: PMC4046656,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4046656/,,,,PMC:Query2
405,10.1186/1471-2164-16-S3-S9,25708381,PMC4331812,A,Neo4j,Neo4j,"Li, Ling; Hur, Manhoi; Lee, Joon-Yong; Zhou, Wenxu; Song, Zhihong; Ransom, Nick; Demirkale, Cumhur Yusuf; Nettleton, Dan; Westgate, Mark; Arendsee, Zebulun; Iyer, Vidya; Shanks, Jackie; Nikolau, Basil; Wurtele, Eve Syrkin",A systems biology approach toward understanding seed composition in soybean,2015,BMC Genomics,,"Background The molecular, biochemical, and genetic mechanisms that regulate the complex metabolic network of soybean seed development determine the ultimate balance of protein, lipid, and carbohydrate stored in the mature seed. Many of the genes and metabolites that participate in seed metabolism are unknown or poorly defined; even more remains to be understood about the regulation of their metabolic networks. A global omics analysis can provide insights into the regulation of seed metabolism, even without a priori assumptions about the structure of these networks. Results With the future goal of predictive biology in mind, we have combined metabolomics, transcriptomics, and metabolic flux technologies to reveal the global developmental and metabolic networks that determine the structure and composition of the mature soybean seed. We have coupled this global approach with interactive bioinformatics and statistical analyses to gain insights into the biochemical programs that determine soybean seed composition. For this purpose, we used Plant/Eukaryotic and Microbial Metabolomics Systems Resource (PMR, http://www.metnetdb.org/pmr, a platform that incorporates metabolomics data to develop hypotheses concerning the organization and regulation of metabolic networks, and MetNet systems biology tools http://www.metnetdb.org for plant omics data, a framework to enable interactive visualization of metabolic and regulatory networks. Conclusions This combination of high-throughput experimental data and bioinformatics analyses has revealed sets of specific genes, genetic perturbations and mechanisms, and metabolic changes that are associated with the developmental variation in soybean seed composition. Researchers can explore these metabolomics and transcriptomics data interactively at PMR.",2015-01-29,2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-05 20:37:08,S9,Suppl 3,16,BMC Genomics,,PubMed Central,PMID: 25708381 PMCID: PMC4331812,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4331812/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
406,10.1186/1748-7188-9-16,25061474,PMC4085724,,,,"Deepak, Akshay; Fernández-Baca, David",Enumerating all maximal frequent subtrees in collections of phylogenetic trees,2014,Algorithms for Molecular Biology : AMB,,"Background A common problem in phylogenetic analysis is to identify frequent patterns in a collection of phylogenetic trees. The goal is, roughly, to find a subset of the species (taxa) on which all or some significant subset of the trees agree. One popular method to do so is through maximum agreement subtrees (MASTs). MASTs are also used, among other things, as a metric for comparing phylogenetic trees, computing congruence indices and to identify horizontal gene transfer events. Results We give algorithms and experimental results for two approaches to identify common patterns in a collection of phylogenetic trees, one based on agreement subtrees, called maximal agreement subtrees, the other on frequent subtrees, called maximal frequent subtrees. These approaches can return subtrees on larger sets of taxa than MASTs, and can reveal new common phylogenetic relationships not present in either MASTs or the majority rule tree (a popular consensus method). Our current implementation is available on the web at https://code.google.com/p/mfst-miner/. Conclusions Our computational results confirm that maximal agreement subtrees and all maximal frequent subtrees can reveal a more complete phylogenetic picture of the common patterns in collections of phylogenetic trees than maximum agreement subtrees; they are also often more resolved than the majority rule tree. Further, our experiments show that enumerating maximal frequent subtrees is considerably more practical than enumerating ordinary (not necessarily maximal) frequent subtrees.",2014-06-18,2021-06-05 21:12:40,16,,9,Algorithms Mol Biol,,PubMed Central,PMID: 25061474 PMCID: PMC4085724,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4085724/,,,,PMC:Query2
407,10.1186/1749-8546-5-2,20205772,PMC2823599,A,AllegroGraph,AllegroGraph,"Cheung, Kei-Hoi; Chen, Huajun",Semantic Web for data harmonization in Chinese medicine,2010,Chinese Medicine,,Scientific studies to investigate Chinese medicine with Western medicine have been generating a large amount of data to be shared preferably under a global data standard. This article provides an overview of Semantic Web and identifies some representative Semantic Web applications in Chinese medicine. Semantic Web is proposed as a standard for representing Chinese medicine data and facilitating their integration with Western medicine data.,2010-01-12,2021-06-05 21:13:27; 2021-06-06 06:38:41; 2021-06-05 20:56:20,2,,5,Chin Med,,PubMed Central,PMID: 20205772 PMCID: PMC2823599,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2823599/,,AllegroGraph,AllegroGraph,PMC:Query3; PMC:AllegroGraph; PMC:Query2
408,10.1186/1752-0509-5-172,22024446,PMC3231954,,,,"Hendrix, Willam; Rocha, Andrea M; Padmanabhan, Kanchana; Choudhary, Alok; Scott, Kathleen; Mihelcic, James R; Samatova, Nagiza F",DENSE: efficient and prior knowledge-driven discovery of phenotype-associated protein functional modules,2011,BMC Systems Biology,,"Background Identifying cellular subsystems that are involved in the expression of a target phenotype has been a very active research area for the past several years. In this paper, cellular subsystem refers to a group of genes (or proteins) that interact and carry out a common function in the cell. Most studies identify genes associated with a phenotype on the basis of some statistical bias, others have extended these statistical methods to analyze functional modules and biological pathways for phenotype-relatedness. However, a biologist might often have a specific question in mind while performing such analysis and most of the resulting subsystems obtained by the existing methods might be largely irrelevant to the question in hand. Arguably, it would be valuable to incorporate biologist's knowledge about the phenotype into the algorithm. This way, it is anticipated that the resulting subsytems would not only be related to the target phenotype but also contain information that the biologist is likely to be interested in. Results In this paper we introduce a fast and theoretically guranteed method called DENSE (Dense and ENriched Subgraph Enumeration) that can take in as input a biologist's prior knowledge as a set of query proteins and identify all the dense functional modules in a biological network that contain some part of the query vertices. The density (in terms of the number of network egdes) and the enrichment (the number of query proteins in the resulting functional module) can be manipulated via two parameters γ and μ, respectively. Conclusion This algorithm has been applied to the protein functional association network of Clostridium acetobutylicum ATCC 824, a hydrogen producing, acid-tolerant organism. The algorithm was able to verify relationships known to exist in literature and also some previously unknown relationships including those with regulatory and signaling functions. Additionally, we were also able to hypothesize that some uncharacterized proteins are likely associated with the target phenotype. The DENSE code can be downloaded from http://www.freescience.org/cs/DENSE/",2011-10-24,2021-06-05 21:13:27,172,,5,BMC Syst Biol,DENSE,PubMed Central,PMID: 22024446 PMCID: PMC3231954,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3231954/,,,,PMC:Query2
409,10.1186/1752-0509-7-S4-S3,24565174,PMC3854656,,,,"Hasan, Md Mahmudul; Kavurucu, Yusuf; Kahveci, Tamer",A scalable method for discovering significant subnetworks,2013,BMC Systems Biology,,"Background Study of biological networks is an essential first step to understand the complex functions they govern in different organisms. The topology of interactions that define how biological networks operate is often determined through high-throughput experiments. Noisy nature of high-throughput experiments, however, can result in multiple alternative network topologies that explain this data equally well. One key step to resolve the differences is to identify the subnetworks which appear significantly more frequently in a biological network data set than expected. Method We present a method named SiS (Significant Subnetworks) to find subnetworks with the largest probability to appear in a collection of biological networks. We define these subnetworks as the most probable subnetworks. SiS summarizes the interactions in the given collection of networks in a special template network. It uses the template network to guide the search for most probable subnetworks. It computes the lower and upper bound scores on how good the potential solutions are (i.e., the number of input networks that contain the subnetwork). As the search continues, it tightens the bound dynamically and prunes a massive number of unpromising solutions in that process. Results and conclusions Experiments on comprehensive data sets depict that the most probable subnetworks found by SiS in a large collection of networks are also very frequent as well. In metabolic network data set, we found that subnetworks in eukaryote are more conserved than those of prokaryote. SiS also scales well to large data sets and subnetworks and runs orders of magnitude faster than an existing method, MULE. Depending on the size of the subnetwork in the same data set, the running time of SiS ranges from a few seconds to minutes; MULE, on the other hand, runs either for hours or does not even finish in days. In human transcription regulatory network data set, SiS finds a large backbone subnetwork that appears frequently regardless of diverse cell types.",2013-10-23,2021-06-05 21:13:27,S3,Suppl 4,7,BMC Syst Biol,,PubMed Central,PMID: 24565174 PMCID: PMC3854656,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3854656/,,,,PMC:Query2
410,10.1186/1752-0509-8-S3-S6,25350277,PMC4243085,,,,"He, Jieyue; Wang, Chunyan; Qiu, Kunpu; Zhong, Wei",An novel frequent probability pattern mining algorithm based on circuit simulation method in uncertain biological networks,2014,BMC Systems Biology,,"Background Motif mining has always been a hot research topic in bioinformatics. Most of current research on biological networks focuses on exact motif mining. However, due to the inevitable experimental error and noisy data, biological network data represented as the probability model could better reflect the authenticity and biological significance, therefore, it is more biological meaningful to discover probability motif in uncertain biological networks. One of the key steps in probability motif mining is frequent pattern discovery which is usually based on the possible world model having a relatively high computational complexity. Methods In this paper, we present a novel method for detecting frequent probability patterns based on circuit simulation in the uncertain biological networks. First, the partition based efficient search is applied to the non-tree like subgraph mining where the probability of occurrence in random networks is small. Then, an algorithm of probability isomorphic based on circuit simulation is proposed. The probability isomorphic combines the analysis of circuit topology structure with related physical properties of voltage in order to evaluate the probability isomorphism between probability subgraphs. The circuit simulation based probability isomorphic can avoid using traditional possible world model. Finally, based on the algorithm of probability subgraph isomorphism, two-step hierarchical clustering method is used to cluster subgraphs, and discover frequent probability patterns from the clusters. Results The experiment results on data sets of the Protein-Protein Interaction (PPI) networks and the transcriptional regulatory networks of E. coli and S. cerevisiae show that the proposed method can efficiently discover the frequent probability subgraphs. The discovered subgraphs in our study contain all probability motifs reported in the experiments published in other related papers. Conclusions The algorithm of probability graph isomorphism evaluation based on circuit simulation method excludes most of subgraphs which are not probability isomorphism and reduces the search space of the probability isomorphism subgraphs using the mismatch values in the node voltage set. It is an innovative way to find the frequent probability patterns, which can be efficiently applied to probability motif discovery problems in the further studies.",2014-10-22,2021-06-05 21:12:40,S6,Suppl 3,8,BMC Syst Biol,,PubMed Central,PMID: 25350277 PMCID: PMC4243085,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4243085/,,,,PMC:Query2
411,10.1186/1756-0500-3-175,20569493,PMC2911465,A,Virtuoso,Virtuoso,"Xiang, Zuoshuang; Courtot, Mélanie; Brinkman, Ryan R; Ruttenberg, Alan; He, Yongqun",OntoFox: web-based support for ontology reuse,2010,BMC Research Notes,,"Background Ontology development is a rapidly growing area of research, especially in the life sciences domain. To promote collaboration and interoperability between different projects, the OBO Foundry principles require that these ontologies be open and non-redundant, avoiding duplication of terms through the re-use of existing resources. As current options to do so present various difficulties, a new approach, MIREOT, allows specifying import of single terms. Initial implementations allow for controlled import of selected annotations and certain classes of related terms. Findings OntoFox http://ontofox.hegroup.org/ is a web-based system that allows users to input terms, fetch selected properties, annotations, and certain classes of related terms from the source ontologies and save the results using the RDF/XML serialization of the Web Ontology Language (OWL). Compared to an initial implementation of MIREOT, OntoFox allows additional and more easily configurable options for selecting and rewriting annotation properties, and for inclusion of all or a computed subset of terms between low and top level terms. Additional methods for including related classes include a SPARQL-based ontology term retrieval algorithm that extracts terms related to a given set of signature terms and an option to extract the hierarchy rooted at a specified ontology term. OntoFox's output can be directly imported into a developer's ontology. OntoFox currently supports term retrieval from a selection of 15 ontologies accessible via SPARQL endpoints and allows users to extend this by specifying additional endpoints. An OntoFox application in the development of the Vaccine Ontology (VO) is demonstrated. Conclusions OntoFox provides a timely publicly available service, providing different options for users to collect terms from external ontologies, making them available for reuse by import into client OWL ontologies.",2010-06-22,2021-06-05 21:13:27; 2021-06-05 20:56:20; 2021-06-05 20:59:14,175,,3,BMC Res Notes,OntoFox,PubMed Central,PMID: 20569493 PMCID: PMC2911465,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2911465/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
412,10.1186/1756-0500-5-391,22839199,PMC3532365,,,,"Ho, Hui Kian; Gange, Graeme; Kuiper, Michael J; Ramamohanarao, Kotagiri",BetaSearch: a new method for querying β-residue motifs,2012,BMC Research Notes,,"Background Searching for structural motifs across known protein structures can be useful for identifying unrelated proteins with similar function and characterising secondary structures such as β-sheets. This is infeasible using conventional sequence alignment because linear protein sequences do not contain spatial information. β-residue motifs are β-sheet substructures that can be represented as graphs and queried using existing graph indexing methods, however, these approaches are designed for general graphs that do not incorporate the inherent structural constraints of β-sheets and require computationally-expensive filtering and verification procedures. 3D substructure search methods, on the other hand, allow β-residue motifs to be queried in a three-dimensional context but at significant computational costs. Findings We developed a new method for querying β-residue motifs, called BetaSearch, which leverages the natural planar constraints of β-sheets by indexing them as 2D matrices, thus avoiding much of the computational complexities involved with structural and graph querying. BetaSearch exhibits faster filtering, verification, and overall query time than existing graph indexing approaches whilst producing comparable index sizes. Compared to 3D substructure search methods, BetaSearch achieves 33 and 240 times speedups over index-based and pairwise alignment-based approaches, respectively. Furthermore, we have presented case-studies to demonstrate its capability of motif matching in sequentially dissimilar proteins and described a method for using BetaSearch to predict β-strand pairing. Conclusions We have demonstrated that BetaSearch is a fast method for querying substructure motifs. The improvements in speed over existing approaches make it useful for efficiently performing high-volume exploratory querying of possible protein substructural motifs or conformations. BetaSearch was used to identify a nearly identical β-residue motif between an entirely synthetic (Top7) and a naturally-occurring protein (Charcot-Leyden crystal protein), as well as identifying structural similarities between biotin-binding domains of avidin, streptavidin and the lipocalin gamma subunit of human C8.",2012-07-30,2021-06-05 21:13:27,391,,5,BMC Res Notes,BetaSearch,PubMed Central,PMID: 22839199 PMCID: PMC3532365,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3532365/,,,,PMC:Query2
413,10.1186/1758-2946-3-20,21595881,PMC3121712,A,Virtuoso,Virtuoso,"Chepelev, Leonid L; Dumontier, Michel",Chemical Entity Semantic Specification: Knowledge representation for efficient semantic cheminformatics and facile data integration,2011,Journal of Cheminformatics,,"Background Over the past several centuries, chemistry has permeated virtually every facet of human lifestyle, enriching fields as diverse as medicine, agriculture, manufacturing, warfare, and electronics, among numerous others. Unfortunately, application-specific, incompatible chemical information formats and representation strategies have emerged as a result of such diverse adoption of chemistry. Although a number of efforts have been dedicated to unifying the computational representation of chemical information, disparities between the various chemical databases still persist and stand in the way of cross-domain, interdisciplinary investigations. Through a common syntax and formal semantics, Semantic Web technology offers the ability to accurately represent, integrate, reason about and query across diverse chemical information. Results Here we specify and implement the Chemical Entity Semantic Specification (CHESS) for the representation of polyatomic chemical entities, their substructures, bonds, atoms, and reactions using Semantic Web technologies. CHESS provides means to capture aspects of their corresponding chemical descriptors, connectivity, functional composition, and geometric structure while specifying mechanisms for data provenance. We demonstrate that using our readily extensible specification, it is possible to efficiently integrate multiple disparate chemical data sources, while retaining appropriate correspondence of chemical descriptors, with very little additional effort. We demonstrate the impact of some of our representational decisions on the performance of chemically-aware knowledgebase searching and rudimentary reaction candidate selection. Finally, we provide access to the tools necessary to carry out chemical entity encoding in CHESS, along with a sample knowledgebase. Conclusions By harnessing the power of Semantic Web technologies with CHESS, it is possible to provide a means of facile cross-domain chemical knowledge integration with full preservation of data correspondence and provenance. Our representation builds on existing cheminformatics technologies and, by the virtue of RDF specification, remains flexible and amenable to application- and domain-specific annotations without compromising chemical data integration. We conclude that the adoption of a consistent and semantically-enabled chemical specification is imperative for surviving the coming chemical data deluge and supporting systems science research.",2011-05-19,2021-06-05 21:13:27; 2021-06-05 20:56:20; 2021-06-05 20:59:14,20,,3,J Cheminform,Chemical Entity Semantic Specification,PubMed Central,PMID: 21595881 PMCID: PMC3121712,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3121712/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
414,10.1186/1758-2946-4-15,22870956,PMC3434037,,,,"Phadungsukanan, Weerapong; Kraft, Markus; Townsend, Joe A; Murray-Rust, Peter",The semantics of Chemical Markup Language (CML) for computational chemistry : CompChem,2012,Journal of Cheminformatics,,"This paper introduces a subdomain chemistry format for storing computational chemistry data called CompChem. It has been developed based on the design, concepts and methodologies of Chemical Markup Language (CML) by adding computational chemistry semantics on top of the CML Schema. The format allows a wide range of ab initio quantum chemistry calculations of individual molecules to be stored. These calculations include, for example, single point energy calculation, molecular geometry optimization, and vibrational frequency analysis. The paper also describes the supporting infrastructure, such as processing software, dictionaries, validation tools and database repositories. In addition, some of the challenges and difficulties in developing common computational chemistry dictionaries are discussed. The uses of CompChem are illustrated by two practical applications.",2012-08-07,2021-06-05 21:13:27,15,,4,J Cheminform,The semantics of Chemical Markup Language (CML) for computational chemistry,PubMed Central,PMID: 22870956 PMCID: PMC3434037,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3434037/,,,,PMC:Query2
415,10.1186/1878-5085-5-16,25538797,PMC4274760,,,,"Berliner, Leonard; Lemke, Heinz U; vanSonnenberg, Eric; Ashamalla, Hani; Mattes, Malcolm D; Dosik, David; Hazin, Hesham; Shah, Syed; Mohanty, Smruti; Verma, Sid; Esposito, Giuseppe; Bargellini, Irene; Battaglia, Valentina; Caramella, Davide; Bartolozzi, Carlo; Morrison, Paul","Model-guided therapy for hepatocellular carcinoma: a role for information technology in predictive, preventive and personalized medicine",2014,The EPMA Journal,,"Predictive, preventive and personalized medicine (PPPM) may have the potential to eventually improve the nature of health care delivery. However, the tools required for a practical and comprehensive form of PPPM that is capable of handling the vast amounts of medical information that is currently available are currently lacking. This article reviews a rationale and method for combining and integrating diagnostic and therapeutic management with information technology (IT), in a manner that supports patients through their continuum of care. It is imperative that any program devised to explore and develop personalized health care delivery must be firmly rooted in clinically confirmed and accepted principles and technologies. Therefore, a use case, relating to hepatocellular carcinoma (HCC), was developed. The approach to the management of medical information we have taken is based on model theory and seeks to implement a form of model-guided therapy (MGT) that can be used as a decision support system in the treatment of patients with HCC. The IT structures to be utilized in MGT include a therapy imaging and model management system (TIMMS) and a digital patient model (DPM). The system that we propose will utilize patient modeling techniques to generate valid DPMs (which factor in age, physiologic condition, disease and co-morbidities, genetics, biomarkers and responses to previous treatments). We may, then, be able to develop a statistically valid methodology, on an individual basis, to predict certain diseases or conditions, to predict certain treatment outcomes, to prevent certain diseases or complications and to develop treatment regimens that are personalized for that particular patient. An IT system for predictive, preventive and personalized medicine (ITS-PM) for HCC is presented to provide a comprehensive system to provide unified access to general medical and patient-specific information for medical researchers and health care providers from different disciplines including hepatologists, gastroenterologists, medical and surgical oncologists, liver transplant teams, interventional radiologists and radiation oncologists. The article concludes with a review providing an outlook and recommendations for the application of MGT to enhance the medical management of HCC through PPPM.",2014-09-23,2021-06-05 21:12:40,16,1,5,EPMA J,Model-guided therapy for hepatocellular carcinoma,PubMed Central,PMID: 25538797 PMCID: PMC4274760,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4274760/,,,,PMC:Query2
416,10.1186/2041-1480-2-S2-S1,21624155,PMC3102889,A,Virtuoso,Virtuoso,"Luciano, Joanne S; Andersson, Bosse; Batchelor, Colin; Bodenreider, Olivier; Clark, Tim; Denney, Christine K; Domarew, Christopher; Gambet, Thomas; Harland, Lee; Jentzsch, Anja; Kashyap, Vipul; Kos, Peter; Kozlovsky, Julia; Lebo, Timothy; Marshall, Scott M; McCusker, James P; McGuinness, Deborah L; Ogbuji, Chimezie; Pichler, Elgar; Powers, Robert L; Prud’hommeaux, Eric; Samwald, Matthias; Schriml, Lynn; Tonellato, Peter J; Whetzel, Patricia L; Zhao, Jun; Stephens, Susie; Dumontier, Michel",The Translational Medicine Ontology and Knowledge Base: driving personalized medicine by bridging the gap between bench and bedside,2011,Journal of Biomedical Semantics,,"Background Translational medicine requires the integration of knowledge using heterogeneous data from health care to the life sciences. Here, we describe a collaborative effort to produce a prototype Translational Medicine Knowledge Base (TMKB) capable of answering questions relating to clinical practice and pharmaceutical drug discovery. Results We developed the Translational Medicine Ontology (TMO) as a unifying ontology to integrate chemical, genomic and proteomic data with disease, treatment, and electronic health records. We demonstrate the use of Semantic Web technologies in the integration of patient and biomedical data, and reveal how such a knowledge base can aid physicians in providing tailored patient care and facilitate the recruitment of patients into active clinical trials. Thus, patients, physicians and researchers may explore the knowledge base to better understand therapeutic options, efficacy, and mechanisms of action. Conclusions This work takes an important step in using Semantic Web technologies to facilitate integration of relevant, distributed, external sources and progress towards a computational platform to support personalized medicine. Availability TMO can be downloaded from http://code.google.com/p/translationalmedicineontology and TMKB can be accessed at http://tm.semanticscience.org/sparql.",2011-05-17,2021-06-05 21:13:27; 2021-06-05 20:56:20; 2021-06-05 20:59:14,S1,Suppl 2,2,J Biomed Semantics,The Translational Medicine Ontology and Knowledge Base,PubMed Central,PMID: 21624155 PMCID: PMC3102889,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3102889/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
417,10.1186/2041-1480-2-S2-S3,21624158,PMC3102892,A,Virtuoso,Virtuoso,"Callahan, Alison; Dumontier, Michel; Shah, Nigam H",HyQue: evaluating hypotheses using Semantic Web technologies,2011,Journal of Biomedical Semantics,,"Background Key to the success of e-Science is the ability to computationally evaluate expert-composed hypotheses for validity against experimental data. Researchers face the challenge of collecting, evaluating and integrating large amounts of diverse information to compose and evaluate a hypothesis. Confronted with rapidly accumulating data, researchers currently do not have the software tools to undertake the required information integration tasks. Results We present HyQue, a Semantic Web tool for querying scientific knowledge bases with the purpose of evaluating user submitted hypotheses. HyQue features a knowledge model to accommodate diverse hypotheses structured as events and represented using Semantic Web languages (RDF/OWL). Hypothesis validity is evaluated against experimental and literature-sourced evidence through a combination of SPARQL queries and evaluation rules. Inference over OWL ontologies (for type specifications, subclass assertions and parthood relations) and retrieval of facts stored as Bio2RDF linked data provide support for a given hypothesis. We evaluate hypotheses of varying levels of detail about the genetic network controlling galactose metabolism in Saccharomyces cerevisiae to demonstrate the feasibility of deploying such semantic computing tools over a growing body of structured knowledge in Bio2RDF. Conclusions HyQue is a query-based hypothesis evaluation system that can currently evaluate hypotheses about the galactose metabolism in S. cerevisiae. Hypotheses as well as the supporting or refuting data are represented in RDF and directly linked to one another allowing scientists to browse from data to hypothesis and vice versa. HyQue hypotheses and data are available at http://semanticscience.org/projects/hyque.",2011-05-17,2021-06-05 21:13:27; 2021-06-05 20:56:20; 2021-06-05 20:59:14,S3,Suppl 2,2,J Biomed Semantics,HyQue,PubMed Central,PMID: 21624158 PMCID: PMC3102892,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3102892/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
418,10.1186/2041-1480-3-S1-S6,22541597,PMC3337266,A,Virtuoso; AllegroGraph,Virtuoso; AllegroGraph,"Good, Benjamin M; Clarke, Erik L; Loguercio, Salvatore; Su, Andrew I",Linking genes to diseases with a SNPedia-Gene Wiki mashup,2012,Journal of Biomedical Semantics,,"Background A variety of topic-focused wikis are used in the biomedical sciences to enable the mass-collaborative synthesis and distribution of diverse bodies of knowledge. To address complex problems such as defining the relationships between genes and disease, it is important to bring the knowledge from many different domains together. Here we show how advances in wiki technology and natural language processing can be used to automatically assemble ‘meta-wikis’ that present integrated views over the data collaboratively created in multiple source wikis. Results We produced a semantic meta-wiki called the Gene Wiki+ that automatically mirrors and integrates data from the Gene Wiki and SNPedia. The Gene Wiki+, available at (http://genewikiplus.org/), captures 8,047 distinct gene-disease relationships. SNPedia accounts for 4,149 of the gene-disease pairs, the Gene Wiki provides 4,377 and only 479 appear independently in both sources. All of this content is available to query and browse and is provided as linked open data. Conclusions Wikis contain increasing amounts of diverse, biological information useful for elucidating the connections between genes and disease. The Gene Wiki+ shows how wiki technology can be used in concert with natural language processing to provide integrated views over diverse underlying data sources.",2012-04-24,2021-06-05 21:13:27; 2021-06-06 06:38:41; 2021-06-05 20:56:20; 2021-06-05 20:59:14,S6,Suppl 1,3,J Biomed Semantics,,PubMed Central,PMID: 22541597 PMCID: PMC3337266,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3337266/,,Virtuoso; AllegroGraph,Virtuoso; AllegroGraph,PMC:Query3; PMC:AllegroGraph; PMC:Query2; PMC:Virtuoso
419,10.1186/2041-1480-4-S1-S1,23735196,PMC3632999,A,Virtuoso,Virtuoso,"Callahan, Alison; Cruz-Toledo, José; Dumontier, Michel",Ontology-Based Querying with Bio2RDF’s Linked Open Data,2013,Journal of Biomedical Semantics,,"Background A key activity for life scientists in this post “-omics” age involves searching for and integrating biological data from a multitude of independent databases. However, our ability to find relevant data is hampered by non-standard web and database interfaces backed by an enormous variety of data formats. This heterogeneity presents an overwhelming barrier to the discovery and reuse of resources which have been developed at great public expense.To address this issue, the open-source Bio2RDF project promotes a simple convention to integrate diverse biological data using Semantic Web technologies. However, querying Bio2RDF remains difficult due to the lack of uniformity in the representation of Bio2RDF datasets. Results We describe an update to Bio2RDF that includes tighter integration across 19 new and updated RDF datasets. All available open-source scripts were first consolidated to a single GitHub repository and then redeveloped using a common API that generates normalized IRIs using a centralized dataset registry. We then mapped dataset specific types and relations to the Semanticscience Integrated Ontology (SIO) and demonstrate simplified federated queries across multiple Bio2RDF endpoints. Conclusions This coordinated release marks an important milestone for the Bio2RDF open source linked data framework. Principally, it improves the quality of linked data in the Bio2RDF network and makes it easier to access or recreate the linked data locally. We hope to continue improving the Bio2RDF network of linked data by identifying priority databases and increasing the vocabulary coverage to additional dataset vocabularies beyond SIO.",2013-04-15,2021-06-05 21:13:27; 2021-06-05 20:56:20; 2021-06-05 20:59:14,S1,Suppl 1,4,J Biomed Semantics,,PubMed Central,PMID: 23735196 PMCID: PMC3632999,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3632999/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
420,10.1186/2041-1480-5-32,25089180,PMC4118313,A,Virtuoso,Virtuoso,"Wu, Hongyan; Fujiwara, Toyofumi; Yamamoto, Yasunori; Bolleman, Jerven; Yamaguchi, Atsuko",BioBenchmark Toyama 2012: an evaluation of the performance of triple stores on biological data,2014,Journal of Biomedical Semantics,,"Background Biological databases vary enormously in size and data complexity, from small databases that contain a few million Resource Description Framework (RDF) triples to large databases that contain billions of triples. In this paper, we evaluate whether RDF native stores can be used to meet the needs of a biological database provider. Prior evaluations have used synthetic data with a limited database size. For example, the largest BSBM benchmark uses 1 billion synthetic e-commerce knowledge RDF triples on a single node. However, real world biological data differs from the simple synthetic data much. It is difficult to determine whether the synthetic e-commerce data is efficient enough to represent biological databases. Therefore, for this evaluation, we used five real data sets from biological databases. Results We evaluated five triple stores, 4store, Bigdata, Mulgara, Virtuoso, and OWLIM-SE, with five biological data sets, Cell Cycle Ontology, Allie, PDBj, UniProt, and DDBJ, ranging in size from approximately 10 million to 8 billion triples., For each database, we loaded all the data into our single node and prepared the database for use in a classical data warehouse scenario. Then, we ran a series of SPARQL queries against each endpoint and recorded the execution time and the accuracy of the query response. Conclusions Our paper shows that with appropriate configuration Virtuoso and OWLIM-SE can satisfy the basic requirements to load and query biological data less than 8 billion or so on a single node, for the simultaneous access of 64 clients., OWLIM-SE performs best for databases with approximately 11 million triples; For data sets that contain 94 million and 590 million triples, OWLIM-SE and Virtuoso perform best. They do not show overwhelming advantage over each other; For data over 4 billion Virtuoso works best., 4store performs well on small data sets with limited features when the number of triples is less than 100 million, and our test shows its scalability is poor; Bigdata demonstrates average performance and is a good open source triple store for middle-sized (500 million or so) data set; Mulgara shows a little of fragility.",2014-07-10,2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-05 20:59:14,32,,5,J Biomed Semantics,BioBenchmark Toyama 2012,PubMed Central,PMID: 25089180 PMCID: PMC4118313,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4118313/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
421,10.1186/2041-1480-6-5,26464783,PMC4603842,A,AllegroGraph,AllegroGraph,"Mina, Eleni; Thompson, Mark; Kaliyaperumal, Rajaram; Zhao, Jun; der Horst, van Eelke; Tatum, Zuotian; Hettne, Kristina M; Schultes, Erik A; Mons, Barend; Roos, Marco",Nanopublications for exposing experimental data in the life-sciences: a Huntington’s Disease case study,2015,Journal of Biomedical Semantics,,"Data from high throughput experiments often produce far more results than can ever appear in the main text or tables of a single research article. In these cases, the majority of new associations are often archived either as supplemental information in an arbitrary format or in publisher-independent databases that can be difficult to find. These data are not only lost from scientific discourse, but are also elusive to automated search, retrieval and processing. Here, we use the nanopublication model to make scientific assertions that were concluded from a workflow analysis of Huntington’s Disease data machine-readable, interoperable, and citable. We followed the nanopublication guidelines to semantically model our assertions as well as their provenance metadata and authorship. We demonstrate interoperability by linking nanopublication provenance to the Research Object model. These results indicate that nanopublications can provide an incentive for researchers to expose data that is interoperable and machine-readable for future use and preservation for which they can get credits for their effort. Nanopublications can have a leading role into hypotheses generation offering opportunities to produce large-scale data integration.",2015-02-09,2021-06-06 06:38:41; 2021-06-05 20:56:20; 2021-06-05 21:12:40,,,6,J Biomed Semantics,Nanopublications for exposing experimental data in the life-sciences,PubMed Central,PMID: 26464783 PMCID: PMC4603842,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4603842/,,AllegroGraph,AllegroGraph,PMC:Query3; PMC:AllegroGraph; PMC:Query2
422,10.1186/2047-217X-3-5,24843788,PMC4006453,A,Neo4j,Neo4j,"Mesiti, Marco; Re, Matteo; Valentini, Giorgio",Think globally and solve locally: secondary memory-based network learning for automated multi-species function prediction,2014,GigaScience,,"Background Network-based learning algorithms for automated function prediction (AFP) are negatively affected by the limited coverage of experimental data and limited a priori known functional annotations. As a consequence their application to model organisms is often restricted to well characterized biological processes and pathways, and their effectiveness with poorly annotated species is relatively limited. A possible solution to this problem might consist in the construction of big networks including multiple species, but this in turn poses challenging computational problems, due to the scalability limitations of existing algorithms and the main memory requirements induced by the construction of big networks. Distributed computation or the usage of big computers could in principle respond to these issues, but raises further algorithmic problems and require resources not satisfiable with simple off-the-shelf computers. Results We propose a novel framework for scalable network-based learning of multi-species protein functions based on both a local implementation of existing algorithms and the adoption of innovative technologies: we solve “locally” the AFP problem, by designing “vertex-centric” implementations of network-based algorithms, but we do not give up thinking “globally” by exploiting the overall topology of the network. This is made possible by the adoption of secondary memory-based technologies that allow the efficient use of the large memory available on disks, thus overcoming the main memory limitations of modern off-the-shelf computers. This approach has been applied to the analysis of a large multi-species network including more than 300 species of bacteria and to a network with more than 200,000 proteins belonging to 13 Eukaryotic species. To our knowledge this is the first work where secondary-memory based network analysis has been applied to multi-species function prediction using biological networks with hundreds of thousands of proteins. Conclusions The combination of these algorithmic and technological approaches makes feasible the analysis of large multi-species networks using ordinary computers with limited speed and primary memory, and in perspective could enable the analysis of huge networks (e.g. the whole proteomes available in SwissProt), using well-equipped stand-alone machines.",2014-04-23,2021-06-05 21:13:27; 2021-06-05 20:56:20; 2021-06-05 20:37:08,5,,3,Gigascience,Think globally and solve locally,PubMed Central,PMID: 24843788 PMCID: PMC4006453,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4006453/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
423,10.1186/gb-2009-10-5-r58,19480664,PMC2718524,A,Virtuoso,Virtuoso,"Antezana, Erick; Egaña, Mikel; Blondé, Ward; Illarramendi, Aitzol; Bilbao, Iñaki; De Baets, Bernard; Stevens, Robert; Mironov, Vladimir; Kuiper, Martin",The Cell Cycle Ontology: an application ontology for the representation and integrated analysis of the cell cycle process,2009,Genome Biology,,"A software resource for the analysis of cell cycle related molecular networks., The Cell Cycle Ontology ( is an application ontology that automatically captures and integrates detailed knowledge on the cell cycle process. Cell Cycle Ontology is enabled by semantic web technologies, and is accessible via the web for browsing, visualizing, advanced querying, and computational reasoning. Cell Cycle Ontology facilitates a detailed analysis of cell cycle-related molecular network components. Through querying and automated reasoning, it may provide new hypotheses to help steer a systems biology approach to biological network building.",2009,2021-06-05 21:13:27; 2021-06-05 20:56:20; 2021-06-05 20:59:14,R58,5,10,Genome Biol,The Cell Cycle Ontology,PubMed Central,PMID: 19480664 PMCID: PMC2718524,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2718524/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
424,10.1186/s12859-014-0386-y,25490885,PMC4279962,A,Virtuoso,Virtuoso,"Venkatesan, Aravind; Tripathi, Sushil; Sanz de Galdeano, Alejandro; Blondé, Ward; Lægreid, Astrid; Mironov, Vladimir; Kuiper, Martin",Finding gene regulatory network candidates using the gene expression knowledge base,2014,BMC Bioinformatics,,"Background Network-based approaches for the analysis of large-scale genomics data have become well established. Biological networks provide a knowledge scaffold against which the patterns and dynamics of ‘omics’ data can be interpreted. The background information required for the construction of such networks is often dispersed across a multitude of knowledge bases in a variety of formats. The seamless integration of this information is one of the main challenges in bioinformatics. The Semantic Web offers powerful technologies for the assembly of integrated knowledge bases that are computationally comprehensible, thereby providing a potentially powerful resource for constructing biological networks and network-based analysis. Results We have developed the Gene eXpression Knowledge Base (GeXKB), a semantic web technology based resource that contains integrated knowledge about gene expression regulation. To affirm the utility of GeXKB we demonstrate how this resource can be exploited for the identification of candidate regulatory network proteins. We present four use cases that were designed from a biological perspective in order to find candidate members relevant for the gastrin hormone signaling network model. We show how a combination of specific query definitions and additional selection criteria derived from gene expression data and prior knowledge concerning candidate proteins can be used to retrieve a set of proteins that constitute valid candidates for regulatory network extensions. Conclusions Semantic web technologies provide the means for processing and integrating various heterogeneous information sources. The GeXKB offers biologists such an integrated knowledge resource, allowing them to address complex biological questions pertaining to gene expression. This work illustrates how GeXKB can be used in combination with gene expression results and literature information to identify new potential candidates that may be considered for extending a gene regulatory network. Electronic supplementary material The online version of this article (doi:10.1186/s12859-014-0386-y) contains supplementary material, which is available to authorized users.",2014-12-10,2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-05 20:59:14,,1,15,BMC Bioinformatics,,PubMed Central,PMID: 25490885 PMCID: PMC4279962,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4279962/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
425,10.1186/s12859-015-0559-3,25903923,PMC4448321,A,Virtuoso; AllegroGraph,Virtuoso; AllegroGraph,"Livingston, Kevin M; Bada, Michael; Baumgartner, William A; Hunter, Lawrence E",KaBOB: ontology-based semantic integration of biomedical databases,2015,BMC Bioinformatics,,"Background The ability to query many independent biological databases using a common ontology-based semantic model would facilitate deeper integration and more effective utilization of these diverse and rapidly growing resources. Despite ongoing work moving toward shared data formats and linked identifiers, significant problems persist in semantic data integration in order to establish shared identity and shared meaning across heterogeneous biomedical data sources. Results We present five processes for semantic data integration that, when applied collectively, solve seven key problems. These processes include making explicit the differences between biomedical concepts and database records, aggregating sets of identifiers denoting the same biomedical concepts across data sources, and using declaratively represented forward-chaining rules to take information that is variably represented in source databases and integrating it into a consistent biomedical representation. We demonstrate these processes and solutions by presenting KaBOB (the Knowledge Base Of Biomedicine), a knowledge base of semantically integrated data from 18 prominent biomedical databases using common representations grounded in Open Biomedical Ontologies. An instance of KaBOB with data about humans and seven major model organisms can be built using on the order of 500 million RDF triples. All source code for building KaBOB is available under an open-source license. Conclusions KaBOB is an integrated knowledge base of biomedical data representationally based in prominent, actively maintained Open Biomedical Ontologies, thus enabling queries of the underlying data in terms of biomedical concepts (e.g., genes and gene products, interactions and processes) rather than features of source-specific data schemas or file formats. KaBOB resolves many of the issues that routinely plague biomedical researchers intending to work with data from multiple data sources and provides a platform for ongoing data integration and development and for formal reasoning over a wealth of integrated biomedical data. Electronic supplementary material The online version of this article (doi:10.1186/s12859-015-0559-3) contains supplementary material, which is available to authorized users.",2015-04-23,2021-06-06 06:38:41; 2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-05 20:59:14,,1,16,BMC Bioinformatics,KaBOB,PubMed Central,PMID: 25903923 PMCID: PMC4448321,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4448321/,,Virtuoso; AllegroGraph,Virtuoso; AllegroGraph,PMC:Query3; PMC:AllegroGraph; PMC:Query2; PMC:Virtuoso
426,10.1186/s12859-015-0836-1,26652480,PMC4676132,A,Neo4j,Neo4j,"Del Vecchio, Filippo; Gallo, Francesco; Di Marco, Antinisca; Mastroiaco, Valentina; Caianiello, Pasquale; Zazzeroni, Francesca; Alesse, Edoardo; Tessitore, Alessandra",Bioinformatics approach to predict target genes for dysregulated microRNAs in hepatocellular carcinoma: study on a chemically-induced HCC mouse model,2015,BMC Bioinformatics,,"Background Hepatocellular carcinoma (HCC) is an aggressive epithelial tumor which shows very poor prognosis and high rate of recurrence, representing an urgent problem for public healthcare. MicroRNAs (miRNAs/miRs) are a class of small, non-coding RNAs that attract great attention because of their role in regulation of processes such as cellular growth, proliferation, apoptosis. Because of the thousands of potential interactions between a single miR and target mRNAs, bioinformatics prediction tools are very useful to facilitate the task for individuating and selecting putative target genes. In this study, we present a chemically-induced HCC mouse model to identify differential expression of miRNAs during the progression of the hepatic injury up to HCC onset. In addition, we describe an established bioinformatics approach to highlight putative target genes and protein interaction networks where they are involved. Results We describe four miRs (miR-125a-5p, miR-27a, miR-182, miR-193b) which showed to be differentially expressed in the chemically-induced HCC mouse model. The miRs were subjected to four of the most used predictions tools and 15 predicted target genes were identified. The expression of one (ANK3) among the 15 predicted targets was further validated by immunoblotting. Then, enrichment annotation analysis was performed revealing significant clusters, including some playing a role in ion transporter activity, regulation of receptor protein serine/threonine kinase signaling pathway, protein import into nucleus, regulation of intracellular protein transport, regulation of cell adhesion, growth factor binding, and regulation of TGF-beta/SMAD signaling pathway. A network construction was created and links between the selected miRs, the predicted targets as well as the possible interactions among them and other proteins were built up. Conclusions In this study, we combined miRNA expression analysis, obtained by an in vivo HCC mouse model, with a bioinformatics-based workflow. New genes, pathways and protein interactions, putatively involved in HCC initiation and progression, were identified and explored. Electronic supplementary material The online version of this article (doi:10.1186/s12859-015-0836-1) contains supplementary material, which is available to authorized users.",2015-12-10,2021-06-05 20:55:40; 2021-06-05 21:12:40; 2021-06-05 20:37:08,,,16,BMC Bioinformatics,Bioinformatics approach to predict target genes for dysregulated microRNAs in hepatocellular carcinoma,PubMed Central,PMID: 26652480 PMCID: PMC4676132,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4676132/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
427,10.1186/s12859-016-1131-5,27454167,PMC4959351,,,,"Bai, Tian; Gong, Leiguang; Wang, Ye; Wang, Yan; Kulikowski, Casimir A.; Huang, Lan",A method for exploring implicit concept relatedness in biomedical knowledge network,2016,BMC Bioinformatics,,"Background Biomedical information and knowledge, structural and non-structural, stored in different repositories can be semantically connected to form a hybrid knowledge network. How to compute relatedness between concepts and discover valuable but implicit information or knowledge from it effectively and efficiently is of paramount importance for precision medicine, and a major challenge facing the biomedical research community. Results In this study, a hybrid biomedical knowledge network is constructed by linking concepts across multiple biomedical ontologies as well as non-structural biomedical knowledge sources. To discover implicit relatedness between concepts in ontologies for which potentially valuable relationships (implicit knowledge) may exist, we developed a Multi-Ontology Relatedness Model (MORM) within the knowledge network, for which a relatedness network (RN) is defined and computed across multiple ontologies using a formal inference mechanism of set-theoretic operations. Semantic constraints are designed and implemented to prune the search space of the relatedness network. Conclusions Experiments to test examples of several biomedical applications have been carried out, and the evaluation of the results showed an encouraging potential of the proposed approach to biomedical knowledge discovery.",2016-07-19,2021-06-05 21:12:01,,Suppl 9,17,BMC Bioinformatics,,PubMed Central,PMID: 27454167 PMCID: PMC4959351,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4959351/,,,,PMC:Query2
428,10.1186/s12859-016-1394-x,27919219,PMC5139139,A,Neo4j,Neo4j,"Touré, Vasundra; Mazein, Alexander; Waltemath, Dagmar; Balaur, Irina; Saqi, Mansoor; Henkel, Ron; Pellet, Johann; Auffray, Charles",STON: exploring biological pathways using the SBGN standard and graph databases,2016,BMC bioinformatics; BMC Bioinformatics,,"BACKGROUND: When modeling in Systems Biology and Systems Medicine, the data is often extensive, complex and heterogeneous. Graphs are a natural way of representing biological networks. Graph databases enable efficient storage and processing of the encoded biological relationships. They furthermore support queries on the structure of biological networks. RESULTS: We present the Java-based framework STON (SBGN TO Neo4j). STON imports and translates metabolic, signalling and gene regulatory pathways represented in the Systems Biology Graphical Notation into a graph-oriented format compatible with the Neo4j graph database. CONCLUSION: STON exploits the power of graph databases to store and query complex biological pathways. This advances the possibility of: i) identifying subnetworks in a given pathway; ii) linking networks across different levels of granularity to address difficulties related to incomplete knowledge representation at single level; and iii) identifying common patterns between pathways in the database.; Background When modeling in Systems Biology and Systems Medicine, the data is often extensive, complex and heterogeneous. Graphs are a natural way of representing biological networks. Graph databases enable efficient storage and processing of the encoded biological relationships. They furthermore support queries on the structure of biological networks. Results We present the Java-based framework STON (SBGN TO Neo4j). STON imports and translates metabolic, signalling and gene regulatory pathways represented in the Systems Biology Graphical Notation into a graph-oriented format compatible with the Neo4j graph database. Conclusion STON exploits the power of graph databases to store and query complex biological pathways. This advances the possibility of: i) identifying subnetworks in a given pathway; ii) linking networks across different levels of granularity to address difficulties related to incomplete knowledge representation at single level; and iii) identifying common patterns between pathways in the database. Electronic supplementary material The online version of this article (doi:10.1186/s12859-016-1394-x) contains supplementary material, which is available to authorized users.",2016-12-05,2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 20:37:08; 2021-06-05 21:12:01; 2021-06-05 20:55:40; 2021-06-05 21:24:28,494,1,17,BMC Bioinformatics,STON,PubMed; PubMed Central,PMID: 27919219 PMCID: PMC5139139,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5139139/; http://www.ncbi.nlm.nih.gov/pubmed/27919219,"Databases, Factual; Gene Regulatory Networks; Graph database; Humans; Metabolic Networks and Pathways; Neo4j; Signal Transduction; Software; Systems biology; Systems Biology; Systems biology graphical notation; Systems medicine",Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
429,10.1186/s12859-017-1519-x,28193156,PMC5307852,,,,"Alborzi, Seyed Ziaeddin; Devignes, Marie-Dominique; Ritchie, David W.",ECDomainMiner: discovering hidden associations between enzyme commission numbers and Pfam domains,2017,BMC Bioinformatics,,"Background Many entries in the protein data bank (PDB) are annotated to show their component protein domains according to the Pfam classification, as well as their biological function through the enzyme commission (EC) numbering scheme. However, despite the fact that the biological activity of many proteins often arises from specific domain-domain and domain-ligand interactions, current on-line resources rarely provide a direct mapping from structure to function at the domain level. Since the PDB now contains many tens of thousands of protein chains, and since protein sequence databases can dwarf such numbers by orders of magnitude, there is a pressing need to develop automatic structure-function annotation tools which can operate at the domain level. Results This article presents ECDomainMiner, a novel content-based filtering approach to automatically infer associations between EC numbers and Pfam domains. ECDomainMiner finds a total of 20,728 non-redundant EC-Pfam associations with a F-measure of 0.95 with respect to a “Gold Standard” test set extracted from InterPro. Compared to the 1515 manually curated EC-Pfam associations in InterPro, ECDomainMiner infers a 13-fold increase in the number of EC-Pfam associations. Conclusion These EC-Pfam associations could be used to annotate some 58,722 protein chains in the PDB which currently lack any EC annotation. The ECDomainMiner database is publicly available at http://ecdm.loria.fr/.",2017-02-13,2021-06-05 21:12:01,,,18,BMC Bioinformatics,ECDomainMiner,PubMed Central,PMID: 28193156 PMCID: PMC5307852,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5307852/,,,,PMC:Query2
430,10.1186/s12859-017-1777-7,28797229,PMC5553995,A,Neo4j,Neo4j,"Guhlin, Joseph; Silverstein, Kevin A. T.; Zhou, Peng; Tiffin, Peter; Young, Nevin D.","ODG: Omics database generator - a tool for generating, querying, and analyzing multi-omics comparative databases to facilitate biological understanding",2017,BMC bioinformatics; BMC Bioinformatics,,"BACKGROUND: Rapid generation of omics data in recent years have resulted in vast amounts of disconnected datasets without systemic integration and knowledge building, while individual groups have made customized, annotated datasets available on the web with few ways to link them to in-lab datasets. With so many research groups generating their own data, the ability to relate it to the larger genomic and comparative genomic context is becoming increasingly crucial to make full use of the data. RESULTS: The Omics Database Generator (ODG) allows users to create customized databases that utilize published genomics data integrated with experimental data which can be queried using a flexible graph database. When provided with omics and experimental data, ODG will create a comparative, multi-dimensional graph database. ODG can import definitions and annotations from other sources such as InterProScan, the Gene Ontology, ENZYME, UniPathway, and others. This annotation data can be especially useful for studying new or understudied species for which transcripts have only been predicted, and rapidly give additional layers of annotation to predicted genes. In better studied species, ODG can perform syntenic annotation translations or rapidly identify characteristics of a set of genes or nucleotide locations, such as hits from an association study. ODG provides a web-based user-interface for configuring the data import and for querying the database. Queries can also be run from the command-line and the database can be queried directly through programming language hooks available for most languages. ODG supports most common genomic formats as well as generic, easy to use tab-separated value format for user-provided annotations. CONCLUSIONS: ODG is a user-friendly database generation and query tool that adapts to the supplied data to produce a comparative genomic database or multi-layered annotation database. ODG provides rapid comparative genomic annotation and is therefore particularly useful for non-model or understudied species. For species for which more data are available, ODG can be used to conduct complex multi-omics, pattern-matching queries.; Background Rapid generation of omics data in recent years have resulted in vast amounts of disconnected datasets without systemic integration and knowledge building, while individual groups have made customized, annotated datasets available on the web with few ways to link them to in-lab datasets. With so many research groups generating their own data, the ability to relate it to the larger genomic and comparative genomic context is becoming increasingly crucial to make full use of the data. Results The Omics Database Generator (ODG) allows users to create customized databases that utilize published genomics data integrated with experimental data which can be queried using a flexible graph database. When provided with omics and experimental data, ODG will create a comparative, multi-dimensional graph database. ODG can import definitions and annotations from other sources such as InterProScan, the Gene Ontology, ENZYME, UniPathway, and others. This annotation data can be especially useful for studying new or understudied species for which transcripts have only been predicted, and rapidly give additional layers of annotation to predicted genes. In better studied species, ODG can perform syntenic annotation translations or rapidly identify characteristics of a set of genes or nucleotide locations, such as hits from an association study. ODG provides a web-based user-interface for configuring the data import and for querying the database. Queries can also be run from the command-line and the database can be queried directly through programming language hooks available for most languages. ODG supports most common genomic formats as well as generic, easy to use tab-separated value format for user-provided annotations. Conclusions ODG is a user-friendly database generation and query tool that adapts to the supplied data to produce a comparative genomic database or multi-layered annotation database. ODG provides rapid comparative genomic annotation and is therefore particularly useful for non-model or understudied species. For species for which more data are available, ODG can be used to conduct complex multi-omics, pattern-matching queries. Electronic supplementary material The online version of this article (doi:10.1186/s12859-017-1777-7) contains supplementary material, which is available to authorized users.",2017-08-10,2021-06-05 20:55:40; 2021-06-05 21:06:22; 2021-06-05 21:12:01; 2021-06-05 20:36:32,367,1,18,BMC Bioinformatics,ODG,PubMed; PubMed Central,PMID: 28797229 PMCID: PMC5553995,http://www.ncbi.nlm.nih.gov/pubmed/28797229; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5553995/,"Annotation; Comparative genomics; Data integration; Databases, Nucleic Acid; Genomics; Graph database; Molecular Sequence Annotation; Non-model species; Software",Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PubMed:Query2; PMC:Query2
431,10.1186/s12859-017-1840-4,28969593,PMC5625622,A,Virtuoso,Virtuoso,"Zaki, Nazar; Tennakoon, Chandana",BioCarian: search engine for exploratory searches in heterogeneous biological databases,2017,BMC Bioinformatics,,"Background There are a large number of biological databases publicly available for scientists in the web. Also, there are many private databases generated in the course of research projects. These databases are in a wide variety of formats. Web standards have evolved in the recent times and semantic web technologies are now available to interconnect diverse and heterogeneous sources of data. Therefore, integration and querying of biological databases can be facilitated by techniques used in semantic web. Heterogeneous databases can be converted into Resource Description Format (RDF) and queried using SPARQL language. Searching for exact queries in these databases is trivial. However, exploratory searches need customized solutions, especially when multiple databases are involved. This process is cumbersome and time consuming for those without a sufficient background in computer science. In this context, a search engine facilitating exploratory searches of databases would be of great help to the scientific community. Results We present BioCarian, an efficient and user-friendly search engine for performing exploratory searches on biological databases. The search engine is an interface for SPARQL queries over RDF databases. We note that many of the databases can be converted to tabular form. We first convert the tabular databases to RDF. The search engine provides a graphical interface based on facets to explore the converted databases. The facet interface is more advanced than conventional facets. It allows complex queries to be constructed, and have additional features like ranking of facet values based on several criteria, visually indicating the relevance of a facet value and presenting the most important facet values when a large number of choices are available. For the advanced users, SPARQL queries can be run directly on the databases. Using this feature, users will be able to incorporate federated searches of SPARQL endpoints. We used the search engine to do an exploratory search on previously published viral integration data and were able to deduce the main conclusions of the original publication. BioCarian is accessible via http://www.biocarian.com. Conclusions We have developed a search engine to explore RDF databases that can be used by both novice and advanced users. Electronic supplementary material The online version of this article (doi:10.1186/s12859-017-1840-4) contains supplementary material, which is available to authorized users.",2017-10-02,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:59:14,,,18,BMC Bioinformatics,BioCarian,PubMed Central,PMID: 28969593 PMCID: PMC5625622,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5625622/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
432,10.1186/s12859-017-1921-4,29244012,PMC5731498,A,Neo4j,Neo4j,"Jelínek, Jan; Škoda, Petr; Hoksza, David",Utilizing knowledge base of amino acids structural neighborhoods to predict protein-protein interaction sites,2017,BMC Bioinformatics,,"Background Protein-protein interactions (PPI) play a key role in an investigation of various biochemical processes, and their identification is thus of great importance. Although computational prediction of which amino acids take part in a PPI has been an active field of research for some time, the quality of in-silico methods is still far from perfect. Results We have developed a novel prediction method called INSPiRE which benefits from a knowledge base built from data available in Protein Data Bank. All proteins involved in PPIs were converted into labeled graphs with nodes corresponding to amino acids and edges to pairs of neighboring amino acids. A structural neighborhood of each node was then encoded into a bit string and stored in the knowledge base. When predicting PPIs, INSPiRE labels amino acids of unknown proteins as interface or non-interface based on how often their structural neighborhood appears as interface or non-interface in the knowledge base. We evaluated INSPiRE’s behavior with respect to different types and sizes of the structural neighborhood. Furthermore, we examined the suitability of several different features for labeling the nodes. Our evaluations showed that INSPiRE clearly outperforms existing methods with respect to Matthews correlation coefficient. Conclusion In this paper we introduce a new knowledge-based method for identification of protein-protein interaction sites called INSPiRE. Its knowledge base utilizes structural patterns of known interaction sites in the Protein Data Bank which are then used for PPI prediction. Extensive experiments on several well-established datasets show that INSPiRE significantly surpasses existing PPI approaches.",2017-12-06,2021-06-05 20:55:40; 2021-06-05 21:11:16; 2021-06-05 20:36:32,,Suppl 15,18,BMC Bioinformatics,,PubMed Central,PMID: 29244012 PMCID: PMC5731498,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5731498/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
433,10.1186/s12859-017-1999-8,29304741,PMC5756413,A,Virtuoso,Virtuoso,"Rodríguez-García, Miguel Ángel; Hoehndorf, Robert",Inferring ontology graph structures using OWL reasoning,2018,BMC Bioinformatics,,"Background Ontologies are representations of a conceptualization of a domain. Traditionally, ontologies in biology were represented as directed acyclic graphs (DAG) which represent the backbone taxonomy and additional relations between classes. These graphs are widely exploited for data analysis in the form of ontology enrichment or computation of semantic similarity. More recently, ontologies are developed in a formal language such as the Web Ontology Language (OWL) and consist of a set of axioms through which classes are defined or constrained. While the taxonomy of an ontology can be inferred directly from the axioms of an ontology as one of the standard OWL reasoning tasks, creating general graph structures from OWL ontologies that exploit the ontologies’ semantic content remains a challenge. Results We developed a method to transform ontologies into graphs using an automated reasoner while taking into account all relations between classes. Searching for (existential) patterns in the deductive closure of ontologies, we can identify relations between classes that are implied but not asserted and generate graph structures that encode for a large part of the ontologies’ semantic content. We demonstrate the advantages of our method by applying it to inference of protein-protein interactions through semantic similarity over the Gene Ontology and demonstrate that performance is increased when graph structures are inferred using deductive inference according to our method. Our software and experiment results are available at http://github.com/bio-ontology-research-group/Onto2Graph. Conclusions Onto2Graph is a method to generate graph structures from OWL ontologies using automated reasoning. The resulting graphs can be used for improved ontology visualization and ontology-based data analysis. Electronic supplementary material The online version of this article (doi:10.1186/s12859-017-1999-8) contains supplementary material, which is available to authorized users.",2018-01-05,2021-06-05 20:55:40; 2021-06-05 21:11:16; 2021-06-05 20:59:14,,,19,BMC Bioinformatics,,PubMed Central,PMID: 29304741 PMCID: PMC5756413,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5756413/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
434,10.1186/s12859-018-2167-5,29843590,PMC5975655,,,,"Sang, Shengtian; Yang, Zhihao; Wang, Lei; Liu, Xiaoxia; Lin, Hongfei; Wang, Jian",SemaTyP: a knowledge graph based literature mining method for drug discovery,2018,BMC Bioinformatics,,"Background Drug discovery is the process through which potential new medicines are identified. High-throughput screening and computer-aided drug discovery/design are the two main drug discovery methods for now, which have successfully discovered a series of drugs. However, development of new drugs is still an extremely time-consuming and expensive process. Biomedical literature contains important clues for the identification of potential treatments. It could support experts in biomedicine on their way towards new discoveries. Methods Here, we propose a biomedical knowledge graph-based drug discovery method called SemaTyP, which discovers candidate drugs for diseases by mining published biomedical literature. We first construct a biomedical knowledge graph with the relations extracted from biomedical abstracts, then a logistic regression model is trained by learning the semantic types of paths of known drug therapies’ existing in the biomedical knowledge graph, finally the learned model is used to discover drug therapies for new diseases. Results The experimental results show that our method could not only effectively discover new drug therapies for new diseases, but also could provide the potential mechanism of action of the candidate drugs. Conclusions In this paper we propose a novel knowledge graph based literature mining method for drug discovery. It could be a supplementary method for current drug discovery methods. Electronic supplementary material The online version of this article (10.1186/s12859-018-2167-5) contains supplementary material, which is available to authorized users.",2018-05-30,2021-06-05 21:11:16,,,19,BMC Bioinformatics,SemaTyP,PubMed Central,PMID: 29843590 PMCID: PMC5975655,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5975655/,,,,PMC:Query2
435,10.1186/s12859-018-2298-8,30367585,PMC6191940,A,Neo4j,Neo4j,"Bonnici, Vincenzo; Caro, Giorgio De; Constantino, Giorgio; Liuni, Sabino; D’Elia, Domenica; Bombieri, Nicola; Licciulli, Flavio; Giugno, Rosalba",Arena-Idb: a platform to build human non-coding RNA interaction networks,2018,BMC Bioinformatics,,"Background High throughput technologies have provided the scientific community an unprecedented opportunity for large-scale analysis of genomes. Non-coding RNAs (ncRNAs), for a long time believed to be non-functional, are emerging as one of the most important and large family of gene regulators and key elements for genome maintenance. Functional studies have been able to assign to ncRNAs a wide spectrum of functions in primary biological processes, and for this reason they are assuming a growing importance as a potential new family of cancer therapeutic targets. Nevertheless, the number of functionally characterized ncRNAs is still too poor if compared to the number of new discovered ncRNAs. Thus platforms able to merge information from available resources addressing data integration issues are necessary and still insufficient to elucidate ncRNAs biological roles. Results In this paper, we describe a platform called Arena-Idb for the retrieval of comprehensive and non-redundant annotated ncRNAs interactions. Arena-Idb provides a framework for network reconstruction of ncRNA heterogeneous interactions (i.e., with other type of molecules) and relationships with human diseases which guide the integration of data, extracted from different sources, via mapping of entities and minimization of ambiguity. Conclusions Arena-Idb provides a schema and a visualization system to integrate ncRNA interactions that assists in discovering ncRNA functions through the extraction of heterogeneous interaction networks. The Arena-Idb is available at http://arenaidb.ba.itb.cnr.it",2018-10-15,2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:36:32,,Suppl 10,19,BMC Bioinformatics,Arena-Idb,PubMed Central,PMID: 30367585 PMCID: PMC6191940,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6191940/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
436,10.1186/s12859-018-2316-x,30223767,PMC6142695,,,,"Zheng, Wei; Lin, Hongfei; Liu, Xiaoxia; Xu, Bo",A document level neural model integrated domain knowledge for chemical-induced disease relations,2018,BMC Bioinformatics,,"Background The effective combination of texts and knowledge may improve performances of natural language processing tasks. For the recognition of chemical-induced disease (CID) relations which may span sentence boundaries in an article, although existing CID systems explored the utilization for knowledge bases, the effects of different knowledge on the identification of a special CID haven’t been distinguished by these systems. Moreover, systems based on neural network only constructed sentence or mention level models. Results In this work, we proposed an effective document level neural model integrated domain knowledge to extract CID relations from biomedical articles. Basic semantic information of an article with respect to a special CID candidate pair was learned from the document level sub-network module. Furthermore, knowledge attention depending on the representation of the article was proposed to distinguish the influences of different knowledge on the special CID pair and then the final representation of knowledge was formed by aggregating weighed knowledge. Finally, the integrated representations of texts and knowledge were passed to a softmax classifier to perform the CID recognition. Experimental results on the chemical-disease relation corpus proposed by BioCreative V show that our proposed system integrated knowledge achieves a good overall performance compared with other state-of-the-art systems. Conclusions Experimental analyses demonstrate that the introduced attention mechanism on domain knowledge plays a significant role in distinguishing influences of different knowledge on the judgment for a special CID relation.",2018-09-17,2021-06-05 21:11:16,,,19,BMC Bioinformatics,,PubMed Central,PMID: 30223767 PMCID: PMC6142695,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6142695/,,,,PMC:Query2
437,10.1186/s12859-018-2362-4,30257640,PMC6158922,A,Neo4j,Neo4j,"Sheikhizadeh Anari, Siavash; de Ridder, Dick; Schranz, M. Eric; Smit, Sandra",Efficient inference of homologs in large eukaryotic pan-proteomes,2018,BMC Bioinformatics,,"Background Identification of homologous genes is fundamental to comparative genomics, functional genomics and phylogenomics. Extensive public homology databases are of great value for investigating homology but need to be continually updated to incorporate new sequences. As new sequences are rapidly being generated, there is a need for efficient standalone tools to detect homologs in novel data. Results To address this, we present a fast method for detecting homology groups across a large number of individuals and/or species. We adopted a k-mer based approach which considerably reduces the number of pairwise protein alignments without sacrificing sensitivity. We demonstrate accuracy, scalability, efficiency and applicability of the presented method for detecting homology in large proteomes of bacteria, fungi, plants and Metazoa. Conclusions We clearly observed the trade-off between recall and precision in our homology inference. Favoring recall or precision strongly depends on the application. The clustering behavior of our program can be optimized for particular applications by altering a few key parameters. The program is available for public use at https://github.com/sheikhizadeh/pantools as an extension to our pan-genomic analysis tool, PanTools. Electronic supplementary material The online version of this article (10.1186/s12859-018-2362-4) contains supplementary material, which is available to authorized users.",2018-09-26,2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:36:32,,,19,BMC Bioinformatics,,PubMed Central,PMID: 30257640 PMCID: PMC6158922,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6158922/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
438,10.1186/s12859-018-2393-x,30352578,PMC6199797,A,Neo4j,Neo4j,"Hühne, Rolf; Kessler, Viktor; Fürstberger, Axel; Kühlwein, Silke; Platzer, Matthias; Sühnel, Jürgen; Lausser, Ludwig; Kestler, Hans A.",3D Network exploration and visualisation for lifespan data,2018,BMC Bioinformatics,,"Background The Ageing Factor Database AgeFactDB contains a large number of lifespan observations for ageing-related factors like genes, chemical compounds, and other factors such as dietary restriction in different organisms. These data provide quantitative information on the effect of ageing factors from genetic interventions or manipulations of lifespan. Analysis strategies beyond common static database queries are highly desirable for the inspection of complex relationships between AgeFactDB data sets. 3D visualisation can be extremely valuable for advanced data exploration. Results Different types of networks and visualisation strategies are proposed, ranging from basic networks of individual ageing factors for a single species to complex multi-species networks. The augmentation of lifespan observation networks by annotation nodes, like gene ontology terms, is shown to facilitate and speed up data analysis. We developed a new Javascript 3D network viewer JANet that provides the proposed visualisation strategies and has a customised interface for AgeFactDB data. It enables the analysis of gene lists in combination with AgeFactDB data and the interactive visualisation of the results. Conclusion Interactive 3D network visualisation allows to supplement complex database queries by a visually guided exploration process. The JANet interface allows gaining deeper insights into lifespan data patterns not accessible by common database queries alone. These concepts can be utilised in many other research fields. Electronic supplementary material The online version of this article (10.1186/s12859-018-2393-x) contains supplementary material, which is available to authorized users.",2018-10-23,2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:36:32,,,19,BMC Bioinformatics,,PubMed Central,PMID: 30352578 PMCID: PMC6199797,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6199797/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
439,10.1186/s12859-018-2580-9,30612540,PMC6322262,,,,"Singh, Indresh; Kuscuoglu, Mehmet; Harkins, Derek M.; Sutton, Granger; Fouts, Derrick E.; Nelson, Karen E.","OMeta: an ontology-based, data-driven metadata tracking system",2019,BMC Bioinformatics,,"Background The development of high-throughput sequencing and analysis has accelerated multi-omics studies of thousands of microbial species, metagenomes, and infectious disease pathogens. Omics studies are enabling genotype-phenotype association studies which identify genetic determinants of pathogen virulence and drug resistance, as well as phylogenetic studies designed to track the origin and spread of disease outbreaks. These omics studies are complex and often employ multiple assay technologies including genomics, metagenomics, transcriptomics, proteomics, and metabolomics. To maximize the impact of omics studies, it is essential that data be accompanied by detailed contextual metadata (e.g., specimen, spatial-temporal, phenotypic characteristics) in clear, organized, and consistent formats. Over the years, many metadata standards developed by various metadata standards initiatives have arisen; the Genomic Standards Consortium’s minimal information standards (MIxS), the GSCID/BRC Project and Sample Application Standard. Some tools exist for tracking metadata, but they do not provide event based capabilities to configure, collect, validate, and distribute metadata. To address this gap in the scientific community, an event based data-driven application, OMeta, was created that allows users to quickly configure, collect, validate, distribute, and integrate metadata. Results A data-driven web application, OMeta, has been developed for use by researchers consisting of a browser-based interface, a command-line interface (CLI), and server-side components that provide an intuitive platform for configuring, capturing, viewing, and sharing metadata. Project and sample metadata can be set based on existing standards or based on projects goals. Recorded information includes details on the biological samples, procedures, protocols, and experimental technologies, etc. This information can be organized based on events, including sample collection, sample quantification, sequencing assay, and analysis results. OMeta enables configuration in various presentation types: checkbox, file, drop-box, ontology, and fields can be configured to use the National Center for Biomedical Ontology (NCBO), a biomedical ontology server. Furthermore, OMeta maintains a complete audit trail of all changes made by users and allows metadata export in comma separated value (CSV) format for convenient deposition of data into public databases. Conclusions We present, OMeta, a web-based software application that is built on data-driven principles for configuring and customizing data standards, capturing, curating, and sharing metadata. Electronic supplementary material The online version of this article (10.1186/s12859-018-2580-9) contains supplementary material, which is available to authorized users.",2019-01-07,2021-06-05 21:10:37,,,20,BMC Bioinformatics,OMeta,PubMed Central,PMID: 30612540 PMCID: PMC6322262,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6322262/,,,,PMC:Query2
440,10.1186/s12859-020-03937-0,33902433,PMC8073886,A,Neo4j,Neo4j,"D’Agostino, Daniele; Liò, Pietro; Aldinucci, Marco; Merelli, Ivan; D'Agostino, Daniele; Liò, Pietro; Aldinucci, Marco; Merelli, Ivan",Advantages of using graph databases to explore chromatin conformation capture experiments,2021,BMC bioinformatics; BMC Bioinformatics,,"Background High-throughput sequencing Chromosome Conformation Capture (Hi-C) allows the study of DNA interactions and 3D chromosome folding at the genome-wide scale. Usually, these data are represented as matrices describing the binary contacts among the different chromosome regions. On the other hand, a graph-based representation can be advantageous to describe the complex topology achieved by the DNA in the nucleus of eukaryotic cells. Methods Here we discuss the use of a graph database for storing and analysing data achieved by performing Hi-C experiments. The main issue is the size of the produced data and, working with a graph-based representation, the consequent necessity of adequately managing a large number of edges (contacts) connecting nodes (genes), which represents the sources of information. For this, currently available graph visualisation tools and libraries fall short with Hi-C data. The use of graph databases, instead, supports both the analysis and the visualisation of the spatial pattern present in Hi-C data, in particular for comparing different experiments or for re-mapping omics data in a space-aware context efficiently. In particular, the possibility of describing graphs through statistical indicators and, even more, the capability of correlating them through statistical distributions allows highlighting similarities and differences among different Hi-C experiments, in different cell conditions or different cell types. Results These concepts have been implemented in NeoHiC, an open-source and user-friendly web application for the progressive visualisation and analysis of Hi-C networks based on the use of the Neo4j graph database (version 3.5). Conclusion With the accumulation of more experiments, the tool will provide invaluable support to compare neighbours of genes across experiments and conditions, helping in highlighting changes in functional domains and identifying new co-organised genomic compartments. Supplementary Information The online version contains supplementary material available at 10.1186/s12859-020-03937-0.; BACKGROUND: High-throughput sequencing Chromosome Conformation Capture (Hi-C) allows the study of DNA interactions and 3D chromosome folding at the genome-wide scale. Usually, these data are represented as matrices describing the binary contacts among the different chromosome regions. On the other hand, a graph-based representation can be advantageous to describe the complex topology achieved by the DNA in the nucleus of eukaryotic cells. METHODS: Here we discuss the use of a graph database for storing and analysing data achieved by performing Hi-C experiments. The main issue is the size of the produced data and, working with a graph-based representation, the consequent necessity of adequately managing a large number of edges (contacts) connecting nodes (genes), which represents the sources of information. For this, currently available graph visualisation tools and libraries fall short with Hi-C data. The use of graph databases, instead, supports both the analysis and the visualisation of the spatial pattern present in Hi-C data, in particular for comparing different experiments or for re-mapping omics data in a space-aware context efficiently. In particular, the possibility of describing graphs through statistical indicators and, even more, the capability of correlating them through statistical distributions allows highlighting similarities and differences among different Hi-C experiments, in different cell conditions or different cell types. RESULTS: These concepts have been implemented in NeoHiC, an open-source and user-friendly web application for the progressive visualisation and analysis of Hi-C networks based on the use of the Neo4j graph database (version 3.5). CONCLUSION: With the accumulation of more experiments, the tool will provide invaluable support to compare neighbours of genes across experiments and conditions, helping in highlighting changes in functional domains and identifying new co-organised genomic compartments.",2021-04-26,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36; 2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 21:24:28,43,Suppl 2,22,BMC Bioinformatics,,PubMed; PubMed Central,PMID: 33902433 PMCID: PMC8073886,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8073886/; http://www.ncbi.nlm.nih.gov/pubmed/33902433,Chromatin; Chromatin capture; Chromosomes; Genome; Genomics; Graph databases; Graph visualisation; Hi-C; Molecular Conformation,Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
441,10.1186/s12859-020-3352-x,32164553,PMC7068854,A,Neo4j; Giraph,Neo4j; Giraph,"Angles, Renzo; Arenas-Salinas, Mauricio; García, Roberto; Reyes-Suarez, Jose Antonio; Pohl, Ehmke","GSP4PDB: a web tool to visualize, search and explore protein-ligand structural patterns",2020,BMC Bioinformatics,,"Background In the field of protein engineering and biotechnology, the discovery and characterization of structural patterns is highly relevant as these patterns can give fundamental insights into protein-ligand interaction and protein function. This paper presents GSP4PDB, a bioinformatics web tool that enables the user to visualize, search and explore protein-ligand structural patterns within the entire Protein Data Bank. Results We introduce the notion of graph-based structural pattern (GSP) as an abstract model for representing protein-ligand interactions. A GSP is a graph where the nodes represent entities of the protein-ligand complex (amino acids and ligands) and the edges represent structural relationships (e.g. distances ligand - amino acid). The novel feature of GSP4PDB is a simple and intuitive graphical interface where the user can “draw” a GSP and execute its search in a relational database containing the structural data of each PDB entry. The results of the search are displayed using the same graph-based representation of the pattern. The user can further explore and analyse the results using a wide range of filters, or download their related information for external post-processing and analysis. Conclusions GSP4PDB is a user-friendly and efficient application to search and discover new patterns of protein-ligand interaction.",2020-03-11,2021-06-05 20:35:57; 2021-06-06 07:04:00; 2021-06-05 20:54:31; 2021-06-05 21:10:08,,Suppl 2,21,BMC Bioinformatics,GSP4PDB,PubMed Central,PMID: 32164553 PMCID: PMC7068854,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7068854/,,Neo4j; Giraph,Neo4j; Giraph,PMC:Query3; PMC:Neo4j; PMC:Query2; PMC:Giraph
442,10.1186/s12859-021-04129-0,33888059,PMC8061067,,,,"Licheri, Nicola; Bonnici, Vincenzo; Beccuti, Marco; Giugno, Rosalba",GRAPES-DD: exploiting decision diagrams for index-driven search in biological graph databases,2021,BMC bioinformatics; BMC Bioinformatics,,"Background Graphs are mathematical structures widely used for expressing relationships among elements when representing biomedical and biological information. On top of these representations, several analyses are performed. A common task is the search of one substructure within one graph, called target. The problem is referred to as one-to-one subgraph search, and it is known to be NP-complete. Heuristics and indexing techniques can be applied to facilitate the search. Indexing techniques are also exploited in the context of searching in a collection of target graphs, referred to as one-to-many subgraph problem. Filter-and-verification methods that use indexing approaches provide a fast pruning of target graphs or parts of them that do not contain the query. The expensive verification phase is then performed only on the subset of promising targets. Indexing strategies extract graph features at a sufficient granularity level for performing a powerful filtering step. Features are memorized in data structures allowing an efficient access. Indexing size, querying time and filtering power are key points for the development of efficient subgraph searching solutions. Results An existing approach, GRAPES, has been shown to have good performance in terms of speed-up for both one-to-one and one-to-many cases. However, it suffers in the size of the built index. For this reason, we propose GRAPES-DD, a modified version of GRAPES in which the indexing structure has been replaced with a Decision Diagram. Decision Diagrams are a broad class of data structures widely used to encode and manipulate functions efficiently. Experiments on biomedical structures and synthetic graphs have confirmed our expectation showing that GRAPES-DD has substantially reduced the memory utilization compared to GRAPES without worsening the searching time. Conclusion The use of Decision Diagrams for searching in biochemical and biological graphs is completely new and potentially promising thanks to their ability to encode compactly sets by exploiting their structure and regularity, and to manipulate entire sets of elements at once, instead of exploring each single element explicitly. Search strategies based on Decision Diagram makes the indexing for biochemical graphs, and not only, more affordable allowing us to potentially deal with huge and ever growing collections of biochemical and biological structures.; BACKGROUND: Graphs are mathematical structures widely used for expressing relationships among elements when representing biomedical and biological information. On top of these representations, several analyses are performed. A common task is the search of one substructure within one graph, called target. The problem is referred to as one-to-one subgraph search, and it is known to be NP-complete. Heuristics and indexing techniques can be applied to facilitate the search. Indexing techniques are also exploited in the context of searching in a collection of target graphs, referred to as one-to-many subgraph problem. Filter-and-verification methods that use indexing approaches provide a fast pruning of target graphs or parts of them that do not contain the query. The expensive verification phase is then performed only on the subset of promising targets. Indexing strategies extract graph features at a sufficient granularity level for performing a powerful filtering step. Features are memorized in data structures allowing an efficient access. Indexing size, querying time and filtering power are key points for the development of efficient subgraph searching solutions. RESULTS: An existing approach, GRAPES, has been shown to have good performance in terms of speed-up for both one-to-one and one-to-many cases. However, it suffers in the size of the built index. For this reason, we propose GRAPES-DD, a modified version of GRAPES in which the indexing structure has been replaced with a Decision Diagram. Decision Diagrams are a broad class of data structures widely used to encode and manipulate functions efficiently. Experiments on biomedical structures and synthetic graphs have confirmed our expectation showing that GRAPES-DD has substantially reduced the memory utilization compared to GRAPES without worsening the searching time. CONCLUSION: The use of Decision Diagrams for searching in biochemical and biological graphs is completely new and potentially promising thanks to their ability to encode compactly sets by exploiting their structure and regularity, and to manipulate entire sets of elements at once, instead of exploring each single element explicitly. Search strategies based on Decision Diagram makes the indexing for biochemical graphs, and not only, more affordable allowing us to potentially deal with huge and ever growing collections of biochemical and biological structures.",2021-04-22,2021-06-05 21:06:22; 2021-06-05 21:09:36,209,1,22,BMC Bioinformatics,GRAPES-DD,PubMed; PubMed Central,PMID: 33888059 PMCID: PMC8061067,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8061067/; http://www.ncbi.nlm.nih.gov/pubmed/33888059,"Abstracting and Indexing; Algorithms; Databases, Factual; Decision diagrams; Graph indexing; Pattern matching; Query processing; Subgraph isomorphism; Vitis",,,PubMed:Query2; PMC:Query2
443,10.1186/s12859-021-04133-4,33926379,PMC8082839,,,,"Bae, Jeongmin; Jeon, Hajin; Kim, Min-Soo",GPrimer: a fast GPU-based pipeline for primer design for qPCR experiments,2021,BMC Bioinformatics,,"Background Design of valid high-quality primers is essential for qPCR experiments. MRPrimer is a powerful pipeline based on MapReduce that combines both primer design for target sequences and homology tests on off-target sequences. It takes an entire sequence DB as input and returns all feasible and valid primer pairs existing in the DB. Due to the effectiveness of primers designed by MRPrimer in qPCR analysis, it has been widely used for developing many online design tools and building primer databases. However, the computational speed of MRPrimer is too slow to deal with the sizes of sequence DBs growing exponentially and thus must be improved. Results We develop a fast GPU-based pipeline for primer design (GPrimer) that takes the same input and returns the same output with MRPrimer. MRPrimer consists of a total of seven MapReduce steps, among which two steps are very time-consuming. GPrimer significantly improves the speed of those two steps by exploiting the computational power of GPUs. In particular, it designs data structures for coalesced memory access in GPU and workload balancing among GPU threads and copies the data structures between main memory and GPU memory in a streaming fashion. For human RefSeq DB, GPrimer achieves a speedup of 57 times for the entire steps and a speedup of 557 times for the most time-consuming step using a single machine of 4 GPUs, compared with MRPrimer running on a cluster of six machines. Conclusions We propose a GPU-based pipeline for primer design that takes an entire sequence DB as input and returns all feasible and valid primer pairs existing in the DB at once without an additional step using BLAST-like tools. The software is available at https://github.com/qhtjrmin/GPrimer.git.",2021-04-29,2021-06-05 21:09:36,,,22,BMC Bioinformatics,GPrimer,PubMed Central,PMID: 33926379 PMCID: PMC8082839,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8082839/,,,,PMC:Query2
444,10.1186/s12864-016-3327-5,28155652,PMC5259817,,,,"Li, Honglan; Joh, Yoon Sung; Kim, Hyunwoo; Paek, Eunok; Lee, Sang-Won; Hwang, Kyu-Baek",Evaluating the effect of database inflation in proteogenomic search on sensitive and reliable peptide identification,2016,BMC Genomics,,"Background Proteogenomics is a promising approach for various tasks ranging from gene annotation to cancer research. Databases for proteogenomic searches are often constructed by adding peptide sequences inferred from genomic or transcriptomic evidence to reference protein sequences. Such inflation of databases has potential of identifying novel peptides. However, it also raises concerns on sensitive and reliable peptide identification. Spurious peptides included in target databases may result in underestimated false discovery rate (FDR). On the other hand, inflation of decoy databases could decrease the sensitivity of peptide identification due to the increased number of high-scoring random hits. Although several studies have addressed these issues, widely applicable guidelines for sensitive and reliable proteogenomic search have hardly been available. Results To systematically evaluate the effect of database inflation in proteogenomic searches, we constructed a variety of real and simulated proteogenomic databases for yeast and human tandem mass spectrometry (MS/MS) data, respectively. Against these databases, we tested two popular database search tools with various approaches to search result validation: the target-decoy search strategy (with and without a refined scoring-metric) and a mixture model-based method. The effect of separate filtering of known and novel peptides was also examined. The results from real and simulated proteogenomic searches confirmed that separate filtering increases the sensitivity and reliability in proteogenomic search. However, no one method consistently identified the largest (or the smallest) number of novel peptides from real proteogenomic searches. Conclusions We propose to use a set of search result validation methods with separate filtering, for sensitive and reliable identification of peptides in proteogenomic search. Electronic supplementary material The online version of this article (doi:10.1186/s12864-016-3327-5) contains supplementary material, which is available to authorized users.",2016-12-22,2021-06-05 21:12:01,,Suppl 13,17,BMC Genomics,,PubMed Central,PMID: 28155652 PMCID: PMC5259817,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5259817/,,,,PMC:Query2
445,10.1186/s12864-017-3664-z,28388878,PMC5383985,A,Virtuoso,Virtuoso,"Spokevicius, Antanas V.; Tibbits, Josquin; Rigault, Philippe; Nolin, Marc-Alexandre; Müller, Caroline; Merchant, Andrew",Medium term water deficit elicits distinct transcriptome responses in Eucalyptus species of contrasting environmental origin,2017,BMC Genomics,,"Background Climatic and edaphic conditions over geological timescales have generated enormous diversity of adaptive traits and high speciation within the genus Eucalyptus (L. Hér.). Eucalypt species occur from high rainfall to semi-arid zones and from the tropics to latitudes as high as 43°S. Despite several morphological and metabolomic characterizations, little is known regarding gene expression differences that underpin differences in tolerance to environmental change. Using species of contrasting taxonomy, morphology and physiology (E. globulus and E. cladocalyx), this study combines physiological characterizations with ‘second-generation’ sequencing to identify key genes involved in eucalypt responses to medium-term water limitation. Results One hundred twenty Million high-quality HiSeq reads were created from 14 tissue samples in plants that had been successfully subjected to a water deficit treatment or a well-watered control. Alignment to the E. grandis genome saw 23,623 genes of which 468 exhibited differential expression (FDR < 0.01) in one or both ecotypes in response to the treatment. Further analysis identified 80 genes that demonstrated a significant species-specific response of which 74 were linked to the ‘dry’ species E. cladocalyx where 23 of these genes were uncharacterised. The majority (approximately 80%) of these differentially expressed genes, were expressed in stem tissue. Key genes that differentiated species responses were linked to photoprotection/redox balance, phytohormone/signalling, primary photosynthesis/cellular metabolism and secondary metabolism based on plant metabolic pathway network analysis. Conclusion These results highlight a more definitive response to water deficit by a ‘dry’ climate eucalypt, particularly in stem tissue, identifying key pathways and associated genes that are responsible for the differences between ‘wet’ and ‘dry’ climate eucalypts. This knowledge provides the opportunity to further investigate and understand the mechanisms and genetic variation linked to this important environmental response that will assist with genomic efforts in managing native populations as well as in tree improvement programs under future climate scenarios. Electronic supplementary material The online version of this article (doi:10.1186/s12864-017-3664-z) contains supplementary material, which is available to authorized users.",2017-04-07,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:59:14,,,18,BMC Genomics,,PubMed Central,PMID: 28388878 PMCID: PMC5383985,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5383985/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
446,10.1186/s12864-021-07583-5,33849459,PMC8045196,,,,"Jonkheer, Eef M.; Brankovics, Balázs; Houwers, Ilse M.; van der Wolf, Jan M.; Bonants, Peter J. M.; Vreeburg, Robert A. M.; Bollema, Robert; de Haan, Jorn R.; Berke, Lidija; Smit, Sandra; de Ridder, Dick; van der Lee, Theo A. J.","The Pectobacterium pangenome, with a focus on Pectobacterium brasiliense, shows a robust core and extensive exchange of genes from a shared gene pool",2021,BMC Genomics,,"Background Bacterial plant pathogens of the Pectobacterium genus are responsible for a wide spectrum of diseases in plants, including important crops such as potato, tomato, lettuce, and banana. Investigation of the genetic diversity underlying virulence and host specificity can be performed at genome level by using a comprehensive comparative approach called pangenomics. A pangenomic approach, using newly developed functionalities in PanTools, was applied to analyze the complex phylogeny of the Pectobacterium genus. We specifically used the pangenome to investigate genetic differences between virulent and avirulent strains of P. brasiliense, a potato blackleg causing species dominantly present in Western Europe. Results Here we generated a multilevel pangenome for Pectobacterium, comprising 197 strains across 19 species, including type strains, with a focus on P. brasiliense. The extensive phylogenetic analysis of the Pectobacterium genus showed robust distinct clades, with most detail provided by 452,388 parsimony-informative single-nucleotide polymorphisms identified in single-copy orthologs. The average Pectobacterium genome consists of 47% core genes, 1% unique genes, and 52% accessory genes. Using the pangenome, we zoomed in on differences between virulent and avirulent P. brasiliense strains and identified 86 genes associated to virulent strains. We found that the organization of genes is highly structured and linked with gene conservation, function, and transcriptional orientation. Conclusion The pangenome analysis demonstrates that evolution in Pectobacteria is a highly dynamic process, including gene acquisitions partly in clusters, genome rearrangements, and loss of genes. Pectobacterium species are typically not characterized by a set of species-specific genes, but instead present themselves using new gene combinations from the shared gene pool. A multilevel pangenomic approach, fusing DNA, protein, biological function, taxonomic group, and phenotypes, facilitates studies in a flexible taxonomic context. Supplementary Information The online version contains supplementary material available at 10.1186/s12864-021-07583-5.",2021-04-14,2021-06-05 21:09:36,,,22,BMC Genomics,,PubMed Central,PMID: 33849459 PMCID: PMC8045196,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8045196/,,,,PMC:Query2
447,10.1186/s12911-017-0515-4,28821246,PMC5563027,,,,"Sánchez-de-Madariaga, Ricardo; Muñoz, Adolfo; Lozano-Rubí, Raimundo; Serrano-Balazote, Pablo; Castro, Antonio L.; Moreno, Oscar; Pascual, Mario",Examining database persistence of ISO/EN 13606 standardized electronic health record extracts: relational vs. NoSQL approaches,2017,BMC Medical Informatics and Decision Making,,"Background The objective of this research is to compare the relational and non-relational (NoSQL) database systems approaches in order to store, recover, query and persist standardized medical information in the form of ISO/EN 13606 normalized Electronic Health Record XML extracts, both in isolation and concurrently. NoSQL database systems have recently attracted much attention, but few studies in the literature address their direct comparison with relational databases when applied to build the persistence layer of a standardized medical information system. Methods One relational and two NoSQL databases (one document-based and one native XML database) of three different sizes have been created in order to evaluate and compare the response times (algorithmic complexity) of six different complexity growing queries, which have been performed on them. Similar appropriate results available in the literature have also been considered. Results Relational and non-relational NoSQL database systems show almost linear algorithmic complexity query execution. However, they show very different linear slopes, the former being much steeper than the two latter. Document-based NoSQL databases perform better in concurrency than in isolation, and also better than relational databases in concurrency. Conclusion Non-relational NoSQL databases seem to be more appropriate than standard relational SQL databases when database size is extremely high (secondary use, research applications). Document-based NoSQL databases perform in general better than native XML NoSQL databases. EHR extracts visualization and edition are also document-based tasks more appropriate to NoSQL database systems. However, the appropriate database solution much depends on each particular situation and specific problem. Electronic supplementary material The online version of this article (doi:10.1186/s12911-017-0515-4) contains supplementary material, which is available to authorized users.",2017-08-18,2021-06-05 21:12:01,,,17,BMC Med Inform Decis Mak,Examining database persistence of ISO/EN 13606 standardized electronic health record extracts,PubMed Central,PMID: 28821246 PMCID: PMC5563027,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5563027/,,,,PMC:Query2
448,10.1186/s12911-018-0635-5,30066655,PMC6069686,,,,"Lossio-Ventura, Juan Antonio; Hogan, William; Modave, François; Guo, Yi; He, Zhe; Yang, Xi; Zhang, Hansi; Bian, Jiang",OC-2-KB: integrating crowdsourcing into an obesity and cancer knowledge base curation system,2018,BMC Medical Informatics and Decision Making,,"Background There is strong scientific evidence linking obesity and overweight to the risk of various cancers and to cancer survivorship. Nevertheless, the existing online information about the relationship between obesity and cancer is poorly organized, not evidenced-based, of poor quality, and confusing to health information consumers. A formal knowledge representation such as a Semantic Web knowledge base (KB) can help better organize and deliver quality health information. We previously presented the OC-2-KB (Obesity and Cancer to Knowledge Base), a software pipeline that can automatically build an obesity and cancer KB from scientific literature. In this work, we investigated crowdsourcing strategies to increase the number of ground truth annotations and improve the quality of the KB. Methods We developed a new release of the OC-2-KB system addressing key challenges in automatic KB construction. OC-2-KB automatically extracts semantic triples in the form of subject-predicate-object expressions from PubMed abstracts related to the obesity and cancer literature. The accuracy of the facts extracted from scientific literature heavily relies on both the quantity and quality of the available ground truth triples. Thus, we incorporated a crowdsourcing process to improve the quality of the KB. Results We conducted two rounds of crowdsourcing experiments using a new corpus with 82 obesity and cancer-related PubMed abstracts. We demonstrated that crowdsourcing is indeed a low-cost mechanism to collect labeled data from non-expert laypeople. Even though individual layperson might not offer reliable answers, the collective wisdom of the crowd is comparable to expert opinions. We also retrained the relation detection machine learning models in OC-2-KB using the crowd annotated data and evaluated the content of the curated KB with a set of competency questions. Our evaluation showed improved performance of the underlying relation detection model in comparison to the baseline OC-2-KB. Conclusions We presented a new version of OC-2-KB, a system that automatically builds an evidence-based obesity and cancer KB from scientific literature. Our KB construction framework integrated automatic information extraction with crowdsourcing techniques to verify the extracted knowledge. Our ultimate goal is a paradigm shift in how the general public access, read, digest, and use online health information.",2018-07-23,2021-06-05 21:11:16,,Suppl 2,18,BMC Med Inform Decis Mak,OC-2-KB,PubMed Central,PMID: 30066655 PMCID: PMC6069686,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6069686/,,,,PMC:Query2
449,10.1186/s12911-018-0651-5,30170591,PMC6119323,,,,"El-Sappagh, Shaker; Franda, Francesco; Ali, Farman; Kwak, Kyung-Sup",SNOMED CT standard ontology based on the ontology for general medical science,2018,BMC Medical Informatics and Decision Making,,"Background Systematized Nomenclature of Medicine—Clinical Terms (SNOMED CT, hereafter abbreviated SCT) is a comprehensive medical terminology used for standardizing the storage, retrieval, and exchange of electronic health data. Some efforts have been made to capture the contents of SCT as Web Ontology Language (OWL), but these efforts have been hampered by the size and complexity of SCT. Method Our proposal here is to develop an upper-level ontology and to use it as the basis for defining the terms in SCT in a way that will support quality assurance of SCT, for example, by allowing consistency checks of definitions and the identification and elimination of redundancies in the SCT vocabulary. Our proposed upper-level SCT ontology (SCTO) is based on the Ontology for General Medical Science (OGMS). Results The SCTO is implemented in OWL 2, to support automatic inference and consistency checking. The approach will allow integration of SCT data with data annotated using Open Biomedical Ontologies (OBO) Foundry ontologies, since the use of OGMS will ensure consistency with the Basic Formal Ontology, which is the top-level ontology of the OBO Foundry. Currently, the SCTO contains 304 classes, 28 properties, 2400 axioms, and 1555 annotations. It is publicly available through the bioportal at http://bioportal.bioontology.org/ontologies/SCTO/. Conclusion The resulting ontology can enhance the semantics of clinical decision support systems and semantic interoperability among distributed electronic health records. In addition, the populated ontology can be used for the automation of mobile health applications.",2018-08-31,2021-06-05 21:11:16,,,18,BMC Med Inform Decis Mak,,PubMed Central,PMID: 30170591 PMCID: PMC6119323,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6119323/,,,,PMC:Query2
450,10.1186/s12911-019-0750-y,30764811,PMC6376747,A,Neo4j,Neo4j,"Jing, Xia; Emerson, Matthew; Masters, David; Brooks, Matthew; Buskirk, Jacob; Abukamail, Nasseef; Liu, Chang; Cimino, James J.; Shubrook, Jay; De Lacalle, Sonsoles; Zhou, Yuchun; Patel, Vimla L.",A visual interactive analytic tool for filtering and summarizing large health data sets coded with hierarchical terminologies (VIADS),2019,BMC Medical Informatics and Decision Making,,"Background Vast volumes of data, coded through hierarchical terminologies (e.g., International Classification of Diseases, Tenth Revision–Clinical Modification [ICD10-CM], Medical Subject Headings [MeSH]), are generated routinely in electronic health record systems and medical literature databases. Although graphic representations can help to augment human understanding of such data sets, a graph with hundreds or thousands of nodes challenges human comprehension. To improve comprehension, new tools are needed to extract the overviews of such data sets. We aim to develop a visual interactive analytic tool for filtering and summarizing large health data sets coded with hierarchical terminologies (VIADS) as an online, and publicly accessible tool. The ultimate goals are to filter, summarize the health data sets, extract insights, compare and highlight the differences between various health data sets by using VIADS. The results generated from VIADS can be utilized as data-driven evidence to facilitate clinicians, clinical researchers, and health care administrators to make more informed clinical, research, and administrative decisions. We utilized the following tools and the development environments to develop VIADS: Django, Python, JavaScript, Vis.js, Graph.js, JQuery, Plotly, Chart.js, Unittest, R, and MySQL. Results VIADS was developed successfully and the beta version is accessible publicly. In this paper, we introduce the architecture design, development, and functionalities of VIADS. VIADS includes six modules: user account management module, data sets validation module, data analytic module, data visualization module, terminology module, dashboard. Currently, VIADS supports health data sets coded by ICD-9, ICD-10, and MeSH. We also present the visualization improvement provided by VIADS in regard to interactive features (e.g., zoom in and out, customization of graph layout, expanded information of nodes, 3D plots) and efficient screen space usage. Conclusions VIADS meets the design objectives and can be used to filter, summarize, compare, highlight and visualize large health data sets that coded by hierarchical terminologies, such as ICD-9, ICD-10 and MeSH. Our further usability and utility studies will provide more details about how the end users are using VIADS to facilitate their clinical, research or health administrative decision making.",2019-02-14,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,,,19,BMC Med Inform Decis Mak,,PubMed Central,PMID: 30764811 PMCID: PMC6376747,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6376747/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
451,10.1186/s12911-019-0798-8,30935389,PMC6444506,A,Neo4j,Neo4j,"Ruan, Tong; Huang, Yueqi; Liu, Xuli; Xia, Yuhang; Gao, Ju",QAnalysis: a question-answer driven analytic tool on knowledge graphs for leveraging electronic medical records for clinical research,2019,BMC Medical Informatics and Decision Making; BMC medical informatics and decision making,,"Background While doctors should analyze a large amount of electronic medical record (EMR) data to conduct clinical research, the analyzing process requires information technology (IT) skills, which is difficult for most doctors in China. Methods In this paper, we build a novel tool QAnalysis, where doctors enter their analytic requirements in their natural language and then the tool returns charts and tables to the doctors. For a given question from a user, we first segment the sentence, and then we use grammar parser to analyze the structure of the sentence. After linking the segmentations to concepts and predicates in knowledge graphs, we convert the question into a set of triples connected with different kinds of operators. These triples are converted to queries in Cypher, the query language for Neo4j. Finally, the query is executed on Neo4j, and the results shown in terms of tables and charts are returned to the user. Results The tool supports top 50 questions we gathered from two hospital departments with the Delphi method. We also gathered 161 questions from clinical research papers with statistical requirements on EMR data. Experimental results show that our tool can directly cover 78.20% of these statistical questions and the precision is as high as 96.36%. Such extension is easy to achieve with the help of knowledge-graph technology we have adopted. The recorded demo can be accessed from https://github.com/NLP-BigDataLab/QAnalysis-project. Conclusion Our tool shows great flexibility in processing different kinds of statistic questions, which provides a convenient way for doctors to get statistical results directly in natural language.; BACKGROUND: While doctors should analyze a large amount of electronic medical record (EMR) data to conduct clinical research, the analyzing process requires information technology (IT) skills, which is difficult for most doctors in China. METHODS: In this paper, we build a novel tool QAnalysis, where doctors enter their analytic requirements in their natural language and then the tool returns charts and tables to the doctors. For a given question from a user, we first segment the sentence, and then we use grammar parser to analyze the structure of the sentence. After linking the segmentations to concepts and predicates in knowledge graphs, we convert the question into a set of triples connected with different kinds of operators. These triples are converted to queries in Cypher, the query language for Neo4j. Finally, the query is executed on Neo4j, and the results shown in terms of tables and charts are returned to the user. RESULTS: The tool supports top 50 questions we gathered from two hospital departments with the Delphi method. We also gathered 161 questions from clinical research papers with statistical requirements on EMR data. Experimental results show that our tool can directly cover 78.20% of these statistical questions and the precision is as high as 96.36%. Such extension is easy to achieve with the help of knowledge-graph technology we have adopted. The recorded demo can be accessed from https://github.com/NLP-BigDataLab/QAnalysis-project . CONCLUSION: Our tool shows great flexibility in processing different kinds of statistic questions, which provides a convenient way for doctors to get statistical results directly in natural language.",2019-04-01,2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 21:10:37; 2021-06-05 20:55:01; 2021-06-05 21:24:28; 2021-06-05 20:36:32,82,1,19,BMC Med Inform Decis Mak,QAnalysis,PubMed; PubMed Central,PMID: 30935389 PMCID: PMC6444506,http://www.ncbi.nlm.nih.gov/pubmed/30935389; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6444506/,"Biomedical Research; China; Context-free grammar; Electronic Health Records; Electronic medical record; Graph database; Humans; Natural Language Processing; Pattern Recognition, Automated; Software; Statistical question answering",Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
452,10.1186/s12911-019-0857-1,31391091,PMC6686235,A,Neo4j,Neo4j,"He, Xing; Zhang, Rui; Rizvi, Rubina; Vasilakes, Jake; Yang, Xi; Guo, Yi; He, Zhe; Prosperi, Mattia; Huo, Jinhai; Alpert, Jordan; Bian, Jiang",ALOHA: developing an interactive graph-based visualization for dietary supplement knowledge graph through user-centered design,2019,BMC Medical Informatics and Decision Making,,"Background Dietary supplements (DSs) are widely used. However, consumers know little about the safety and efficacy of DSs. There is a growing interest in accessing health information online; however, health information, especially online information on DSs, is scattered with varying levels of quality. In our previous work, we prototyped a web application, ALOHA, with interactive graph-based visualization to facilitate consumers’ browsing of the integrated DIetary Supplement Knowledge base (iDISK) curated from scientific resources, following an iterative user-centered design (UCD) process. Methods Following UCD principles, we carried out two design iterations to enrich the functionalities of ALOHA and enhance its usability. For each iteration, we conducted a usability assessment and design session with a focus group of 8–10 participants and evaluated the usability with a modified System Usability Scale (SUS). Through thematic analysis, we summarized the identified usability issues and conducted a heuristic evaluation to map them to the Gerhardt-Powals’ cognitive engineering principles. We derived suggested improvements from each of the usability assessment session and enhanced ALOHA accordingly in the next design iteration. Results The SUS score in the second design iteration decreased to 52.2 ± 11.0 from 63.75 ± 7.2 in our original work, possibly due to the high number of new functionalities we introduced. By refining existing functionalities to make the user interface simpler, the SUS score increased to 64.4 ± 7.2 in the third design iteration. All participants agreed that such an application is urgently needed to address the gaps in how DS information is currently organized and consumed online. Moreover, most participants thought that the graph-based visualization in ALOHA is a creative and visually appealing format to obtain health information. Conclusions In this study, we improved a novel interactive visualization platform, ALOHA, for the general public to obtain DS-related information through two UCD design iterations. The lessons learned from the two design iterations could serve as a guide to further enhance ALOHA and the development of other knowledge graph-based applications. Our study also showed that graph-based interactive visualization is a novel and acceptable approach to end-users who are interested in seeking online health information of various domains.",2019-08-08,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,,Suppl 4,19,BMC Med Inform Decis Mak,ALOHA,PubMed Central,PMID: 31391091 PMCID: PMC6686235,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6686235/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
453,10.1186/s12911-019-0938-1,31801534,PMC6894101,,,,"Li, Xuedong; Wang, Yue; Wang, Dongwu; Yuan, Walter; Peng, Dezhong; Mei, Qiaozhu",Improving rare disease classification using imperfect knowledge graph,2019,BMC Medical Informatics and Decision Making,,"Background Accurately recognizing rare diseases based on symptom description is an important task in patient triage, early risk stratification, and target therapies. However, due to the very nature of rare diseases, the lack of historical data poses a great challenge to machine learning-based approaches. On the other hand, medical knowledge in automatically constructed knowledge graphs (KGs) has the potential to compensate the lack of labeled training examples. This work aims to develop a rare disease classification algorithm that makes effective use of a knowledge graph, even when the graph is imperfect. Method We develop a text classification algorithm that represents a document as a combination of a “bag of words” and a “bag of knowledge terms,” where a “knowledge term” is a term shared between the document and the subgraph of KG relevant to the disease classification task. We use two Chinese disease diagnosis corpora to evaluate the algorithm. The first one, HaoDaiFu, contains 51,374 chief complaints categorized into 805 diseases. The second data set, ChinaRe, contains 86,663 patient descriptions categorized into 44 disease categories. Results On the two evaluation data sets, the proposed algorithm delivers robust performance and outperforms a wide range of baselines, including resampling, deep learning, and feature selection approaches. Both classification-based metric (macro-averaged F1 score) and ranking-based metric (mean reciprocal rank) are used in evaluation. Conclusion Medical knowledge in large-scale knowledge graphs can be effectively leveraged to improve rare diseases classification models, even when the knowledge graph is incomplete.",2019-12-05,2021-06-05 21:10:37,,Suppl 5,19,BMC Med Inform Decis Mak,,PubMed Central,PMID: 31801534 PMCID: PMC6894101,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6894101/,,,,PMC:Query2
454,10.1186/s12911-020-1112-5,32646496,PMC7346328,A,Neo4j,Neo4j,"Li, Nan; Yang, Zhihao; Luo, Ling; Wang, Lei; Zhang, Yin; Lin, Hongfei; Wang, Jian",KGHC: a knowledge graph for hepatocellular carcinoma,2020,BMC Medical Informatics and Decision Making; BMC medical informatics and decision making,,"BACKGROUND: Hepatocellular carcinoma is one of the most general malignant neoplasms in adults with high mortality. Mining relative medical knowledge from rapidly growing text data and integrating it with other existing biomedical resources will provide support to the research on the hepatocellular carcinoma. To this purpose, we constructed a knowledge graph for Hepatocellular Carcinoma (KGHC). METHODS: We propose an approach to build a knowledge graph for hepatocellular carcinoma. Specifically, we first extracted knowledge from structured data and unstructured data. Since the extracted entities may contain some noise, we applied a biomedical information extraction system, named BioIE, to filter the data in KGHC. Then we introduced a fusion method which is used to fuse the extracted data. Finally, we stored the data into the Neo4j which can help researchers analyze the network of hepatocellular carcinoma. RESULTS: KGHC contains 13,296 triples and provides the knowledge of hepatocellular carcinoma for healthcare professionals, making them free of digging into a large amount of biomedical literatures. This could hopefully improve the efficiency of researches on the hepatocellular carcinoma. KGHC is accessible free for academic research purpose at http://202.118.75.18:18895/browser/ . CONCLUSIONS: In this paper, we present a knowledge graph associated with hepatocellular carcinoma, which is constructed with vast amounts of structured and unstructured data. The evaluation results show that the data in KGHC is of high quality.; Background Hepatocellular carcinoma is one of the most general malignant neoplasms in adults with high mortality. Mining relative medical knowledge from rapidly growing text data and integrating it with other existing biomedical resources will provide support to the research on the hepatocellular carcinoma. To this purpose, we constructed a knowledge graph for Hepatocellular Carcinoma (KGHC). Methods We propose an approach to build a knowledge graph for hepatocellular carcinoma. Specifically, we first extracted knowledge from structured data and unstructured data. Since the extracted entities may contain some noise, we applied a biomedical information extraction system, named BioIE, to filter the data in KGHC. Then we introduced a fusion method which is used to fuse the extracted data. Finally, we stored the data into the Neo4j which can help researchers analyze the network of hepatocellular carcinoma. Results KGHC contains 13,296 triples and provides the knowledge of hepatocellular carcinoma for healthcare professionals, making them free of digging into a large amount of biomedical literatures. This could hopefully improve the efficiency of researches on the hepatocellular carcinoma. KGHC is accessible free for academic research purpose at http://202.118.75.18:18895/browser/. Conclusions In this paper, we present a knowledge graph associated with hepatocellular carcinoma, which is constructed with vast amounts of structured and unstructured data. The evaluation results show that the data in KGHC is of high quality.",2020-07-09,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08; 2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 21:24:28,135,Suppl 3,20,BMC Med Inform Decis Mak,KGHC,PubMed; PubMed Central,PMID: 32646496 PMCID: PMC7346328,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7346328/; http://www.ncbi.nlm.nih.gov/pubmed/32646496,"Carcinoma, Hepatocellular; Hepatocellular carcinoma; Humans; Information extraction; Information Storage and Retrieval; Knowledge Bases; Knowledge graph; Liver Neoplasms; Pattern Recognition, Automated",Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
455,10.1186/s12911-021-01402-3,33541342,PMC7863488,A,Neo4j,Neo4j,"Zhang, Fei; Sun, Bo; Diao, Xiaolin; Zhao, Wei; Shu, Ting",Prediction of adverse drug reactions based on knowledge graph embedding,2021,BMC Medical Informatics and Decision Making,,"Background Adverse drug reactions (ADRs) are an important concern in the medication process and can pose a substantial economic burden for patients and hospitals. Because of the limitations of clinical trials, it is difficult to identify all possible ADRs of a drug before it is marketed. We developed a new model based on data mining technology to predict potential ADRs based on available drug data. Method Based on the Word2Vec model in Nature Language Processing, we propose a new knowledge graph embedding method that embeds drugs and ADRs into their respective vectors and builds a logistic regression classification model to predict whether a given drug will have ADRs. Result First, a new knowledge graph embedding method was proposed, and comparison with similar studies showed that our model not only had high prediction accuracy but also was simpler in model structure. In our experiments, the AUC of the classification model reached a maximum of 0.87, and the mean AUC was 0.863. Conclusion In this paper, we introduce a new method to embed knowledge graph to vectorize drugs and ADRs, then use a logistic regression classification model to predict whether there is a causal relationship between them. The experiment showed that the use of knowledge graph embedding can effectively encode drugs and ADRs. And the proposed ADRs prediction system is also very effective.",2021-02-04,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,,21,BMC Med Inform Decis Mak,,PubMed Central,PMID: 33541342 PMCID: PMC7863488,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7863488/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
456,10.1186/s12918-014-0091-5,25182954,PMC4423647,A,Virtuoso,Virtuoso,"Wimalaratne, Sarala M; Grenon, Pierre; Hermjakob, Henning; Le Novère, Nicolas; Laibe, Camille",BioModels linked dataset,2014,BMC Systems Biology,,"Background BioModels Database is a reference repository of mathematical models used in biology. Models are stored as SBML files on a file system and metadata is provided in a relational database. Models can be retrieved through a web interface and programmatically via web services. In addition to those more traditional ways to access information, Linked Data using Semantic Web technologies (such as the Resource Description Framework, RDF), is becoming an increasingly popular means to describe and expose biological relevant data. Results We present the BioModels Linked Dataset, which exposes the models’ content as a dereferencable interlinked dataset. BioModels Linked Dataset makes use of the wealth of annotations available within a large number of manually curated models to link and integrate data and models from other resources. Conclusions The BioModels Linked Dataset provides users with a dataset interoperable with other semantic web resources. It supports powerful search queries, some of which were not previously available to users and allow integration of data from multiple resources. This provides a distributed platform to find similar models for comparison, processing and enrichment.",2014-08-15,2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-05 20:59:14,,,8,BMC Syst Biol,,PubMed Central,PMID: 25182954 PMCID: PMC4423647,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4423647/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
457,10.1186/s12918-018-0533-6,29671392,PMC5907309,,,,"Mukherjee, Kingshuk; Hasan, Md Mahmudul; Boucher, Christina; Kahveci, Tamer",Counting motifs in dynamic networks,2018,BMC Systems Biology,,"Background A network motif is a sub-network that occurs frequently in a given network. Detection of such motifs is important since they uncover functions and local properties of the given biological network. Finding motifs is however a computationally challenging task as it requires solving the costly subgraph isomorphism problem. Moreover, the topology of biological networks change over time. These changing networks are called dynamic biological networks. As the network evolves, frequency of each motif in the network also changes. Computing the frequency of a given motif from scratch in a dynamic network as the network topology evolves is infeasible, particularly for large and fast evolving networks. Results In this article, we design and develop a scalable method for counting the number of motifs in a dynamic biological network. Our method incrementally updates the frequency of each motif as the underlying network’s topology evolves. Our experiments demonstrate that our method can update the frequency of each motif in orders of magnitude faster than counting the motif embeddings every time the network changes. If the network evolves more frequently, the margin with which our method outperforms the existing static methods, increases. Conclusions We evaluated our method extensively using synthetic and real datasets, and show that our method is highly accurate(≥ 96%) and that it can be scaled to large dense networks. The results on real data demonstrate the utility of our method in revealing interesting insights on the evolution of biological processes.",2018-04-11,2021-06-05 21:11:16,,Suppl 1,12,BMC Syst Biol,,PubMed Central,PMID: 29671392 PMCID: PMC5907309,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5907309/,,,,PMC:Query2
458,10.1186/s12918-018-0616-4,30458802,PMC6245492,A,OrientDB; Neo4j,OrientDB; Neo4j,"Messina, Antonio; Fiannaca, Antonino; La Paglia, Laura; La Rosa, Massimo; Urso, Alfonso",BioGraph: a web application and a graph database for querying and analyzing bioinformatics resources,2018,BMC Systems Biology; BMC systems biology,,"Background Several online databases provide a large amount of biomedical data of different biological entities. These resources are typically stored in systems implementing their own data model, user interface and query language. On the other hand, in many bioinformatics scenarios there is often the need to use more than one resource. The availability of a single bioinformatics platform that integrates many biological resources and services is, for those reasons a fundamental issue. Description Here, we present BioGraph, a web application that allows to query, visualize and analyze biological data belonging to several online available sources. BioGraph is built upon our previously developed graph database called BioGraphDB, that integrates and stores heterogeneous biological resources and make them available by means of a common structure and a unique query language. BioGraph implements state-of-the-art technologies and provides pre-compiled bioinformatics scenarios, as well as the possibility to perform custom queries and obtaining an interactive and dynamic visualization of results. Conclusion We present a case study about functional analysis of microRNA in breast cancer in order to demonstrate the functionalities of the system. BioGraph is freely available at http://biograph.pa.icar.cnr.it. Source files are available on GitHub at https://github.com/IcarPA-TBlab/BioGraph; BACKGROUND: Several online databases provide a large amount of biomedical data of different biological entities. These resources are typically stored in systems implementing their own data model, user interface and query language. On the other hand, in many bioinformatics scenarios there is often the need to use more than one resource. The availability of a single bioinformatics platform that integrates many biological resources and services is, for those reasons a fundamental issue. DESCRIPTION: Here, we present BioGraph, a web application that allows to query, visualize and analyze biological data belonging to several online available sources. BioGraph is built upon our previously developed graph database called BioGraphDB, that integrates and stores heterogeneous biological resources and make them available by means of a common structure and a unique query language. BioGraph implements state-of-the-art technologies and provides pre-compiled bioinformatics scenarios, as well as the possibility to perform custom queries and obtaining an interactive and dynamic visualization of results. CONCLUSION: We present a case study about functional analysis of microRNA in breast cancer in order to demonstrate the functionalities of the system. BioGraph is freely available at http://biograph.pa.icar.cnr.it . Source files are available on GitHub at https://github.com/IcarPA-TBlab/BioGraph.",2018-11-20,2021-06-06 06:49:06; 2021-06-05 21:06:22; 2021-06-05 21:10:37; 2021-06-05 20:55:01; 2021-06-05 20:36:32,98,Suppl 5,12,BMC Syst Biol,BioGraph,PubMed; PubMed Central,PMID: 30458802 PMCID: PMC6245492,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6245492/; http://www.ncbi.nlm.nih.gov/pubmed/30458802,"BioGraphDB; Bioinformatics databases; Breast Neoplasms; Computational Biology; Databases, Genetic; Female; Gene Expression Regulation, Neoplastic; Graph databases; Humans; Integrated databases; Internet; MicroRNAs; miRNA; Software; User-Computer Interface",OrientDB; Neo4j,OrientDB; Neo4j,PMC:Query2; PMC:OrientDB; PMC:Query3; PMC:Neo4j; PubMed:Query2
459,10.1186/s12920-018-0415-1,30454054,PMC6245588,A,Neo4j,Neo4j,"Xu, Bo; Li, Changlong; Zhuang, Hang; Wang, Jiali; Wang, Qingfeng; Wang, Chao; Zhou, Xuehai",Distributed gene clinical decision support system based on cloud computing,2018,BMC Medical Genomics,,"Background The clinical decision support system can effectively break the limitations of doctors’ knowledge and reduce the possibility of misdiagnosis to enhance health care. The traditional genetic data storage and analysis methods based on stand-alone environment are hard to meet the computational requirements with the rapid genetic data growth for the limited scalability. Methods In this paper, we propose a distributed gene clinical decision support system, which is named GCDSS. And a prototype is implemented based on cloud computing technology. At the same time, we present CloudBWA which is a novel distributed read mapping algorithm leveraging batch processing strategy to map reads on Apache Spark. Results Experiments show that the distributed gene clinical decision support system GCDSS and the distributed read mapping algorithm CloudBWA have outstanding performance and excellent scalability. Compared with state-of-the-art distributed algorithms, CloudBWA achieves up to 2.63 times speedup over SparkBWA. Compared with stand-alone algorithms, CloudBWA with 16 cores achieves up to 11.59 times speedup over BWA-MEM with 1 core. Conclusions GCDSS is a distributed gene clinical decision support system based on cloud computing techniques. In particular, we incorporated a distributed genetic data analysis pipeline framework in the proposed GCDSS system. To boost the data processing of GCDSS, we propose CloudBWA, which is a novel distributed read mapping algorithm to leverage batch processing technique in mapping stage using Apache Spark platform.",2018-11-20,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,,Suppl 5,11,BMC Med Genomics,,PubMed Central,PMID: 30454054 PMCID: PMC6245588,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6245588/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
460,10.1186/s12920-019-0634-0,31856825,PMC6923916,A,Neo4j,Neo4j,"Park, Byungkyu; Lee, Wook; Park, Inhee; Han, Kyungsook",Finding prognostic gene pairs for cancer from patient-specific gene networks,2019,BMC Medical Genomics,,"Background Molecular characterization of individual cancer patients is important because cancer is a complex and heterogeneous disease with many possible genetic and environmental causes. Many studies have been conducted to identify diagnostic or prognostic gene signatures for cancer from gene expression profiles. However, some gene signatures may fail to serve as diagnostic or prognostic biomarkers and gene signatures may not be found in gene expression profiles. Methods In this study, we developed a general method for constructing patient-specific gene correlation networks and for identifying prognostic gene pairs from the networks. A patient-specific gene correlation network was constructed by comparing a reference gene correlation network from normal samples to a network perturbed by a single patient sample. The main difference of our method from previous ones includes (1) it is focused on finding prognostic gene pairs rather than prognostic genes and (2) it can identify prognostic gene pairs from gene expression profiles even when no significant prognostic genes exist. Results Evaluation of our method with extensive data sets of three cancer types (breast invasive carcinoma, colon adenocarcinoma, and lung adenocarcinoma) showed that our approach is general and that gene pairs can serve as more reliable prognostic signatures for cancer than genes. Conclusions Our study revealed that prognosis of individual cancer patients is associated with the existence of prognostic gene pairs in the patient-specific network and the size of a subnetwork of the prognostic gene pairs in the patient-specific network. Although preliminary, our approach will be useful for finding gene pairs to predict survival time of patients and to tailor treatments to individual characteristics. The program for dynamically constructing patient-specific gene networks and for finding prognostic gene pairs is available at http://bclab.inha.ac.kr/pancancer.",2019-12-20,2021-06-05 20:35:57; 2021-06-05 20:55:01; 2021-06-05 21:10:08,,Suppl 8,12,BMC Med Genomics,,PubMed Central,PMID: 31856825 PMCID: PMC6923916,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6923916/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
461,10.1186/s13002-020-00412-1,33028342,PMC7539384,A,,,"Gilmore, Michael P.; Griffiths, Brian M.; Bowler, Mark",The socio-cultural significance of mineral licks to the Maijuna of the Peruvian Amazon: implications for the sustainable management of hunting,2020,Journal of Ethnobiology and Ethnomedicine,,"BACKGROUND: The overhunting of wild species is a major threat to biodiversity in the Amazon; yet, managed, sustainable hunting is widely considered part of the solution to conserving wildlife populations. Hunting is both a culturally important activity for Indigenous people and provides an important food source. Mineral licks, a focal point of hunting in Amazonia, are naturally occurring areas in the forest where animals come to obtain essential minerals or clays that are thought to neutralize plant-based alkaloids. We sought to better understand the socio-cultural importance of mineral licks to the Maijuna Indigenous group to inform the sustainable management of this habitat and associated wildlife populations. METHODS: Semi-structured interviews, focus groups, and participatory mapping were carried out with hunters to assess the significance of mineral licks and their associated animal resources as well as to determine how the relationship that the Maijuna have with mineral licks has changed over time. RESULTS: Mineral licks are culturally significant and useful to the Maijuna in a variety of ways. Hunters target these areas year-round both during the day and night, and animals killed are consumed for subsistence and sold to generate income. The spatial use of mineral licks across the landscape is determined on the generational family level, with families maintaining exclusive use of selected mineral licks and excluding access by other hunters. The Maijuna also have traditional beliefs for why animals visit mineral licks, which is linked to the traditional Maijuna story of the creation of the first tapir. The relationship that the Maijuna have with mineral licks has changed considerably over time, which is observed through changes in hunting technologies and methods as well as the loss of traditional knowledge and beliefs. CONCLUSIONS: Traditional and current Maijuna hunting conventions, in which families maintain exclusive use of selected mineral licks, likely reduce the probability of overexploitation of animal populations. Community-based management plans for mineral licks in Maijuna lands and beyond must incorporate and account for the multiple cultural and economic needs of local communities while also striving toward ecological sustainability. Country-wide strategies to conserving forests and using them sustainably should aim to ensure land tenure for rural peoples and encourage management that incorporates traditional sustainable hunting conventions.",2020-10-07,2021-06-05 21:24:28; 2021-06-05 21:06:22,59,1,16,J Ethnobiol Ethnomed,The socio-cultural significance of mineral licks to the Maijuna of the Peruvian Amazon,PubMed,PMID: 33028342 PMCID: PMC7539384,http://www.ncbi.nlm.nih.gov/pubmed/33028342,"Adult; Aged; Animals; Animals, Wild; Biodiversity; Conservation; Conservation of Natural Resources; Culture; Ecosystem; Ethnoecology; Forests; Humans; Indigenous Peoples; Knowledge; Mammals; Middle Aged; Minerals; Peru; Traditional ecological knowledge; Wildlife; Young Adult",,,PubMed:Query3; PubMed:Query2
462,10.1186/s13023-017-0597-1,28253932,PMC5335492,A,OrientDB,OrientDB,"Hee, Siew Wan; Willis, Adrian; Tudur Smith, Catrin; Day, Simon; Miller, Frank; Madan, Jason; Posch, Martin; Zohar, Sarah; Stallard, Nigel",Does the low prevalence affect the sample size of interventional clinical trials of rare diseases? An analysis of data from the aggregate analysis of clinicaltrials.gov,2017,Orphanet Journal of Rare Diseases,,"Background Clinical trials are typically designed using the classical frequentist framework to constrain type I and II error rates. Sample sizes required in such designs typically range from hundreds to thousands of patients which can be challenging for rare diseases. It has been shown that rare disease trials have smaller sample sizes than non-rare disease trials. Indeed some orphan drugs were approved by the European Medicines Agency based on studies with as few as 12 patients. However, some studies supporting marketing authorisation included several hundred patients. In this work, we explore the relationship between disease prevalence and other factors and the size of interventional phase 2 and 3 rare disease trials conducted in the US and/or EU. We downloaded all clinical trials from Aggregate Analysis of ClinialTrials.gov (AACT) and identified rare disease trials by cross-referencing MeSH terms in AACT with the list from Orphadata. We examined the effects of prevalence and phase of study in a multiple linear regression model adjusting for other statistically significant trial characteristics. Results Of 186941 ClinicalTrials.gov trials only 1567 (0.8%) studied a single rare condition with prevalence information from Orphadata. There were 19 (1.2%) trials studying disease with prevalence <1/1,000,000, 126 (8.0%) trials with 1–9/1,000,000, 791 (50.5%) trials with 1–9/100,000 and 631 (40.3%) trials with 1–5/10,000. Of the 1567 trials, 1160 (74%) were phase 2 trials. The fitted mean sample size for the rarest disease (prevalence <1/1,000,000) in phase 2 trials was the lowest (mean, 15.7; 95% CI, 8.7–28.1) but were similar across all the other prevalence classes; mean, 26.2 (16.1–42.6), 33.8 (22.1–51.7) and 35.6 (23.3–54.3) for prevalence 1–9/1,000,000, 1–9/100,000 and 1–5/10,000, respectively. Fitted mean size of phase 3 trials of rarer diseases, <1/1,000,000 (19.2, 6.9–53.2) and 1–9/1,000,000 (33.1, 18.6–58.9), were similar to those in phase 2 but were statistically significant lower than the slightly less rare diseases, 1–9/100,000 (75.3, 48.2–117.6) and 1-5/10,000 (77.7, 49.6–121.8), trials. Conclusions We found that prevalence was associated with the size of phase 3 trials with trials of rarer diseases noticeably smaller than the less rare diseases trials where phase 3 rarer disease (prevalence <1/100,000) trials were more similar in size to those for phase 2 but were larger than those for phase 2 in the less rare disease (prevalence ≥1/100,000) trials.",2017-03-02,2021-06-06 06:49:06; 2021-06-05 20:55:40; 2021-06-05 21:12:01,,,12,Orphanet J Rare Dis,Does the low prevalence affect the sample size of interventional clinical trials of rare diseases?,PubMed Central,PMID: 28253932 PMCID: PMC5335492,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5335492/,,OrientDB,OrientDB,PMC:Query3; PMC:Query2; PMC:OrientDB
463,10.1186/s13040-016-0092-6,27069509,PMC4827231,,,,"Moore, Jason H.; Holmes, John H.",The golden era of biomedical informatics has begun,2016,BioData Mining,,"Biomedical informatics has become a central focus for many academic medical centers and universities as biomedical research because increasingly reliant on the processing, analysis, and interpretation of large volumes of data, information, and knowledge. We posit here that this is the beginning of the golden era of biomedical informatics with opportunity for this maturing discipline to have a substantial impact on the biggest questions and challenges facing efforts to improve human health and the healthcare system.",2016-04-11,2021-06-05 21:12:40,,,9,BioData Min,,PubMed Central,PMID: 27069509 PMCID: PMC4827231,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4827231/,,,,PMC:Query2
464,10.1186/s13040-016-0102-8,27462371,PMC4960687,A,Neo4j,Neo4j,"Lysenko, Artem; Roznovăţ, Irina A.; Saqi, Mansoor; Mazein, Alexander; Rawlings, Christopher J; Auffray, Charles; Lysenko, Artem; Roznovăţ, Irina A.; Saqi, Mansoor; Mazein, Alexander; Rawlings, Christopher J.; Auffray, Charles",Representing and querying disease networks using graph databases,2016,BioData Mining,,"BACKGROUND: Systems biology experiments generate large volumes of data of multiple modalities and this information presents a challenge for integration due to a mix of complexity together with rich semantics. Here, we describe how graph databases provide a powerful framework for storage, querying and envisioning of biological data. RESULTS: We show how graph databases are well suited for the representation of biological information, which is typically highly connected, semi-structured and unpredictable. We outline an application case that uses the Neo4j graph database for building and querying a prototype network to provide biological context to asthma related genes. CONCLUSIONS: Our study suggests that graph databases provide a flexible solution for the integration of multiple types of biological data and facilitate exploratory data mining to support hypothesis generation.; Background Systems biology experiments generate large volumes of data of multiple modalities and this information presents a challenge for integration due to a mix of complexity together with rich semantics. Here, we describe how graph databases provide a powerful framework for storage, querying and envisioning of biological data. Results We show how graph databases are well suited for the representation of biological information, which is typically highly connected, semi-structured and unpredictable. We outline an application case that uses the Neo4j graph database for building and querying a prototype network to provide biological context to asthma related genes. Conclusions Our study suggests that graph databases provide a flexible solution for the integration of multiple types of biological data and facilitate exploratory data mining to support hypothesis generation. Electronic supplementary material The online version of this article (doi:10.1186/s13040-016-0102-8) contains supplementary material, which is available to authorized users.",2016-07-25; 2016,2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 20:37:08; 2021-06-05 21:12:01; 2021-06-05 20:55:40; 2021-06-05 21:24:28,23,,9,BioData Min,,PubMed; PubMed Central,PMID: 27462371 PMCID: PMC4960687,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4960687/; http://www.ncbi.nlm.nih.gov/pubmed/27462371,Computational approach; Disease management platform; Graph database; Neo4j graph; Protein-centric framework; Systems medicine,Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
465,10.1186/s13040-016-0105-5,27489569,PMC4971676,A,Neo4j,Neo4j,"Chang, Jennifer; Cho, Hyejin; Chou, Hui-Hsien",Mango: combining and analyzing heterogeneous biological networks,2016,BioData Mining,,"Background Heterogeneous biological data such as sequence matches, gene expression correlations, protein-protein interactions, and biochemical pathways can be merged and analyzed via graphs, or networks. Existing software for network analysis has limited scalability to large data sets or is only accessible to software developers as libraries. In addition, the polymorphic nature of the data sets requires a more standardized method for integration and exploration. Results Mango facilitates large network analyses with its Graph Exploration Language, automatic graph attribute handling, and real-time 3-dimensional visualization. On a personal computer Mango can load, merge, and analyze networks with millions of links and can connect to online databases to fetch and merge biological pathways. Conclusions Mango is written in C++ and runs on Mac OS, Windows, and Linux. The stand-alone distributions, including the Graph Exploration Language integrated development environment, are freely available for download from http://www.complex.iastate.edu/download/Mango. The Mango User Guide listing all features can be found at http://www.gitbook.com/book/j23414/mango-user-guide.",2016-08-02,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:37:08,,,9,BioData Min,Mango,PubMed Central,PMID: 27489569 PMCID: PMC4971676,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4971676/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
466,10.1186/s13040-018-0181-9,30202444,PMC6122726,,,,"Mrzic, Aida; Meysman, Pieter; Bittremieux, Wout; Moris, Pieter; Cule, Boris; Goethals, Bart; Laukens, Kris",Grasping frequent subgraph mining for bioinformatics applications,2018,BioData Mining,,"Searching for interesting common subgraphs in graph data is a well-studied problem in data mining. Subgraph mining techniques focus on the discovery of patterns in graphs that exhibit a specific network structure that is deemed interesting within these data sets. The definition of which subgraphs are interesting and which are not is highly dependent on the application. These techniques have seen numerous applications and are able to tackle a range of biological research questions, spanning from the detection of common substructures in sets of biomolecular compounds, to the discovery of network motifs in large-scale molecular interaction networks. Thus far, information about the bioinformatics application of subgraph mining remains scattered over heterogeneous literature. In this review, we provide an introduction to subgraph mining for life scientists. We give an overview of various subgraph mining algorithms from a bioinformatics perspective and present several of their potential biomedical applications.",2018-09-03,2021-06-05 21:11:16,,,11,BioData Min,,PubMed Central,PMID: 30202444 PMCID: PMC6122726,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6122726/,,,,PMC:Query2
467,10.1186/s13040-021-00250-1,33726790,PMC7962222,,,,"Salem, Saeed; Alokshiya, Mohammed; Hasan, Mohammad Al",RASMA: a reverse search algorithm for mining maximal frequent subgraphs,2021,BioData Mining,,"Background Given a collection of coexpression networks over a set of genes, identifying subnetworks that appear frequently is an important research problem known as mining frequent subgraphs. Maximal frequent subgraphs are a representative set of frequent subgraphs; A frequent subgraph is maximal if it does not have a super-graph that is frequent. In the bioinformatics discipline, methodologies for mining frequent and/or maximal frequent subgraphs can be used to discover interesting network motifs that elucidate complex interactions among genes, reflected through the edges of the frequent subnetworks. Further study of frequent coexpression subnetworks enhances the discovery of biological modules and biological signatures for gene expression and disease classification. Results We propose a reverse search algorithm, called RASMA, for mining frequent and maximal frequent subgraphs in a given collection of graphs. A key innovation in RASMA is a connected subgraph enumerator that uses a reverse-search strategy to enumerate connected subgraphs of an undirected graph. Using this enumeration strategy, RASMA obtains all maximal frequent subgraphs very efficiently. To overcome the computationally prohibitive task of enumerating all frequent subgraphs while mining for the maximal frequent subgraphs, RASMA employs several pruning strategies that substantially improve its overall runtime performance. Experimental results show that on large gene coexpression networks, the proposed algorithm efficiently mines biologically relevant maximal frequent subgraphs. Conclusion Extracting recurrent gene coexpression subnetworks from multiple gene expression experiments enables the discovery of functional modules and subnetwork biomarkers. We have proposed a reverse search algorithm for mining maximal frequent subnetworks. Enrichment analysis of the extracted maximal frequent subnetworks reveals that subnetworks that are frequent are highly enriched with known biological ontologies.",2021-03-16,2021-06-05 21:09:36,,,14,BioData Min,RASMA,PubMed Central,PMID: 33726790 PMCID: PMC7962222,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7962222/,,,,PMC:Query2
468,10.1186/s13059-014-0560-6,25723102,PMC4310165,A,Virtuoso,Virtuoso,"Lizio, Marina; Harshbarger, Jayson; Shimoji, Hisashi; Severin, Jessica; Kasukawa, Takeya; Sahin, Serkan; Abugessaisa, Imad; Fukuda, Shiro; Hori, Fumi; Ishikawa-Kato, Sachi; Mungall, Christopher J; Arner, Erik; Baillie, J Kenneth; Bertin, Nicolas; Bono, Hidemasa; de Hoon, Michiel; Diehl, Alexander D; Dimont, Emmanuel; Freeman, Tom C; Fujieda, Kaori; Hide, Winston; Kaliyaperumal, Rajaram; Katayama, Toshiaki; Lassmann, Timo; Meehan, Terrence F; Nishikata, Koro; Ono, Hiromasa; Rehli, Michael; Sandelin, Albin; Schultes, Erik A; ‘t Hoen, Peter AC; Tatum, Zuotian; Thompson, Mark; Toyoda, Tetsuro; Wright, Derek W; Daub, Carsten O; Itoh, Masayoshi; Carninci, Piero; Hayashizaki, Yoshihide; Forrest, Alistair RR; Kawaji, Hideya",Gateways to the FANTOM5 promoter level mammalian expression atlas,2015,Genome Biology,,"The FANTOM5 project investigates transcription initiation activities in more than 1,000 human and mouse primary cells, cell lines and tissues using CAGE. Based on manual curation of sample information and development of an ontology for sample classification, we assemble the resulting data into a centralized data resource (http://fantom.gsc.riken.jp/5/). This resource contains web-based tools and data-access points for the research community to search and extract data related to samples, genes, promoter activities, transcription factors and enhancers across the FANTOM5 atlas.",2015,2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-05 20:59:14,,1,16,Genome Biol,,PubMed Central,PMID: 25723102 PMCID: PMC4310165,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4310165/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
469,10.1186/s13059-015-0836-5,26679168,PMC4699365,A,Neo4j,Neo4j,"Antal, Bálint; Chessel, Anatole; Carazo Salas, Rafael E.",Mineotaur: a tool for high-content microscopy screen sharing and visual analytics,2015,Genome Biology,,"High-throughput/high-content microscopy-based screens are powerful tools for functional genomics, yielding intracellular information down to the level of single-cells for thousands of genotypic conditions. However, accessing their data requires specialized knowledge and most often that data is no longer analyzed after initial publication. We describe Mineotaur (http://www.mineotaur.org), a open-source, downloadable web application that allows easy online sharing and interactive visualisation of large screen datasets, facilitating their dissemination and further analysis, and enhancing their impact.",2015,2021-06-05 20:55:40; 2021-06-05 21:12:40; 2021-06-05 20:37:08,,,16,Genome Biol,Mineotaur,PubMed Central,PMID: 26679168 PMCID: PMC4699365,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4699365/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
470,10.1186/s13062-019-0249-6,31752974,PMC6868770,A,Neo4j,Neo4j,"Mihaylov, Iliyan; Kańduła, Maciej; Krachunov, Milko; Vassilev, Dimitar",A novel framework for horizontal and vertical data integration in cancer studies with application to survival time prediction models,2019,Biology Direct,,"Background Recently high-throughput technologies have been massively used alongside clinical tests to study various types of cancer. Data generated in such large-scale studies are heterogeneous, of different types and formats. With lack of effective integration strategies novel models are necessary for efficient and operative data integration, where both clinical and molecular information can be effectively joined for storage, access and ease of use. Such models, combined with machine learning methods for accurate prediction of survival time in cancer studies, can yield novel insights into disease development and lead to precise personalized therapies. Results We developed an approach for intelligent data integration of two cancer datasets (breast cancer and neuroblastoma) − provided in the CAMDA 2018 ‘Cancer Data Integration Challenge’, and compared models for prediction of survival time. We developed a novel semantic network-based data integration framework that utilizes NoSQL databases, where we combined clinical and expression profile data, using both raw data records and external knowledge sources. Utilizing the integrated data we introduced Tumor Integrated Clinical Feature (TICF) − a new feature for accurate prediction of patient survival time. Finally, we applied and validated several machine learning models for survival time prediction. Conclusion We developed a framework for semantic integration of clinical and omics data that can borrow information across multiple cancer studies. By linking data with external domain knowledge sources our approach facilitates enrichment of the studied data by discovery of internal relations. The proposed and validated machine learning models for survival time prediction yielded accurate results. Reviewers This article was reviewed by Eran Elhaik, Wenzhong Xiao and Carlos Loucera.",2019-11-21,2021-06-05 20:35:57; 2021-06-05 20:55:01; 2021-06-05 21:10:37,,,14,Biol Direct,,PubMed Central,PMID: 31752974 PMCID: PMC6868770,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6868770/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
471,10.1186/s13072-020-00338-8,32178731,PMC7076959,,,,"Freeman, Dana M.; Lou, Dan; Li, Yanqiang; Martos, Suzanne N.; Wang, Zhibin",The conserved DNMT1-dependent methylation regions in human cells are vulnerable to neurotoxicant rotenone exposure,2020,Epigenetics & Chromatin,,"Background Allele-specific DNA methylation (ASM) describes genomic loci that maintain CpG methylation at only one inherited allele rather than having coordinated methylation across both alleles. The most prominent of these regions are germline ASMs (gASMs) that control the expression of imprinted genes in a parent of origin-dependent manner and are associated with disease. However, our recent report reveals numerous ASMs at non-imprinted genes. These non-germline ASMs are dependent on DNA methyltransferase 1 (DNMT1) and strikingly show the feature of random, switchable monoallelic methylation patterns in the mouse genome. The significance of these ASMs to human health has not been explored. Due to their shared allelicity with gASMs, herein, we propose that non-traditional ASMs are sensitive to exposures in association with human disease. Results We first explore their conservancy in the human genome. Our data show that our putative non-germline ASMs were in conserved regions of the human genome and located adjacent to genes vital for neuronal development and maturation. We next tested the hypothesized vulnerability of these regions by exposing human embryonic kidney cell HEK293 with the neurotoxicant rotenone for 24 h. Indeed,14 genes adjacent to our identified regions were differentially expressed from RNA-sequencing. We analyzed the base-resolution methylation patterns of the predicted non-germline ASMs at two neurological genes, HCN2 and NEFM, with potential to increase the risk of neurodegeneration. Both regions were significantly hypomethylated in response to rotenone. Conclusions Our data indicate that non-germline ASMs seem conserved between mouse and human genomes, overlap important regulatory factor binding motifs, and regulate the expression of genes vital to neuronal function. These results support the notion that ASMs are sensitive to environmental factors such as rotenone and may alter the risk of neurological disease later in life by disrupting neuronal development.",2020-03-16,2021-06-05 21:10:08,,,13,Epigenetics Chromatin,,PubMed Central,PMID: 32178731 PMCID: PMC7076959,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7076959/,,,,PMC:Query2
472,10.1186/s13073-020-0713-z,32075696,PMC7029532,,,,"Aarestrup, F. M.; Albeyatti, A.; Armitage, W. J.; Auffray, C.; Augello, L.; Balling, R.; Benhabiles, N.; Bertolini, G.; Bjaalie, J. G.; Black, M.; Blomberg, N.; Bogaert, P.; Bubak, M.; Claerhout, B.; Clarke, L.; De Meulder, B.; D’Errico, G.; Di Meglio, A.; Forgo, N.; Gans-Combe, C.; Gray, A. E.; Gut, I.; Gyllenberg, A.; Hemmrich-Stanisak, G.; Hjorth, L.; Ioannidis, Y.; Jarmalaite, S.; Kel, A.; Kherif, F.; Korbel, J. O.; Larue, C.; Laszlo, M.; Maas, A.; Magalhaes, L.; Manneh-Vangramberen, I.; Morley-Fletcher, E.; Ohmann, C.; Oksvold, P.; Oxtoby, N. P.; Perseil, I.; Pezoulas, V.; Riess, O.; Riper, H.; Roca, J.; Rosenstiel, P.; Sabatier, P.; Sanz, F.; Tayeb, M.; Thomassen, G.; Van Bussel, J.; Van den Bulcke, M.; Van Oyen, H.",Towards a European health research and innovation cloud (HRIC),2020,Genome Medicine,,"The European Union (EU) initiative on the Digital Transformation of Health and Care (Digicare) aims to provide the conditions necessary for building a secure, flexible, and decentralized digital health infrastructure. Creating a European Health Research and Innovation Cloud (HRIC) within this environment should enable data sharing and analysis for health research across the EU, in compliance with data protection legislation while preserving the full trust of the participants. Such a HRIC should learn from and build on existing data infrastructures, integrate best practices, and focus on the concrete needs of the community in terms of technologies, governance, management, regulation, and ethics requirements. Here, we describe the vision and expected benefits of digital data sharing in health research activities and present a roadmap that fosters the opportunities while answering the challenges of implementing a HRIC. For this, we put forward five specific recommendations and action points to ensure that a European HRIC: i) is built on established standards and guidelines, providing cloud technologies through an open and decentralized infrastructure; ii) is developed and certified to the highest standards of interoperability and data security that can be trusted by all stakeholders; iii) is supported by a robust ethical and legal framework that is compliant with the EU General Data Protection Regulation (GDPR); iv) establishes a proper environment for the training of new generations of data and medical scientists; and v) stimulates research and innovation in transnational collaborations through public and private initiatives and partnerships funded by the EU through Horizon 2020 and Horizon Europe.",2020-02-19,2021-06-05 21:10:08,,,12,Genome Med,,PubMed Central,PMID: 32075696 PMCID: PMC7029532,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7029532/,,,,PMC:Query2
473,10.1186/s13321-015-0069-3,26052348,PMC4456712,,,,"Bajusz, Dávid; Rácz, Anita; Héberger, Károly",Why is Tanimoto index an appropriate choice for fingerprint-based similarity calculations?,2015,Journal of Cheminformatics,,"Background Cheminformaticians are equipped with a very rich toolbox when carrying out molecular similarity calculations. A large number of molecular representations exist, and there are several methods (similarity and distance metrics) to quantify the similarity of molecular representations. In this work, eight well-known similarity/distance metrics are compared on a large dataset of molecular fingerprints with sum of ranking differences (SRD) and ANOVA analysis. The effects of molecular size, selection methods and data pretreatment methods on the outcome of the comparison are also assessed. Results A supplier database (https://mcule.com/) was used as the source of compounds for the similarity calculations in this study. A large number of datasets, each consisting of one hundred compounds, were compiled, molecular fingerprints were generated and similarity values between a randomly chosen reference compound and the rest were calculated for each dataset. Similarity metrics were compared based on their ranking of the compounds within one experiment (one dataset) using sum of ranking differences (SRD), while the results of the entire set of experiments were summarized on box and whisker plots. Finally, the effects of various factors (data pretreatment, molecule size, selection method) were evaluated with analysis of variance (ANOVA). Conclusions This study complements previous efforts to examine and rank various metrics for molecular similarity calculations. Here, however, an entirely general approach was taken to neglect any a priori knowledge on the compounds involved, as well as any bias introduced by examining only one or a few specific scenarios. The Tanimoto index, Dice index, Cosine coefficient and Soergel distance were identified to be the best (and in some sense equivalent) metrics for similarity calculations, i.e. these metrics could produce the rankings closest to the composite (average) ranking of the eight metrics. The similarity metrics derived from Euclidean and Manhattan distances are not recommended on their own, although their variability and diversity from other similarity metrics might be advantageous in certain cases (e.g. for data fusion). Conclusions are also drawn regarding the effects of molecule size, selection method and data pretreatment on the ranking behavior of the studied metrics.,                             Graphical Abstract                                A visual summary of the comparison of similarity metrics with sum of ranking differences (SRD).                                                       Electronic supplementary material The online version of this article (doi:10.1186/s13321-015-0069-3) contains supplementary material, which is available to authorized users.",2015-05-20,2021-06-05 21:12:40,,,7,J Cheminform,,PubMed Central,PMID: 26052348 PMCID: PMC4456712,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4456712/,,,,PMC:Query2
474,10.1186/s13321-015-0095-1,26473018,PMC4607025,,,,"Kothiwale, Sandeepkumar; Mendenhall, Jeffrey L.; Meiler, Jens",BCL::Conf: small molecule conformational sampling using a knowledge based rotamer library,2015,Journal of Cheminformatics,,"The interaction of a small molecule with a protein target depends on its ability to adopt a three-dimensional structure that is complementary. Therefore, complete and rapid prediction of the conformational space a small molecule can sample is critical for both structure- and ligand-based drug discovery algorithms such as small molecule docking or three-dimensional quantitative structure–activity relationships. Here we have derived a database of small molecule fragments frequently sampled in experimental structures within the Cambridge Structure Database and the Protein Data Bank. Likely conformations of these fragments are stored as ‘rotamers’ in analogy to amino acid side chain rotamer libraries used for rapid sampling of protein conformational space. Explicit fragments take into account correlations between multiple torsion bonds and effect of substituents on torsional profiles. A conformational ensemble for small molecules can then be generated by recombining fragment rotamers with a Monte Carlo search strategy. BCL::Conf was benchmarked against other conformer generator methods including Confgen, Moe, Omega and RDKit in its ability to recover experimentally determined protein bound conformations of small molecules, diversity of conformational ensembles, and sampling rate. BCL::Conf recovers at least one conformation with a root mean square deviation of 2 Å or better to the experimental structure for 99 % of the small molecules in the Vernalis benchmark dataset. The ‘rotamer’ approach will allow integration of BCL::Conf into respective computational biology programs such as Rosetta.Graphical abstract:Conformation sampling is carried out using explicit fragment conformations derived from crystallographic structure databases. Molecules from the database are decomposed into fragments and most likely conformations/rotamers are used to sample correspondng sub-structure of a molecule of interest.",2015-09-30,2021-06-05 21:12:40,,,7,J Cheminform,BCL,PubMed Central,PMID: 26473018 PMCID: PMC4607025,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4607025/,,,,PMC:Query2
475,10.1186/s13321-016-0144-4,27275187,PMC4893829,A,Virtuoso; GraphDB,Virtuoso; GraphDB,"Galgonek, Jakub; Hurt, Tomáš; Michlíková, Vendula; Onderka, Petr; Schwarz, Jan; Vondrášek, Jiří",Advanced SPARQL querying in small molecule databases,2016,Journal of Cheminformatics,,"Background In recent years, the Resource Description Framework (RDF) and the SPARQL query language have become more widely used in the area of cheminformatics and bioinformatics databases. These technologies allow better interoperability of various data sources and powerful searching facilities. However, we identified several deficiencies that make usage of such RDF databases restrictive or challenging for common users. Results We extended a SPARQL engine to be able to use special procedures inside SPARQL queries. This allows the user to work with data that cannot be simply precomputed and thus cannot be directly stored in the database. We designed an algorithm that checks a query against data ontology to identify possible user errors. This greatly improves query debugging. We also introduced an approach to visualize retrieved data in a user-friendly way, based on templates describing visualizations of resource classes. To integrate all of our approaches, we developed a simple web application. Conclusions Our system was implemented successfully, and we demonstrated its usability on the ChEBI database transformed into RDF form. To demonstrate procedure call functions, we employed compound similarity searching based on OrChem. The application is publicly available at https://bioinfo.uochb.cas.cz/projects/chemRDF. Graphical Abstract",2016-06-06,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:59:14; 2021-06-06 06:54:16,,,8,J Cheminform,,PubMed Central,PMID: 27275187 PMCID: PMC4893829,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4893829/,,Virtuoso; GraphDB,Virtuoso; GraphDB,PMC:Query3; PMC:GraphDB; PMC:Query2; PMC:Virtuoso
476,10.1186/s13321-016-0168-9,27795738,PMC5064921,,,,"Chalk, Stuart J.",SciData: a data model and ontology for semantic representation of scientific data,2016,Journal of Cheminformatics,,"With the move toward global, Internet enabled science there is an inherent need to capture, store, aggregate and search scientific data across a large corpus of heterogeneous data silos. As a result, standards development is needed to create an infrastructure capable of representing the diverse nature of scientific data. This paper describes a fundamental data model for scientific data that can be applied to data currently stored in any format, and an associated ontology that affords semantic representation of the structure of scientific data (and its metadata), upon which discipline specific semantics can be applied. Application of this data model to experimental and computational chemistry data are presented, implemented using JavaScript Object Notation for Linked Data. Full examples are available at the project website (Chalk in SciData: a scientific data model. http://stuchalk.github.io/scidata/, ).",2016-10-14,2021-06-05 21:12:01,,,8,J Cheminform,SciData,PubMed Central,PMID: 27795738 PMCID: PMC5064921,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5064921/,,,,PMC:Query2
477,10.1186/s13321-017-0242-y,29138947,PMC5686034,,,,"Merkys, Andrius; Mounet, Nicolas; Cepellotti, Andrea; Marzari, Nicola; Gražulis, Saulius; Pizzi, Giovanni",A posteriori metadata from automated provenance tracking: integration of AiiDA and TCOD,2017,Journal of Cheminformatics,,"In order to make results of computational scientific research findable, accessible, interoperable and re-usable, it is necessary to decorate them with standardised metadata. However, there are a number of technical and practical challenges that make this process difficult to achieve in practice. Here the implementation of a protocol is presented to tag crystal structures with their computed properties, without the need of human intervention to curate the data. This protocol leverages the capabilities of AiiDA, an open-source platform to manage and automate scientific computational workflows, and the TCOD, an open-access database storing computed materials properties using a well-defined and exhaustive ontology. Based on these, the complete procedure to deposit computed data in the TCOD database is automated. All relevant metadata are extracted from the full provenance information that AiiDA tracks and stores automatically while managing the calculations. Such a protocol also enables reproducibility of scientific data in the field of computational materials science. As a proof of concept, the AiiDA–TCOD interface is used to deposit 170 theoretical structures together with their computed properties and their full provenance graphs, consisting in over 4600 AiiDA nodes.",2017-11-14,2021-06-05 21:11:16,,,9,J Cheminform,A posteriori metadata from automated provenance tracking,PubMed Central,PMID: 29138947 PMCID: PMC5686034,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5686034/,,,,PMC:Query2
478,10.1186/s13321-019-0367-2,31254167,PMC6599361,A,Virtuoso,Virtuoso,"Kratochvíl, Miroslav; Vondrášek, Jiří; Galgonek, Jakub",Interoperable chemical structure search service,2019,Journal of Cheminformatics,,"Motivation The existing connections between large databases of chemicals, proteins, metabolites and assays offer valuable resources for research in fields ranging from drug design to metabolomics. Transparent search across multiple databases provides a way to efficiently utilize these resources. To simplify such searches, many databases have adopted semantic technologies that allow interoperable querying of the datasets using SPARQL query language. However, the interoperable interfaces of the chemical databases still lack the functionality of structure-driven chemical search, which is a fundamental method of data discovery in the chemical search space. Results We present a SPARQL service that augments existing semantic services by making interoperable substructure and similarity searches in small-molecule databases possible. The service thus offers new possibilities for querying interoperable databases, and simplifies writing of heterogeneous queries that include chemical-structure search terms. Availability The service is freely available and accessible using a standard SPARQL endpoint interface. The service documentation and user-oriented demonstration interfaces that allow quick explorative querying of datasets are available at https://idsm.elixir-czech.cz.",2019-06-28,2021-06-05 20:55:01; 2021-06-05 20:59:14; 2021-06-05 21:10:37,,,11,J Cheminform,,PubMed Central,PMID: 31254167 PMCID: PMC6599361,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6599361/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
479,10.1186/s13321-020-00476-x,33292568,PMC7713369,,,,"Delannée, Victorien; Nicklaus, Marc C.","ReactionCode: format for reaction searching, analysis, classification, transform, and encoding/decoding",2020,Journal of Cheminformatics,,"In the past two decades a lot of different formats for molecules and reactions have been created. These formats were mostly developed for the purposes of identifiers, representation, classification, analysis and data exchange. A lot of efforts have been made on molecule formats but only few for reactions where the endeavors have been made mostly by companies leading to proprietary formats. Here, we present ReactionCode: a new open-source format that allows one to encode and decode a reaction into multi-layer machine readable code, which aggregates reactants and products into a condensed graph of reaction (CGR). This format is flexible and can be used in a context of reaction similarity searching and classification. It is also designed for database organization, machine learning applications and as a new transform reaction language.",2020-12-03,2021-06-05 21:09:36,,,12,J Cheminform,ReactionCode,PubMed Central,PMID: 33292568 PMCID: PMC7713369,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7713369/,,,,PMC:Query2
480,10.1186/s13321-020-0409-9,33430980,PMC6974502,A,Neo4j,Neo4j,"Zahoránszky-Kőhalmi, Gergely; Sheils, Timothy; Oprea, Tudor I.",SmartGraph: a network pharmacology investigation platform,2020,Journal of Cheminformatics,,"MOTIVATION: Drug discovery investigations need to incorporate network pharmacology concepts while navigating the complex landscape of drug-target and target-target interactions. This task requires solutions that integrate high-quality biomedical data, combined with analytic and predictive workflows as well as efficient visualization. SmartGraph is an innovative platform that utilizes state-of-the-art technologies such as a Neo4j graph-database, Angular web framework, RxJS asynchronous event library and D3 visualization to accomplish these goals. RESULTS: The SmartGraph framework integrates high quality bioactivity data and biological pathway information resulting in a knowledgebase comprised of 420,526 unique compound-target interactions defined between 271,098 unique compounds and 2018 targets. SmartGraph then performs bioactivity predictions based on the 63,783 Bemis-Murcko scaffolds extracted from these compounds. Through several use-cases, we illustrate the use of SmartGraph to generate hypotheses for elucidating mechanism-of-action, drug-repurposing and off-target prediction. AVAILABILITY: https://smartgraph.ncats.io/.; Motivation Drug discovery investigations need to incorporate network pharmacology concepts while navigating the complex landscape of drug-target and target-target interactions. This task requires solutions that integrate high-quality biomedical data, combined with analytic and predictive workflows as well as efficient visualization. SmartGraph is an innovative platform that utilizes state-of-the-art technologies such as a Neo4j graph-database, Angular web framework, RxJS asynchronous event library and D3 visualization to accomplish these goals. Results The SmartGraph framework integrates high quality bioactivity data and biological pathway information resulting in a knowledgebase comprised of 420,526 unique compound-target interactions defined between 271,098 unique compounds and 2018 targets. SmartGraph then performs bioactivity predictions based on the 63,783 Bemis-Murcko scaffolds extracted from these compounds. Through several use-cases, we illustrate the use of SmartGraph to generate hypotheses for elucidating mechanism-of-action, drug-repurposing and off-target prediction. Availability https://smartgraph.ncats.io/.",2020-01-21,2021-06-05 20:35:57; 2021-06-05 21:10:08; 2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 20:55:01; 2021-06-05 21:24:28,5,1,12,J Cheminform,SmartGraph,PubMed; PubMed Central,PMID: 33430980 PMCID: PMC6974502,http://www.ncbi.nlm.nih.gov/pubmed/33430980; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6974502/,Bioactivity prediction; neo4j; Network perturbation; Network pharmacology; Network visualization; Pathway analysis; Potent chemical pattern; Protein–protein interactions (PPIs); Scaffold; Target deconvolution,Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
481,10.1186/s13326-015-0014-4,25904997,PMC4405863,,,,"Alm, Rebekka; Waltemath, Dagmar; Wolfien, Markus; Wolkenhauer, Olaf; Henkel, Ron",Annotation-based feature extraction from sets of SBML models,2015,Journal of Biomedical Semantics,,"Background Model repositories such as BioModels Database provide computational models of biological systems for the scientific community. These models contain rich semantic annotations that link model entities to concepts in well-established bio-ontologies such as Gene Ontology. Consequently, thematically similar models are likely to share similar annotations. Based on this assumption, we argue that semantic annotations are a suitable tool to characterize sets of models. These characteristics improve model classification, allow to identify additional features for model retrieval tasks, and enable the comparison of sets of models. Results In this paper we discuss four methods for annotation-based feature extraction from model sets. We tested all methods on sets of models in SBML format which were composed from BioModels Database. To characterize each of these sets, we analyzed and extracted concepts from three frequently used ontologies, namely Gene Ontology, ChEBI and SBO. We find that three out of the methods are suitable to determine characteristic features for arbitrary sets of models: The selected features vary depending on the underlying model set, and they are also specific to the chosen model set. We show that the identified features map on concepts that are higher up in the hierarchy of the ontologies than the concepts used for model annotations. Our analysis also reveals that the information content of concepts in ontologies and their usage for model annotation do not correlate. Conclusions Annotation-based feature extraction enables the comparison of model sets, as opposed to existing methods for model-to-keyword comparison, or model-to-model comparison. Electronic supplementary material The online version of this article (doi:10.1186/s13326-015-0014-4) contains supplementary material, which is available to authorized users.",2015-04-15,2021-06-05 21:12:40,,,6,J Biomed Semantics,,PubMed Central,PMID: 25904997 PMCID: PMC4405863,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4405863/,,,,PMC:Query2
482,10.1186/s13326-015-0021-5,26150906,PMC4492092,,,,"Weissenborn, Dirk; Schroeder, Michael; Tsatsaronis, George",Discovering relations between indirectly connected biomedical concepts,2015,Journal of Biomedical Semantics,,"Background The complexity and scale of the knowledge in the biomedical domain has motivated research work towards mining heterogeneous data from both structured and unstructured knowledge bases. Towards this direction, it is necessary to combine facts in order to formulate hypotheses or draw conclusions about the domain concepts. This work addresses this problem by using indirect knowledge connecting two concepts in a knowledge graph to discover hidden relations between them. The graph represents concepts as vertices and relations as edges, stemming from structured (ontologies) and unstructured (textual) data. In this graph, path patterns, i.e. sequences of relations, are mined using distant supervision that potentially characterize a biomedical relation. Results It is possible to identify characteristic path patterns of biomedical relations from this representation using machine learning. For experimental evaluation two frequent biomedical relations, namely “has target”, and “may treat”, are chosen. Results suggest that relation discovery using indirect knowledge is possible, with an AUC that can reach up to 0.8, a result which is a great improvement compared to the random classification, and which shows that good predictions can be prioritized by following the suggested approach. Conclusions Analysis of the results indicates that the models can successfully learn expressive path patterns for the examined relations. Furthermore, this work demonstrates that the constructed graph allows for the easy integration of heterogeneous information and discovery of indirect connections between biomedical concepts. Electronic supplementary material The online version of this article (doi:10.1186/s13326-015-0021-5) contains supplementary material, which is available to authorized users.",2015-07-06,2021-06-05 21:12:40,,,6,J Biomed Semantics,,PubMed Central,PMID: 26150906 PMCID: PMC4492092,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4492092/,,,,PMC:Query2
483,10.1186/s13326-015-0029-x,26185615,PMC4504081,A,Virtuoso; AllegroGraph,Virtuoso; AllegroGraph,"Asiaee, Amir H.; Minning, Todd; Doshi, Prashant; Tarleton, Rick L.",A framework for ontology-based question answering with application to parasite immunology,2015,Journal of Biomedical Semantics,,"Background Large quantities of biomedical data are being produced at a rapid pace for a variety of organisms. With ontologies proliferating, data is increasingly being stored using the RDF data model and queried using RDF based querying languages. While existing systems facilitate the querying in various ways, the scientist must map the question in his or her mind to the interface used by the systems. The field of natural language processing has long investigated the challenges of designing natural language based retrieval systems. Recent efforts seek to bring the ability to pose natural language questions to RDF data querying systems while leveraging the associated ontologies. These analyze the input question and extract triples (subject, relationship, object), if possible, mapping them to RDF triples in the data. However, in the biomedical context, relationships between entities are not always explicit in the question and these are often complex involving many intermediate concepts. Results We present a new framework, OntoNLQA, for querying RDF data annotated using ontologies which allows posing questions in natural language. OntoNLQA offers five steps in order to answer natural language questions. In comparison to previous systems, OntoNLQA differs in how some of the methods are realized. In particular, it introduces a novel approach for discovering the sophisticated semantic associations that may exist between the key terms of a natural language question, in order to build an intuitive query and retrieve precise answers. We apply this framework to the context of parasite immunology data, leading to a system called AskCuebee that allows parasitologists to pose genomic, proteomic and pathway questions in natural language related to the parasite, Trypanosoma cruzi. We separately evaluate the accuracy of each component of OntoNLQA as implemented in AskCuebee and the accuracy of the whole system. AskCuebee answers 68 % of the questions in a corpus of 125 questions, and 60 % of the questions in a new previously unseen corpus. If we allow simple corrections by the scientists, this proportion increases to 92 %. Conclusions We introduce a novel framework for question answering and apply it to parasite immunology data. Evaluations of translating the questions to RDF triple queries by combining machine learning, lexical similarity matching with ontology classes, properties and instances for specificity, and discovering associations between them demonstrate that the approach performs well and improves on previous systems. Subsequently, OntoNLQA offers a viable framework for building question answering systems in other biomedical domains. Electronic supplementary material The online version of this article (doi:10.1186/s13326-015-0029-x) contains supplementary material, which is available to authorized users.",2015-07-17,2021-06-06 06:38:41; 2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-05 20:59:14,,,6,J Biomed Semantics,,PubMed Central,PMID: 26185615 PMCID: PMC4504081,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4504081/,,Virtuoso; AllegroGraph,Virtuoso; AllegroGraph,PMC:Query3; PMC:AllegroGraph; PMC:Query2; PMC:Virtuoso
484,10.1186/s13326-016-0068-y,27148435,PMC4855778,A,Stardog,Stardog,"Brochhausen, Mathias; Zheng, Jie; Birtwell, David; Williams, Heather; Masci, Anna Maria; Ellis, Helena Judge; Stoeckert, Christian J.",OBIB-a novel ontology for biobanking,2016,Journal of Biomedical Semantics,,Background Biobanking necessitates extensive integration of data to allow data analysis and specimen sharing. Ontologies have been demonstrated to be a promising approach in fostering better semantic integration of biobank-related data. Hitherto no ontology provided the coverage needed to capture a broad spectrum of biobank user scenarios. Methods Based in the principles laid out by the Open Biological and Biomedical Ontologies Foundry two biobanking ontologies have been developed. These two ontologies were merged using a modular approach consistent with the initial development principles. The merging was facilitated by the fact that both ontologies use the same Upper Ontology and re-use classes from a similar set of pre-existing ontologies. Results Based on the two previous ontologies the Ontology for Biobanking (http://purl.obolibrary.org/obo/obib.owl) was created. Due to the fact that there was no overlap between the two source ontologies the coverage of the resulting ontology is significantly larger than of the two source ontologies. The ontology is successfully used in managing biobank information of the Penn Medicine BioBank. Conclusions Sharing development principles and Upper Ontologies facilitates subsequent merging of ontologies to achieve a broader coverage.,2016-05-02,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-06 07:15:03,,,7,J Biomed Semantics,,PubMed Central,PMID: 27148435 PMCID: PMC4855778,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4855778/,,Stardog,Stardog,PMC:Query3; PMC:Query2; PMC:Stardog
485,10.1186/s13326-016-0091-z,27751176,PMC5067895,A,Neo4j,Neo4j,"Duque-Ramos, Astrid; Quesada-Martínez, Manuel; Iniesta-Moreno, Miguela; Fernández-Breis, Jesualdo Tomás; Stevens, Robert",Supporting the analysis of ontology evolution processes through the combination of static and dynamic scaling functions in OQuaRE,2016,Journal of Biomedical Semantics,,"Background The biomedical community has now developed a significant number of ontologies. The curation of biomedical ontologies is a complex task and biomedical ontologies evolve rapidly, so new versions are regularly and frequently published in ontology repositories. This has the implication of there being a high number of ontology versions over a short time span. Given this level of activity, ontology designers need to be supported in the effective management of the evolution of biomedical ontologies as the different changes may affect the engineering and quality of the ontology. This is why there is a need for methods that contribute to the analysis of the effects of changes and evolution of ontologies. Results In this paper we approach this issue from the ontology quality perspective. In previous work we have developed an ontology evaluation framework based on quantitative metrics, called OQuaRE. Here, OQuaRE is used as a core component in a method that enables the analysis of the different versions of biomedical ontologies using the quality dimensions included in OQuaRE. Moreover, we describe and use two scales for evaluating the changes between the versions of a given ontology. The first one is the static scale used in OQuaRE and the second one is a new, dynamic scale, based on the observed values of the quality metrics of a corpus defined by all the versions of a given ontology (life-cycle). In this work we explain how OQuaRE can be adapted for understanding the evolution of ontologies. Its use has been illustrated with the ontology of bioinformatics operations, types of data, formats, and topics (EDAM). Conclusions The two scales included in OQuaRE provide complementary information about the evolution of the ontologies. The application of the static scale, which is the original OQuaRE scale, to the versions of the EDAM ontology reveals a design based on good ontological engineering principles. The application of the dynamic scale has enabled a more detailed analysis of the evolution of the ontology, measured through differences between versions. The statistics of change based on the OQuaRE quality scores make possible to identify key versions where some changes in the engineering of the ontology triggered a change from the OQuaRE quality perspective. In the case of the EDAM, this study let us to identify that the fifth version of the ontology has the largest impact in the quality metrics of the ontology, when comparative analyses between the pairs of consecutive versions are performed.",2016-10-17,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:37:08,,,7,J Biomed Semantics,,PubMed Central,PMID: 27751176 PMCID: PMC5067895,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5067895/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
486,10.1186/s13326-017-0125-1,28427468,PMC5399403,,,,"Dalleau, Kevin; Marzougui, Yassine; Da Silva, Sébastien; Ringot, Patrice; Ndiaye, Ndeye Coumba; Coulet, Adrien",Learning from biomedical linked data to suggest valid pharmacogenes,2017,Journal of Biomedical Semantics,,"Background A standard task in pharmacogenomics research is identifying genes that may be involved in drug response variability, i.e., pharmacogenes. Because genomic experiments tended to generate many false positives, computational approaches based on the use of background knowledge have been proposed. Until now, only molecular networks or the biomedical literature were used, whereas many other resources are available. Method We propose here to consume a diverse and larger set of resources using linked data related either to genes, drugs or diseases. One of the advantages of linked data is that they are built on a standard framework that facilitates the joint use of various sources, and thus facilitates considering features of various origins. We propose a selection and linkage of data sources relevant to pharmacogenomics, including for example DisGeNET and Clinvar. We use machine learning to identify and prioritize pharmacogenes that are the most probably valid, considering the selected linked data. This identification relies on the classification of gene–drug pairs as either pharmacogenomically associated or not and was experimented with two machine learning methods –random forest and graph kernel–, which results are compared in this article. Results We assembled a set of linked data relative to pharmacogenomics, of 2,610,793 triples, coming from six distinct resources. Learning from these data, random forest enables identifying valid pharmacogenes with a F-measure of 0.73, on a 10 folds cross-validation, whereas graph kernel achieves a F-measure of 0.81. A list of top candidates proposed by both approaches is provided and their obtention is discussed. Electronic supplementary material The online version of this article (doi:10.1186/s13326-017-0125-1) contains supplementary material, which is available to authorized users.",2017-04-20,2021-06-05 21:12:01,,,8,J Biomed Semantics,,PubMed Central,PMID: 28427468 PMCID: PMC5399403,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5399403/,,,,PMC:Query2
487,10.1186/s13326-017-0133-1,28764813,PMC5540339,A,Stardog,Stardog,"Gonçalves, Rafael S.; Tu, Samson W.; Nyulas, Csongor I.; Tierney, Michael J.; Musen, Mark A.",An ontology-driven tool for structured data acquisition using Web forms,2017,Journal of Biomedical Semantics,,"Background Structured data acquisition is a common task that is widely performed in biomedicine. However, current solutions for this task are far from providing a means to structure data in such a way that it can be automatically employed in decision making (e.g., in our example application domain of clinical functional assessment, for determining eligibility for disability benefits) based on conclusions derived from acquired data (e.g., assessment of impaired motor function). To use data in these settings, we need it structured in a way that can be exploited by automated reasoning systems, for instance, in the Web Ontology Language (OWL); the de facto ontology language for the Web. Results We tackle the problem of generating Web-based assessment forms from OWL ontologies, and aggregating input gathered through these forms as an ontology of “semantically-enriched” form data that can be queried using an RDF query language, such as SPARQL. We developed an ontology-based structured data acquisition system, which we present through its specific application to the clinical functional assessment domain. We found that data gathered through our system is highly amenable to automatic analysis using queries. Conclusions We demonstrated how ontologies can be used to help structuring Web-based forms and to semantically enrich the data elements of the acquired structured data. The ontologies associated with the enriched data elements enable automated inferences and provide a rich vocabulary for performing queries.",2017-08-01,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-06 07:15:03,,,8,J Biomed Semantics,,PubMed Central,PMID: 28764813 PMCID: PMC5540339,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5540339/,,Stardog,Stardog,PMC:Query3; PMC:Query2; PMC:Stardog
488,10.1186/s13326-017-0154-9,28962670,PMC5622544,A,Virtuoso,Virtuoso,"Esteban-Gil, Angel; Fernández-Breis, Jesualdo Tomás; Boeker, Martin",Analysis and visualization of disease courses in a semantically-enabled cancer registry,2017,Journal of Biomedical Semantics,,"Background Regional and epidemiological cancer registries are important for cancer research and the quality management of cancer treatment. Many technological solutions are available to collect and analyse data for cancer registries nowadays. However, the lack of a well-defined common semantic model is a problem when user-defined analyses and data linking to external resources are required. The objectives of this study are: (1) design of a semantic model for local cancer registries; (2) development of a semantically-enabled cancer registry based on this model; and (3) semantic exploitation of the cancer registry for analysing and visualising disease courses. Results Our proposal is based on our previous results and experience working with semantic technologies. Data stored in a cancer registry database were transformed into RDF employing a process driven by OWL ontologies. The semantic representation of the data was then processed to extract semantic patient profiles, which were exploited by means of SPARQL queries to identify groups of similar patients and to analyse the disease timelines of patients., Based on the requirements analysis, we have produced a draft of an ontology that models the semantics of a local cancer registry in a pragmatic extensible way. We have implemented a Semantic Web platform that allows transforming and storing data from cancer registries in RDF. This platform also permits users to formulate incremental user-defined queries through a graphical user interface. The query results can be displayed in several customisable ways. The complex disease timelines of individual patients can be clearly represented. Different events, e.g. different therapies and disease courses, are presented according to their temporal and causal relations. Conclusion The presented platform is an example of the parallel development of ontologies and applications that take advantage of semantic web technologies in the medical field. The semantic structure of the representation renders it easy to analyse key figures of the patients and their evolution at different granularity levels.",2017-09-29,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:59:14,,,8,J Biomed Semantics,,PubMed Central,PMID: 28962670 PMCID: PMC5622544,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5622544/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
489,10.1186/s13326-017-0161-x,29122012,PMC5679337,A,Neo4j,Neo4j,"Lin, Yu; Mehta, Saurabh; Küçük-McGinty, Hande; Turner, John Paul; Vidovic, Dusica; Forlin, Michele; Koleti, Amar; Nguyen, Dac-Trung; Jensen, Lars Juhl; Guha, Rajarshi; Mathias, Stephen L.; Ursu, Oleg; Stathias, Vasileios; Duan, Jianbin; Nabizadeh, Nooshin; Chung, Caty; Mader, Christopher; Visser, Ubbo; Yang, Jeremy J.; Bologa, Cristian G.; Oprea, Tudor I.; Schürer, Stephan C.",Drug target ontology to classify and integrate drug discovery data,2017,Journal of Biomedical Semantics,,"Background One of the most successful approaches to develop new small molecule therapeutics has been to start from a validated druggable protein target. However, only a small subset of potentially druggable targets has attracted significant research and development resources. The Illuminating the Druggable Genome (IDG) project develops resources to catalyze the development of likely targetable, yet currently understudied prospective drug targets. A central component of the IDG program is a comprehensive knowledge resource of the druggable genome. Results As part of that effort, we have developed a framework to integrate, navigate, and analyze drug discovery data based on formalized and standardized classifications and annotations of druggable protein targets, the Drug Target Ontology (DTO). DTO was constructed by extensive curation and consolidation of various resources. DTO classifies the four major drug target protein families, GPCRs, kinases, ion channels and nuclear receptors, based on phylogenecity, function, target development level, disease association, tissue expression, chemical ligand and substrate characteristics, and target-family specific characteristics. The formal ontology was built using a new software tool to auto-generate most axioms from a database while supporting manual knowledge acquisition. A modular, hierarchical implementation facilitate ontology development and maintenance and makes use of various external ontologies, thus integrating the DTO into the ecosystem of biomedical ontologies. As a formal OWL-DL ontology, DTO contains asserted and inferred axioms. Modeling data from the Library of Integrated Network-based Cellular Signatures (LINCS) program illustrates the potential of DTO for contextual data integration and nuanced definition of important drug target characteristics. DTO has been implemented in the IDG user interface Portal, Pharos and the TIN-X explorer of protein target disease relationships. Conclusions DTO was built based on the need for a formal semantic model for druggable targets including various related information such as protein, gene, protein domain, protein structure, binding site, small molecule drug, mechanism of action, protein tissue localization, disease association, and many other types of information. DTO will further facilitate the otherwise challenging integration and formal linking to biological assays, phenotypes, disease models, drug poly-pharmacology, binding kinetics and many other processes, functions and qualities that are at the core of drug discovery. The first version of DTO is publically available via the website http://drugtargetontology.org/, Github (http://github.com/DrugTargetOntology/DTO), and the NCBO Bioportal (http://bioportal.bioontology.org/ontologies/DTO). The long-term goal of DTO is to provide such an integrative framework and to populate the ontology with this information as a community resource. Electronic supplementary material The online version of this article (10.1186/s13326-017-0161-x) contains supplementary material, which is available to authorized users.",2017-11-09,2021-06-05 20:55:40; 2021-06-05 21:11:16; 2021-06-05 20:36:32,,,8,J Biomed Semantics,,PubMed Central,PMID: 29122012 PMCID: PMC5679337,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5679337/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
490,10.1186/s13326-020-00222-0,32819435,PMC7439527,A,GraphDB,GraphDB,"Duncan, William D.; Thyvalikakath, Thankam; Haendel, Melissa; Torniai, Carlo; Hernandez, Pedro; Song, Mei; Acharya, Amit; Caplan, Daniel J.; Schleyer, Titus; Ruttenberg, Alan","Structuring, reuse and analysis of electronic dental data using the Oral Health and Disease Ontology",2020,Journal of Biomedical Semantics,,"Background A key challenge for improving the quality of health care is to be able to use a common framework to work with patient information acquired in any of the health and life science disciplines. Patient information collected during dental care exposes many of the challenges that confront a wider scale approach. For example, to improve the quality of dental care, we must be able to collect and analyze data about dental procedures from multiple practices. However, a number of challenges make doing so difficult. First, dental electronic health record (EHR) information is often stored in complex relational databases that are poorly documented. Second, there is not a commonly accepted and implemented database schema for dental EHR systems. Third, integrative work that attempts to bridge dentistry and other settings in healthcare is made difficult by the disconnect between representations of medical information within dental and other disciplines’ EHR systems. As dentistry increasingly concerns itself with the general health of a patient, for example in increased efforts to monitor heart health and systemic disease, the impact of this disconnect becomes more and more severe., To demonstrate how to address these problems, we have developed the open-source Oral Health and Disease Ontology (OHD) and our instance-based representation as a framework for dental and medical health care information. We envision a time when medical record systems use a common data back end that would make interoperating trivial and obviate the need for a dedicated messaging framework to move data between systems., The OHD is not yet complete. It includes enough to be useful and to demonstrate how it is constructed. We demonstrate its utility in an analysis of longevity of dental restorations. Our first narrow use case provides a prototype, and is intended demonstrate a prospective design for a principled data backend that can be used consistently and encompass both dental and medical information in a single framework. Results The OHD contains over 1900 classes and 59 relationships. Most of the classes and relationships were imported from existing OBO Foundry ontologies. Using the LSW2 (LISP Semantic Web) software library, we translated data from a dental practice’s EHR system into a corresponding Web Ontology Language (OWL) representation based on the OHD framework. The OWL representation was then loaded into a triple store, and as a proof of concept, we addressed a question of clinical relevance – a survival analysis of the longevity of resin filling restorations. We provide queries using SPARQL and statistical analysis code in R to demonstrate how to perform clinical research using a framework such as the OHD, and we compare our results with previous studies. Conclusions This proof-of-concept project translated data from a single practice. By using dental practice data, we demonstrate that the OHD and the instance-based approach are sufficient to represent data generated in real-world, routine clinical settings. While the OHD is applicable to integration of data from multiple practices with different dental EHR systems, we intend our work to be understood as a prospective design for EHR data storage that would simplify medical informatics. The system has well-understood semantics because of our use of BFO-based realist ontology and its representation in OWL. The data model is a well-defined web standard.",2020-08-20,2021-06-06 06:54:16; 2021-06-05 20:54:31; 2021-06-05 21:10:08,,,11,J Biomed Semantics,,PubMed Central,PMID: 32819435 PMCID: PMC7439527,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7439527/,,GraphDB,GraphDB,PMC:Query3; PMC:GraphDB; PMC:Query2
491,10.1186/s13326-020-00232-y,33183351,PMC7663894,A,Neo4j,Neo4j,"Zhu, Qian; Nguyen, Dac-Trung; Grishagin, Ivan; Southall, Noel; Sid, Eric; Pariser, Anne","An integrative knowledge graph for rare diseases, derived from the Genetic and Rare Diseases Information Center (GARD)",2020,Journal of Biomedical Semantics,,"BACKGROUND: The Genetic and Rare Diseases (GARD) Information Center was established by the National Institutes of Health (NIH) to provide freely accessible consumer health information on over 6500 genetic and rare diseases. As the cumulative scientific understanding and underlying evidence for these diseases have expanded over time, existing practices to generate knowledge from these publications and resources have not been able to keep pace. Through determining the applicability of computational approaches to enhance or replace manual curation tasks, we aim to both improve the sustainability and relevance of consumer health information, but also to develop a foundational database, from which translational science researchers may start to unravel disease characteristics that are vital to the research process. RESULTS: We developed a meta-ontology based integrative knowledge graph for rare diseases in Neo4j. This integrative knowledge graph includes a total of 3,819,623 nodes and 84,223,681 relations from 34 different biomedical data resources, including curated drug and rare disease associations. Semi-automatic mappings were generated for 2154 unique FDA orphan designations to 776 unique GARD diseases, and 3322 unique FDA designated drugs to UNII, as well as 180,363 associations between drug and indication from Inxight Drugs, which were integrated into the knowledge graph. We conducted four case studies to demonstrate the capabilities of this integrative knowledge graph in accelerating the curation of scientific understanding on rare diseases through the generation of disease mappings/profiles and pathogenesis associations. CONCLUSIONS: By integrating well-established database resources, we developed an integrative knowledge graph containing a large volume of biomedical and research data. Demonstration of several immediate use cases and limitations of this process reveal both the potential feasibility and barriers of utilizing graph-based resources and approaches to support their use by providers of consumer health information, such as GARD, that may struggle with the needs of maintaining knowledge reliant on an evolving and growing evidence-base. Finally, the successful integration of these datasets into a freely accessible knowledge graph highlights an opportunity to take a translational science view on the field of rare diseases by enabling researchers to identify disease characteristics, which may play a role in the translation of discover across different research domains.; Background The Genetic and Rare Diseases (GARD) Information Center was established by the National Institutes of Health (NIH) to provide freely accessible consumer health information on over 6500 genetic and rare diseases. As the cumulative scientific understanding and underlying evidence for these diseases have expanded over time, existing practices to generate knowledge from these publications and resources have not been able to keep pace. Through determining the applicability of computational approaches to enhance or replace manual curation tasks, we aim to both improve the sustainability and relevance of consumer health information, but also to develop a foundational database, from which translational science researchers may start to unravel disease characteristics that are vital to the research process. Results We developed a meta-ontology based integrative knowledge graph for rare diseases in Neo4j. This integrative knowledge graph includes a total of 3,819,623 nodes and 84,223,681 relations from 34 different biomedical data resources, including curated drug and rare disease associations. Semi-automatic mappings were generated for 2154 unique FDA orphan designations to 776 unique GARD diseases, and 3322 unique FDA designated drugs to UNII, as well as 180,363 associations between drug and indication from Inxight Drugs, which were integrated into the knowledge graph. We conducted four case studies to demonstrate the capabilities of this integrative knowledge graph in accelerating the curation of scientific understanding on rare diseases through the generation of disease mappings/profiles and pathogenesis associations. Conclusions By integrating well-established database resources, we developed an integrative knowledge graph containing a large volume of biomedical and research data. Demonstration of several immediate use cases and limitations of this process reveal both the potential feasibility and barriers of utilizing graph-based resources and approaches to support their use by providers of consumer health information, such as GARD, that may struggle with the needs of maintaining knowledge reliant on an evolving and growing evidence-base. Finally, the successful integration of these datasets into a freely accessible knowledge graph highlights an opportunity to take a translational science view on the field of rare diseases by enabling researchers to identify disease characteristics, which may play a role in the translation of discover across different research domains.",2020-11-12,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36; 2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 21:24:28,13,1,11,J Biomed Semantics,,PubMed; PubMed Central,PMID: 33183351 PMCID: PMC7663894,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7663894/; http://www.ncbi.nlm.nih.gov/pubmed/33183351,Data integration; GARD; Knowledge graph; Ontology; Rare diseases,Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
492,10.1186/s13326-021-00239-z,33761996,PMC7992819,A,GraphDB,GraphDB,"Grigoriu, Andreea; Zaveri, Amrapali; Weiss, Gerhard; Dumontier, Michel",SIENA: Semi-automatic semantic enhancement of datasets using concept recognition,2021,Journal of Biomedical Semantics,,"Background The amount of available data, which can facilitate answering scientific research questions, is growing. However, the different formats of published data are expanding as well, creating a serious challenge when multiple datasets need to be integrated for answering a question. Results This paper presents a semi-automated framework that provides semantic enhancement of biomedical data, specifically gene datasets. The framework involved a concept recognition task using machine learning, in combination with the BioPortal annotator. Compared to using methods which require only the BioPortal annotator for semantic enhancement, the proposed framework achieves the highest results. Conclusions Using concept recognition combined with machine learning techniques and annotation with a biomedical ontology, the proposed framework can provide datasets to reach their full potential of providing meaningful information, which can answer scientific research questions.",2021-03-24,2021-06-06 06:54:16; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,,12,J Biomed Semantics,SIENA,PubMed Central,PMID: 33761996 PMCID: PMC7992819,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7992819/,,GraphDB,GraphDB,PMC:Query3; PMC:GraphDB; PMC:Query2
493,10.1186/s13742-016-0147-0,,PMC5103253,A,Neo4j,Neo4j,"Craddock, R. Cameron; Bellec, Pierre; Margules, Daniel S.; Nichols, B. Nolan; Pfannmöller, Jörg P.; Badhwar, AmanPreet; Kennedy, David; Poline, Jean-Baptiste; Toro, Roberto; Cipollini, Ben; Rokem, Ariel; Clark, Daniel; Gorgolewski, Krzysztof J.; Craddock, R. Cameron; Craddock, R. Cameron; Clark, Daniel J.; Das, Samir; Madjar, Cécile; Sengupta, Ayan; Mohades, Zia; Dery, Sebastien; Deng, Weiran; Earl, Eric; Demeter, Damion V.; Mills, Kate; Mihai, Glad; Ruzic, Luka; Ketz, Nick; Reineberg, Andrew; Reddan, Marianne C.; Goddings, Anne-Lise; Gonzalez-Castillo, Javier; Gorgolewski, Krzysztof J.; Froehlich, Caroline; Dekel, Gil; Margulies, Daniel S.; Craddock, R. Cameron; Fulcher, Ben D.; Glatard, Tristan; Das, Samir; Adalat, Reza; Beck, Natacha; Bernard, Rémi; Khalili-Mahani, Najmeh; Rioux, Pierre; Rousseau, Marc-Étienne; Evans, Alan C.; Halchenko, Yaroslav O.; Castello, Matteo Visconti di Oleggio; Hernández-Pérez, Raúl; Morales, Edgar A.; Cuaya, Laura V.; Ito, Kaori L.; Liew, Sook-Lei; Johnson, Hans J.; Kan, Erik; Anglin, Julia; Borich, Michael; Jahanshad, Neda; Thompson, Paul; Liew, Sook-Lei; Margulies, Daniel S.; Falkiewicz, Marcel; Huntenburg, Julia M.; O’Connor, David; Clark, Daniel J.; Milham, Michael P.; Craddock, R. Cameron; Pereira, Ramon Fraga; Heinsfeld, Anibal Sólon; Franco, Alexandre Rosa; Buchweitz, Augusto; Meneguzzi, Felipe; Pfannmöller, Jörg P.; Mesquita, Rickson; Herrera, Luis C. T.; Dentico, Daniela; Sochat, Vanessa; Nichols, B. Nolan; Heinsfeld, Anibal Sólon; Franco, Alexandre Rosa; Buchweitz, Augusto; Meneguzzi, Felipe; Villalon-Reina, Julio E.; Garyfallidis, Eleftherios",2015 Brainhack Proceedings,2016,GigaScience,,"I1 Introduction to the 2015 Brainhack Proceedings, R. Cameron Craddock, Pierre Bellec, Daniel S. Margules, B. Nolan Nichols, Jörg P. Pfannmöller, A1 Distributed collaboration: the case for the enhancement of Brainspell’s interface, AmanPreet Badhwar, David Kennedy, Jean-Baptiste Poline, Roberto Toro, A2 Advancing open science through NiData, Ben Cipollini, Ariel Rokem, A3 Integrating the Brain Imaging Data Structure (BIDS) standard into C-PAC, Daniel Clark, Krzysztof J. Gorgolewski, R. Cameron Craddock, A4 Optimized implementations of voxel-wise degree centrality and local functional connectivity density mapping in AFNI, R. Cameron Craddock, Daniel J. Clark, A5 LORIS: DICOM anonymizer, Samir Das, Cécile Madjar, Ayan Sengupta, Zia Mohades, A6 Automatic extraction of academic collaborations in neuroimaging, Sebastien Dery, A7 NiftyView: a zero-footprint web application for viewing DICOM and NIfTI files, Weiran Deng, A8 Human Connectome Project Minimal Preprocessing Pipelines to Nipype, Eric Earl, Damion V. Demeter, Kate Mills, Glad Mihai, Luka Ruzic, Nick Ketz, Andrew Reineberg, Marianne C. Reddan, Anne-Lise Goddings, Javier Gonzalez-Castillo, Krzysztof J. Gorgolewski, A9 Generating music with resting-state fMRI data, Caroline Froehlich, Gil Dekel, Daniel S. Margulies, R. Cameron Craddock, A10 Highly comparable time-series analysis in Nitime, Ben D. Fulcher, A11 Nipype interfaces in CBRAIN, Tristan Glatard, Samir Das, Reza Adalat, Natacha Beck, Rémi Bernard, Najmeh Khalili-Mahani, Pierre Rioux, Marc-Étienne Rousseau, Alan C. Evans, A12 DueCredit: automated collection of citations for software, methods, and data, Yaroslav O. Halchenko, Matteo Visconti di Oleggio Castello, A13 Open source low-cost device to register dog’s heart rate and tail movement, Raúl Hernández-Pérez, Edgar A. Morales, Laura V. Cuaya, A14 Calculating the Laterality Index Using FSL for Stroke Neuroimaging Data, Kaori L. Ito, Sook-Lei Liew, A15 Wrapping FreeSurfer 6 for use in high-performance computing environments, Hans J. Johnson, A16 Facilitating big data meta-analyses for clinical neuroimaging through ENIGMA wrapper scripts, Erik Kan, Julia Anglin, Michael Borich, Neda Jahanshad, Paul Thompson, Sook-Lei Liew, A17 A cortical surface-based geodesic distance package for Python, Daniel S Margulies, Marcel Falkiewicz, Julia M Huntenburg, A18 Sharing data in the cloud, David O’Connor, Daniel J. Clark, Michael P. Milham, R. Cameron Craddock, A19 Detecting task-based fMRI compliance using plan abandonment techniques, Ramon Fraga Pereira, Anibal Sólon Heinsfeld, Alexandre Rosa Franco, Augusto Buchweitz, Felipe Meneguzzi, A20 Self-organization and brain function, Jörg P. Pfannmöller, Rickson Mesquita, Luis C.T. Herrera, Daniela Dentico, A21 The Neuroimaging Data Model (NIDM) API, Vanessa Sochat, B Nolan Nichols, A22 NeuroView: a customizable browser-base utility, Anibal Sólon Heinsfeld, Alexandre Rosa Franco, Augusto Buchweitz, Felipe Meneguzzi, A23 DIPY: Brain tissue classification, Julio E. Villalon-Reina, Eleftherios Garyfallidis",2016-11-01,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:37:08,1-26,Suppl 1,5,Gigascience,,PubMed Central,PMID:  PMCID: PMC5103253,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5103253/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
494,10.1186/s40064-016-2251-0,27350905,PMC4899405,A,Neo4j; Giraph,Neo4j; Giraph,"Batarfi, Omar; Elshawi, Radwa; Fayoumi, Ayman; Barnawi, Ahmed; Sakr, Sherif",A distributed query execution engine of big attributed graphs,2016,SpringerPlus,,"A graph is a popular data model that has become pervasively used for modeling structural relationships between objects. In practice, in many real-world graphs, the graph vertices and edges need to be associated with descriptive attributes. Such type of graphs are referred to as attributed graphs. G-SPARQL has been proposed as an expressive language, with a centralized execution engine, for querying attributed graphs. G-SPARQL supports various types of graph querying operations including reachability, pattern matching and shortest path where any G-SPARQL query may include value-based predicates on the descriptive information (attributes) of the graph edges/vertices in addition to the structural predicates. In general, a main limitation of centralized systems is that their vertical scalability is always restricted by the physical limits of computer systems. This article describes the design, implementation in addition to the performance evaluation of DG-SPARQL, a distributed, hybrid and adaptive parallel execution engine of G-SPARQL queries. In this engine, the topology of the graph is distributed over the main memory of the underlying nodes while the graph data are maintained in a relational store which is replicated on the disk of each of the underlying nodes. DG-SPARQL evaluates parts of the query plan via SQL queries which are pushed to the underlying relational stores while other parts of the query plan, as necessary, are evaluated via indexless memory-based graph traversal algorithms. Our experimental evaluation shows the efficiency and the scalability of DG-SPARQL on querying massive attributed graph datasets in addition to its ability to outperform the performance of Apache Giraph, a popular distributed graph processing system, by orders of magnitudes.",2016-05-23,2021-06-05 20:55:40; 2021-06-06 07:04:00; 2021-06-05 21:12:01; 2021-06-05 20:37:08,,1,5,Springerplus,,PubMed Central,PMID: 27350905 PMCID: PMC4899405,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4899405/,,Neo4j; Giraph,Neo4j; Giraph,PMC:Query3; PMC:Neo4j; PMC:Query2; PMC:Giraph
495,10.1186/s40537-020-00357-y,32953386,PMC7493068,,,,"Adoni, Wilfried Yves Hamilton; Nahhal, Tarik; Krichen, Moez; El byed, Abdeltif; Assayad, Ismail",DHPV: a distributed algorithm for large-scale graph partitioning,2020,Journal of Big Data,,"Big graphs are part of the movement of “Not Only SQL” databases (also called NoSQL) focusing on the relationships between data, rather than the values themselves. The data is stored in vertices while the edges model the interactions or relationships between these data. They offer flexibility in handling data that is strongly connected to each other. The analysis of a big graph generally involves exploring all of its vertices. Thus, this operation is costly in time and resources because big graphs are generally composed of millions of vertices connected through billions of edges. Consequently, the graph algorithms are expansive compared to the size of the big graph, and are therefore ineffective for data exploration. Thus, partitioning the graph stands out as an efficient and less expensive alternative for exploring a big graph. This technique consists in partitioning the graph into a set of k sub-graphs in order to reduce the complexity of the queries. Nevertheless, it presents many challenges because it is an NP-complete problem. In this article, we present DPHV (Distributed Placement of Hub-Vertices) an efficient parallel and distributed heuristic for large-scale graph partitioning. An application on a real-world graphs demonstrates the feasibility and reliability of our method. The experiments carried on a 10-nodes Spark cluster proved that the proposed methodology achieves significant gain in term of time and outperforms JA-BE-JA, Greedy, DFEP.",2020,2021-06-05 21:10:08,,1,7,J Big Data,DHPV,PubMed Central,PMID: 32953386 PMCID: PMC7493068,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7493068/,,,,PMC:Query2
496,10.1186/s40537-020-00383-w,33489717,PMC7799375,,,,"Liang, Shiqi; Stockinger, Kurt; de Farias, Tarcisio Mendes; Anisimova, Maria; Gil, Manuel",Querying knowledge graphs in natural language,2021,Journal of Big Data,,"Knowledge graphs are a powerful concept for querying large amounts of data. These knowledge graphs are typically enormous and are often not easily accessible to end-users because they require specialized knowledge in query languages such as SPARQL. Moreover, end-users need a deep understanding of the structure of the underlying data models often based on the Resource Description Framework (RDF). This drawback has led to the development of Question-Answering (QA) systems that enable end-users to express their information needs in natural language. While existing systems simplify user access, there is still room for improvement in the accuracy of these systems. In this paper we propose a new QA system for translating natural language questions into SPARQL queries. The key idea is to break up the translation process into 5 smaller, more manageable sub-tasks and use ensemble machine learning methods as well as Tree-LSTM-based neural network models to automatically learn and translate a natural language question into a SPARQL query. The performance of our proposed QA system is empirically evaluated using the two renowned benchmarks-the 7th Question Answering over Linked Data Challenge (QALD-7) and the Large-Scale Complex Question Answering Dataset (LC-QuAD). Experimental results show that our QA system outperforms the state-of-art systems by 15% on the QALD-7 dataset and by 48% on the LC-QuAD dataset, respectively. In addition, we make our source code available.",2021,2021-06-05 21:09:36,,1,8,J Big Data,,PubMed Central,PMID: 33489717 PMCID: PMC7799375,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7799375/,,,,PMC:Query2
497,10.1186/s40537-021-00423-z,33614394,PMC7883950,A,Neo4j; COVID19,Neo4j; COVID19,"Villanustre, Flavio; Chala, Arjuna; Dev, Roger; Xu, Lili; LexisNexis, Jesse Shaw; Furht, Borko; Khoshgoftaar, Taghi",Modeling and tracking Covid-19 cases using Big Data analytics on HPCC system platformm,2021,Journal of Big Data,,"This project is funded by the US National Science Foundation (NSF) through their NSF RAPID program under the title “Modeling Corona Spread Using Big Data Analytics.” The project is a joint effort between the Department of Computer & Electrical Engineering and Computer Science at FAU and a research group from LexisNexis Risk Solutions., The novel coronavirus Covid-19 originated in China in early December 2019 and has rapidly spread to many countries around the globe, with the number of confirmed cases increasing every day. Covid-19 is officially a pandemic. It is a novel infection with serious clinical manifestations, including death, and it has reached at least 124 countries and territories. Although the ultimate course and impact of Covid-19 are uncertain, it is not merely possible but likely that the disease will produce enough severe illness to overwhelm the worldwide health care infrastructure. Emerging viral pandemics can place extraordinary and sustained demands on public health and health systems and on providers of essential community services., Modeling the Covid-19 pandemic spread is challenging. But there are data that can be used to project resource demands. Estimates of the reproductive number (R) of SARS-CoV-2 show that at the beginning of the epidemic, each infected person spreads the virus to at least two others, on average (Emanuel et al. in N Engl J Med. 2020, Livingston and Bucher in JAMA 323(14):1335, 2020). A conservatively low estimate is that 5 % of the population could become infected within 3 months. Preliminary data from China and Italy regarding the distribution of case severity and fatality vary widely (Wu and McGoogan in JAMA 323(13):1239–42, 2020). A recent large-scale analysis from China suggests that 80 % of those infected either are asymptomatic or have mild symptoms; a finding that implies that demand for advanced medical services might apply to only 20 % of the total infected. Of patients infected with Covid-19, about 15 % have severe illness and 5 % have critical illness (Emanuel et al. in N Engl J Med. 2020). Overall, mortality ranges from 0.25 % to as high as 3.0 % (Emanuel et al. in N Engl J Med. 2020, Wilson et al. in Emerg Infect Dis 26(6):1339, 2020). Case fatality rates are much higher for vulnerable populations, such as persons over the age of 80 years (> 14 %) and those with coexisting conditions (10 % for those with cardiovascular disease and 7 % for those with diabetes) (Emanuel et al. in N Engl J Med. 2020). Overall, Covid-19 is substantially deadlier than seasonal influenza, which has a mortality of roughly 0.1 %., Public health efforts depend heavily on predicting how diseases such as those caused by Covid-19 spread across the globe. During the early days of a new outbreak, when reliable data are still scarce, researchers turn to mathematical models that can predict where people who could be infected are going and how likely they are to bring the disease with them. These computational methods use known statistical equations that calculate the probability of individuals transmitting the illness. Modern computational power allows these models to quickly incorporate multiple inputs, such as a given disease’s ability to pass from person to person and the movement patterns of potentially infected people traveling by air and land. This process sometimes involves making assumptions about unknown factors, such as an individual’s exact travel pattern. By plugging in different possible versions of each input, however, researchers can update the models as new information becomes available and compare their results to observed patterns for the illness., In this paper we describe the development a model of Corona spread by using innovative big data analytics techniques and tools. We leveraged our experience from research in modeling Ebola spread (Shaw et al. Modeling Ebola Spread and Using HPCC/KEL System. In: Big Data Technologies and Applications 2016 (pp. 347-385). Springer, Cham) to successfully model Corona spread, we will obtain new results, and help in reducing the number of Corona patients. We closely collaborated with LexisNexis, which is a leading US data analytics company and a member of our NSF I/UCRC for Advanced Knowledge Enablement., The lack of a comprehensive view and informative analysis of the status of the pandemic can also cause panic and instability within society. Our work proposes the HPCC Systems Covid-19 tracker, which provides a multi-level view of the pandemic with the informative virus spreading indicators in a timely manner. The system embeds a classical epidemiological model known as SIR and spreading indicators based on causal model. The data solution of the tracker is built on top of the Big Data processing platform HPCC Systems, from ingesting and tracking of various data sources to fast delivery of the data to the public. The HPCC Systems Covid-19 tracker presents the Covid-19 data on a daily, weekly, and cumulative basis up to global-level and down to the county-level. It also provides statistical analysis for each level such as new cases per 100,000 population. The primary analysis such as Contagion Risk and Infection State is based on causal model with a seven-day sliding window. Our work has been released as a publicly available website to the world and attracted a great volume of traffic. The project is open-sourced and available on GitHub. The system was developed on the LexisNexis HPCC Systems, which is briefly described in the paper.",2021,2021-06-05 20:35:57; 2021-06-05 21:35:36; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,1,8,J Big Data,,PubMed Central,PMID: 33614394 PMCID: PMC7883950,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7883950/,,Neo4j; COVID19,Neo4j; COVID19,PMC:Query3; PMC:Neo4j; PMC:COVID19; PMC:Query2
498,10.1186/s40537-021-00443-9,33850687,PMC8033100,A,COVID19; JanusGraph; Giraph; Neo4j,COVID19; JanusGraph; Giraph; Neo4j,"Coimbra, Miguel E.; Francisco, Alexandre P.; Veiga, Luís",An analysis of the graph processing landscape,2021,Journal of Big Data,,"The value of graph-based big data can be unlocked by exploring the topology and metrics of the networks they represent, and the computational approaches to this exploration take on many forms. For the use-case of performing global computations over a graph, it is first ingested into a graph processing system from one of many digital representations. Extracting information from graphs involves processing all their elements globally, which can be done with single-machine systems (with varying approaches to hardware usage), distributed systems (either homogeneous or heterogeneous groups of machines) and systems dedicated to high-performance computing (HPC). For these systems focused on processing the bulk of graph elements, common use-cases consist in executing for example algorithms for vertex ranking or community detection, which produce insights on graph structure and relevance of their elements. Many distributed systems (such as Flink, Spark) and libraries (e.g. Gelly, GraphX) have been built to enable these tasks and improve performance. This is achieved with techniques ranging from classic load balancing (often geared to reduce communication overhead) to exploring trade-offs between delaying computation and relaxing accuracy. In this survey we firstly familiarize the reader with common graph datasets and applications in the world of today. We provide an overview of different aspects of the graph processing landscape and describe classes of systems based on a set of dimensions we describe. The dimensions we detail encompass paradigms to express graph processing, different types of systems to use, coordination and communication models in distributed graph processing, partitioning techniques and different definitions related to the potential for a graph to be updated. This survey is aimed at both the experienced software engineer or researcher as well as the graduate student looking for an understanding of the landscape of solutions (and their limitations) for graph processing.",2021,2021-06-05 20:35:57; 2021-06-05 21:35:36; 2021-06-05 20:54:31; 2021-06-05 21:09:36; 2021-06-06 07:06:30; 2021-06-06 07:04:00,,1,8,J Big Data,,PubMed Central,PMID: 33850687 PMCID: PMC8033100,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8033100/,,COVID19; JanusGraph; Giraph; Neo4j,COVID19; JanusGraph; Giraph; Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PMC:COVID19; PMC:Giraph; PMC:JanusGraph
499,10.1186/s42826-020-00068-8,33455583,PMC7811887,A,Virtuoso; COVID19,Virtuoso; COVID19,"Masuya, Hiroshi; Usuda, Daiki; Nakata, Hatsumi; Yuhara, Naomi; Kurihara, Keiko; Namiki, Yuri; Iwase, Shigeru; Takada, Toyoyuki; Tanaka, Nobuhiko; Suzuki, Kenta; Yamagata, Yuki; Kobayashi, Norio; Yoshiki, Atsushi; Kushida, Tatsuya",Establishment and application of information resource of mutant mice in RIKEN BioResource Research Center,2021,Laboratory Animal Research,,"Online databases are crucial infrastructures to facilitate the wide effective and efficient use of mouse mutant resources in life sciences. The number and types of mouse resources have been rapidly growing due to the development of genetic modification technology with associated information of genomic sequence and phenotypes. Therefore, data integration technologies to improve the findability, accessibility, interoperability, and reusability of mouse strain data becomes essential for mouse strain repositories. In 2020, the RIKEN BioResource Research Center released an integrated database of bioresources including, experimental mouse strains, Arabidopsis thaliana as a laboratory plant, cell lines, microorganisms, and genetic materials using Resource Description Framework-related technologies. The integrated database shows multiple advanced features for the dissemination of bioresource information. The current version of our online catalog of mouse strains which functions as a part of the integrated database of bioresources is available from search bars on the page of the Center (https://brc.riken.jp) and the Experimental Animal Division (https://mus.brc.riken.jp/) websites. The BioResource Research Center also released a genomic variation database of mouse strains established in Japan and Western Europe, MoG+ (https://molossinus.brc.riken.jp/mogplus/), and a database for phenotype-phenotype associations across the mouse phenome using data from the International Mouse Phenotyping Platform. In this review, we describe features of current version of databases related to mouse strain resources in RIKEN BioResource Research Center and discuss future views.",2021-01-18,2021-06-05 21:35:36; 2021-06-05 20:54:31; 2021-06-05 20:59:14; 2021-06-05 21:09:36,,,37,Lab Anim Res,,PubMed Central,PMID: 33455583 PMCID: PMC7811887,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7811887/,,Virtuoso; COVID19,Virtuoso; COVID19,PMC:Query3; PMC:COVID19; PMC:Query2; PMC:Virtuoso
500,10.1200/CCI.19.00110,32097025,PMC7049249,A,Neo4j; Dgraph,Neo4j; Dgraph,"Struck, Adam; Walsh, Brian; Buchanan, Alexander; Lee, Jordan A.; Spangler, Ryan; Stuart, Joshua M.; Ellrott, Kyle",Exploring Integrative Analysis Using the BioMedical Evidence Graph,2020,JCO Clinical Cancer Informatics; JCO clinical cancer informatics,,"PURPOSE: The analysis of cancer biology data involves extremely heterogeneous data sets, including information from RNA sequencing, genome-wide copy number, DNA methylation data reporting on epigenetic regulation, somatic mutations from whole-exome or whole-genome analyses, pathology estimates from imaging sections or subtyping, drug response or other treatment outcomes, and various other clinical and phenotypic measurements. Bringing these different resources into a common framework, with a data model that allows for complex relationships as well as dense vectors of features, will unlock integrated data set analysis. METHODS: We introduce the BioMedical Evidence Graph (BMEG), a graph database and query engine for discovery and analysis of cancer biology. The BMEG is unique from other biologic data graphs in that sample-level molecular and clinical information is connected to reference knowledge bases. It combines gene expression and mutation data with drug-response experiments, pathway information databases, and literature-derived associations. RESULTS: The construction of the BMEG has resulted in a graph containing > 41 million vertices and 57 million edges. The BMEG system provides a graph query-based application programming interface to enable analysis, with client code available for Python, Javascript, and R, and a server online at bmeg.io. Using this system, we have demonstrated several forms of cross-data set analysis to show the utility of the system. CONCLUSION: The BMEG is an evolving resource dedicated to enabling integrative analysis. We have demonstrated queries on the system that illustrate mutation significance analysis, drug-response machine learning, patient-level knowledge-base queries, and pathway level analysis. We have compared the resulting graph to other available integrated graph systems and demonstrated the former is unique in the scale of the graph and the type of data it makes available.; PURPOSE The analysis of cancer biology data involves extremely heterogeneous data sets, including information from RNA sequencing, genome-wide copy number, DNA methylation data reporting on epigenetic regulation, somatic mutations from whole-exome or whole-genome analyses, pathology estimates from imaging sections or subtyping, drug response or other treatment outcomes, and various other clinical and phenotypic measurements. Bringing these different resources into a common framework, with a data model that allows for complex relationships as well as dense vectors of features, will unlock integrated data set analysis. METHODS We introduce the BioMedical Evidence Graph (BMEG), a graph database and query engine for discovery and analysis of cancer biology. The BMEG is unique from other biologic data graphs in that sample-level molecular and clinical information is connected to reference knowledge bases. It combines gene expression and mutation data with drug-response experiments, pathway information databases, and literature-derived associations. RESULTS The construction of the BMEG has resulted in a graph containing > 41 million vertices and 57 million edges. The BMEG system provides a graph query–based application programming interface to enable analysis, with client code available for Python, Javascript, and R, and a server online at bmeg.io. Using this system, we have demonstrated several forms of cross–data set analysis to show the utility of the system. CONCLUSION The BMEG is an evolving resource dedicated to enabling integrative analysis. We have demonstrated queries on the system that illustrate mutation significance analysis, drug-response machine learning, patient-level knowledge-base queries, and pathway level analysis. We have compared the resulting graph to other available integrated graph systems and demonstrated the former is unique in the scale of the graph and the type of data it makes available.",2020-02-25; 2020-02,2021-06-05 20:35:57; 2021-06-05 21:10:08; 2021-06-06 07:26:31; 2021-06-05 21:06:22; 2021-06-05 20:55:01,147-159,,4,JCO Clin Cancer Inform,,PubMed; PubMed Central,PMID: 32097025 PMCID: PMC7049249,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7049249/; http://www.ncbi.nlm.nih.gov/pubmed/32097025,"Antineoplastic Agents; Biomarkers, Tumor; Computational Biology; Computer Graphics; Databases, Factual; Gene Expression Regulation, Neoplastic; Gene Regulatory Networks; Humans; Medical Informatics; Neoplasms; Signal Transduction",Neo4j; Dgraph,Neo4j; Dgraph,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Query2; PMC:Dgraph
501,10.1200/CCI.19.00115,32383981,PMC7265796,A,Neo4j,Neo4j,"Yuan, Zhou; Finan, Sean; Warner, Jeremy; Savova, Guergana; Hochheiser, Harry",Interactive Exploration of Longitudinal Cancer Patient Histories Extracted From Clinical Text,2020,JCO Clinical Cancer Informatics,,"PURPOSE Retrospective cancer research requires identification of patients matching both categorical and temporal inclusion criteria, often on the basis of factors exclusively available in clinical notes. Although natural language processing approaches for inferring higher-level concepts have shown promise for bringing structure to clinical texts, interpreting results is often challenging, involving the need to move between abstracted representations and constituent text elements. Our goal was to build interactive visual tools to support the process of interpreting rich representations of histories of patients with cancer. METHODS Qualitative inquiry into user tasks and goals, a structured data model, and an innovative natural language processing pipeline were used to guide design. RESULTS The resulting information visualization tool provides cohort- and patient-level views with linked interactions between components. CONCLUSION Interactive tools hold promise for facilitating the interpretation of patient summaries and identification of cohorts for retrospective research.",2020-05-08,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,,,4,JCO Clin Cancer Inform,,PubMed Central,PMID: 32383981 PMCID: PMC7265796,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7265796/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
502,10.12688/f1000research.13925.3,30026924,PMC6039941,A,Neo4j,Neo4j,"Godard, Patrice; van Eyll, Jonathan",BED: a Biological Entity Dictionary based on a graph data model,2018,F1000Research,,"The understanding of molecular processes involved in a specific biological system can be significantly improved by combining and comparing different data sets and knowledge resources. However, these information sources often use different identification systems and an identifier conversion step is required before any integration effort. Mapping between identifiers is often provided by the reference information resources and several tools have been implemented to simplify their use. However, most of these tools do not combine the information provided by individual resources to increase the completeness of the mapping process. Also, deprecated identifiers from former versions of databases are not taken into account. Finally, finding automatically the most relevant path to map identifiers from one scope to the other is often not trivial. The Biological Entity Dictionary (BED) addresses these three challenges by relying on a graph data model describing possible relationships between entities and their identifiers. This model has been implemented using Neo4j and an R package provides functions to query the graph but also to create and feed a custom instance of the database. This design combined with a local installation of the graph database and a cache system make BED very efficient to convert large lists of identifiers.",2018; 2018-07-19,2021-06-05 21:11:16; 2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 20:55:01; 2021-06-05 21:24:28; 2021-06-05 20:36:32,195,,7,F1000Res,BED,PubMed; PubMed Central,PMID: 30026924 PMCID: PMC6039941,http://www.ncbi.nlm.nih.gov/pubmed/30026924; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6039941/,database; genomics; identifiers; microarray; proteomics; RNA-seq; transcriptomics,Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
503,10.12688/f1000research.18236.1,32308977,PMC7141167,A,Virtuoso,Virtuoso,"Vos, Rutger A.; Katayama, Toshiaki; Mishima, Hiroyuki; Kawano, Shin; Kawashima, Shuichi; Kim, Jin-Dong; Moriya, Yuki; Tokimatsu, Toshiaki; Yamaguchi, Atsuko; Yamamoto, Yasunori; Wu, Hongyan; Amstutz, Peter; Antezana, Erick; Aoki, Nobuyuki P.; Arakawa, Kazuharu; Bolleman, Jerven T.; Bolton, Evan; Bonnal, Raoul J. P.; Bono, Hidemasa; Burger, Kees; Chiba, Hirokazu; Cohen, Kevin B.; Deutsch, Eric W.; Fernández-Breis, Jesualdo T.; Fu, Gang; Fujisawa, Takatomo; Fukushima, Atsushi; García, Alexander; Goto, Naohisa; Groza, Tudor; Hercus, Colin; Hoehndorf, Robert; Itaya, Kotone; Juty, Nick; Kawashima, Takeshi; Kim, Jee-Hyub; Kinjo, Akira R.; Kotera, Masaaki; Kozaki, Kouji; Kumagai, Sadahiro; Kushida, Tatsuya; Lütteke, Thomas; Matsubara, Masaaki; Miyamoto, Joe; Mohsen, Attayeb; Mori, Hiroshi; Naito, Yuki; Nakazato, Takeru; Nguyen-Xuan, Jeremy; Nishida, Kozo; Nishida, Naoki; Nishide, Hiroyo; Ogishima, Soichi; Ohta, Tazro; Okuda, Shujiro; Paten, Benedict; Perret, Jean-Luc; Prathipati, Philip; Prins, Pjotr; Queralt-Rosinach, Núria; Shinmachi, Daisuke; Suzuki, Shinya; Tabata, Tsuyosi; Takatsuki, Terue; Taylor, Kieron; Thompson, Mark; Uchiyama, Ikuo; Vieira, Bruno; Wei, Chih-Hsuan; Wilkinson, Mark; Yamada, Issaku; Yamanaka, Ryota; Yoshitake, Kazutoshi; Yoshizawa, Akiyasu C.; Dumontier, Michel; Kosaki, Kenjiro; Takagi, Toshihisa",BioHackathon 2015: Semantics of data for life sciences and reproducible research,2020,F1000Research,,"We report on the activities of the 2015 edition of the BioHackathon, an annual event that brings together researchers and developers from around the world to develop tools and technologies that promote the reusability of biological data. We discuss issues surrounding the representation, publication, integration, mining and reuse of biological data and metadata across a wide range of biomedical data types of relevance for the life sciences, including chemistry, genotypes and phenotypes, orthology and phylogeny, proteomics, genomics, glycomics, and metabolomics. We describe our progress to address ongoing challenges to the reusability and reproducibility of research results, and identify outstanding issues that continue to impede the progress of bioinformatics research. We share our perspective on the state of the art, continued challenges, and goals for future research and development for the life sciences Semantic Web.",2020-02-24,2021-06-05 21:10:08; 2021-06-05 20:55:01; 2021-06-05 20:59:14,,,9,F1000Res,BioHackathon 2015,PubMed Central,PMID: 32308977 PMCID: PMC7141167,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7141167/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
504,10.12688/f1000research.19161.2,32760576,PMC7376384,,,,"Navale, Vivek; Ji, Michele; Vovk, Olga; Misquitta, Leonie; Gebremichael, Tsega; Garcia, Alison; Fann, Yang; McAuliffe, Matthew",Development of an informatics system for accelerating biomedical research.,2020,F1000Research,,"The Biomedical Research Informatics Computing System (BRICS) was developed to support multiple disease-focused research programs. Seven service modules are integrated together to provide a collaborative and extensible web-based environment. The modules—Data Dictionary, Account Management, Query Tool, Protocol and Form Research Management System, Meta Study, Data Repository and Globally Unique Identifier —facilitate the management of research protocols, to submit, process, curate, access and store clinical, imaging, and derived genomics data within the associated data repositories. Multiple instances of BRICS are deployed to support various biomedical research communities focused on accelerating discoveries for rare diseases, Traumatic Brain Injury, Parkinson’s Disease, inherited eye diseases and symptom science research. No Personally Identifiable Information is stored within the data repositories. Digital Object Identifiers are associated with the research studies. Reusability of biomedical data is enhanced by Common Data Elements (CDEs) which enable systematic collection, analysis and sharing of data. The use of CDEs with a service-oriented informatics architecture enabled the development of disease-specific repositories that support hypothesis-based biomedical research.",2020-07-13,2021-06-05 21:10:08,,,8,F1000Res,,PubMed Central,PMID: 32760576 PMCID: PMC7376384,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7376384/,,,,PMC:Query2
505,10.12688/f1000research.24345.1,32742640,PMC7366035,A,Neo4j,Neo4j,"Wagner, Justin; Kancherla, Jayaram; Braccia, Domenick; Matsumara, James; Felix, Victor; Crabtree, Jonathan; Mahurkar, Anup; Corrada Bravo, Héctor",Interactive exploratory data analysis of Integrative Human Microbiome Project data using Metaviz,2020,F1000Research,,"The rich data produced by the second phase of the Human Microbiome Project (iHMP) offers a unique opportunity to test hypotheses that interactions between microbial communities and a human host might impact an individual’s health or disease status. In this work we describe infrastructure that integrates Metaviz, an interactive microbiome data analysis and visualization tool, with the iHMP Data Coordination Center web portal and the HMP2Data R/Bioconductor package. We describe integrative statistical and visual analyses of two datasets from iHMP using Metaviz along with the metagenomeSeq R/Bioconductor package for statistical analysis of differential abundance analysis. These use cases demonstrate the utility of a combined approach to access and analyze data from this resource.",2020-06-12,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,,,9,F1000Res,,PubMed Central,PMID: 32742640 PMCID: PMC7366035,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7366035/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
506,10.12688/f1000research.6656.2,26594341,PMC4642848,,,,"Rinnone, Fabio; Micale, Giovanni; Bonnici, Vincenzo; Bader, Gary D.; Shasha, Dennis; Ferro, Alfredo; Pulvirenti, Alfredo; Giugno, Rosalba",NetMatchStar: an enhanced Cytoscape network querying app,2015,F1000Research,,"We present NetMatchStar, a Cytoscape app to find all the occurrences of a query graph in a network and check for its significance as a motif with respect to seven different random models. The query can be uploaded or built from scratch using Cytoscape facilities. The app significantly enhances the previous NetMatch in style, performance and functionality. Notably NetMatchStar allows queries with wildcards.",2015-11-03,2021-06-05 21:12:40,,,4,F1000Res,NetMatchStar,PubMed Central,PMID: 26594341 PMCID: PMC4642848,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4642848/,,,,PMC:Query2
507,10.12688/f1000research.9416.3,27703668,PMC5031134,,,,"Koehorst, Jasper J.; Saccenti, Edoardo; Schaap, Peter J.; Martins dos Santos, Vitor A. P.; Suarez-Diez, Maria","Protein domain architectures provide a fast, efficient and scalable alternative to sequence-based methods for comparative functional genomics",2017,F1000Research,,"A functional comparative genome analysis is essential to understand the mechanisms underlying bacterial evolution and adaptation. Detection of functional orthologs using standard global sequence similarity methods faces several problems; the need for defining arbitrary acceptance thresholds for similarity and alignment length, lateral gene acquisition and the high computational cost for finding bi-directional best matches at a large scale. We investigated the use of protein domain architectures for large scale functional comparative analysis as an alternative method. The performance of both approaches was assessed through functional comparison of 446 bacterial genomes sampled at different taxonomic levels. We show that protein domain architectures provide a fast and efficient alternative to methods based on sequence similarity to identify groups of functionally equivalent proteins within and across taxonomic boundaries, and it is suitable for large scale comparative analysis. Running both methods in parallel pinpoints potential functional adaptations that may add to bacterial fitness.",2017-06-27,2021-06-05 21:12:01,,,5,F1000Res,,PubMed Central,PMID: 27703668 PMCID: PMC5031134,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5031134/,,,,PMC:Query2
508,10.12688/wellcomeopenres.10210.2,28948232,PMC5527546,A,Virtuoso,Virtuoso,"Venkatesan, Aravind; Kim, Jee-Hyub; Talo, Francesco; Ide-Smith, Michele; Gobeill, Julien; Carter, Jacob; Batista-Navarro, Riza; Ananiadou, Sophia; Ruch, Patrick; McEntyre, Johanna",SciLite: a platform for displaying text-mined annotations as a means to link research articles with biological data,2017,Wellcome Open Research,,"The tremendous growth in biological data has resulted in an increase in the number of research papers being published. This presents a great challenge for scientists in searching and assimilating facts described in those papers. Particularly, biological databases depend on curators to add highly precise and useful information that are usually extracted by reading research articles. Therefore, there is an urgent need to find ways to improve linking literature to the underlying data, thereby minimising the effort in browsing content and identifying key biological concepts.  ,  As part of the development of Europe PMC, we have developed a new platform, SciLite, which integrates text-mined annotations from different sources and overlays those outputs on research articles. The aim is to aid researchers and curators using Europe PMC in finding key concepts more easily and provide links to related resources or tools, bridging the gap between literature and biological data.",2017-07-10,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:59:14,,,1,Wellcome Open Res,SciLite,PubMed Central,PMID: 28948232 PMCID: PMC5527546,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5527546/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
509,10.12688/wellcomeopenres.14073.3,30271886,PMC6134339,A,Neo4j,Neo4j,"Deffur, Armin; Wilkinson, Robert J.; Mayosi, Bongani M.; Mulder, Nicola M.",ANIMA: Association network integration for multiscale analysis,2018,Wellcome Open Research,,"Contextual functional interpretation of -omics data derived from clinical samples is a classical and difficult problem in computational systems biology. The measurement of thousands of data points on single samples has become routine but relating 'big data' datasets to the complexities of human pathobiology is an area of ongoing research. Complicating this is the fact that many publicly available datasets use bulk transcriptomics data from complex tissues like blood. The most prevalent analytic approaches derive molecular 'signatures' of disease states or apply modular analysis frameworks to the data. Here we describe ANIMA (association network integration for multiscale analysis), a network-based data integration method using clinical phenotype and microarray data as inputs. ANIMA is implemented in R and Neo4j and runs in Docker containers. In short, the build algorithm iterates over one or more transcriptomics datasets to generate a large, multipartite association network by executing multiple independent analytic steps (differential expression, deconvolution, modular analysis based on co-expression, pathway analysis) and integrating the results. Once the network is built, it can be queried directly using Cypher (a graph query language), or by custom functions that communicate with the graph database via language-specific APIs. We developed a web application using Shiny, which provides fully interactive, multiscale views of the data. Using our approach, we show that we can reconstruct multiple features of disease states at various scales of organization, from transcript abundance patterns of individual genes through co-expression patterns of groups of genes to patterns of cellular behaviour in whole blood samples, both in single experiments as well in meta-analyses of multiple datasets.; Contextual functional interpretation of -omics data derived from clinical samples is a classical and difficult problem in computational systems biology. The measurement of thousands of data points on single samples has become routine but relating ‘big data’ datasets to the complexities of human pathobiology is an area of ongoing research. Complicating this is the fact that many publicly available datasets use bulk transcriptomics data from complex tissues like blood. The most prevalent analytic approaches derive molecular ‘signatures’ of disease states or apply modular analysis frameworks to the data. Here we describe ANIMA (association network integration for multiscale analysis), a network-based data integration method using clinical phenotype and microarray data as inputs. ANIMA is implemented in R and Neo4j and runs in Docker containers. In short, the build algorithm iterates over one or more transcriptomics datasets to generate a large, multipartite association network by executing multiple independent analytic steps (differential expression, deconvolution, modular analysis based on co-expression, pathway analysis) and integrating the results. Once the network is built, it can be queried directly using Cypher (a graph query language), or by custom functions that communicate with the graph database via language-specific APIs. We developed a web application using Shiny, which provides fully interactive, multiscale views of the data. Using our approach, we show that we can reconstruct multiple features of disease states at various scales of organization, from transcript abundance patterns of individual genes through co-expression patterns of groups of genes to patterns of cellular behaviour in whole blood samples, both in single experiments as well in meta-analyses of multiple datasets.",2018-11-14; 2018,2021-06-05 21:11:16; 2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 20:55:01; 2021-06-05 21:24:28; 2021-06-05 20:36:32,27,,3,Wellcome Open Res,ANIMA,PubMed; PubMed Central,PMID: 30271886 PMCID: PMC6134339,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6134339/; http://www.ncbi.nlm.nih.gov/pubmed/30271886,complex networks; data integration; graph databases; Transcriptomics,Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
510,10.12688/wellcomeopenres.15933.1,33154979,PMC7610178,,,,"Maguire, Brittany J.; McLean, Alistair R.D.; Rashan, Sumayyah; Antonio, Emilia Sitsofe; Bagaria, Jayshree; Bentounsi, Zineb; Brack, Matthew; Caldwell, Fiona; Carrara, Verena Ilona; Citarella, Barbara Wanjiru; Dahal, Prabin; Feteh, Vitalis Fambombi; H.B. Guérin, Marius; Kennon, Kalynn; Bilton Lahaut, Kathinka; Makuka, Gerald Jamberi; Ngu, Roland; Obiesie, Sopuruchukwu; Richmond, Caitlin; Singh-Phulgenda, Sauman; Strudwick, Samantha; Tyrrell, Carina S.B.; Schwinn, Austin; King, David; Newton, Paul N.; Price, Ric N.; Merson, Laura; Stepniewska, Kasia; Guérin, Philippe J.",Baseline results of a living systematic review for COVID-19 clinical trial registrations,2020,Wellcome Open Research,,"Background: Since the coronavirus disease 2019 (COVID-19) outbreak was first reported in December 2019, many independent trials have been planned that aim to answer similar questions. Tools allowing researchers to review studies already underway can facilitate collaboration, cooperation and harmonisation. The Infectious Diseases Data Observatory (IDDO) has undertaken a living systematic review (LSR) to provide an open, accessible and frequently updated resource summarising characteristics of COVID-19 study registrations.,  Methods: Review of all eligible trial records identified by systematic searches as of 3 April 2020 and initial synthesis of clinical study characteristics were conducted. In partnership with Exaptive, an open access, cloud-based knowledge graph has been created using the results. ,  Results: There were 728 study registrations which met eligibility criteria and were still active. Median (25 th, 75 th percentile) sample size was 130 (60, 400) for all studies and 134 (70, 300) for RCTs. Eight lower middle and low income countries were represented among the planned recruitment sites. Overall 109 pharmacological interventions or advanced therapy medicinal products covering 23 drug categories were studied. Majority (57%, 62/109) of them were planned only in one study arm, either alone or in combination with other interventions. There were 49 distinct combinations studied with 90% (44/49) of them administered in only one or two study arms. The data and interactive platform are available at https://iddo.cognitive.city/.,  Conclusions:  Baseline review highlighted that the majority of investigations in the first three months of the outbreak were small studies with unique treatment arms, likely to be unpowered to provide solid evidence.  The continued work of this LSR will allow a more dependable overview of interventions tested, predict the likely strength of evidence generated, allow fast and informative filtering of relevant trials for specific user groups and provide the rapid guidance needed by investigators and funders to avoid duplication of efforts.",2020-06-02,2021-06-05 21:10:08,,,5,Wellcome Open Res,,PubMed Central,PMID: 33154979 PMCID: PMC7610178,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7610178/,,,,PMC:Query2
511,10.1371/journal.pbio.3000344,31260438,PMC6625714,,,,"Amunts, Katrin; Knoll, Alois C.; Lippert, Thomas; Pennartz, Cyriel M. A.; Ryvlin, Philippe; Destexhe, Alain; Jirsa, Viktor K.; D’Angelo, Egidio; Bjaalie, Jan G.","The Human Brain Project—Synergy between neuroscience, computing, informatics, and brain-inspired technologies",2019,PLoS Biology,,"The Human Brain Project (HBP) is a European flagship project with a 10-year horizon aiming to understand the human brain and to translate neuroscience knowledge into medicine and technology. To achieve such aims, the HBP explores the multilevel complexity of the brain in space and time; transfers the acquired knowledge to brain-derived applications in health, computing, and technology; and provides shared and open computing tools and data through the HBP European brain research infrastructure. We discuss how the HBP creates a transdisciplinary community of researchers united by the quest to understand the brain, with fascinating perspectives on societal benefits., This Community Page article presents the Human Brain Project; a European Flagship project with a ten-year horizon aiming to understand the human brain and translate neuroscience knowledge into medicine and technology.",2019-07-01,2021-06-05 21:10:37,,7,17,PLoS Biol,,PubMed Central,PMID: 31260438 PMCID: PMC6625714,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6625714/,,,,PMC:Query2
512,10.1371/journal.pcbi.1000203,18949022,PMC2561054,,,,"Banks, Eric; Nabieva, Elena; Chazelle, Bernard; Singh, Mona",Organization of Physical Interactomes as Uncovered by Network Schemas,2008,PLoS Computational Biology,,"Large-scale protein-protein interaction networks provide new opportunities for understanding cellular organization and functioning. We introduce network schemas to elucidate shared mechanisms within interactomes. Network schemas specify descriptions of proteins and the topology of interactions among them. We develop algorithms for systematically uncovering recurring, over-represented schemas in physical interaction networks. We apply our methods to the S. cerevisiae interactome, focusing on schemas consisting of proteins described via sequence motifs and molecular function annotations and interacting with one another in one of four basic network topologies. We identify hundreds of recurring and over-represented network schemas of various complexity, and demonstrate via graph-theoretic representations how more complex schemas are organized in terms of their lower-order constituents. The uncovered schemas span a wide range of cellular activities, with many signaling and transport related higher-order schemas. We establish the functional importance of the schemas by showing that they correspond to functionally cohesive sets of proteins, are enriched in the frequency with which they have instances in the H. sapiens interactome, and are useful for predicting protein function. Our findings suggest that network schemas are a powerful paradigm for organizing, interrogating, and annotating cellular networks., Large-scale networks of protein-protein interactions provide a view into the workings of the cell. However, these interaction maps do not come with a key for interpreting them, so it is necessary to develop methods that shed light on their functioning and organization. We propose the language of network schemas for describing recurring patterns of specific types of proteins and their interactions. That is, network schemas describe proteins and specify the topology of interactions among them. A single network schema can describe, for example, a common template that underlies several distinct cellular pathways, such as signaling pathways. We develop a computational methodology for identifying network schemas that are recurrent and over-represented in the network, even given the distributions of their constituent components. We apply this methodology to the physical interaction network in S. cerevisiae and begin to build a hierarchy of schemas starting with the four simplest topologies. We validate the biological relevance of the schemas that we find, discuss the insights our findings lend into the organization of interactomes, touch upon cross-genomic aspects of schema analysis, and show how to use schemas to annotate uncharacterized protein families.",2008-10-24,2021-06-05 21:13:27,,10,4,PLoS Comput Biol,,PubMed Central,PMID: 18949022 PMCID: PMC2561054,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2561054/,,,,PMC:Query2
513,10.1371/journal.pcbi.1003223,24086118,PMC3784503,A,Neo4j,Neo4j,"Smith, Stephen A.; Brown, Joseph W.; Hinchliff, Cody E.",Analyzing and Synthesizing Phylogenies Using Tree Alignment Graphs,2013,PLoS Computational Biology,,"Phylogenetic trees are used to analyze and visualize evolution. However, trees can be imperfect datatypes when summarizing multiple trees. This is especially problematic when accommodating for biological phenomena such as horizontal gene transfer, incomplete lineage sorting, and hybridization, as well as topological conflict between datasets. Additionally, researchers may want to combine information from sets of trees that have partially overlapping taxon sets. To address the problem of analyzing sets of trees with conflicting relationships and partially overlapping taxon sets, we introduce methods for aligning, synthesizing and analyzing rooted phylogenetic trees within a graph, called a tree alignment graph (TAG). The TAG can be queried and analyzed to explore uncertainty and conflict. It can also be synthesized to construct trees, presenting an alternative to supertrees approaches. We demonstrate these methods with two empirical datasets. In order to explore uncertainty, we constructed a TAG of the bootstrap trees from the Angiosperm Tree of Life project. Analysis of the resulting graph demonstrates that areas of the dataset that are unresolved in majority-rule consensus tree analyses can be understood in more detail within the context of a graph structure, using measures incorporating node degree and adjacency support. As an exercise in synthesis (i.e., summarization of a TAG constructed from the alignment trees), we also construct a TAG consisting of the taxonomy and source trees from a recent comprehensive bird study. We synthesized this graph into a tree that can be reconstructed in a repeatable fashion and where the underlying source information can be updated. The methods presented here are tractable for large scale analyses and serve as a basis for an alternative to consensus tree and supertree methods. Furthermore, the exploration of these graphs can expose structures and patterns within the dataset that are otherwise difficult to observe., Phylogenetic trees are the most common datatype by which we examine evolutionary patterns. However, biological and practical considerations require the exploration of other models. Here, we address a problem concerning the representation of conflicting and partially overlapping datasets in phylogenetics. We examine the problem of aligning many source trees from independent phylogenetic analyses into a structure that can be analyzed and synthesized but retain all of the original structure and source information. We present methods to map trees into a common graph structure using a graph database. This allows the information in the trees to be stored and synthesized in several ways. Specifically, we demonstrate how these graphs can be used to construct enormous trees as an alternative to labor-intensive grafting exercise and other methods that make the synthetic tree difficult to update. We also show how examination of the relationships in the graph allows patterns to emerge concerning support and information that are difficult to discern with existing methods. Because these methods scale well into the millions of nodes, these techniques should lead to the construction and maintenance of even larger phylogenies and new techniques for analyzing graphs that maintain the structure of the underlying trees.",2013-09-26,2021-06-05 21:13:27; 2021-06-05 20:56:20; 2021-06-05 20:37:08,,9,9,PLoS Comput Biol,,PubMed Central,PMID: 24086118 PMCID: PMC3784503,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3784503/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
514,10.1371/journal.pcbi.1003465,24516375,PMC3916221,,,,"Pitkänen, Esa; Jouhten, Paula; Hou, Jian; Syed, Muhammad Fahad; Blomberg, Peter; Kludas, Jana; Oja, Merja; Holm, Liisa; Penttilä, Merja; Rousu, Juho; Arvas, Mikko",Comparative Genome-Scale Reconstruction of Gapless Metabolic Networks for Present and Ancestral Species,2014,PLoS Computational Biology,,"We introduce a novel computational approach, CoReCo, for comparative metabolic reconstruction and provide genome-scale metabolic network models for 49 important fungal species. Leveraging on the exponential growth in sequenced genome availability, our method reconstructs genome-scale gapless metabolic networks simultaneously for a large number of species by integrating sequence data in a probabilistic framework. High reconstruction accuracy is demonstrated by comparisons to the well-curated Saccharomyces cerevisiae consensus model and large-scale knock-out experiments. Our comparative approach is particularly useful in scenarios where the quality of available sequence data is lacking, and when reconstructing evolutionary distant species. Moreover, the reconstructed networks are fully carbon mapped, allowing their use in 13C flux analysis. We demonstrate the functionality and usability of the reconstructed fungal models with computational steady-state biomass production experiment, as these fungi include some of the most important production organisms in industrial biotechnology. In contrast to many existing reconstruction techniques, only minimal manual effort is required before the reconstructed models are usable in flux balance experiments. CoReCo is available at http://esaskar.github.io/CoReCo/., Advances in next-generation sequencing technologies are revolutionizing molecular biology. Sequencing-enabled cost-effective characterization of microbial genomes is a particularly exciting development in metabolic engineering. There, considerable effort has been put to reconstructing genome-scale metabolic networks that describe the collection of hundreds to thousands of biochemical reactions available for a microbial cell. These network models are instrumental in understanding microbial metabolism and guiding metabolic engineering efforts to improve biochemical yields. We have developed a novel computational method, CoReCo, which bridges the growing gap between the availability of sequenced genomes and respective reconstructed metabolic networks. The method reconstructs genome-scale metabolic networks simultaneously for related microbial species. It utilizes the available sequencing data from these species to correct for incomplete and missing data. We used the method to reconstruct metabolic networks for a set of 49 fungal species providing the method protein sequence data and a phylogenetic tree describing the evolutionary relationships between the species. We demonstrate the applicability of the method by comparing a metabolic reconstruction of Saccharomyces cerevisiae to the manually curated, high-quality consensus network. We also provide an easy-to-use implementation of the method, usable both in single computer and distributed computing environments.",2014-02-06,2021-06-05 21:13:27,,2,10,PLoS Comput Biol,,PubMed Central,PMID: 24516375 PMCID: PMC3916221,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3916221/,,,,PMC:Query2
515,10.1371/journal.pcbi.1005968,29377902,PMC5805351,A,Neo4j,Neo4j,"Fabregat, Antonio; Korninger, Florian; Viteri, Guilherme; Sidiropoulos, Konstantinos; Marin-Garcia, Pablo; Ping, Peipei; Wu, Guanming; Stein, Lincoln; D’Eustachio, Peter; Hermjakob, Henning; Fabregat, Antonio; Korninger, Florian; Viteri, Guilherme; Sidiropoulos, Konstantinos; Marin-Garcia, Pablo; Ping, Peipei; Wu, Guanming; Stein, Lincoln; D'Eustachio, Peter; Hermjakob, Henning",Reactome graph database: Efficient access to complex pathway data,2018,PLoS computational biology; PLoS Computational Biology,,"Reactome is a free, open-source, open-data, curated and peer-reviewed knowledgebase of biomolecular pathways. One of its main priorities is to provide easy and efficient access to its high quality curated data. At present, biological pathway databases typically store their contents in relational databases. This limits access efficiency because there are performance issues associated with queries traversing highly interconnected data. The same data in a graph database can be queried more efficiently. Here we present the rationale behind the adoption of a graph database (Neo4j) as well as the new ContentService (REST API) that provides access to these data. The Neo4j graph database and its query language, Cypher, provide efficient access to the complex Reactome data model, facilitating easy traversal and knowledge discovery. The adoption of this technology greatly improved query efficiency, reducing the average query time by 93%. The web service built on top of the graph database provides programmatic access to Reactome data by object oriented queries, but also supports more complex queries that take advantage of the new underlying graph-based data storage. By adopting graph database technology we are providing a high performance pathway data resource to the community. The Reactome graph database use case shows the power of NoSQL database engines for complex biological data types.; Reactome is a free, open-source, open-data, curated and peer-reviewed knowledgebase of biomolecular pathways. One of its main priorities is to provide easy and efficient access to its high quality curated data. At present, biological pathway databases typically store their contents in relational databases. This limits access efficiency because there are performance issues associated with queries traversing highly interconnected data. The same data in a graph database can be queried more efficiently. Here we present the rationale behind the adoption of a graph database (Neo4j) as well as the new ContentService (REST API) that provides access to these data. The Neo4j graph database and its query language, Cypher, provide efficient access to the complex Reactome data model, facilitating easy traversal and knowledge discovery. The adoption of this technology greatly improved query efficiency, reducing the average query time by 93%. The web service built on top of the graph database provides programmatic access to Reactome data by object oriented queries, but also supports more complex queries that take advantage of the new underlying graph-based data storage. By adopting graph database technology we are providing a high performance pathway data resource to the community. The Reactome graph database use case shows the power of NoSQL database engines for complex biological data types., To better support genome analysis, modeling, systems biology and education, we now offer our knowledgebase of biomolecular pathways as a graph database. We have developed a tool to migrate the Reactome content from the relational database used in curation to a graph database during each quarterly release process. The new graph database has two main advantages; higher performance and simpler ways to perform complex queries. Reactome has already adapted its software infrastructure to benefit from this growing in popularity storage technology, significantly improving query efficiency, by reducing the average query time by 93%. We strongly believe that the successful adoption of a graph database by Reactome demonstrates the positive impact this new technology could potentially have in the field and could provide a practical example for other community projects with similar complex data models to move their storage to a graph database while retaining their data models.",2018-01-29; 2018-01,2021-06-05 21:11:16; 2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 20:55:40; 2021-06-05 21:24:28; 2021-06-05 20:36:32,e1005968,1,14,PLoS Comput Biol,Reactome graph database,PubMed; PubMed Central,PMID: 29377902 PMCID: PMC5805351,http://www.ncbi.nlm.nih.gov/pubmed/29377902; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5805351/,"Computational Biology; Computer Graphics; Databases, Factual; Humans; Information Storage and Retrieval; Internet; Knowledge Bases; Software; Systems Biology; User-Computer Interface",Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
516,10.1371/journal.pcbi.1006099,29668682,PMC5927471,A,Neo4j,Neo4j,"Hannigan, Geoffrey D.; Duhaime, Melissa B.; Koutra, Danai; Schloss, Patrick D.",Biogeography and environmental conditions shape bacteriophage-bacteria networks across the human microbiome,2018,PLoS Computational Biology,,"Viruses and bacteria are critical components of the human microbiome and play important roles in health and disease. Most previous work has relied on studying bacteria and viruses independently, thereby reducing them to two separate communities. Such approaches are unable to capture how these microbial communities interact, such as through processes that maintain community robustness or allow phage-host populations to co-evolve. We implemented a network-based analytical approach to describe phage-bacteria network diversity throughout the human body. We built these community networks using a machine learning algorithm to predict which phages could infect which bacteria in a given microbiome. Our algorithm was applied to paired viral and bacterial metagenomic sequence sets from three previously published human cohorts. We organized the predicted interactions into networks that allowed us to evaluate phage-bacteria connectedness across the human body. We observed evidence that gut and skin network structures were person-specific and not conserved among cohabitating family members. High-fat diets appeared to be associated with less connected networks. Network structure differed between skin sites, with those exposed to the external environment being less connected and likely more susceptible to network degradation by microbial extinction events. This study quantified and contrasted the diversity of virome-microbiome networks across the human body and illustrated how environmental factors may influence phage-bacteria interactive dynamics. This work provides a baseline for future studies to better understand system perturbations, such as disease states, through ecological networks., The human microbiome, the collection of microbial communities that colonize the human body, is a crucial component to health and disease. Two major components of the human microbiome are the bacterial and viral communities. These communities have primarily been studied separately using metrics of community composition and diversity. These approaches have failed to capture the complex dynamics of interacting bacteria and phage communities, which frequently share genetic information and work together to maintain ecosystem homestatsis (e.g. kill-the-winner dynamics). Removal of bacteria or phage can disrupt or even collapse those ecosystems. Relationship-based network approaches allow us to capture this interaction information. Using this network-based approach with three independent human cohorts, we were able to present an initial understanding of how phage-bacteria networks differ throughout the human body, so as to provide a baseline for future studies of how and why microbiome networks differ in disease states.",2018-04-18,2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:36:32,,4,14,PLoS Comput Biol,,PubMed Central,PMID: 29668682 PMCID: PMC5927471,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5927471/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
517,10.1371/journal.pcbi.1006790,30726205,PMC6380598,,,,"Dunn, Nathan A.; Unni, Deepak R.; Diesh, Colin; Munoz-Torres, Monica; Harris, Nomi L.; Yao, Eric; Rasche, Helena; Holmes, Ian H.; Elsik, Christine G.; Lewis, Suzanna E.",Apollo: Democratizing genome annotation,2019,PLoS Computational Biology,,"Genome annotation is the process of identifying the location and function of a genome's encoded features. Improving the biological accuracy of annotation is a complex and iterative process requiring researchers to review and incorporate multiple sources of information such as transcriptome alignments, predictive models based on sequence profiles, and comparisons to features found in related organisms. Because rapidly decreasing costs are enabling an ever-growing number of scientists to incorporate sequencing as a routine laboratory technique, there is widespread demand for tools that can assist in the deliberative analytical review of genomic information. To this end, we present Apollo, an open source software package that enables researchers to efficiently inspect and refine the precise structure and role of genomic features in a graphical browser-based platform. Some of Apollo’s newer user interface features include support for real-time collaboration, allowing distributed users to simultaneously edit the same encoded features while also instantly seeing the updates made by other researchers on the same region in a manner similar to Google Docs. Its technical architecture enables Apollo to be integrated into multiple existing genomic analysis pipelines and heterogeneous laboratory workflow platforms. Finally, we consider the implications that Apollo and related applications may have on how the results of genome research are published and made accessible.",2019-02-06,2021-06-05 21:10:37,,2,15,PLoS Comput Biol,Apollo,PubMed Central,PMID: 30726205 PMCID: PMC6380598,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6380598/,,,,PMC:Query2
518,10.1371/journal.pcbi.1006856,30849072,PMC6426265,,,,"Yang, Pei-Chi; Purawat, Shweta; Ieong, Pek U.; Jeng, Mao-Tsuen; DeMarco, Kevin R.; Vorobyov, Igor; McCulloch, Andrew D.; Altintas, Ilkay; Amaro, Rommie E.; Clancy, Colleen E.","A demonstration of modularity, reuse, reproducibility, portability and scalability for modeling and simulation of cardiac electrophysiology using Kepler Workflows",2019,PLoS Computational Biology,,"Multi-scale computational modeling is a major branch of computational biology as evidenced by the US federal interagency Multi-Scale Modeling Consortium and major international projects. It invariably involves specific and detailed sequences of data analysis and simulation, often with multiple tools and datasets, and the community recognizes improved modularity, reuse, reproducibility, portability and scalability as critical unmet needs in this area. Scientific workflows are a well-recognized strategy for addressing these needs in scientific computing. While there are good examples if the use of scientific workflows in bioinformatics, medical informatics, biomedical imaging and data analysis, there are fewer examples in multi-scale computational modeling in general and cardiac electrophysiology in particular. Cardiac electrophysiology simulation is a mature area of multi-scale computational biology that serves as an excellent use case for developing and testing new scientific workflows. In this article, we develop, describe and test a computational workflow that serves as a proof of concept of a platform for the robust integration and implementation of a reusable and reproducible multi-scale cardiac cell and tissue model that is expandable, modular and portable. The workflow described leverages Python and Kepler-Python actor for plotting and pre/post-processing. During all stages of the workflow design, we rely on freely available open-source tools, to make our workflow freely usable by scientists., We present a computational workflow as a proof of concept for integration and implementation of a reusable and reproducible cardiac multi-scale electrophysiology model that is expandable, modular and portable. This framework enables scientists to create intuitive, user-friendly and flexible end-to-end automated scientific workflows using a graphical user interface. Kepler is an advanced open-source platform that supports multiple models of computation. The underlying workflow engine handles scalability, provenance, reproducibility aspects of the code, performs orchestration of data flow, and automates execution on heterogeneous computing resources. One of the main advantages of workflow utilization is the integration of code written in multiple languages Standardization occurs at the interfaces of the workflow elements and allows for general applications and easy comparison and integration of code from different research groups or even multiple programmers coding in different languages for various purposes from the same group. A workflow driven problem-solving approach enables domain scientists to focus on resolving the core science questions, and delegates the computational and process management burden to the underlying Workflow. The workflow driven approach allows scaling the computational experiment with distributed data-parallel execution on multiple computing platforms, such as, HPC resources, GPU clusters, Cloud etc. The workflow framework tracks software version information along with hardware information to allow users an opportunity to trace any variation in workflow outcome to the system configurations.",2019-03-08,2021-06-05 21:10:37,,3,15,PLoS Comput Biol,,PubMed Central,PMID: 30849072 PMCID: PMC6426265,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6426265/,,,,PMC:Query2
519,10.1371/journal.pcbi.1007384,31652258,PMC6834280,,,,"Franzese, Nicholas; Groce, Adam; Murali, T. M.; Ritz, Anna",Hypergraph-based connectivity measures for signaling pathway topologies,2019,PLoS Computational Biology,,"Characterizing cellular responses to different extrinsic signals is an active area of research, and curated pathway databases describe these complex signaling reactions. Here, we revisit a fundamental question in signaling pathway analysis: are two molecules “connected” in a network? This question is the first step towards understanding the potential influence of molecules in a pathway, and the answer depends on the choice of modeling framework. We examined the connectivity of Reactome signaling pathways using four different pathway representations. We find that Reactome is very well connected as a graph, moderately well connected as a compound graph or bipartite graph, and poorly connected as a hypergraph (which captures many-to-many relationships in reaction networks). We present a novel relaxation of hypergraph connectivity that iteratively increases connectivity from a node while preserving the hypergraph topology. This measure, B-relaxation distance, provides a parameterized transition between hypergraph connectivity and graph connectivity. B-relaxation distance is sensitive to the presence of small molecules that participate in many functionally unrelated reactions in the network. We also define a score that quantifies one pathway’s downstream influence on another, which can be calculated as B-relaxation distance gradually relaxes the connectivity constraint in hypergraphs. Computing this score across all pairs of 34 Reactome pathways reveals pairs of pathways with statistically significant influence. We present two such case studies, and we describe the specific reactions that contribute to the large influence score. Finally, we investigate the ability for connectivity measures to capture functional relationships among proteins, and use the evidence channels in the STRING database as a benchmark dataset. STRING interactions whose proteins are B-connected in Reactome have statistically significantly higher scores than interactions connected in the bipartite graph representation. Our method lays the groundwork for other generalizations of graph-theoretic concepts to hypergraphs in order to facilitate signaling pathway analysis., Signaling pathways describe how cells respond to external signals through molecular interactions. As we gain a deeper understanding of these signaling reactions, it is important to understand how molecules may influence downstream responses and how pathways may affect each other. As the amount of information in signaling pathway databases continues to grow, we have the opportunity to analyze properties about pathway structure. We pose an intuitive question about signaling pathways: when are two molecules “connected” in a pathway? This answer varies dramatically based on the assumptions we make about how reactions link molecules. Here, examine four approaches for modeling the structural topology of signaling pathways, and present methods to quantify whether two molecules are “connected” in a pathway database. We find that existing approaches are either too permissive (molecules are connected to many others) or restrictive (molecules are connected to a handful of others), and we present a new measure that offers a continuum between these two extremes. We then expand our question to ask when an entire signaling pathway is “downstream” of another pathway, and show two case studies from the Reactome pathway database that uncovers pathway influence. Finally, we show that the strict notion of connectivity can capture functional relationships among proteins using an independent benchmark dataset. Our approach to quantify connectivity in pathways considers a biologically-motivated definition of connectivity, laying the foundation for more sophisticated analyses that leverage the detailed information in pathway databases.",2019-10-25,2021-06-05 21:10:37,,10,15,PLoS Comput Biol,,PubMed Central,PMID: 31652258 PMCID: PMC6834280,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6834280/,,,,PMC:Query2
520,10.1371/journal.pcbi.1007616,32012148,PMC7043350,A,Neo4j,Neo4j,"Arloth, Janine; Eraslan, Gökcen; Andlauer, Till F. M.; Martins, Jade; Iurato, Stella; Kühnel, Brigitte; Waldenberger, Melanie; Frank, Josef; Gold, Ralf; Hemmer, Bernhard; Luessi, Felix; Nischwitz, Sandra; Paul, Friedemann; Wiendl, Heinz; Gieger, Christian; Heilmann-Heimbach, Stefanie; Kacprowski, Tim; Laudes, Matthias; Meitinger, Thomas; Peters, Annette; Rawal, Rajesh; Strauch, Konstantin; Lucae, Susanne; Müller-Myhsok, Bertram; Rietschel, Marcella; Theis, Fabian J.; Binder, Elisabeth B.; Mueller, Nikola S.",DeepWAS: Multivariate genotype-phenotype associations by directly integrating regulatory information using deep learning,2020,PLoS Computational Biology,,"Genome-wide association studies (GWAS) identify genetic variants associated with traits or diseases. GWAS never directly link variants to regulatory mechanisms. Instead, the functional annotation of variants is typically inferred by post hoc analyses. A specific class of deep learning-based methods allows for the prediction of regulatory effects per variant on several cell type-specific chromatin features. We here describe “DeepWAS”, a new approach that integrates these regulatory effect predictions of single variants into a multivariate GWAS setting. Thereby, single variants associated with a trait or disease are directly coupled to their impact on a chromatin feature in a cell type. Up to 61 regulatory SNPs, called dSNPs, were associated with multiple sclerosis (MS, 4,888 cases and 10,395 controls), major depressive disorder (MDD, 1,475 cases and 2,144 controls), and height (5,974 individuals). These variants were mainly non-coding and reached at least nominal significance in classical GWAS. The prediction accuracy was higher for DeepWAS than for classical GWAS models for 91% of the genome-wide significant, MS-specific dSNPs. DSNPs were enriched in public or cohort-matched expression and methylation quantitative trait loci and we demonstrated the potential of DeepWAS to generate testable functional hypotheses based on genotype data alone. DeepWAS is available at https://github.com/cellmapslab/DeepWAS., In the era of steadily increasing amounts of available genetic data, we still lack novel and innovative ideas on how to improve fine-mapping of regulatory variants identified by genome-wide association studies (GWAS), especially in non-coding regions. Current approaches for the identification of functional variants conduct functional annotation after the GWAS analysis either using position-based overlaps of each variant with regulatory elements or deep-learning-based methods predicting regulatory effects per variant on cell-type-specific chromatin features. We here present DeepWAS, which integrates these regulatory effect predictions of single variants into a multivariate GWAS setting. Our results provide evidence that DeepWAS results directly identify disease/trait-associated SNPs with a common effect on a specific chromatin feature in a relevant tissue. We can show for multiple sclerosis, major depressive disorder, and body height, that the SNPs identified by DeepWAS are at least nominally significant in classical univariate GWAS analysis of the same cohorts or larger published GWAS. By integrating expression and methylation quantitative trait loci (eQTL and meQTL) information of multiple resources and tissues, we can show that DeepWAS identifies disease/trait-relevant transcriptionally active genomic loci. We demonstrate that DeepWAS identifies both known variants and highlights underlying molecular mechanisms.",2020-02-03,2021-06-05 20:35:57; 2021-06-05 20:55:01; 2021-06-05 21:10:08,,2,16,PLoS Comput Biol,DeepWAS,PubMed Central,PMID: 32012148 PMCID: PMC7043350,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7043350/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
521,10.1371/journal.pcbi.1008376,33232313,PMC7685442,A,Neo4j,Neo4j,"Thessen, Anne E.; Walls, Ramona L.; Vogt, Lars; Singer, Jessica; Warren, Robert; Buttigieg, Pier Luigi; Balhoff, James P.; Mungall, Christopher J.; McGuinness, Deborah L.; Stucky, Brian J.; Yoder, Matthew J.; Haendel, Melissa A.",Transforming the study of organisms: Phenomic data models and knowledge bases,2020,PLoS Computational Biology,,"The rapidly decreasing cost of gene sequencing has resulted in a deluge of genomic data from across the tree of life; however, outside a few model organism databases, genomic data are limited in their scientific impact because they are not accompanied by computable phenomic data. The majority of phenomic data are contained in countless small, heterogeneous phenotypic data sets that are very difficult or impossible to integrate at scale because of variable formats, lack of digitization, and linguistic problems. One powerful solution is to represent phenotypic data using data models with precise, computable semantics, but adoption of semantic standards for representing phenotypic data has been slow, especially in biodiversity and ecology. Some phenotypic and trait data are available in a semantic language from knowledge bases, but these are often not interoperable. In this review, we will compare and contrast existing ontology and data models, focusing on nonhuman phenotypes and traits. We discuss barriers to integration of phenotypic data and make recommendations for developing an operationally useful, semantically interoperable phenotypic data ecosystem., Organism traits determine the role of species in economies and ecosystems, and the expression of those traits relies on interactions between an organism’s genes and environment. The key to predicting trait expression is having a large pool of data to derive models, but most organism trait observations are recorded in ways that are not computational. In this paper, intended for an interdisciplinary audience, we discuss data models for representing organism traits in a computable format. Increasing acceptance of a data model for traits will greatly increase the pool of available data for studying the dynamic processes that determine trait expression. We hope that explaining these data models in a straightforward way and articulating their potential for accelerating discovery will increase adoption of this promising data standard.",2020-11-24,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,11,16,PLoS Comput Biol,Transforming the study of organisms,PubMed Central,PMID: 33232313 PMCID: PMC7685442,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7685442/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
522,10.1371/journal.pgen.1008057,30875366,PMC6436758,,,,"Liaud, Nadège; Horlbeck, Max A.; Gilbert, Luke A.; Gjoni, Ketrin; Weissman, Jonathan S.; Cate, Jamie H. D.",Cellular response to small molecules that selectively stall protein synthesis by the ribosome,2019,PLoS Genetics,,"Identifying small molecules that inhibit protein synthesis by selectively stalling the ribosome constitutes a new strategy for therapeutic development. Compounds that inhibit the translation of PCSK9, a major regulator of low-density lipoprotein cholesterol, have been identified that reduce LDL cholesterol in preclinical models and that affect the translation of only a few off-target proteins. Although some of these compounds hold potential for future therapeutic development, it is not known how they impact the physiology of cells or ribosome quality control pathways. Here we used a genome-wide CRISPRi screen to identify proteins and pathways that modulate cell growth in the presence of high doses of a selective PCSK9 translational inhibitor, PF-06378503 (PF8503). The two most potent genetic modifiers of cell fitness in the presence of PF8503, the ubiquitin binding protein ASCC2 and helicase ASCC3, bind to the ribosome and protect cells from toxic effects of high concentrations of the compound. Surprisingly, translation quality control proteins Pelota (PELO) and HBS1L sensitize cells to PF8503 treatment. In genetic interaction experiments, ASCC3 acts together with ASCC2, and functions downstream of HBS1L. Taken together, these results identify new connections between ribosome quality control pathways, and provide new insights into the selectivity of compounds that stall human translation that will aid the development of next-generation selective translation stalling compounds to treat disease., A fundamentally new approach to treat human diseases caused by “undruggable” proteins would be to use small molecules to selectively inhibit their synthesis by the ribosome. Here we compare two related compounds (PF846, PF8503) that selectively stall human translation to the effects of a more general translation inhibitor, homoharringtonin. We used genome-wide approaches to probe the effects of these compounds, including measurements of which messenger RNAs are being translated and the effects of knocking down gene expression on cell growth. These experiments revealed new and surprising genetic connections between ribosome quality control pathways. We then used biochemical and cell-based experiments to test the involvement of particular ribosome quality control proteins such as ASCC2, ASCC3 and HBS1L in the physiological response of cells to translation inhibitors. The genetic and biochemical insights presented here should aid the development of next-generation selective translation inhibitors to treat disease.",2019-03-15,2021-06-05 21:10:37,,3,15,PLoS Genet,,PubMed Central,PMID: 30875366 PMCID: PMC6436758,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6436758/,,,,PMC:Query2
523,10.1371/journal.pntd.0001458,22272365,PMC3260319,A,Virtuoso,Virtuoso,"Parikh, Priti P.; Minning, Todd A.; Nguyen, Vinh; Lalithsena, Sarasi; Asiaee, Amir H.; Sahoo, Satya S.; Doshi, Prashant; Tarleton, Rick; Sheth, Amit P.",A Semantic Problem Solving Environment for Integrative Parasite Research: Identification of Intervention Targets for Trypanosoma cruzi,2012,PLoS Neglected Tropical Diseases,,"Effective research in parasite biology requires analyzing experimental lab data in the context of constantly expanding public data resources. Integrating lab data with public resources is particularly difficult for biologists who may not possess significant computational skills to acquire and process heterogeneous data stored at different locations. Therefore, we develop a semantic problem solving environment (SPSE) that allows parasitologists to query their lab data integrated with public resources using ontologies. An ontology specifies a common vocabulary and formal relationships among the terms that describe an organism, and experimental data and processes in this case. SPSE supports capturing and querying provenance information, which is metadata on the experimental processes and data recorded for reproducibility, and includes a visual query-processing tool to formulate complex queries without learning the query language syntax. We demonstrate the significance of SPSE in identifying gene knockout targets for T. cruzi. The overall goal of SPSE is to help researchers discover new or existing knowledge that is implicitly present in the data but not always easily detected. Results demonstrate improved usefulness of SPSE over existing lab systems and approaches, and support for complex query design that is otherwise difficult to achieve without the knowledge of query language syntax.",2012-01-17,2021-06-05 21:13:27; 2021-06-05 20:56:20; 2021-06-05 20:59:14,,1,6,PLoS Negl Trop Dis,A Semantic Problem Solving Environment for Integrative Parasite Research,PubMed Central,PMID: 22272365 PMCID: PMC3260319,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3260319/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
524,10.1371/journal.pone.0008057,20016828,PMC2790089,,,,"Dehmer, Matthias; Barbarini, Nicola; Varmuza, Kurt; Graber, Armin",A Large Scale Analysis of Information-Theoretic Network Complexity Measures Using Chemical Structures,2009,PLoS ONE,,"This paper aims to investigate information-theoretic network complexity measures which have already been intensely used in mathematical- and medicinal chemistry including drug design. Numerous such measures have been developed so far but many of them lack a meaningful interpretation, e.g., we want to examine which kind of structural information they detect. Therefore, our main contribution is to shed light on the relatedness between some selected information measures for graphs by performing a large scale analysis using chemical networks. Starting from several sets containing real and synthetic chemical structures represented by graphs, we study the relatedness between a classical (partition-based) complexity measure called the topological information content of a graph and some others inferred by a different paradigm leading to partition-independent measures. Moreover, we evaluate the uniqueness of network complexity measures numerically. Generally, a high uniqueness is an important and desirable property when designing novel topological descriptors having the potential to be applied to large chemical databases.",2009-12-15,2021-06-05 21:13:27,,12,4,PLoS One,,PubMed Central,PMID: 20016828 PMCID: PMC2790089,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2790089/,,,,PMC:Query2
525,10.1371/journal.pone.0031214,22393358,PMC3290601,,,,"Dehmer, Matthias; Grabner, Martin; Varmuza, Kurt",Information Indices with High Discriminative Power for Graphs,2012,PLoS ONE,,"In this paper, we evaluate the uniqueness of several information-theoretic measures for graphs based on so-called information functionals and compare the results with other information indices and non-information-theoretic measures such as the well-known Balaban  index. We show that, by employing an information functional based on degree-degree associations, the resulting information index outperforms the Balaban  index tremendously. These results have been obtained by using nearly 12 million exhaustively generated, non-isomorphic and unweighted graphs. Also, we obtain deeper insights on these and other topological descriptors when exploring their uniqueness by using exhaustively generated sets of alkane trees representing connected and acyclic graphs in which the degree of a vertex is at most four.",2012-02-29,2021-06-05 21:13:27,,2,7,PLoS One,,PubMed Central,PMID: 22393358 PMCID: PMC3290601,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3290601/,,,,PMC:Query2
526,10.1371/journal.pone.0050821,23272073,PMC3522720,,,,"Zhao, Liang; Hoi, Steven C. H.; Wong, Limsoon; Hamp, Tobias; Li, Jinyan",Structural and Functional Analysis of Multi-Interface Domains,2012,PLoS ONE,,"A multi-interface domain is a domain that can shape multiple and distinctive binding sites to contact with many other domains, forming a hub in domain-domain interaction networks. The functions played by the multiple interfaces are usually different, but there is no strict bijection between the functions and interfaces as some subsets of the interfaces play the same function. This work applies graph theory and algorithms to discover fingerprints for the multiple interfaces of a domain and to establish associations between the interfaces and functions, based on a huge set of multi-interface proteins from PDB. We found that about 40% of proteins have the multi-interface property, however the involved multi-interface domains account for only a tiny fraction (1.8%) of the total number of domains. The interfaces of these domains are distinguishable in terms of their fingerprints, indicating the functional specificity of the multiple interfaces in a domain. Furthermore, we observed that both cooperative and distinctive structural patterns, which will be useful for protein engineering, exist in the multiple interfaces of a domain.",2012-12-14,2021-06-05 21:13:27,,12,7,PLoS One,,PubMed Central,PMID: 23272073 PMCID: PMC3522720,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3522720/,,,,PMC:Query2
527,10.1371/journal.pone.0058363,23484021,PMC3590154,,,,"Corbacho, Jorge; Romojaro, Félix; Pech, Jean-Claude; Latché, Alain; Gomez-Jimenez, Maria C.",Transcriptomic Events Involved in Melon Mature-Fruit Abscission Comprise the Sequential Induction of Cell-Wall Degrading Genes Coupled to a Stimulation of Endo and Exocytosis,2013,PLoS ONE,,"Background Mature-fruit abscission (MFA) in fleshy-fruit is a genetically controlled process with mechanisms that, contrary to immature-fruit abscission, has not been fully characterized. Here, we use pyrosequencing to characterize the transcriptomes of melon abscission zone (AZ) at three stages during AZ-cell separation in order to understand MFA control at an early stage of AZ-activation. Principal Findings The results show that by early induction of MFA, the melon AZ exhibits major gene induction, while by late induction of MFA, melon AZ shows major gene repression. Although some genes displayed similar regulation in both early and late induction of abscission, such as EXT1-EXT4, EGase1, IAA2, ERF1, AP2D15, FLC, MADS2, ERAF17, SAP5 and SCL13 genes, the majority had different expression patterns. This implies that time-specific events occur during MFA, and emphasizes the value of characterizing multiple time-specific abscission transcriptomes. Analysis of gene-expression from these AZs reveal that a sequential induction of cell-wall-degrading genes is associated with the upregulation of genes involved in endo and exocytosis, and a shift in plant-hormone metabolism and signaling genes during MFA. This is accompanied by transcriptional activity of small-GTPases and synthaxins together with tubulins, dynamins, V-type ATPases and kinesin-like proteins potentially involved in MFA signaling. Early events are potentially controlled by down-regulation of MADS-box, AP2/ERF and Aux/IAA transcription-factors, and up-regulation of homeobox, zinc finger, bZIP, and WRKY transcription-factors, while late events may be controlled by up-regulation of MYB transcription-factors. Significance Overall, the data provide a comprehensive view on MFA in fleshy-fruit, identifying candidate genes and pathways associated with early induction of MFA. Our comprehensive gene-expression profile will be very useful for elucidating gene regulatory networks of the MFA in fleshy-fruit.",2013-03-06,2021-06-05 21:13:27,,3,8,PLoS One,,PubMed Central,PMID: 23484021 PMCID: PMC3590154,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3590154/,,,,PMC:Query2
528,10.1371/journal.pone.0076911,24167551,PMC3805575,,,,"Giugno, Rosalba; Bonnici, Vincenzo; Bombieri, Nicola; Pulvirenti, Alfredo; Ferro, Alfredo; Shasha, Dennis",GRAPES: A Software for Parallel Searching on Biological Graphs Targeting Multi-Core Architectures,2013,PLoS ONE,,"Biological applications, from genomics to ecology, deal with graphs that represents the structure of interactions. Analyzing such data requires searching for subgraphs in collections of graphs. This task is computationally expensive. Even though multicore architectures, from commodity computers to more advanced symmetric multiprocessing (SMP), offer scalable computing power, currently published software implementations for indexing and graph matching are fundamentally sequential. As a consequence, such software implementations (i) do not fully exploit available parallel computing power and (ii) they do not scale with respect to the size of graphs in the database. We present GRAPES, software for parallel searching on databases of large biological graphs. GRAPES implements a parallel version of well-established graph searching algorithms, and introduces new strategies which naturally lead to a faster parallel searching system especially for large graphs. GRAPES decomposes graphs into subcomponents that can be efficiently searched in parallel. We show the performance of GRAPES on representative biological datasets containing antiviral chemical compounds, DNA, RNA, proteins, protein contact maps and protein interactions networks.",2013-10-22,2021-06-05 21:13:27,,10,8,PLoS One,GRAPES,PubMed Central,PMID: 24167551 PMCID: PMC3805575,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3805575/,,,,PMC:Query2
529,10.1371/journal.pone.0082160,24340000,PMC3855388,A,Neo4j,Neo4j,"Kutmon, Martina; Kelder, Thomas; Mandaviya, Pooja; Evelo, Chris T. A.; Coort, Susan L.",CyTargetLinker: A Cytoscape App to Integrate Regulatory Interactions in Network Analysis,2013,PLoS ONE,,"Introduction The high complexity and dynamic nature of the regulation of gene expression, protein synthesis, and protein activity pose a challenge to fully understand the cellular machinery. By deciphering the role of important players, including transcription factors, microRNAs, or small molecules, a better understanding of key regulatory processes can be obtained. Various databases contain information on the interactions of regulators with their targets for different organisms, data recently being extended with the results of the ENCODE (Encyclopedia of DNA Elements) project. A systems biology approach integrating our understanding on different regulators is essential in interpreting the regulation of molecular biological processes. Implementation We developed CyTargetLinker (http://projects.bigcat.unimaas.nl/cytargetlinker), a Cytoscape app, for integrating regulatory interactions in network analysis. Recently we released CyTargetLinker as one of the first apps for Cytoscape 3. It provides a user-friendly and flexible interface to extend biological networks with regulatory interactions, such as microRNA-target, transcription factor-target and/or drug-target. Importantly, CyTargetLinker employs identifier mapping to combine various interaction data resources that use different types of identifiers. Results Three case studies demonstrate the strength and broad applicability of CyTargetLinker, (i) extending a mouse molecular interaction network, containing genes linked to diabetes mellitus, with validated and predicted microRNAs, (ii) enriching a molecular interaction network, containing DNA repair genes, with ENCODE transcription factor and (iii) building a regulatory meta-network in which a biological process is extended with information on transcription factor, microRNA and drug regulation. Conclusions CyTargetLinker provides a simple and extensible framework for biologists and bioinformaticians to integrate different regulatory interactions into their network analysis approaches. Visualization options enable biological interpretation of complex regulatory networks in a graphical way. Importantly the incorporation of our tool into the Cytoscape framework allows the application of CyTargetLinker in combination with a wide variety of other apps for state-of-the-art network analysis.",2013-12-05,2021-06-05 21:13:27; 2021-06-05 20:56:20; 2021-06-05 20:37:08,,12,8,PLoS One,CyTargetLinker,PubMed Central,PMID: 24340000 PMCID: PMC3855388,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3855388/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
530,10.1371/journal.pone.0097178,24853266,PMC4031119,,,,"Zhu, Lei; Song, Qinbao; Guo, Yuchen; Du, Lei; Zhu, Xiaoyan; Wang, Guangtao",A Coding Method for Efficient Subgraph Querying on Vertex- and Edge-Labeled Graphs; A coding method for efficient subgraph querying on vertex- and edge-labeled graphs,2014,PLoS ONE; PloS One,,"Labeled graphs are widely used to model complex data in many domains, so subgraph querying has been attracting more and more attention from researchers around the world. Unfortunately, subgraph querying is very time consuming since it involves subgraph isomorphism testing that is known to be an NP-complete problem. In this paper, we propose a novel coding method for subgraph querying that is based on Laplacian spectrum and the number of walks. Our method follows the filtering-and-verification framework and works well on graph databases with frequent updates. We also propose novel two-step filtering conditions that can filter out most false positives and prove that the two-step filtering conditions satisfy the no-false-negative requirement (no dismissal in answers). Extensive experiments on both real and synthetic graphs show that, compared with six existing counterpart methods, our method can effectively improve the efficiency of subgraph querying.",2014-05-22; 2014,2021-06-05 21:13:27; 2021-06-05 21:06:22,e97178,5,9,PLoS One,,PubMed; PubMed Central,PMID: 24853266 PMCID: PMC4031119,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4031119/; http://www.ncbi.nlm.nih.gov/pubmed/24853266,"Computational Biology; Information Storage and Retrieval; Models, Theoretical; Programming Languages; Search Engine; Software",,,PubMed:Query2; PMC:Query2
531,10.1371/journal.pone.0128089,26030752,PMC4451068,A,Neo4j,Neo4j,"Chiang, Kevin; Shu, Jiang; Zempleni, Janos; Cui, Juan",Dietary MicroRNA Database (DMD): An Archive Database and Analytic Tool for Food-Borne microRNAs,2015,PLoS ONE,,"With the advent of high throughput technology, a huge amount of microRNA information has been added to the growing body of knowledge for non-coding RNAs. Here we present the Dietary MicroRNA Databases (DMD), the first repository for archiving and analyzing the published and novel microRNAs discovered in dietary resources. Currently there are fifteen types of dietary species, such as apple, grape, cow milk, and cow fat, included in the database originating from 9 plant and 5 animal species. Annotation for each entry, a mature microRNA indexed as DM0000*, covers information of the mature sequences, genome locations, hairpin structures of parental pre-microRNAs, cross-species sequence comparison, disease relevance, and the experimentally validated gene targets. Furthermore, a few functional analyses including target prediction, pathway enrichment and gene network construction have been integrated into the system, which enable users to generate functional insights through viewing the functional pathways and building protein-protein interaction networks associated with each microRNA. Another unique feature of DMD is that it provides a feature generator where a total of 411 descriptive attributes can be calculated for any given microRNAs based on their sequences and structures. DMD would be particularly useful for research groups studying microRNA regulation from a nutrition point of view. The database can be accessed at http://sbbi.unl.edu/dmd/.",2015-06-01,2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-05 20:37:08,,6,10,PLoS One,Dietary MicroRNA Database (DMD),PubMed Central,PMID: 26030752 PMCID: PMC4451068,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4451068/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
532,10.1371/journal.pone.0128752,26065899,PMC4465747,,,,"Springer, Nathaniel P.; Garbach, Kelly; Guillozet, Kathleen; Haden, Van R.; Hedao, Prashant; Hollander, Allan D.; Huber, Patrick R.; Ingersoll, Christina; Langner, Megan; Lipari, Genevieve; Mohammadi, Yaser; Musker, Ruthie; Piatto, Marina; Riggle, Courtney; Schweisguth, Melissa; Sin, Emily; Snider, Sara; Vidic, Nataša; White, Aubrey; Brodt, Sonja; Quinn, James F.; Tomich, Thomas P.",Sustainable Sourcing of Global Agricultural Raw Materials: Assessing Gaps in Key Impact and Vulnerability Issues and Indicators,2015,PLoS ONE,,"Understanding how to source agricultural raw materials sustainably is challenging in today’s globalized food system given the variety of issues to be considered and the multitude of suggested indicators for representing these issues. Furthermore, stakeholders in the global food system both impact these issues and are themselves vulnerable to these issues, an important duality that is often implied but not explicitly described. The attention given to these issues and conceptual frameworks varies greatly—depending largely on the stakeholder perspective—as does the set of indicators developed to measure them. To better structure these complex relationships and assess any gaps, we collate a comprehensive list of sustainability issues and a database of sustainability indicators to represent them. To assure a breadth of inclusion, the issues are pulled from the following three perspectives: major global sustainability assessments, sustainability communications from global food companies, and conceptual frameworks of sustainable livelihoods from academic publications. These terms are integrated across perspectives using a common vocabulary, classified by their relevance to impacts and vulnerabilities, and categorized into groups by economic, environmental, physical, human, social, and political characteristics. These issues are then associated with over 2,000 sustainability indicators gathered from existing sources. A gap analysis is then performed to determine if particular issues and issue groups are over or underrepresented. This process results in 44 “integrated” issues—24 impact issues and 36 vulnerability issues —that are composed of 318 “component” issues. The gap analysis shows that although every integrated issue is mentioned at least 40% of the time across perspectives, no issue is mentioned more than 70% of the time. A few issues infrequently mentioned across perspectives also have relatively few indicators available to fully represent them. Issues in the impact framework generally have fewer gaps than those in the vulnerability framework.",2015-06-11,2021-06-05 21:12:40,,6,10,PLoS One,Sustainable Sourcing of Global Agricultural Raw Materials,PubMed Central,PMID: 26065899 PMCID: PMC4465747,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4465747/,,,,PMC:Query2
533,10.1371/journal.pone.0141892,26720074,PMC4699901,A,Neo4j,Neo4j,"Kämpf, Mirko; Tessenow, Eric; Kenett, Dror Y.; Kantelhardt, Jan W.",The Detection of Emerging Trends Using Wikipedia Traffic Data and Context Networks,2015,PLoS ONE,,"Can online media predict new and emerging trends, since there is a relationship between trends in society and their representation in online systems? While several recent studies have used Google Trends as the leading online information source to answer corresponding research questions, we focus on the online encyclopedia Wikipedia often used for deeper topical reading. Wikipedia grants open access to all traffic data and provides lots of additional (semantic) information in a context network besides single keywords. Specifically, we suggest and study context-normalized and time-dependent measures for a topic’s importance based on page-view time series of Wikipedia articles in different languages and articles related to them by internal links. As an example, we present a study of the recently emerging Big Data market with a focus on the Hadoop ecosystem, and compare the capabilities of Wikipedia versus Google in predicting its popularity and life cycles. To support further applications, we have developed an open web platform to share results of Wikipedia analytics, providing context-rich and language-independent relevance measures for emerging trends.",2015-12-31,2021-06-05 20:55:40; 2021-06-05 21:12:40; 2021-06-05 20:37:08,,12,10,PLoS One,,PubMed Central,PMID: 26720074 PMCID: PMC4699901,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4699901/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
534,10.1371/journal.pone.0144578,26656740,PMC4684231,A,Virtuoso; Neo4j,Virtuoso; Neo4j,"Alocci, Davide; Mariethoz, Julien; Horlacher, Oliver; Bolleman, Jerven T.; Campbell, Matthew P.; Lisacek, Frederique",Property Graph vs RDF Triple Store: A Comparison on Glycan Substructure Search,2015,PLoS ONE; PloS One,,"Resource description framework (RDF) and Property Graph databases are emerging technologies that are used for storing graph-structured data. We compare these technologies through a molecular biology use case: glycan substructure search. Glycans are branched tree-like molecules composed of building blocks linked together by chemical bonds. The molecular structure of a glycan can be encoded into a direct acyclic graph where each node represents a building block and each edge serves as a chemical linkage between two building blocks. In this context, Graph databases are possible software solutions for storing glycan structures and Graph query languages, such as SPARQL and Cypher, can be used to perform a substructure search. Glycan substructure searching is an important feature for querying structure and experimental glycan databases and retrieving biologically meaningful data. This applies for example to identifying a region of the glycan recognised by a glycan binding protein (GBP). In this study, 19,404 glycan structures were selected from GlycomeDB (www.glycome-db.org) and modelled for being stored into a RDF triple store and a Property Graph. We then performed two different sets of searches and compared the query response times and the results from both technologies to assess performance and accuracy. The two implementations produced the same results, but interestingly we noted a difference in the query response times. Qualitative measures such as portability were also used to define further criteria for choosing the technology adapted to solving glycan substructure search and other comparable issues.",2015; 2015-12-14,2021-06-05 21:06:22; 2021-06-05 21:12:40; 2021-06-05 20:59:14; 2021-06-05 20:37:08; 2021-06-05 20:55:40,e0144578,12,10,PLoS One,Property Graph vs RDF Triple Store,PubMed; PubMed Central,PMID: 26656740 PMCID: PMC4684231,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4684231/; http://www.ncbi.nlm.nih.gov/pubmed/26656740,"Computational Biology; Databases, Factual; Information Storage and Retrieval; Molecular Structure; Polysaccharides; Software",Virtuoso; Neo4j,Virtuoso; Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PMC:Virtuoso; PubMed:Query2
535,10.1371/journal.pone.0146581,26751378,PMC4709234,,,,"Givon, Lev E.; Lazar, Aurel A.",Neurokernel: An Open Source Platform for Emulating the Fruit Fly Brain,2016,PLoS ONE,,"We have developed an open software platform called Neurokernel for collaborative development of comprehensive models of the brain of the fruit fly Drosophila melanogaster and their execution and testing on multiple Graphics Processing Units (GPUs). Neurokernel provides a programming model that capitalizes upon the structural organization of the fly brain into a fixed number of functional modules to distinguish between these modules’ local information processing capabilities and the connectivity patterns that link them. By defining mandatory communication interfaces that specify how data is transmitted between models of each of these modules regardless of their internal design, Neurokernel explicitly enables multiple researchers to collaboratively model the fruit fly’s entire brain by integration of their independently developed models of its constituent processing units. We demonstrate the power of Neurokernel’s model integration by combining independently developed models of the retina and lamina neuropils in the fly’s visual system and by demonstrating their neuroinformation processing capability. We also illustrate Neurokernel’s ability to take advantage of direct GPU-to-GPU data transfers with benchmarks that demonstrate scaling of Neurokernel’s communication performance both over the number of interface ports exposed by an emulation’s constituent modules and the total number of modules comprised by an emulation.",2016-01-11,2021-06-05 21:12:40,,1,11,PLoS One,Neurokernel,PubMed Central,PMID: 26751378 PMCID: PMC4709234,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4709234/,,,,PMC:Query2
536,10.1371/journal.pone.0151771,26998997,PMC4801359,A,Neo4j,Neo4j,"Preusse, Martin; Theis, Fabian J.; Mueller, Nikola S.",miTALOS v2: Analyzing Tissue Specific microRNA Function,2016,PLoS ONE; PloS One,,"MicroRNAs are involved in almost all biological processes and have emerged as regulators of signaling pathways. We show that miRNA target genes and pathway genes are not uniformly expressed across human tissues. To capture tissue specific effects, we developed a novel methodology for tissue specific pathway analysis of miRNAs. We incorporated the most recent and highest quality miRNA targeting data (TargetScan and StarBase), RNA-seq based gene expression data (EBI Expression Atlas) and multiple new pathway data sources to increase the biological relevance of the predicted miRNA-pathway associations. We identified new potential roles of miR-199a-3p, miR-199b-3p and the miR-200 family in hepatocellular carcinoma, involving the regulation of metastasis through MAPK and Wnt signaling. Also, an association of miR-571 and Notch signaling in liver fibrosis was proposed. To facilitate data update and future extensions of our tool, we developed a flexible database backend using the graph database neo4j. The new backend as well as the novel methodology were included in the updated miTALOS v2, a tool that provides insights into tissue specific miRNA regulation of biological pathways. miTALOS v2 is available at http://mips.helmholtz-muenchen.de/mitalos.",2016-03-21; 2016,2021-06-05 21:06:22; 2021-06-05 21:12:40; 2021-06-05 21:16:51; 2021-06-05 20:37:08; 2021-06-05 20:55:40; 2021-06-05 21:24:28,e0151771,3,11,PLoS One,miTALOS v2,PubMed; PubMed Central,PMID: 26998997 PMCID: PMC4801359,http://www.ncbi.nlm.nih.gov/pubmed/26998997; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4801359/,Animals; Humans; Liver Diseases; Mice; MicroRNAs; Organ Specificity; Software; User-Computer Interface,Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
537,10.1371/journal.pone.0152976,27096157,PMC4838325,A,Neo4j,Neo4j,"Chełkowski, Tadeusz; Gloor, Peter; Jemielniak, Dariusz",Inequalities in Open Source Software Development: Analysis of Contributor’s Commits in Apache Software Foundation Projects,2016,PLoS ONE,,"While researchers are becoming increasingly interested in studying OSS phenomenon, there is still a small number of studies analyzing larger samples of projects investigating the structure of activities among OSS developers. The significant amount of information that has been gathered in the publicly available open-source software repositories and mailing-list archives offers an opportunity to analyze projects structures and participant involvement. In this article, using on commits data from 263 Apache projects repositories (nearly all), we show that although OSS development is often described as collaborative, but it in fact predominantly relies on radically solitary input and individual, non-collaborative contributions. We also show, in the first published study of this magnitude, that the engagement of contributors is based on a power-law distribution.",2016-04-20,2021-06-05 20:55:40; 2021-06-05 21:12:40; 2021-06-05 20:37:08,,4,11,PLoS One,Inequalities in Open Source Software Development,PubMed Central,PMID: 27096157 PMCID: PMC4838325,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4838325/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
538,10.1371/journal.pone.0155417,27192059,PMC4871418,,,,"Thapen, Nicholas; Simmie, Donal; Hankin, Chris; Gillard, Joseph",DEFENDER: Detecting and Forecasting Epidemics Using Novel Data-Analytics for Enhanced Response,2016,PLoS ONE,,"In recent years social and news media have increasingly been used to explain patterns in disease activity and progression. Social media data, principally from the Twitter network, has been shown to correlate well with official disease case counts. This fact has been exploited to provide advance warning of outbreak detection, forecasting of disease levels and the ability to predict the likelihood of individuals developing symptoms. In this paper we introduce DEFENDER, a software system that integrates data from social and news media and incorporates algorithms for outbreak detection, situational awareness and forecasting. As part of this system we have developed a technique for creating a location network for any country or region based purely on Twitter data. We also present a disease nowcasting (forecasting the current but still unknown level) approach which leverages counts from multiple symptoms, which was found to improve the nowcasting accuracy by 37 percent over a model that used only previous case data. Finally we attempt to forecast future levels of symptom activity based on observed user movement on Twitter, finding a moderate gain of 5 percent over a time series forecasting model.",2016-05-18,2021-06-05 21:12:01,,5,11,PLoS One,DEFENDER,PubMed Central,PMID: 27192059 PMCID: PMC4871418,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4871418/,,,,PMC:Query2
539,10.1371/journal.pone.0155811,27196054,PMC4873016,A,Neo4j,Neo4j,"Mullen, Joseph; Cockell, Simon J.; Woollard, Peter; Wipat, Anil",An Integrated Data Driven Approach to Drug Repositioning Using Gene-Disease Associations,2016,PLoS ONE; PloS One,,"Drug development is both increasing in cost whilst decreasing in productivity. There is a general acceptance that the current paradigm of R&D needs to change. One alternative approach is drug repositioning. With target-based approaches utilised heavily in the field of drug discovery, it becomes increasingly necessary to have a systematic method to rank gene-disease associations. Although methods already exist to collect, integrate and score these associations, they are often not a reliable reflection of expert knowledge. Furthermore, the amount of data available in all areas covered by bioinformatics is increasing dramatically year on year. It thus makes sense to move away from more generalised hypothesis driven approaches to research to one that allows data to generate their own hypothesis. We introduce an integrated, data driven approach to drug repositioning. We first apply a Bayesian statistics approach to rank 309,885 gene-disease associations using existing knowledge. Ranked associations are then integrated with other biological data to produce a semantically-rich drug discovery network. Using this network, we show how our approach identifies diseases of the central nervous system (CNS) to be an area of interest. CNS disorders are identified due to the low numbers of such disorders that currently have marketed treatments, in comparison to other therapeutic areas. We then systematically mine our network for semantic subgraphs that allow us to infer drug-disease relations that are not captured in the network. We identify and rank 275,934 drug-disease has_indication associations after filtering those that are more likely to be side effects, whilst commenting on the top ranked associations in more detail. The dataset has been created in Neo4j and is available for download at https://bitbucket.org/ncl-intbio/genediseaserepositioning along with a Java implementation of the searching algorithm.",2016-05-19; 2016,2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 20:37:08; 2021-06-05 21:12:01; 2021-06-05 20:55:40; 2021-06-05 21:24:28,e0155811,5,11,PLoS One,,PubMed; PubMed Central,PMID: 27196054 PMCID: PMC4873016,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4873016/; http://www.ncbi.nlm.nih.gov/pubmed/27196054,Algorithms; Area Under Curve; Bayes Theorem; Central Nervous System; Computational Biology; Computer Graphics; Data Mining; Drug Discovery; Drug Repositioning; Drug-Related Side Effects and Adverse Reactions; Humans; Medical Subject Headings; ROC Curve; Semantics; Software,Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
540,10.1371/journal.pone.0163861,27706199,PMC5051930,A,Neo4j,Neo4j,"Carson, Matthew B.; Scholtens, Denise M.; Frailey, Conor N.; Gravenor, Stephanie J.; Kricke, Gayle E.; Soulakis, Nicholas D.",An Outcome-Weighted Network Model for Characterizing Collaboration,2016,PLoS ONE,,"Shared patient encounters form the basis of collaborative relationships, which are crucial to the success of complex and interdisciplinary teamwork in healthcare. Quantifying the strength of these relationships using shared risk-adjusted patient outcomes provides insight into interactions that occur between healthcare providers. We developed the Shared Positive Outcome Ratio (SPOR), a novel parameter that quantifies the concentration of positive outcomes between a pair of healthcare providers over a set of shared patient encounters. We constructed a collaboration network using hospital emergency department patient data from electronic health records (EHRs) over a three-year period. Based on an outcome indicating patient satisfaction, we used this network to assess pairwise collaboration and evaluate the SPOR. By comparing this network of 574 providers and 5,615 relationships to a set of networks based on randomized outcomes, we identified 295 (5.2%) pairwise collaborations having significantly higher patient satisfaction rates. Our results show extreme high- and low-scoring relationships over a set of shared patient encounters and quantify high variability in collaboration between providers. We identified 29 top performers in terms of patient satisfaction. Providers in the high-scoring group had both a greater average number of associated encounters and a higher percentage of total encounters with positive outcomes than those in the low-scoring group, implying that more experienced individuals may be able to collaborate more successfully. Our study shows that a healthcare collaboration network can be structurally evaluated to characterize the collaborative interactions that occur between healthcare providers in a hospital setting.",2016-10-05,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:37:08,,10,11,PLoS One,,PubMed Central,PMID: 27706199 PMCID: PMC5051930,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5051930/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
541,10.1371/journal.pone.0171046,28141874,PMC5283729,A,Neo4j,Neo4j,"Wanichthanarak, Kwanjeera; Fan, Sili; Grapov, Dmitry; Barupal, Dinesh Kumar; Fiehn, Oliver","Metabox: A Toolbox for Metabolomic Data Analysis, Interpretation and Integrative Exploration",2017,PLoS ONE,,"Similar to genomic and proteomic platforms, metabolomic data acquisition and analysis is becoming a routine approach for investigating biological systems. However, computational approaches for metabolomic data analysis and integration are still maturing. Metabox is a bioinformatics toolbox for deep phenotyping analytics that combines data processing, statistical analysis, functional analysis and integrative exploration of metabolomic data within proteomic and transcriptomic contexts. With the number of options provided in each analysis module, it also supports data analysis of other ‘omic’ families. The toolbox is an R-based web application, and it is freely available at http://kwanjeeraw.github.io/metabox/ under the GPL-3 license.",2017-01-31,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:37:08,,1,12,PLoS One,Metabox,PubMed Central,PMID: 28141874 PMCID: PMC5283729,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5283729/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
542,10.1371/journal.pone.0179130,28708831,PMC5510799,A,Neo4j,Neo4j,"Swainston, Neil; Batista-Navarro, Riza; Carbonell, Pablo; Dobson, Paul D.; Dunstan, Mark; Jervis, Adrian J.; Vinaixa, Maria; Williams, Alan R.; Ananiadou, Sophia; Faulon, Jean-Loup; Mendes, Pedro; Kell, Douglas B.; Scrutton, Nigel S.; Breitling, Rainer",biochem4j: Integrated and extensible biochemical knowledge through graph databases,2017,PLoS ONE; PloS One,,"Biologists and biochemists have at their disposal a number of excellent, publicly available data resources such as UniProt, KEGG, and NCBI Taxonomy, which catalogue biological entities. Despite the usefulness of these resources, they remain fundamentally unconnected. While links may appear between entries across these databases, users are typically only able to follow such links by manual browsing or through specialised workflows. Although many of the resources provide web-service interfaces for computational access, performing federated queries across databases remains a non-trivial but essential activity in interdisciplinary systems and synthetic biology programmes. What is needed are integrated repositories to catalogue both biological entities and-crucially-the relationships between them. Such a resource should be extensible, such that newly discovered relationships-for example, those between novel, synthetic enzymes and non-natural products-can be added over time. With the introduction of graph databases, the barrier to the rapid generation, extension and querying of such a resource has been lowered considerably. With a particular focus on metabolic engineering as an illustrative application domain, biochem4j, freely available at http://biochem4j.org, is introduced to provide an integrated, queryable database that warehouses chemical, reaction, enzyme and taxonomic data from a range of reliable resources. The biochem4j framework establishes a starting point for the flexible integration and exploitation of an ever-wider range of biological data sources, from public databases to laboratory-specific experimental datasets, for the benefit of systems biologists, biosystems engineers and the wider community of molecular biologists and biological chemists.; Biologists and biochemists have at their disposal a number of excellent, publicly available data resources such as UniProt, KEGG, and NCBI Taxonomy, which catalogue biological entities. Despite the usefulness of these resources, they remain fundamentally unconnected. While links may appear between entries across these databases, users are typically only able to follow such links by manual browsing or through specialised workflows. Although many of the resources provide web-service interfaces for computational access, performing federated queries across databases remains a non-trivial but essential activity in interdisciplinary systems and synthetic biology programmes. What is needed are integrated repositories to catalogue both biological entities and–crucially–the relationships between them. Such a resource should be extensible, such that newly discovered relationships–for example, those between novel, synthetic enzymes and non-natural products–can be added over time. With the introduction of graph databases, the barrier to the rapid generation, extension and querying of such a resource has been lowered considerably. With a particular focus on metabolic engineering as an illustrative application domain, biochem4j, freely available at http://biochem4j.org, is introduced to provide an integrated, queryable database that warehouses chemical, reaction, enzyme and taxonomic data from a range of reliable resources. The biochem4j framework establishes a starting point for the flexible integration and exploitation of an ever-wider range of biological data sources, from public databases to laboratory-specific experimental datasets, for the benefit of systems biologists, biosystems engineers and the wider community of molecular biologists and biological chemists.",2017; 2017-07-14,2021-06-05 20:55:40; 2021-06-05 21:06:22; 2021-06-05 21:12:01; 2021-06-05 20:36:32,e0179130,7,12,PLoS One,biochem4j,PubMed; PubMed Central,PMID: 28708831 PMCID: PMC5510799,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5510799/; http://www.ncbi.nlm.nih.gov/pubmed/28708831,"Computational Biology; Databases, Factual; Internet; User-Computer Interface",Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PubMed:Query2; PMC:Query2
543,10.1371/journal.pone.0191917,29444127,PMC5812617,A,OrientDB; Neo4j,OrientDB; Neo4j,"Tomaszuk, Dominik; Pąk, Karol",Reducing vertices in property graphs,2018,PLoS ONE; PloS One,,"Graph databases are constantly growing, and, at the same time, some of their data is the same or similar. Our experience with the management of the existing databases, especially the bigger ones, shows that certain vertices are particularly replicated there numerous times. Eliminating repetitive or even very similar data speeds up the access to database resources. We present a modification of this approach, where similarly we group together vertices of identical properties, but then additionally we join together groups of data that are located in distant parts of a graph. The second part of our approach is non-trivial. We show that the search for a partition of a given graph where each member of the partition has only pairwise distant vertices is NP-hard. We indicate a group of heuristics that try to solve our difficult computational problems and then we apply them to check the the effectiveness of our approach.",2018-02-14; 2018,2021-06-05 21:11:16; 2021-06-06 06:49:06; 2021-06-05 21:06:22; 2021-06-05 20:55:40; 2021-06-05 20:36:32,e0191917,2,13,PLoS One,,PubMed; PubMed Central,PMID: 29444127 PMCID: PMC5812617,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5812617/; http://www.ncbi.nlm.nih.gov/pubmed/29444127,"Algorithms; Databases, Factual",OrientDB; Neo4j,OrientDB; Neo4j,PMC:Query2; PMC:OrientDB; PMC:Query3; PMC:Neo4j; PubMed:Query2
544,10.1371/journal.pone.0195271,29723213,PMC5933701,A,Neo4j,Neo4j,"Matiasz, Nicholas J.; Wood, Justin; Doshi, Pranay; Speier, William; Beckemeyer, Barry; Wang, Wei; Hsu, William; Silva, Alcino J.",ResearchMaps.org for integrating and planning research,2018,PLoS ONE,,"To plan experiments, a biologist needs to evaluate a growing set of empirical findings and hypothetical assertions from diverse fields that use increasingly complex techniques. To address this problem, we operationalized principles (e.g., convergence and consistency) that biologists use to test causal relations and evaluate experimental evidence. With the framework we derived, we then created a free, open-source web application that allows biologists to create research maps, graph-based representations of empirical evidence and hypothetical assertions found in research articles, reviews, and other sources. With our ResearchMaps web application, biologists can systematically reason through the research that is most important to them, as well as evaluate and plan experiments with a breadth and precision that are unlikely without such a tool.",2018-05-03,2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:36:32,,5,13,PLoS One,,PubMed Central,PMID: 29723213 PMCID: PMC5933701,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5933701/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
545,10.1371/journal.pone.0198270,30500839,PMC6269127,A,Virtuoso,Virtuoso,"Venkatesan, Aravind; Tagny Ngompe, Gildas; Hassouni, Nordine El; Chentli, Imene; Guignon, Valentin; Jonquet, Clement; Ruiz, Manuel; Larmande, Pierre",Agronomic Linked Data (AgroLD): A knowledge-based system to enable integrative biology in agronomy,2018,PLoS ONE,,"Recent advances in high-throughput technologies have resulted in a tremendous increase in the amount of omics data produced in plant science. This increase, in conjunction with the heterogeneity and variability of the data, presents a major challenge to adopt an integrative research approach. We are facing an urgent need to effectively integrate and assimilate complementary datasets to understand the biological system as a whole. The Semantic Web offers technologies for the integration of heterogeneous data and their transformation into explicit knowledge thanks to ontologies. We have developed the Agronomic Linked Data (AgroLD– www.agrold.org), a knowledge-based system relying on Semantic Web technologies and exploiting standard domain ontologies, to integrate data about plant species of high interest for the plant science community e.g., rice, wheat, arabidopsis. We present some integration results of the project, which initially focused on genomics, proteomics and phenomics. AgroLD is now an RDF (Resource Description Format) knowledge base of 100M triples created by annotating and integrating more than 50 datasets coming from 10 data sources–such as Gramene.org and TropGeneDB–with 10 ontologies–such as the Gene Ontology and Plant Trait Ontology. Our evaluation results show users appreciate the multiple query modes which support different use cases. AgroLD’s objective is to offer a domain specific knowledge platform to solve complex biological and agronomical questions related to the implication of genes/proteins in, for instances, plant disease resistance or high yield traits. We expect the resolution of these questions to facilitate the formulation of new scientific hypotheses to be validated with a knowledge-oriented approach.",2018-11-30,2021-06-05 20:55:01; 2021-06-05 20:59:14; 2021-06-05 21:10:37,,11,13,PLoS One,Agronomic Linked Data (AgroLD),PubMed Central,PMID: 30500839 PMCID: PMC6269127,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6269127/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
546,10.1371/journal.pone.0205860,30359423,PMC6201890,,,,"Gibbon, Andrea; Saunders, Colleen J.; Collins, Malcolm; Gamieldien, Junaid; September, Alison V.",Defining the molecular signatures of Achilles tendinopathy and anterior cruciate ligament ruptures: A whole-exome sequencing approach,2018,PLoS ONE,,"Musculoskeletal soft tissue injuries are complex phenotypes with genetics being one of many proposed risk factors. Case-control association studies using the candidate gene approach have predominately been used to identify risk loci for these injuries. However, the ability to identify all risk conferring variants using this approach alone is unlikely. Therefore, this study aimed to further define the genetic profile of these injuries using an integrated omics approach involving whole exome sequencing and a customised analyses pipeline. The exomes of ten exemplar asymptomatic controls and ten exemplar cases with Achilles tendinopathy were individually sequenced using a platform that included the coverage of the untranslated regions and miRBase miRNA genes. Approximately 200 000 variants were identified in the sequenced samples. Previous research was used to guide a targeted analysis of the genes encoding the tenascin-C (TNC) glycoprotein and the α1 chain of type XXVII collagen (COL27A1) located on chromosome 9. Selection of variants within these genes were; however, not predetermined but based on a tiered filtering strategy. Four variants in TNC (rs1061494, rs1138545, rs2104772 and rs1061495) and three variants in the upstream COL27A1 gene (rs2567706, rs2241671 and rs2567705) were genotyped in larger Achilles tendinopathy and anterior cruciate ligament (ACL) rupture sample groups. The CC genotype of TNC rs1061494 (C/T) was associated with the risk of Achilles tendinopathy (p = 0.018, OR: 2.5 95% CI: 1.2–5.1). Furthermore, the AA genotype of the TNC rs2104772 (A/T) variant was significantly associated with ACL ruptures in the female subgroup (p = 0.035, OR: 2.3 95% CI: 1.1–5.5). An inferred haplotype in the TNC gene was also associated with the risk of Achilles tendinopathy. These results provide a proof of concept for the use of a customised pipeline for the exploration of a larger genomic dataset. This approach, using previous research to guide a targeted analysis of the data has generated new genetic signatures in the biology of musculoskeletal soft tissue injuries.",2018-10-25,2021-06-05 21:11:16,,10,13,PLoS One,Defining the molecular signatures of Achilles tendinopathy and anterior cruciate ligament ruptures,PubMed Central,PMID: 30359423 PMCID: PMC6201890,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6201890/,,,,PMC:Query2
547,10.1371/journal.pone.0206906,30513083,PMC6279051,,,,"Savelyev, Alexander; MacEachren, Alan M.",Augmenting geovisual analytics of social media data with heterogeneous information network mining—Cognitive plausibility assessment,2018,PLoS ONE,,"This paper investigates the feasibility, from a user perspective, of integrating a heterogeneous information network mining (HINM) technique into SensePlace3 (SP3), a web-based geovisual analytics environment. The core contribution of this paper is a user study that determines whether an analyst with minimal background can comprehend the network data modeling metaphors employed by the resulting system, whether they can employ said metaphors to explore spatial data, and whether they can interpret the results of such spatial analysis correctly. This study confirms that all of the above is, indeed, possible, and provides empirical evidence about the importance of a hands-on tutorial and a graphical approach to explaining data modeling metaphors in the successful adoption of advanced data mining techniques. Analysis of outcomes of data exploration by the study participants also demonstrates the kinds of insights that a visual interface to HINM can enable. A second contribution is a realistic case study that demonstrates that our HINM approach (made accessible through a visual interface that provides immediate visual feedback for user queries), produces a clear and a positive difference in the outcome of spatial analysis. Although this study does not aim to validate HINM as a data modeling approach (there is considerable evidence for this in existing literature), the results of the case study suggest that HINM holds promise in the (geo)visual analytics domain as well, particularly when integrated into geovisual analytics applications. A third contribution is a user study protocol that is based on and improves upon the current methodological state of the art. This protocol includes a hands-on tutorial and a set of realistic data analysis tasks. Detailed evaluation protocols are rare in geovisual analytics (and in visual analytics more broadly), with most studies reviewed in this paper failing to provide sufficient details for study replication or comparison work.",2018-12-04,2021-06-05 21:10:37,,12,13,PLoS One,,PubMed Central,PMID: 30513083 PMCID: PMC6279051,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6279051/,,,,PMC:Query2
548,10.1371/journal.pone.0207595,30444913,PMC6239324,A,Neo4j,Neo4j,"Gong, Faming; Ma, Yuhui; Gong, Wenjuan; Li, Xiaoran; Li, Chantao; Yuan, Xiangbing",Neo4j graph database realizes efficient storage performance of oilfield ontology,2018,PLoS ONE; PloS One,,"The integration of oilfield multidisciplinary ontology is increasingly important for the growth of the Semantic Web. However, current methods encounter performance bottlenecks either in storing data and searching for information when processing large amounts of data. To overcome these challenges, we propose a domain-ontology process based on the Neo4j graph database. In this paper, we focus on data storage and information retrieval of oilfield ontology. We have designed mapping rules from ontology files to regulate the Neo4j database, which can greatly reduce the required storage space. A two-tier index architecture, including object and triad indexing, is used to keep loading times low and match with different patterns for accurate retrieval. Therefore, we propose a retrieval method based on this architecture. Based on our evaluation, the retrieval method can save 13.04% of the storage space and improve retrieval efficiency by more than 30 times compared with the methods of relational databases.",2018; 2018-11-16,2021-06-05 21:11:16; 2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 20:55:01; 2021-06-05 21:24:28; 2021-06-05 20:36:32,e0207595,11,13,PLoS One,,PubMed; PubMed Central,PMID: 30444913 PMCID: PMC6239324,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6239324/; http://www.ncbi.nlm.nih.gov/pubmed/30444913,"Biological Ontologies; Database Management Systems; Databases, Factual; Information Storage and Retrieval; Oil and Gas Industry; Search Engine",Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
549,10.1371/journal.pone.0219195,31260503,PMC6602258,A,Neo4j,Neo4j,"Couch, Daniel; Yu, Zhenning; Nam, Jin Hyun; Allen, Carter; Ramos, Paula S.; da Silveira, Willian A.; Hunt, Kelly J.; Hazard, Edward S.; Hardiman, Gary; Lawson, Andrew; Chung, Dongjun",GAIL: An interactive webserver for inference and dynamic visualization of gene-gene associations based on gene ontology guided mining of biomedical literature,2019,PLoS ONE,,"In systems biology, inference of functional associations among genes is compelling because the construction of functional association networks facilitates biomarker discovery. Specifically, such gene associations in human can help identify putative biomarkers that can be used as diagnostic tools in treating patients. Although biomedical literature is considered a valuable data source for this task, currently only a limited number of webservers are available for mining gene-gene associations from the vast amount of biomedical literature using text mining techniques. Moreover, these webservers often have limited coverage of biomedical literature and also lack efficient and user-friendly tools to interpret and visualize mined relationships among genes. To address these limitations, we developed GAIL (Gene-gene Association Inference based on biomedical Literature), an interactive webserver that infers human gene-gene associations from Gene Ontology (GO) guided biomedical literature mining and provides dynamic visualization of the resulting association networks and various gene set enrichment analysis tools. We evaluate the utility and performance of GAIL with applications to gene signatures associated with systemic lupus erythematosus and breast cancer. Results show that GAIL allows effective interrogation and visualization of gene-gene networks and their subnetworks, which facilitates biological understanding of gene-gene associations. GAIL is available at http://chunglab.io/GAIL/.",2019-07-01,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,,7,14,PLoS One,GAIL,PubMed Central,PMID: 31260503 PMCID: PMC6602258,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6602258/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
550,10.1371/journal.pone.0219992,31374080,PMC6677298,A,Virtuoso,Virtuoso,"Chen, Tao; Zhang, Yongjuan; Wang, Zhengjun; Wang, Dongsheng; Li, Hui; Liu, Wei",SinoPedia—A Linked Data Services platform for decentralized knowledge base,2019,PLoS ONE,,"Knowledge bases are largely developed and utilized in academic and industrial fields, such as DBPedia, VIAF, LoC, Getty, and which are published in the Linked Data format. However, if you want to view different resources on these knowledge bases, you have to switch between different web pages from these resources. Therefore, we proposed a decentralized data hub named SinoPedia, which consists of several linked data services and can re-publish these RDF data in one platform. Firstly, these different Linked Data services include: Linked Data Transformation Service (LDTS), Linked Data Query Service (LDQS), Linked Data Publishing Service (LDPS) and Linked Data Knowledge Service (LDKS). The resource URI is the basis and core of the linked data, thus we will focus on the resource forwarding mechanism in LDPS service which can rewrite resource URI using a global and standard format among knowledge bases. Some knowledge bases were configured in SinoPedia platform in this paper. In addition to the above services, Linked Data Reasoning Service (LDRS) and Linked Data Intelligence Service (LDIS) will be added to the platform in the future. In short, all of these Linked Data Services will form the core framework in order to providing a good linked data application ecosystem.",2019-08-02,2021-06-05 20:55:01; 2021-06-05 20:59:14; 2021-06-05 21:10:37,,8,14,PLoS One,,PubMed Central,PMID: 31374080 PMCID: PMC6677298,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6677298/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
551,10.1371/journal.pone.0231916,33755673,PMC7987184,A,Neo4j,Neo4j,"Hannestad, Lance M.; Dančík, Vlado; Godden, Meera; Suen, Imelda W.; Huellas-Bruskiewicz, Kenneth C.; Good, Benjamin M.; Mungall, Christopher J.; Bruskiewich, Richard M.",Knowledge Beacons: Web services for data harvesting of distributed biomedical knowledge,2021,PLoS ONE,,"The continually expanding distributed global compendium of biomedical knowledge is diffuse, heterogeneous and huge, posing a serious challenge for biomedical researchers in knowledge harvesting: accessing, compiling, integrating and interpreting data, information and knowledge. In order to accelerate research towards effective medical treatments and optimizing health, it is critical that efficient and automated tools for identifying key research concepts and their experimentally discovered interrelationships are developed. As an activity within the feasibility phase of a project called “Translator” (https://ncats.nih.gov/translator) funded by the National Center for Advancing Translational Sciences (NCATS) to develop a biomedical science knowledge management platform, we designed a Representational State Transfer (REST) web services Application Programming Interface (API) specification, which we call a Knowledge Beacon. Knowledge Beacons provide a standardized basic API for the discovery of concepts, their relationships and associated supporting evidence from distributed online repositories of biomedical knowledge. This specification also enforces the annotation of knowledge concepts and statements to the NCATS endorsed the Biolink Model data model and semantic encoding standards (https://biolink.github.io/biolink-model/). Implementation of this API on top of diverse knowledge sources potentially enables their uniform integration behind client software which will facilitate research access and integration of biomedical knowledge.",2021-03-23,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,3,16,PLoS One,Knowledge Beacons,PubMed Central,PMID: 33755673 PMCID: PMC7987184,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7987184/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
552,10.1371/journal.pone.0242253,33259475,PMC7707476,,,,"Zhou, Zhigang; Liu, Yanyan; Yu, Hao; Ren, Lihua",The influence of machine learning-based knowledge management model on enterprise organizational capability innovation and industrial development,2020,PLoS ONE,,"The aims are to explore the construction of the knowledge management model for engineering cost consulting enterprises, and to expand the application of data mining techniques and machine learning methods in constructing knowledge management model. Through a questionnaire survey, the construction of the knowledge management model of construction-related enterprises and engineering cost consulting enterprises is discussed. First, through the analysis and discussion of ontology-based data mining (OBDM) algorithm and association analysis (Apriori) algorithm, a data mining algorithm (ML-AR algorithm) on account of ontology-based multilayer association and machine learning is proposed. The performance of the various algorithms is compared and analyzed. Second, based on the knowledge management level, analysis and statistics are conducted on the levels of knowledge acquisition, sharing, storage, and innovation. Finally, according to the foregoing, the knowledge management model based on engineering cost consulting enterprises is built and analyzed. The results show that the reliability coefficient of this questionnaire is above 0.8, and the average extracted value is above 0.7, verifying excellent reliability and validity. The efficiency of the ML-AR algorithm at both the number of transactions and the support level is better than the other two algorithms, which is expected to be applied to the enterprise knowledge management model. There is a positive correlation between each level of knowledge management; among them, the positive correlation between knowledge acquisition and knowledge sharing is the strongest. The enterprise knowledge management model has a positive impact on promoting organizational innovation capability and industrial development. The research work provides a direction for the development of enterprise knowledge management and the improvement of innovation ability.",2020-12-01,2021-06-05 21:09:36,,12,15,PLoS One,,PubMed Central,PMID: 33259475 PMCID: PMC7707476,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7707476/,,,,PMC:Query2
553,10.1371/journal.pone.0247587,33647012,PMC7920367,A,Neo4j,Neo4j,"Yokoyama, Toshiyuki T.; Okada, Masashi; Taniguchi, Tadahiro",Panacea: Visual exploration system for analyzing trends in annual recruitment using time-varying graphs,2021,PLoS ONE,,"Annual recruitment data of new graduates are manually analyzed by human resources (HR) specialists in industries, which signifies the need to evaluate the recruitment strategy of HR specialists. Different job seekers send applications to companies every year. The relationships between applicants’ attributes (e.g., English skill or academic credentials) can be used to analyze the changes in recruitment trends across multiple years. However, most attributes are unnormalized and thus require thorough preprocessing. Such unnormalized data hinder effective comparison of the relationship between applicants in the early stage of data analysis. Thus, a visual exploration system is highly needed to gain insight from the overview of the relationship among applicant qualifications across multiple years. In this study, we propose the Polarizing Attributes for Network Analysis of Correlation on Entities Association (Panacea) visualization system. The proposed system integrates a time-varying graph model and dynamic graph visualization for heterogeneous tabular data. Using this system, HR specialists can interactively inspect the relationships between two attributes of prospective employees across multiple years. Further, we demonstrate the usability of Panacea with representative examples for finding hidden trends in real-world datasets, and we discuss feedback from HR specialists obtained throughout Panacea’s development. The proposed Panacea system enables HR specialists to visually explore the annual recruitment of new graduates.",2021-03-01,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,3,16,PLoS One,Panacea,PubMed Central,PMID: 33647012 PMCID: PMC7920367,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7920367/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
554,10.14778/2824032.2824035,28752014,PMC5526644,,,,"Bhattacherjee, Souvik; Chavan, Amit; Huang, Silu; Deshpande, Amol; Parameswaran, Aditya",Principles of Dataset Versioning: Exploring the Recreation/Storage Tradeoff,2015,Proceedings of the VLDB Endowment. International Conference on Very Large Data Bases,,"The relative ease of collaborative data science and analysis has led to a proliferation of many thousands or millions of versions of the same datasets in many scientific and commercial domains, acquired or constructed at various stages of data analysis across many users, and often over long periods of time. Managing, storing, and recreating these dataset versions is a non-trivial task. The fundamental challenge here is the storage-recreation trade-off: the more storage we use, the faster it is to recreate or retrieve versions, while the less storage we use, the slower it is to recreate or retrieve versions. Despite the fundamental nature of this problem, there has been a surprisingly little amount of work on it. In this paper, we study this trade-off in a principled manner: we formulate six problems under various settings, trading off these quantities in various ways, demonstrate that most of the problems are intractable, and propose a suite of inexpensive heuristics drawing from techniques in delay-constrained scheduling, and spanning tree literature, to solve these problems. We have built a prototype version management system, that aims to serve as a foundation to our DataHub system for facilitating collaborative data science. We demonstrate, via extensive experiments, that our proposed heuristics provide efficient solutions in practical dataset versioning scenarios.",2015-08,2021-06-05 21:12:40,1346-1357,12,8,Proceedings VLDB Endowment,Principles of Dataset Versioning,PubMed Central,PMID: 28752014 PMCID: PMC5526644,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5526644/,,,,PMC:Query2
555,10.14778/2947618.2947619,28149668,PMC5278666,,,,"Maddox, Michael; Goehring, David; Elmore, Aaron J.; Madden, Samuel; Parameswaran, Aditya; Deshpande, Amol",Decibel: The Relational Dataset Branching System,2016,Proceedings of the VLDB Endowment. International Conference on Very Large Data Bases,,"As scientific endeavors and data analysis become increasingly collaborative, there is a need for data management systems that natively support the versioning or branching of datasets to enable concurrent analysis, cleaning, integration, manipulation, or curation of data across teams of individuals. Common practice for sharing and collaborating on datasets involves creating or storing multiple copies of the dataset, one for each stage of analysis, with no provenance information tracking the relationships between these datasets. This results not only in wasted storage, but also makes it challenging to track and integrate modifications made by different users to the same dataset. In this paper, we introduce the Relational Dataset Branching System, Decibel, a new relational storage system with built-in version control designed to address these shortcomings. We present our initial design for Decibel and provide a thorough evaluation of three versioned storage engine designs that focus on efficient query processing with minimal storage overhead. We also develop an exhaustive benchmark to enable the rigorous testing of these and future versioned storage engine designs.",2016-05,2021-06-05 21:12:01,624-635,9,9,Proceedings VLDB Endowment,Decibel,PubMed Central,PMID: 28149668 PMCID: PMC5278666,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5278666/,,,,PMC:Query2
556,10.14778/3397230.3397250,33717631,PMC7955775,,,,"Tziavelis, Nikolaos; Ajwani, Deepak; Gatterbauer, Wolfgang; Riedewald, Mirek; Yang, Xiaofeng",Optimal Algorithms for Ranked Enumeration of Answers to Full Conjunctive Queries,2020,Proceedings of the VLDB Endowment. International Conference on Very Large Data Bases,,"We study ranked enumeration of join-query results according to very general orders defined by selective dioids. Our main contribution is a framework for ranked enumeration over a class of dynamic programming problems that generalizes seemingly different problems that had been studied in isolation. To this end, we extend classic algorithms that find the k-shortest paths in a weighted graph. For full conjunctive queries, including cyclic ones, our approach is optimal in terms of the time to return the top result and the delay between results. These optimality properties are derived for the widely used notion of data complexity, which treats query size as a constant. By performing a careful cost analysis, we are able to uncover a previously unknown trade-off between two incomparable enumeration approaches: one has lower complexity when the number of returned results is small, the other when the number is very large. We theoretically and empirically demonstrate the superiority of our techniques over batch algorithms, which produce the full result and then sort it. Our technique is not only faster for returning the first few results, but on some inputs beats the batch algorithm even when all results are produced.",2020-05,2021-06-05 21:10:08,1582-1597,9,13,Proceedings VLDB Endowment,,PubMed Central,PMID: 33717631 PMCID: PMC7955775,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7955775/,,,,PMC:Query2
557,10.1515/jdis-2017-0019,29355246,PMC5771422,,,,"Smalheiser, Neil R.","Rediscovering Don Swanson: the Past, Present and Future of Literature-Based Discovery",2017,"Journal of data and information science (Warsaw, Poland)",,"The late Don R. Swanson was well appreciated during his lifetime as Dean of the Graduate Library School at University of Chicago, as winner of the American Society for Information Science Award of Merit for 2000, and as author of many seminal articles. In this informal essay, I will give my personal perspective on Don’s contributions to science, and outline some current and future directions in literature-based discovery that are rooted in concepts that he developed.",2017-12,2021-06-05 21:11:16,43-64,4,2,J Data Inf Sci,Rediscovering Don Swanson,PubMed Central,PMID: 29355246 PMCID: PMC5771422,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5771422/,,,,PMC:Query2
558,10.1515/jib-2018-0023,30085931,PMC6340125,A,Neo4j,Neo4j,"Brandizi, Marco; Singh, Ajit; Rawlings, Christopher; Hassani-Pak, Keywan",Towards FAIRer Biological Knowledge Networks Using a Hybrid Linked Data and Graph Database Approach,2018,Journal of Integrative Bioinformatics,,"The speed and accuracy of new scientific discoveries - be it by humans or artificial intelligence - depends on the quality of the underlying data and on the technology to connect, search and share the data efficiently. In recent years, we have seen the rise of graph databases and semi-formal data models such as knowledge graphs to facilitate software approaches to scientific discovery. These approaches extend work based on formalised models, such as the Semantic Web. In this paper, we present our developments to connect, search and share data about genome-scale knowledge networks (GSKN). We have developed a simple application ontology based on OWL/RDF with mappings to standard schemas. We are employing the ontology to power data access services like resolvable URIs, SPARQL endpoints, JSON-LD web APIs and Neo4j-based knowledge graphs. We demonstrate how the proposed ontology and graph databases considerably improve search and access to interoperable and reusable biological knowledge (i.e. the FAIRness data principles).; The speed and accuracy of new scientific discoveries – be it by humans or artificial intelligence – depends on the quality of the underlying data and on the technology to connect, search and share the data efficiently. In recent years, we have seen the rise of graph databases and semi-formal data models such as knowledge graphs to facilitate software approaches to scientific discovery. These approaches extend work based on formalised models, such as the Semantic Web. In this paper, we present our developments to connect, search and share data about genome-scale knowledge networks (GSKN). We have developed a simple application ontology based on OWL/RDF with mappings to standard schemas. We are employing the ontology to power data access services like resolvable URIs, SPARQL endpoints, JSON-LD web APIs and Neo4j-based knowledge graphs. We demonstrate how the proposed ontology and graph databases considerably improve search and access to interoperable and reusable biological knowledge (i.e. the FAIRness data principles).",2018-08-07,2021-06-05 21:11:16; 2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 20:55:01; 2021-06-05 21:24:28; 2021-06-05 20:36:32,,3,15,J Integr Bioinform,,PubMed; PubMed Central,PMID: 30085931 PMCID: PMC6340125,http://www.ncbi.nlm.nih.gov/pubmed/30085931; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6340125/,"bio-ontologies; biological knowledge networks; Computational Biology; Computer Graphics; data integration; Databases, Factual; FAIR data principles; Gene Regulatory Networks; Genome-Wide Association Study; Genome, Human; graph databases; Humans; Knowledge; linked data; semantic web; Software",Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
559,10.1515/jib-2018-0049,30864352,PMC6348742,A,Neo4j,Neo4j,"Shoshi, Alban; Hofestädt, Ralf; Zolotareva, Olga; Friedrichs, Marcel; Maier, Alex; Ivanisenko, Vladimir A.; Dosenko, Victor E.; Bragina, Elena Yu",GenCoNet – A Graph Database for the Analysis of Comorbidities by Gene Networks; GenCoNet - A Graph Database for the Analysis of Comorbidities by Gene Networks,2018,Journal of Integrative Bioinformatics,,"The prevalence of comorbid diseases poses a major health issue for millions of people worldwide and an enormous socio-economic burden for society. The molecular mechanisms for the development of comorbidities need to be investigated. For this purpose, a workflow system was developed to aggregate data on biomedical entities from heterogeneous data sources. The process of integrating and merging all data sources of the workflow system was implemented as a semi-automatic pipeline that provides the import, fusion, and analysis of the highly connected biomedical data in a Neo4j database GenCoNet. As a starting point, data on the common comorbid diseases essential hypertension and bronchial asthma was integrated. GenCoNet (https://genconet.kalis-amts.de) is a curated database that provides a better understanding of hereditary bases of comorbidities.",2018-12-25,2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 21:10:37; 2021-06-05 20:55:01; 2021-06-05 21:24:28; 2021-06-05 20:36:32,,4,15,J Integr Bioinform,,PubMed; PubMed Central,PMID: 30864352 PMCID: PMC6348742,http://www.ncbi.nlm.nih.gov/pubmed/30864352; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6348742/,"Asthma; Comorbidity; Computational Biology; Computer Graphics; Database; Databases, Factual; Essential Hypertension; Gene Regulatory Networks; Humans; Hypertension; Pipeline; Software; Workflow",Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
560,10.1515/jib-2018-0068,30808160,PMC6798860,A,Neo4j,Neo4j,"Vieira, Vítor; Ferreira, Jorge; Rodrigues, Rúben; Liu, Filipe; Rocha, Miguel",A Model Integration Pipeline for the Improvement of Human Genome-Scale Metabolic Reconstructions,2018,Journal of Integrative Bioinformatics,,"Metabolism has been a major field of study in the last years, mainly due to its importance in understanding cell physiology and certain disease phenotypes due to its deregulation. Genome-scale metabolic models (GSMMs) have been established as important tools to help achieve a better understanding of human metabolism. Towards this aim, advances in systems biology and bioinformatics have allowed the reconstruction of several human GSMMs, although some limitations and challenges remain, such as the lack of external identifiers for both metabolites and reactions. A pipeline was developed to integrate multiple GSMMs, starting by retrieving information from the main human GSMMs and evaluating the presence of external database identifiers and annotations for both metabolites and reactions. Information from metabolites was included into a graph database with omics data repositories, allowing clustering of metabolites through their similarity regarding database cross-referencing. Metabolite annotation of several older GSMMs was enriched, allowing the identification and integration of common entities. Using this information, as well as other metrics, we successfully integrated reactions from these models. These methods can be leveraged towards the creation of a unified consensus model of human metabolism.",2018-12-21,2021-06-05 20:55:01; 2021-06-05 21:06:22; 2021-06-05 20:36:32; 2021-06-05 21:10:37,,1,16,J Integr Bioinform,,PubMed; PubMed Central,PMID: 30808160 PMCID: PMC6798860,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6798860/; http://www.ncbi.nlm.nih.gov/pubmed/30808160,"Computational Biology; database integration; Databases, Factual; Genome-scale metabolic models; Genome, Human; human metabolism; Humans; Metabolic Networks and Pathways; Models, Statistical; Molecular Sequence Annotation; omics databases; Transcription, Genetic",Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PubMed:Query2; PMC:Query2
561,10.1515/jib-2019-0004,,PMC6798857,,,,"Fdez-Riverola, Florentino; Rocha, Miguel",Selected Extended Papers of the 12th International Conference on Practical Applications of Computational Biology and Bioinformatics (PACBB),2019,Journal of Integrative Bioinformatics,,,2019-02-15,2021-06-05 21:10:37,,1,16,J Integr Bioinform,,PubMed Central,PMID:  PMCID: PMC6798857,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6798857/,,,,PMC:Query2
562,10.1515/jib-2019-0011,31145693,PMC6798848,,,,"Friedrichs, Marcel; Shoshi, Alban",History and Future of KALIS: Towards Computer-assisted Decision Making in Prescriptive Medicine,2019,Journal of Integrative Bioinformatics,,"With an increasing older population in Germany and the need for polypharmacy to treat multimorbid patients computer-assisted decision making on an individual level is increasingly important to reduce prescription errors and adverse drug reactions. While current systems focus on guidelines and prescribing information, molecular information is equally important for explanation and discovery of drug-related problems. Based on the existing KALIS system and newer projects like PIMBase, a new concept for the KALIS-2 system is presented. Improvements to the modularisation of components enable future extension and greater maintainability. Interoperability with available electronic health records standards and protocols allows the integration and communication with existing workflows for healthcare professionals. Finally, new visualisation modes empower the user to explore and analyze the patient situation in an individual patient subgraph. For offline use and dialogue between patient and general practitioner, the results can be printed out using a new reporting tool. The adherence to findings from previous decision support systems and reasons for their failed adoption is an important task in the development of KALIS-2.",2019-05-30,2021-06-05 21:10:37,,3,16,J Integr Bioinform,History and Future of KALIS,PubMed Central,PMID: 31145693 PMCID: PMC6798848,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6798848/,,,,PMC:Query2
563,10.1515/jib-2020-0033,33618440,,A,Neo4j,Neo4j,"Friedrichs, Marcel",BioDWH2: an automated graph-based data warehouse and mapping tool,2021,Journal of Integrative Bioinformatics,,"Data integration plays a vital role in scientific research. In biomedical research, the OMICS fields have shown the need for larger datasets, like proteomics, pharmacogenomics, and newer fields like foodomics. As research projects require multiple data sources, mapping between these sources becomes necessary. Utilized workflow systems and integration tools therefore need to process large amounts of heterogeneous data formats, check for data source updates, and find suitable mapping methods to cross-reference entities from different databases. This article presents BioDWH2, an open-source, graph-based data warehouse and mapping tool, capable of helping researchers with these issues. A workspace centered approach allows project-specific data source selections and Neo4j or GraphQL server tools enable quick access to the database for analysis. The BioDWH2 tools are available to the scientific community at https://github.com/BioDWH2.",2021-02-22,2021-06-05 21:24:28; 2021-06-05 21:06:22; 2021-06-05 21:16:51,,,,J Integr Bioinform,BioDWH2,PubMed,PMID: 33618440,http://www.ncbi.nlm.nih.gov/pubmed/33618440,data warehousing; database; graph database; pipeline; software tools,Neo4j,Neo4j,PubMed:Neo4j; PubMed:Query3; PubMed:Query2
564,10.15265/IY-2017-018,29063555,PMC6239235,,,,"Rosenbloom, S. T.; Carroll, R. J.; Warner, J. L.; Matheny, M. E.; Denny, J. C.",Representing Knowledge Consistently Across Health Systems,2017,Yearbook of Medical Informatics,,"Objectives: Electronic health records (EHRs) have increasingly emerged as a powerful source of clinical data that can be leveraged for reuse in research and in modular health apps that integrate into diverse health information technologies. A key challenge to these use cases is representing the knowledge contained within data from different EHR systems in a uniform fashion. ,  Method: We reviewed several recent studies covering the knowledge representation in the common data models for the Observational Medical Outcomes Partnership (OMOP) and its Observational Health Data Sciences and Informatics program, and the United States Patient Centered Outcomes Research Network (PCORNet). We also reviewed the Health Level 7 Fast Healthcare Interoperability Resource standard supporting app-like programs that can be used across multiple EHR and research systems. ,  Results: There has been a recent growth in high-impact efforts to support quality-assured and standardized clinical data sharing across different institutions and EHR systems. We focused on three major efforts as part of a larger landscape moving towards shareable, transportable, and computable clinical data. ,  Conclusion: The growth in approaches to developing common data models to support interoperable knowledge representation portends an increasing availability of high-quality clinical data in support of research. Building on these efforts will allow a future whereby significant portions of the populations in the world may be able to share their data for research.",2017-08,2021-06-05 21:12:01,139-147,1,26,Yearb Med Inform,,PubMed Central,PMID: 29063555 PMCID: PMC6239235,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6239235/,,,,PMC:Query2
565,10.15265/IY-2017-030,29063556,PMC6239236,,,,"Dhombres, F.; Charlet, J.","Knowledge Representation and Management, It’s Time to Integrate!",2017,Yearbook of Medical Informatics,,"Objectives: To select, present, and summarize the best papers published in 2016 in the field of Knowledge Representation and Management (KRM). ,  Methods: A comprehensive and standardized review of the medical informatics literature was performed based on a PubMed query. ,  Results: Among the 1,421 retrieved papers, the review process resulted in the selection of four best papers focused on the integration of heterogeneous data via the development and the alignment of terminological resources. In the first article, the authors provide a curated and standardized version of the publicly available US FDA Adverse Event Reporting System. Such a resource will improve the quality of the underlying data, and enable standardized analyses using common vocabularies. The second article describes a project developed in order to facilitate heterogeneous data integration in the i2b2 framework. The originality is to allow users integrate the data described in different terminologies and to build a new repository, with a unique model able to support the representation of the various data. The third paper is dedicated to model the association between multiple phenotypic traits described within the Human Phenotype Ontology (HPO) and the corresponding genotype in the specific context of rare diseases (rare variants). Finally, the fourth paper presents solutions to annotation-ontology mapping in genome-scale data. Of particular interest in this work is the Experimental Factor Ontology (EFO) and its generic association model, the Ontology of Biomedical AssociatioN (OBAN). ,  Conclusion: Ontologies have started to show their efficiency to integrate medical data for various tasks in medical informatics: electronic health records data management, clinical research, and knowledge-based systems development.",2017-08,2021-06-05 21:12:01,148-151,1,26,Yearb Med Inform,,PubMed Central,PMID: 29063556 PMCID: PMC6239236,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6239236/,,,,PMC:Query2
566,10.15265/IYS-2016-s034,27488402,PMC5171504,,,,"Middleton, B.; Sittig, D. F.; Wright, A.",Clinical Decision Support: a 25 Year Retrospective and a 25 Year Vision,2016,Yearbook of Medical Informatics,,"Objective The objective of this review is to summarize the state of the art of clinical decision support (CDS) circa 1990, review progress in the 25 year interval from that time, and provide a vision of what CDS might look like 25 years hence, or circa 2040. Method Informal review of the medical literature with iterative review and discussion among the authors to arrive at six axes (data, knowledge, inference, architecture and technology, implementation and integration, and users) to frame the review and discussion of selected barriers and facilitators to the effective use of CDS. Result In each of the six axes, significant progress has been made. Key advances in structuring and encoding standardized data with an increased availability of data, development of knowledge bases for CDS, and improvement of capabilities to share knowledge artifacts, explosion of methods analyzing and inferring from clinical data, evolution of information technologies and architectures to facilitate the broad application of CDS, improvement of methods to implement CDS and integrate CDS into the clinical workflow, and increasing sophistication of the end-user, all have played a role in improving the effective use of CDS in healthcare delivery. Conclusion CDS has evolved dramatically over the past 25 years and will likely evolve just as dramatically or more so over the next 25 years. Increasingly, the clinical encounter between a clinician and a patient will be supported by a wide variety of cognitive aides to support diagnosis, treatment, care-coordination, surveillance and prevention, and health maintenance or wellness.",2016-05-20,2021-06-05 21:12:01,S103-S116,Suppl 1,,Yearb Med Inform,Clinical Decision Support,PubMed Central,PMID: 27488402 PMCID: PMC5171504,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5171504/,,,,PMC:Query2
567,10.1590/1678-775720130539,25466477,PMC4245757,,,,"de CASTRO, Denise Tornavoi; HOLTZ, Raphael Dias; ALVES, Oswaldo Luiz; WATANABE, Evandro; VALENTE, Mariana Lima da Costa; da SILVA, Cláudia Helena Lovato; dos REIS, Andréa Cândido",Development of a novel resin with antimicrobial properties for dental application,2014,Journal of Applied Oral Science,,The adhesion of biofilm on dental prostheses is a prerequisite for the occurrence of oral diseases.,2014,2021-06-05 21:12:40,442-449,5,22,J Appl Oral Sci,,PubMed Central,PMID: 25466477 PMCID: PMC4245757,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4245757/,,,,PMC:Query2
568,10.1901/jaba.2008.6-39,20448828,PMC2864492,,,,"Smalter, A. M.; Huan, J.; Lushington, G. H.; SMALTER, A. M.; HUAN, J.; LUSHINGTON, G. H.",CHEMICAL COMPOUND CLASSIFICATION WITH AUTOMATICALLY MINED STRUCTURE PATTERNS,2008,Proceedings of the ... Asia-Pacific Bioinformatics Conference; Proceedings of the ... Asia-Pacific bioinformatics conference,,"In this paper we propose new methods of chemical structure classification based on the integration of graph database mining from data mining and graph kernel functions from machine learning. In our method, we first identify a set of general graph patterns in chemical structure data. These patterns are then used to augment a graph kernel function that calculates the pairwise similarity between molecules. The obtained similarity matrix is used as input to classify chemical compounds via a kernel machines such as the support vector machine (SVM). Our results indicate that the use of a pattern-based approach to graph similarity yields performance profiles comparable to, and sometimes exceeding that of the existing state-of-the-art approaches. In addition, the identification of highly discriminative patterns for activity classification provides evidence that our methods can make generalizations about a compound’s function given its chemical structure. While we evaluated our methods on molecular structures, these methods are designed to operate on general graph data and hence could easily be applied to other domains in bioinformatics.; In this paper we propose new methods of chemical structure classification based on the integration of graph database mining from data mining and graph kernel functions from machine learning. In our method, we first identify a set of general graph patterns in chemical structure data. These patterns are then used to augment a graph kernel function that calculates the pairwise similarity between molecules. The obtained similarity matrix is used as input to classify chemical compounds via a kernel machines such as the support vector machine (SVM). Our results indicate that the use of a pattern-based approach to graph similarity yields performance profiles comparable to, and sometimes exceeding that of the existing state-of-the-art approaches. In addition, the identification of highly discriminative patterns for activity classification provides evidence that our methods can make generalizations about a compound's function given its chemical structure. While we evaluated our methods on molecular structures, these methods are designed to operate on general graph data and hence could easily be applied to other domains in bioinformatics.",2008,2021-06-05 21:06:22; 2021-06-05 21:14:07,39-48,,6,Proc Asia Pac Bioinform Conf,,PubMed; PubMed Central,PMID: 20448828 PMCID: PMC2864492,http://www.ncbi.nlm.nih.gov/pubmed/20448828; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2864492/,,,,PubMed:Query2; PMC:Query2
569,10.2196/13756,31899457,PMC6969385,A,ArangoDB,ArangoDB,"Salvi, Dario; Poffley, Emma; Orchard, Elizabeth; Tarassenko, Lionel",The Mobile-Based 6-Minute Walk Test: Usability Study and Algorithm Development and Validation,2020,JMIR mHealth and uHealth,,"Background The 6-min walk test (6MWT) is a convenient method for assessing functional capacity in patients with cardiopulmonary conditions. It is usually performed in the context of a hospital clinic and thus requires the involvement of hospital staff and facilities, with their associated costs. Objective This study aimed to develop a mobile phone–based system that allows patients to perform the 6MWT in the community. Methods We developed 2 algorithms to compute the distance walked during a 6MWT using sensors embedded in a mobile phone. One algorithm makes use of the global positioning system to track the location of the phone when outdoors and hence computes the distance travelled. The other algorithm is meant to be used indoors and exploits the inertial sensors built into the phone to detect U-turns when patients walk back and forth along a corridor of fixed length. We included these algorithms in a mobile phone app, integrated with wireless pulse oximeters and a back-end server. We performed Bland-Altman analysis of the difference between the distances estimated by the phone and by a reference trundle wheel on 49 indoor tests and 30 outdoor tests, with 11 different mobile phones (both Apple iOS and Google Android operating systems). We also assessed usability aspects related to the app in a discussion group with patients and clinicians using a technology acceptance model to guide discussion. Results The mean difference between the mobile phone-estimated distances and the reference values was −2.013 m (SD 7.84 m) for the indoor algorithm and −0.80 m (SD 18.56 m) for the outdoor algorithm. The absolute maximum difference was, in both cases, below the clinically significant threshold. A total of 2 pulmonary hypertension patients, 1 cardiologist, 2 physiologists, and 1 nurse took part in the discussion group, where issues arising from the use of the 6MWT in hospital were identified. The app was demonstrated to be usable, and the 2 patients were keen to use it in the long term. Conclusions The system described in this paper allows patients to perform the 6MWT at a place of their convenience. In addition, the use of pulse oximetry allows more information to be generated about the patient’s health status and, possibly, be more relevant to the real-life impact of their condition. Preliminary assessment has shown that the developed 6MWT app is highly accurate and well accepted by its users. Further tests are needed to assess its clinical value.",2020-01-03,2021-06-05 20:55:01; 2021-06-05 21:10:08; 2021-06-06 06:42:51,,1,8,JMIR Mhealth Uhealth,The Mobile-Based 6-Minute Walk Test,PubMed Central,PMID: 31899457 PMCID: PMC6969385,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6969385/,,ArangoDB,ArangoDB,PMC:Query3; PMC:Query2; PMC:ArangoDB
570,10.2196/17853,32706701,PMC7414401,A,Neo4j,Neo4j,"Zowalla, Richard; Wetter, Thomas; Pfeifer, Daniel",Crawling the German Health Web: Exploratory Study and Graph Analysis,2020,Journal of Medical Internet Research,,"Background The internet has become an increasingly important resource for health information. However, with a growing amount of web pages, it is nearly impossible for humans to manually keep track of evolving and continuously changing content in the health domain. To better understand the nature of all web-based health information as given in a specific language, it is important to identify (1) information hubs for the health domain, (2) content providers of high prestige, and (3) important topics and trends in the health-related web. In this context, an automatic web crawling approach can provide the necessary data for a computational and statistical analysis to answer (1) to (3). Objective This study demonstrates the suitability of a focused crawler for the acquisition of the German Health Web (GHW) which includes all health-related web content of the three mostly German speaking countries Germany, Austria and Switzerland. Based on the gathered data, we provide a preliminary analysis of the GHW’s graph structure covering its size, most important content providers and a ratio of public to private stakeholders. In addition, we provide our experiences in building and operating such a highly scalable crawler. Methods A support vector machine classifier was trained on a large data set acquired from various German content providers to distinguish between health-related and non–health-related web pages. The classifier was evaluated using accuracy, recall and precision on an 80/20 training/test split (TD1) and against a crowd-validated data set (TD2). To implement the crawler, we extended the open-source framework StormCrawler. The actual crawl was conducted for 227 days. The crawler was evaluated by using harvest rate and its recall was estimated using a seed-target approach. Results In total, n=22,405 seed URLs with country-code top level domains .de: 85.36% (19,126/22,405), .at: 6.83% (1530/22,405), .ch: 7.81% (1749/22,405), were collected from Curlie and a previous crawl. The text classifier achieved an accuracy on TD1 of 0.937 (TD2=0.966), a precision on TD1 of 0.934 (TD2=0.954) and a recall on TD1 of 0.944 (TD2=0.989). The crawl yields 13.5 million presumably relevant and 119.5 million nonrelevant web pages. The average harvest rate was 19.76%; recall was 0.821 (4105/5000 targets found). The resulting host-aggregated graph contains 215,372 nodes and 403,175 edges (network diameter=25; average path length=6.466; average degree=1.872; average in-degree=1.892; average out-degree=1.845; modularity=0.723). Among the 25 top-ranked pages for each country (according to PageRank), 40% (30/75) were web sites published by public institutions. 25% (19/75) were published by nonprofit organizations and 35% (26/75) by private organizations or individuals. Conclusions The results indicate, that the presented crawler is a suitable method for acquiring a large fraction of the GHW. As desired, the computed statistical data allows for determining major information hubs and important content providers on the GHW. In the future, the acquired data may be used to assess important topics and trends but also to build health-specific search engines.",2020-07-24,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,,7,22,J Med Internet Res,Crawling the German Health Web,PubMed Central,PMID: 32706701 PMCID: PMC7414401,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7414401/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
571,10.2196/17964,33226347,PMC7721550,,,,"Cox, Steven; Ahalt, Stanley C; Balhoff, James; Bizon, Chris; Fecho, Karamarie; Kebede, Yaphet; Morton, Kenneth; Tropsha, Alexander; Wang, Patrick; Xu, Hao",Visualization Environment for Federated Knowledge Graphs: Development of an Interactive Biomedical Query Language and Web Application Interface,2020,JMIR Medical Informatics,,"Background Efforts are underway to semantically integrate large biomedical knowledge graphs using common upper-level ontologies to federate graph-oriented application programming interfaces (APIs) to the data. However, federation poses several challenges, including query routing to appropriate knowledge sources, generation and evaluation of answer subsets, semantic merger of those answer subsets, and visualization and exploration of results. Objective We aimed to develop an interactive environment for query, visualization, and deep exploration of federated knowledge graphs. Methods We developed a biomedical query language and web application interphase—termed as Translator Query Language (TranQL)—to query semantically federated knowledge graphs and explore query results. TranQL uses the Biolink data model as an upper-level biomedical ontology and an API standard that has been adopted by the Biomedical Data Translator Consortium to specify a protocol for expressing a query as a graph of Biolink data elements compiled from statements in the TranQL query language. Queries are mapped to federated knowledge sources, and answers are merged into a knowledge graph, with mappings between the knowledge graph and specific elements of the query. The TranQL interactive web application includes a user interface to support user exploration of the federated knowledge graph. Results We developed 2 real-world use cases to validate TranQL and address biomedical questions of relevance to translational science. The use cases posed questions that traversed 2 federated Translator API endpoints: Integrated Clinical and Environmental Exposures Service (ICEES) and Reasoning Over Biomedical Objects linked in Knowledge Oriented Pathways (ROBOKOP). ICEES provides open access to observational clinical and environmental data, and ROBOKOP provides access to linked biomedical entities, such as “gene,” “chemical substance,” and “disease,” that are derived largely from curated public data sources. We successfully posed queries to TranQL that traversed these endpoints and retrieved answers that we visualized and evaluated. Conclusions TranQL can be used to ask questions of relevance to translational science, rapidly obtain answers that require assertions from a federation of knowledge sources, and provide valuable insights for translational research and clinical practice.",2020-11-23,2021-06-05 21:09:36,,11,8,JMIR Med Inform,Visualization Environment for Federated Knowledge Graphs,PubMed Central,PMID: 33226347 PMCID: PMC7721550,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7721550/,,,,PMC:Query2
572,10.2196/18287,33026359,PMC7578820,A,Neo4j,Neo4j,"Xiu, Xiaolei; Qian, Qing; Wu, Sizhu",Construction of a Digestive System Tumor Knowledge Graph Based on Chinese Electronic Medical Records: Development and Usability Study,2020,JMIR Medical Informatics,,"Background With the increasing incidences and mortality of digestive system tumor diseases in China, ways to use clinical experience data in Chinese electronic medical records (CEMRs) to determine potentially effective relationships between diagnosis and treatment have become a priority. As an important part of artificial intelligence, a knowledge graph is a powerful tool for information processing and knowledge organization that provides an ideal means to solve this problem. Objective This study aimed to construct a semantic-driven digestive system tumor knowledge graph (DSTKG) to represent the knowledge in CEMRs with fine granularity and semantics. Methods This paper focuses on the knowledge graph schema and semantic relationships that were the main challenges for constructing a Chinese tumor knowledge graph. The DSTKG was developed through a multistep procedure. As an initial step, a complete DSTKG construction framework based on CEMRs was proposed. Then, this research built a knowledge graph schema containing 7 classes and 16 kinds of semantic relationships and accomplished the DSTKG by knowledge extraction, named entity linking, and drawing the knowledge graph. Finally, the quality of the DSTKG was evaluated from 3 aspects: data layer, schema layer, and application layer. Results Experts agreed that the DSTKG was good overall (mean score 4.20). Especially for the aspects of “rationality of schema structure,” “scalability,” and “readability of results,” the DSTKG performed well, with scores of 4.72, 4.67, and 4.69, respectively, which were much higher than the average. However, the small amount of data in the DSTKG negatively affected its “practicability” score. Compared with other Chinese tumor knowledge graphs, the DSTKG can represent more granular entities, properties, and semantic relationships. In addition, the DSTKG was flexible, allowing personalized customization to meet the designer's focus on specific interests in the digestive system tumor. Conclusions We constructed a granular semantic DSTKG. It could provide guidance for the construction of a tumor knowledge graph and provide a preliminary step for the intelligent application of knowledge graphs based on CEMRs. Additional data sources and stronger research on assertion classification are needed to gain insight into the DSTKG’s potential.",2020-10-07,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,,10,8,JMIR Med Inform,Construction of a Digestive System Tumor Knowledge Graph Based on Chinese Electronic Medical Records,PubMed Central,PMID: 33026359 PMCID: PMC7578820,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7578820/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
573,10.2196/18395,33006565,PMC7568218,A,Neo4j,Neo4j,"Zhu, Qian; Nguyen, Dac-Trung; Alyea, Gioconda; Hanson, Karen; Sid, Eric; Pariser, Anne",Phenotypically Similar Rare Disease Identification from an Integrative Knowledge Graph for Data Harmonization: Preliminary Study,2020,JMIR Medical Informatics,,"Background Although many efforts have been made to develop comprehensive disease resources that capture rare disease information for the purpose of clinical decision making and education, there is no standardized protocol for defining and harmonizing rare diseases across multiple resources. This introduces data redundancy and inconsistency that may ultimately increase confusion and difficulty for the wide use of these resources. To overcome such encumbrances, we report our preliminary study to identify phenotypical similarity among genetic and rare diseases (GARD) that are presenting similar clinical manifestations, and support further data harmonization. Objective To support rare disease data harmonization, we aim to systematically identify phenotypically similar GARD diseases from a disease-oriented integrative knowledge graph and determine their similarity types. Methods We identified phenotypically similar GARD diseases programmatically with 2 methods: (1) We measured disease similarity by comparing disease mappings between GARD and other rare disease resources, incorporating manual assessment; 2) we derived clinical manifestations presenting among sibling diseases from disease classifications and prioritized the identified similar diseases based on their phenotypes and genotypes. Results For disease similarity comparison, approximately 87% (341/392) identified, phenotypically similar disease pairs were validated; 80% (271/392) of these disease pairs were accurately identified as phenotypically similar based on similarity score. The evaluation result shows a high precision (94%) and a satisfactory quality (86% F measure). By deriving phenotypical similarity from Monarch Disease Ontology (MONDO) and Orphanet disease classification trees, we identified a total of 360 disease pairs with at least 1 shared clinical phenotype and gene, which were applied for prioritizing clinical relevance. A total of 662 phenotypically similar disease pairs were identified and will be applied for GARD data harmonization. Conclusions We successfully identified phenotypically similar rare diseases among the GARD diseases via 2 approaches, disease mapping comparison and phenotypical similarity derivation from disease classification systems. The results will not only direct GARD data harmonization in expanding translational science research but will also accelerate data transparency and consistency across different disease resources and terminologies, helping to build a robust and up-to-date knowledge resource on rare diseases.",2020-10-02,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,,10,8,JMIR Med Inform,Phenotypically Similar Rare Disease Identification from an Integrative Knowledge Graph for Data Harmonization,PubMed Central,PMID: 33006565 PMCID: PMC7568218,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7568218/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
574,10.2196/18752,33146623,PMC7673979,A,Neo4j,Neo4j,"Ammar, Nariman; Shaban-Nejad, Arash",Explainable Artificial Intelligence Recommendation System by Leveraging the Semantics of Adverse Childhood Experiences: Proof-of-Concept Prototype Development,2020,JMIR Medical Informatics,,"Background The study of adverse childhood experiences and their consequences has emerged over the past 20 years. Although the conclusions from these studies are available, the same is not true of the data. Accordingly, it is a complex problem to build a training set and develop machine-learning models from these studies. Classic machine learning and artificial intelligence techniques cannot provide a full scientific understanding of the inner workings of the underlying models. This raises credibility issues due to the lack of transparency and generalizability. Explainable artificial intelligence is an emerging approach for promoting credibility, accountability, and trust in mission-critical areas such as medicine by combining machine-learning approaches with explanatory techniques that explicitly show what the decision criteria are and why (or how) they have been established. Hence, thinking about how machine learning could benefit from knowledge graphs that combine “common sense” knowledge as well as semantic reasoning and causality models is a potential solution to this problem. Objective In this study, we aimed to leverage explainable artificial intelligence, and propose a proof-of-concept prototype for a knowledge-driven evidence-based recommendation system to improve mental health surveillance. Methods We used concepts from an ontology that we have developed to build and train a question-answering agent using the Google DialogFlow engine. In addition to the question-answering agent, the initial prototype includes knowledge graph generation and recommendation components that leverage third-party graph technology. Results To showcase the framework functionalities, we here present a prototype design and demonstrate the main features through four use case scenarios motivated by an initiative currently implemented at a children’s hospital in Memphis, Tennessee. Ongoing development of the prototype requires implementing an optimization algorithm of the recommendations, incorporating a privacy layer through a personal health library, and conducting a clinical trial to assess both usability and usefulness of the implementation. Conclusions This semantic-driven explainable artificial intelligence prototype can enhance health care practitioners’ ability to provide explanations for the decisions they make.",2020-11-04,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,11,8,JMIR Med Inform,Explainable Artificial Intelligence Recommendation System by Leveraging the Semantics of Adverse Childhood Experiences,PubMed Central,PMID: 33146623 PMCID: PMC7673979,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7673979/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
575,10.2196/22333,33127601,PMC7725650,A,Virtuoso,Virtuoso,"Luo, Lingyun; Feng, Jingtao; Yu, Huijun; Wang, Jiaolong",Automatic Structuring of Ontology Terms Based on Lexical Granularity and Machine Learning: Algorithm Development and Validation,2020,JMIR Medical Informatics,,"Background As the manual creation and maintenance of biomedical ontologies are labor-intensive, automatic aids are desirable in the lifecycle of ontology development. Objective Provided with a set of concept names in the Foundational Model of Anatomy (FMA), we propose an innovative method for automatically generating the taxonomy and the partonomy structures among them, respectively. Methods Our approach comprises 2 main tasks: The first task is predicting the direct relation between 2 given concept names by utilizing word embedding methods and training 2 machine learning models, Convolutional Neural Networks (CNN) and Bidirectional Long Short-term Memory Networks (Bi-LSTM). The second task is the introduction of an original granularity-based method to identify the semantic structures among a group of given concept names by leveraging these trained models. Results Results show that both CNN and Bi-LSTM perform well on the first task, with F1 measures above 0.91. For the second task, our approach achieves an average F1 measure of 0.79 on 100 case studies in the FMA using Bi-LSTM, which outperforms the primitive pairwise-based method. Conclusions We have investigated an automatic way of predicting a hierarchical relationship between 2 concept names; based on this, we have further invented a methodology to structure a group of concept names automatically. This study is an initial investigation that will shed light on further work on the automatic creation and enrichment of biomedical ontologies.",2020-11-25,2021-06-05 20:54:31; 2021-06-05 20:59:14; 2021-06-05 21:09:36,,11,8,JMIR Med Inform,Automatic Structuring of Ontology Terms Based on Lexical Granularity and Machine Learning,PubMed Central,PMID: 33127601 PMCID: PMC7725650,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7725650/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
576,10.2196/24738,33724197,PMC8075073,,,,"Ammar, Nariman; Bailey, James E; Davis, Robert L; Shaban-Nejad, Arash",Using a Personal Health Library–Enabled mHealth Recommender System for Self-Management of Diabetes Among Underserved Populations: Use Case for Knowledge Graphs and Linked Data,2021,JMIR Formative Research,,"Background Traditionally, digital health data management has been based on electronic health record (EHR) systems and has been handled primarily by centralized health providers. New mechanisms are needed to give patients more control over their digital health data. Personal health libraries (PHLs) provide a single point of secure access to patients' digital health data and enable the integration of knowledge stored in their digital health profiles with other sources of global knowledge. PHLs can help empower caregivers and health care providers to make informed decisions about patients’ health by understanding medical events in the context of their lives. Objective This paper reports the implementation of a mobile health digital intervention that incorporates both digital health data stored in patients’ PHLs and other sources of contextual knowledge to deliver tailored recommendations for improving self-care behaviors in diabetic adults. Methods We conducted a thematic assessment of patient functional and nonfunctional requirements that are missing from current EHRs based on evidence from the literature. We used the results to identify the technologies needed to address those requirements. We describe the technological infrastructures used to construct, manage, and integrate the types of knowledge stored in the PHL. We leverage the Social Linked Data (Solid) platform to design a fully decentralized and privacy-aware platform that supports interoperability and care integration. We provided an initial prototype design of a PHL and drafted a use case scenario that involves four actors to demonstrate how the proposed prototype can be used to address user requirements, including the construction and management of the PHL and its utilization for developing a mobile app that queries the knowledge stored and integrated into the PHL in a private and fully decentralized manner to provide better recommendations. Results To showcase the main features of the mobile health app and the PHL, we mapped those features onto a framework comprising the user requirements identified in a use case scenario that features a preventive intervention from the diabetes self-management domain. Ongoing development of the app requires a formative evaluation study and a clinical trial to assess the impact of the digital intervention on patient-users. We provide synopses of both study protocols. Conclusions The proposed PHL helps patients and their caregivers take a central role in making decisions regarding their health and equips their health care providers with informatics tools that support the collection and interpretation of the collected knowledge. By exposing the PHL functionality as an open service, we foster the development of third-party applications or services and provide motivational technological support in several projects crossing different domains of interest.",2021-03-16,2021-06-05 21:09:36,,3,5,JMIR Form Res,Using a Personal Health Library–Enabled mHealth Recommender System for Self-Management of Diabetes Among Underserved Populations,PubMed Central,PMID: 33724197 PMCID: PMC8075073,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8075073/,,,,PMC:Query2
577,10.2196/26836,33460389,PMC7837510,A,Neo4j; COVID19,Neo4j; COVID19,"Mao, Zijun; Yao, Hong; Zou, Qi; Zhang, Weiting; Dong, Ying",Digital Contact Tracing Based on a Graph Database Algorithm for Emergency Management During the COVID-19 Epidemic: Case Study,2021,JMIR mHealth and uHealth,,"BACKGROUND: The COVID-19 epidemic is still spreading globally. Contact tracing is a vital strategy in epidemic emergency management; however, traditional contact tracing faces many limitations in practice. The application of digital technology provides an opportunity for local governments to trace the contacts of individuals with COVID-19 more comprehensively, efficiently, and precisely. OBJECTIVE: Our research aimed to provide new solutions to overcome the limitations of traditional contact tracing by introducing the organizational process, technical process, and main achievements of digital contact tracing in Hainan Province. METHODS: A graph database algorithm, which can efficiently process complex relational networks, was applied in Hainan Province; this algorithm relies on a governmental big data platform to analyze multisource COVID-19 epidemic data and build networks of relationships among high-risk infected individuals, the general population, vehicles, and public places to identify and trace contacts. We summarized the organizational and technical process of digital contact tracing in Hainan Province based on interviews and data analyses. RESULTS: An integrated emergency management command system and a multi-agency coordination mechanism were formed during the emergency management of the COVID-19 epidemic in Hainan Province. The collection, storage, analysis, and application of multisource epidemic data were realized based on the government's big data platform using a centralized model. The graph database algorithm is compatible with this platform and can analyze multisource and heterogeneous big data related to the epidemic. These practices were used to quickly and accurately identify and trace 10,871 contacts among hundreds of thousands of epidemic data records; 378 closest contacts and a number of public places with high risk of infection were identified. A confirmed patient was found after quarantine measures were implemented by all contacts. CONCLUSIONS: During the emergency management of the COVID-19 epidemic, Hainan Province used a graph database algorithm to trace contacts in a centralized model, which can identify infected individuals and high-risk public places more quickly and accurately. This practice can provide support to government agencies to implement precise, agile, and evidence-based emergency management measures and improve the responsiveness of the public health emergency response system. Strengthening data security, improving tracing accuracy, enabling intelligent data collection, and improving data-sharing mechanisms and technologies are directions for optimizing digital contact tracing.; Background The COVID-19 epidemic is still spreading globally. Contact tracing is a vital strategy in epidemic emergency management; however, traditional contact tracing faces many limitations in practice. The application of digital technology provides an opportunity for local governments to trace the contacts of individuals with COVID-19 more comprehensively, efficiently, and precisely. Objective Our research aimed to provide new solutions to overcome the limitations of traditional contact tracing by introducing the organizational process, technical process, and main achievements of digital contact tracing in Hainan Province. Methods A graph database algorithm, which can efficiently process complex relational networks, was applied in Hainan Province; this algorithm relies on a governmental big data platform to analyze multisource COVID-19 epidemic data and build networks of relationships among high-risk infected individuals, the general population, vehicles, and public places to identify and trace contacts. We summarized the organizational and technical process of digital contact tracing in Hainan Province based on interviews and data analyses. Results An integrated emergency management command system and a multi-agency coordination mechanism were formed during the emergency management of the COVID-19 epidemic in Hainan Province. The collection, storage, analysis, and application of multisource epidemic data were realized based on the government’s big data platform using a centralized model. The graph database algorithm is compatible with this platform and can analyze multisource and heterogeneous big data related to the epidemic. These practices were used to quickly and accurately identify and trace 10,871 contacts among hundreds of thousands of epidemic data records; 378 closest contacts and a number of public places with high risk of infection were identified. A confirmed patient was found after quarantine measures were implemented by all contacts. Conclusions During the emergency management of the COVID-19 epidemic, Hainan Province used a graph database algorithm to trace contacts in a centralized model, which can identify infected individuals and high-risk public places more quickly and accurately. This practice can provide support to government agencies to implement precise, agile, and evidence-based emergency management measures and improve the responsiveness of the public health emergency response system. Strengthening data security, improving tracing accuracy, enabling intelligent data collection, and improving data-sharing mechanisms and technologies are directions for optimizing digital contact tracing.",2021-01-22,2021-06-05 20:35:57; 2021-06-05 21:35:36; 2021-06-05 20:54:31; 2021-06-05 21:09:36; 2021-06-05 21:06:22,e26836,1,9,JMIR Mhealth Uhealth,Digital Contact Tracing Based on a Graph Database Algorithm for Emergency Management During the COVID-19 Epidemic,PubMed; PubMed Central,PMID: 33460389 PMCID: PMC7837510,http://www.ncbi.nlm.nih.gov/pubmed/33460389; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7837510/,"Algorithms; big data; Big Data; China; Computer Graphics; Contact Tracing; COVID-19; Data Visualization; Databases, Factual; digital contact tracing; Digital Technology; emergency management; Epidemics; graph database; Humans; visualization",Neo4j; COVID19,Neo4j; COVID19,PMC:Query2; PMC:Query3; PMC:Neo4j; PMC:COVID19; PubMed:Query2
578,10.2196/jmir.4163,25944105,PMC4468594,,,,"Pfundner, Alexander; Schönberg, Tobias; Horn, John; Boyce, Richard D; Samwald, Matthias",Utilizing the Wikidata System to Improve the Quality of Medical Content in Wikipedia in Diverse Languages: A Pilot Study,2015,Journal of Medical Internet Research,,"Background Wikipedia is an important source of medical information for both patients and medical professionals. Given its wide reach, improving the quality, completeness, and accessibility of medical information on Wikipedia could have a positive impact on global health. Objective We created a prototypical implementation of an automated system for keeping drug-drug interaction (DDI) information in Wikipedia up to date with current evidence about clinically significant drug interactions. Our work is based on Wikidata, a novel, graph-based database backend of Wikipedia currently in development. Methods We set up an automated process for integrating data from the Office of the National Coordinator for Health Information Technology (ONC) high priority DDI list into Wikidata. We set up exemplary implementations demonstrating how the DDI data we introduced into Wikidata could be displayed in Wikipedia articles in diverse languages. Finally, we conducted a pilot analysis to explore if adding the ONC high priority data would substantially enhance the information currently available on Wikipedia. Results We derived 1150 unique interactions from the ONC high priority list. Integration of the potential DDI data from Wikidata into Wikipedia articles proved to be straightforward and yielded useful results. We found that even though the majority of current English Wikipedia articles about pharmaceuticals contained sections detailing contraindications, only a small fraction of articles explicitly mentioned interaction partners from the ONC high priority list. For 91.30% (1050/1150) of the interaction pairs we tested, none of the 2 articles corresponding to the interacting substances explicitly mentioned the interaction partner. For 7.21% (83/1150) of the pairs, only 1 of the 2 associated Wikipedia articles mentioned the interaction partner; for only 1.48% (17/1150) of the pairs, both articles contained explicit mentions of the interaction partner. Conclusions Our prototype demonstrated that automated updating of medical content in Wikipedia through Wikidata is a viable option, albeit further refinements and community-wide consensus building are required before integration into public Wikipedia is possible. A long-term endeavor to improve the medical information in Wikipedia through structured data representation and automated workflows might lead to a significant improvement of the quality of medical information in one of the world’s most popular Web resources.",2015-05-05,2021-06-05 21:12:40,,5,17,J Med Internet Res,Utilizing the Wikidata System to Improve the Quality of Medical Content in Wikipedia in Diverse Languages,PubMed Central,PMID: 25944105 PMCID: PMC4468594,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4468594/,,,,PMC:Query2
579,10.2196/jmir.7486,29109069,PMC5696582,,,,"Kandula, Sasikiran; Hsu, Daniel; Shaman, Jeffrey",Subregional Nowcasts of Seasonal Influenza Using Search Trends,2017,Journal of Medical Internet Research,,"Background Limiting the adverse effects of seasonal influenza outbreaks at state or city level requires close monitoring of localized outbreaks and reliable forecasts of their progression. Whereas forecasting models for influenza or influenza-like illness (ILI) are becoming increasingly available, their applicability to localized outbreaks is limited by the nonavailability of real-time observations of the current outbreak state at local scales. Surveillance data collected by various health departments are widely accepted as the reference standard for estimating the state of outbreaks, and in the absence of surveillance data, nowcast proxies built using Web-based activities such as search engine queries, tweets, and access of health-related webpages can be useful. Nowcast estimates of state and municipal ILI were previously published by Google Flu Trends (GFT); however, validations of these estimates were seldom reported. Objective The aim of this study was to develop and validate models to nowcast ILI at subregional geographic scales. Methods We built nowcast models based on autoregressive (autoregressive integrated moving average; ARIMA) and supervised regression methods (Random forests) at the US state level using regional weighted ILI and Web-based search activity derived from Google's Extended Trends application programming interface. We validated the performance of these methods using actual surveillance data for the 50 states across six seasons. We also built state-level nowcast models using state-level estimates of ILI and compared the accuracy of these estimates with the estimates of the regional models extrapolated to the state level and with the nowcast estimates published by GFT. Results Models built using regional ILI extrapolated to state level had a median correlation of 0.84 (interquartile range: 0.74-0.91) and a median root mean square error (RMSE) of 1.01 (IQR: 0.74-1.50), with noticeable variability across seasons and by state population size. Model forms that hypothesize the availability of timely state-level surveillance data show significantly lower errors of 0.83 (0.55-0.23). Compared with GFT, the latter model forms have lower errors but also lower correlation. Conclusions These results suggest that the proposed methods may be an alternative to the discontinued GFT and that further improvements in the quality of subregional nowcasts may require increased access to more finely resolved surveillance data.",2017-11-06,2021-06-05 21:11:16,,11,19,J Med Internet Res,,PubMed Central,PMID: 29109069 PMCID: PMC5696582,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5696582/,,,,PMC:Query2
580,10.2196/medinform.3387,25600290,PMC4288067,,,,"Albin, Aaron; Ji, Xiaonan; Borlawsky, Tara B; Ye, Zhan; Lin, Simon; Payne, Philip RO; Huang, Kun; Xiang, Yang",Enabling Online Studies of Conceptual Relationships Between Medical Terms: Developing an Efficient Web Platform,2014,JMIR Medical Informatics,,"Background The Unified Medical Language System (UMLS) contains many important ontologies in which terms are connected by semantic relations. For many studies on the relationships between biomedical concepts, the use of transitively associated information from ontologies and the UMLS has been shown to be effective. Although there are a few tools and methods available for extracting transitive relationships from the UMLS, they usually have major restrictions on the length of transitive relations or on the number of data sources. Objective Our goal was to design an efficient online platform that enables efficient studies on the conceptual relationships between any medical terms. Methods To overcome the restrictions of available methods and to facilitate studies on the conceptual relationships between medical terms, we developed a Web platform, onGrid, that supports efficient transitive queries and conceptual relationship studies using the UMLS. This framework uses the latest technique in converting natural language queries into UMLS concepts, performs efficient transitive queries, and visualizes the result paths. It also dynamically builds a relationship matrix for two sets of input biomedical terms. We are thus able to perform effective studies on conceptual relationships between medical terms based on their relationship matrix. Results The advantage of onGrid is that it can be applied to study any two sets of biomedical concept relations and the relations within one set of biomedical concepts. We use onGrid to study the disease-disease relationships in the Online Mendelian Inheritance in Man (OMIM). By crossvalidating our results with an external database, the Comparative Toxicogenomics Database (CTD), we demonstrated that onGrid is effective for the study of conceptual relationships between medical terms. Conclusions onGrid is an efficient tool for querying the UMLS for transitive relations, studying the relationship between medical terms, and generating hypotheses.",2014-10-07,2021-06-05 21:12:40,,2,2,JMIR Med Inform,Enabling Online Studies of Conceptual Relationships Between Medical Terms,PubMed Central,PMID: 25600290 PMCID: PMC4288067,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4288067/,,,,PMC:Query2
581,10.2196/medinform.7059,29196280,PMC5732329,,,,"Segura Bedmar, Isabel; Martínez, Paloma; Carruana Martín, Adrián",Search and Graph Database Technologies for Biomedical Semantic Indexing: Experimental Analysis,2017,JMIR medical informatics; JMIR Medical Informatics,,"Background Biomedical semantic indexing is a very useful support tool for human curators in their efforts for indexing and cataloging the biomedical literature. Objective The aim of this study was to describe a system to automatically assign Medical Subject Headings (MeSH) to biomedical articles from MEDLINE. Methods Our approach relies on the assumption that similar documents should be classified by similar MeSH terms. Although previous work has already exploited the document similarity by using a k-nearest neighbors algorithm, we represent documents as document vectors by search engine indexing and then compute the similarity between documents using cosine similarity. Once the most similar documents for a given input document are retrieved, we rank their MeSH terms to choose the most suitable set for the input document. To do this, we define a scoring function that takes into account the frequency of the term into the set of retrieved documents and the similarity between the input document and each retrieved document. In addition, we implement guidelines proposed by human curators to annotate MEDLINE articles; in particular, the heuristic that says if 3 MeSH terms are proposed to classify an article and they share the same ancestor, they should be replaced by this ancestor. The representation of the MeSH thesaurus as a graph database allows us to employ graph search algorithms to quickly and easily capture hierarchical relationships such as the lowest common ancestor between terms. Results Our experiments show promising results with an F1 of 69% on the test dataset. Conclusions To the best of our knowledge, this is the first work that combines search and graph database technologies for the task of biomedical semantic indexing. Due to its horizontal scalability, ElasticSearch becomes a real solution to index large collections of documents (such as the bibliographic database MEDLINE). Moreover, the use of graph search algorithms for accessing MeSH information could provide a support tool for cataloging MEDLINE abstracts in real time.; BACKGROUND: Biomedical semantic indexing is a very useful support tool for human curators in their efforts for indexing and cataloging the biomedical literature. OBJECTIVE: The aim of this study was to describe a system to automatically assign Medical Subject Headings (MeSH) to biomedical articles from MEDLINE. METHODS: Our approach relies on the assumption that similar documents should be classified by similar MeSH terms. Although previous work has already exploited the document similarity by using a k-nearest neighbors algorithm, we represent documents as document vectors by search engine indexing and then compute the similarity between documents using cosine similarity. Once the most similar documents for a given input document are retrieved, we rank their MeSH terms to choose the most suitable set for the input document. To do this, we define a scoring function that takes into account the frequency of the term into the set of retrieved documents and the similarity between the input document and each retrieved document. In addition, we implement guidelines proposed by human curators to annotate MEDLINE articles; in particular, the heuristic that says if 3 MeSH terms are proposed to classify an article and they share the same ancestor, they should be replaced by this ancestor. The representation of the MeSH thesaurus as a graph database allows us to employ graph search algorithms to quickly and easily capture hierarchical relationships such as the lowest common ancestor between terms. RESULTS: Our experiments show promising results with an F1 of 69% on the test dataset. CONCLUSIONS: To the best of our knowledge, this is the first work that combines search and graph database technologies for the task of biomedical semantic indexing. Due to its horizontal scalability, ElasticSearch becomes a real solution to index large collections of documents (such as the bibliographic database MEDLINE). Moreover, the use of graph search algorithms for accessing MeSH information could provide a support tool for cataloging MEDLINE abstracts in real time.",2017-12-01,2021-06-05 21:06:22; 2021-06-05 21:11:16,e48,4,5,JMIR Med Inform,Search and Graph Database Technologies for Biomedical Semantic Indexing,PubMed; PubMed Central,PMID: 29196280 PMCID: PMC5732329,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5732329/; http://www.ncbi.nlm.nih.gov/pubmed/29196280,information storage and retrieval; Medical Subject Headings; semantic indexing,,,PubMed:Query2; PMC:Query2
582,10.2217/pme-2018-0145,30760118,PMC7545355,,,,"Moore, Jason H.; Boland, Mary Regina; Camara, Pablo G.; Chervitz, Hannah; Gonzalez, Graciela; Himes, Blanca E.; Kim, Dokyoon; Mowery, Danielle L.; Ritchie, Marylyn D.; Shen, Li; Urbanowicz, Ryan J.; Holmes, John H.",Preparing next-generation scientists for biomedical big data: Artificial intelligence approaches,2019,Personalized medicine,,"Personalized medicine is being realized by our ability to measure biological and environmental information about patients. Much of these data is being stored in electronic health records yielding big data that presents challenges for its management and analysis. We review here several areas of knowledge that are necessary for next-generation scientists to fully realize the potential of biomedical big data. We begin with an overview of big data and its storage and management. We then review statistics and data science as foundational topics followed by a core curriculum of artificial intelligence, machine learning, and natural language processing that are needed to develop predictive models for clinical decision making. We end with some specific training recommendations for preparing next-generation scientists for biomedical big data.",2019-05-01,2021-06-05 21:10:37,247-257,3,16,Per Med,Preparing next-generation scientists for biomedical big data,PubMed Central,PMID: 30760118 PMCID: PMC7545355,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7545355/,,,,PMC:Query2
583,10.23889/ijpds.v4i2.1136,32935038,PMC7482520,,,,"Schneider, M; Radbone, CG; Vasquez, SA; Palfy, M; Stanley, AK",Population Data Centre Profile: SA NT DataLink (South Australia and Northern Territory),,International Journal of Population Data Science,,"Introduction Originally piloted as a multi-departmental project within the Government of South Australia, SA NT DataLink is now the key provider of data linkage services in South Australia, the Northern Territory of Australia and the Commonwealth of Australia, enabling academics and policy makers to undertake research, policy, planning and evaluation. Approach Uniquely governed by a broad range of consortium partners, SA NT DataLink’s business model operates with flexibility to adapt to researcher priorities and government requirements. Its Data Linkage Unit routinely links data from over 50 sources with more than 57 million records on approximately 2.9 million individuals. It arguably provides the broadest range of linked data sources in Australia, focusing on administrative datasets and clinical registries from various health and human services domains. Operating in strict adherence with the separation principal, SA NT DataLink’s Data Integration Unit separately manages anonymised clinical and service use data in collaboration with the respective data custodians through the Custodian Controlled Data Repository, allowing approved analysts to efficiently access high quality linked anonymised data. To protect individual privacy throughout the process of data linkage and data provision, SA NT DataLink’s processes align with state, territory and federal privacy legislations. Operating consistently with National Health and Medical Research Council guidelines, linkage projects are subject to approvals by the relevant data custodians and approved Human Research Ethics Committees. Noteworthy Outputs SA NT DataLink has provided linkage services to over 160 data linkage projects, informing nationally significant research and policy initiatives, including initiatives to improve indigenous children’s hearing and child development. Conclusion To respond to a changing data linkage landscape, SA NT DataLink is continuously reviewing and improving its systems, linkage processes and governance, addressing administrative, funding, data access, social licence and data linkage challenges and opportunities to meet increasing demand and new business developments.",,2021-06-05 21:10:37,,2,4,Int J Popul Data Sci,Population Data Centre Profile,PubMed Central,PMID: 32935038 PMCID: PMC7482520,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7482520/,,,,PMC:Query2
584,10.26434/chemrxiv.12462623,32601612,PMC7316095,A,Neo4j; COVID19,Neo4j; COVID19,"Korn, Daniel; Bobrowski, Tesia; Li, Michael; Kebede, Yaphet; Wang, Patrick; Owen, Phillips; Vaidya, Gaurav; Muratov, Eugene; Chirkova, Rada; Bizon, Chris; Tropsha, Alexander",COVID-KOP: Integrating Emerging COVID-19 Data with the ROBOKOP Database,2020,ChemRxiv,,"In response to the COVID-19 pandemic, we established COVID-KOP, a new knowledgebase integrating the existing ROBOKOP biomedical knowledge graph with information from recent biomedical literature on COVID-19 annotated in the CORD-19 collection. COVID-KOP can be used effectively to test new hypotheses concerning repurposing of known drugs and clinical drug candidates against COVID-19. COVID-KOP is freely accessible at https://covidkop.renci.org/. For code and instructions for the original ROBOKOP, see: https://github.com/NCATS-Gamma/robokop.",2020-06-18,2021-06-05 20:35:57; 2021-06-05 21:35:36; 2021-06-05 20:54:31; 2021-06-05 21:10:08,,,,ChemRxiv,COVID-KOP,PubMed Central,PMID: 32601612 PMCID: PMC7316095,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7316095/,,Neo4j; COVID19,Neo4j; COVID19,PMC:Query3; PMC:Neo4j; PMC:COVID19; PMC:Query2
585,10.3233/ICA-180570,31093004,PMC6512829,,,,"Schlenoff, Craig; Balakirsky, Stephen; Christensen, Henrik",Introduction: Special Issue on Enabling Robot Autonomy,2018,Integrated computer-aided engineering,,,2018,2021-06-05 21:11:16,,,25,Integr Comput Aided Eng,Introduction,PubMed Central,PMID: 31093004 PMCID: PMC6512829,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6512829/,,,,PMC:Query2
586,10.3233/SHTI190180,31437882,,A,,,"Bouzillé, Guillaume; Morival, Camille; Westerlynck, Richard; Lemordant, Pierre; Chazard, Emmanuel; Lecorre, Pascal; Busnel, Yann; Cuggia, Marc",An Automated Detection System of Drug-Drug Interactions from Electronic Patient Records Using Big Data Analytics,2019,Studies in Health Technology and Informatics,,"The aim of the study was to build a proof-of-concept demonstratrating that big data technology could improve drug safety monitoring in a hospital and could help pharmacovigilance professionals to make data-driven targeted hypotheses on adverse drug events (ADEs) due to drug-drug interactions (DDI). We developed a DDI automatic detection system based on treatment data and laboratory tests from the electronic health records stored in the clinical data warehouse of Rennes academic hospital. We also used OrientDb, a graph database to store informations from five drug knowledge databases and Spark to perform analysis of potential interactions betweens drugs taken by hospitalized patients. Then, we developed a machine learning model to identify the patients in whom an ADE might have occurred because of a DDI. The DDI detection system worked efficiently and computation time was manageable. The system could be routinely employed for monitoring.",2019-08-21,2021-06-05 21:24:28; 2021-06-05 21:06:22,45-49,,264,Stud Health Technol Inform,,PubMed,PMID: 31437882,http://www.ncbi.nlm.nih.gov/pubmed/31437882,Automation; Big Data; Computing Methodologies; Drug Interaction; Drug Interactions; Drug-Related Side Effects and Adverse Reactions; Electronic Health Records; Humans; Machine Learning; Pharmacovigilance,,,PubMed:Query3; PubMed:Query2
587,10.3233/SHTI190546,31438243,,A,,,"Silva Layes, Elizabeth; Bondarenco, Marcelo; Machiavello, Daniel; Frola, Fabián; Lemos, Martín",Implementation of a Terminology Server with SNOMED CT in Graph Databases,2019,Studies in Health Technology and Informatics,,"This paper described the implementation of a terminology server performed at a health institution in Uruguay, whose architecture is based on SNOMED CT using graph databases (NoSQL). The aim of this development was to create an intuitive terminological service, making the most of SNOMED CT's ontology, and which can be used from a clinical, statistical, management, decision support and research point of view, among others, with good performance.",2019-08-21,2021-06-05 21:06:22,1584-1585,,264,Stud Health Technol Inform,,PubMed,PMID: 31438243,http://www.ncbi.nlm.nih.gov/pubmed/31438243,"Computers; Controlled; Databases; Databases, Factual; Factual; Semantics; Systematized Nomenclature of Medicine; Uruguay; Vocabulary",,,PubMed:Query2
588,10.3233/SHTI190804,31483253,,A,Neo4j,Neo4j,"Fette, Georg; Kaspar, Mathias; Liman, Leon; Ertl, Maximilian; Krebs, Jonathan; Störk, Stefan; Puppe, Frank",Implementation of a HL7-CQL Engine Using the Graph Database Neo4J,2019,Studies in Health Technology and Informatics,,"The Clinical Quality Language (CQL) is a useful tool for defining search requests for data stores containing FHIR data. Unfortunately, there are only few execution engines that are able to evaluate CQL queries. As FHIR data represents a graph structure, the authors pursue the approach of storing all data contained in a FHIR server in the graph database Neo4J and to translate CQL queries into Neo4J's query language Cypher. The query results returned by the graph database are retranslated into their FHIR representation and returned to the querying user. The approach has been positively tested on publicly available FHIR servers with a handcrafted set of example CQL queries.",2019-09-03,2021-06-05 21:24:28; 2021-06-05 21:06:22; 2021-06-05 21:16:51,46-51,,267,Stud Health Technol Inform,,PubMed,PMID: 31483253,http://www.ncbi.nlm.nih.gov/pubmed/31483253,"Databases, Factual; FHIR; graph database; Language; Neo4J; query engine",Neo4j,Neo4j,PubMed:Neo4j; PubMed:Query3; PubMed:Query2
589,10.3233/SHTI200147,32570371,,A,,,"Syed, Shorabuddin; Syed, Mahanazuddin; Syeda, Hafsa Bareen; Prior, Fred; Zozus, Meredith; Penning, Melody L.; Orloff, Mohammed",Document Oriented Graphical Analysis and Prediction,2020,Studies in Health Technology and Informatics,,"In general, small-mid size research laboratories struggle with managing clinical and secondary datasets. In addition, faster dissemination, correlation and prediction of information from available datasets is always a bottleneck. To address these challenges, we have developed a novel approach, Document Oriented Graphical Analysis and Prediction (DO-GAP), a hybrid tool, merging strengths of Not only SQL (NoSQL) document oriented and graph databases. DO-GAP provides flexible and simple data integration mechanism using document database, data visualization and knowledge discovery with graph database. We demonstrate how the proposed tool (DO-GAP) can integrate data from heterogeneous sources such as Genomic lab findings, clinical data from Electronic Health Record (EHR) systems and provide simple querying mechanism. Application of DO-GAP can be extended to other diverse clinical studies such as supporting or identifying weakness of clinical diagnosis in comparison to molecular genetic analysis.",2020-06-16,2021-06-05 21:06:22,183-187,,270,Stud Health Technol Inform,,PubMed,PMID: 32570371,http://www.ncbi.nlm.nih.gov/pubmed/32570371,"clinical trials; Data integration; data processing; data quality; Databases, Factual; Genomics",,,PubMed:Query2
590,10.3233/SHTI200194,32570418,,A,Virtuoso,Virtuoso,"Belhadj, Ihssen; Boudemaghe, Thierry",Semantic Querying of Hospital Data Using an Ontology-Based Model of Discharge Summaries and ICD 10,2020,Studies in Health Technology and Informatics,,"This paper focusses on the question of knowledge-based modeling of discharge summaries for semantic requesting in the context of hospital reporting process. An ontology was designed and implemented to capture patient data and required expert knowledge. The modeling process was carried out manually using Protégé after an initial reverse engineering of the official format of discharge summaries. An OWL 2 model was built integrating discharge summaries ontology and ICD 10 hierarchy. The framework is operationalized using the OpenLink Virtuoso database system (RDF store), enabling SPARQL queries and basic reasoning features. The evaluation was performed by implementing a use case based on patient comorbidities.",2020-06-16,2021-06-05 21:18:16; 2021-06-05 21:24:28; 2021-06-05 21:06:22,417-421,,270,Stud Health Technol Inform,,PubMed,PMID: 32570418,http://www.ncbi.nlm.nih.gov/pubmed/32570418,"Databases, Factual; ICD 10; International Classification of Diseases; Knowledge Bases; Ontologies; OpenLink Virtuoso; OWL; Patient Discharge; Protégé; RDF; RDFS; Semantics",Virtuoso,Virtuoso,PubMed:Virtuoso; PubMed:Query3; PubMed:Query2
591,10.3233/SHTI210116,34042701,,A,,,"Martinez-Costa, Catalina; Abad-Navarro, Francisco",Towards a Semantic Data Harmonization Federated Infrastructure,2021,Studies in Health Technology and Informatics,,"Data integration is an increasing need in medical informatics projects like the EU Precise4Q project, in which multidisciplinary semantically and syntactically heterogeneous data across several institutions needs to be integrated. Besides, data sharing agreements often allow a virtual data integration only, because data cannot leave the source repository. We propose a data harmonization infrastructure in which data is virtually integrated by sharing a semantically rich common data representation that allows their homogeneous querying. This common data model integrates content from well-known biomedical ontologies like SNOMED CT by using the BTL2 upper level ontology, and is imported into a graph database. We successfully integrated three datasets and made some test queries showing the feasibility of the approach.",2021-05-27,2021-06-05 21:06:22,38-42,,281,Stud Health Technol Inform,,PubMed,PMID: 34042701,http://www.ncbi.nlm.nih.gov/pubmed/34042701,"Biological Ontologies; Databases, Factual; graph database; Medical Informatics; Ontologies; semantic harmonization; Semantics; SNOMED CT; Systematized Nomenclature of Medicine",,,PubMed:Query2
592,10.3233/SHTI210267,34042671,,A,,,"Daowd, Ali; Barrett, Michael; Abidi, Samina; Abidi, Syed Sibte Raza",Building a Knowledge Graph Representing Causal Associations Between Risk Factors and Incidence of Breast Cancer,2021,Studies in Health Technology and Informatics,,"This paper explores the use of semantic- and evidence-based biomedical knowledge to build the RiskExplorer knowledge graph that outlines causal associations between risk factors and chronic disease or cancers. The intent of this work is to offer an interactive knowledge synthesis platform to empower health-information-seeking individuals to learn about and mitigate modifiable risk factors. Our approach analyzes biomedical text (from PubMed abstracts), Semantic Medline database, evidence-based semantic associations, literature-based discovery, and graph database to discover associations between risk factors and breast cancer. Our methodological framework involves (a) identifying relevant literature on specified chronic diseases or cancers, (b) extracting semantic associations via knowledge mining tool, (c) building rich semantic graph by transforming semantic associations to nodes and edges, (d) applying frequency-based methods and using semantic edge properties to traverse the graph and identify meaningful multi-node NCD risk paths. Generated multi-node risk paths consist of a source node (representing the source risk factor), one or more intermediate nodes (representing biomedical phenotypes), a target node (representing a chronic disease or cancer), and edges between nodes representing meaningful semantic associations. The results demonstrate that our methodology is capable of generating biomedically valid knowledge related to causal risk and protective factors related to breast cancer.",2021-05-27,2021-06-05 21:06:22,724-728,,281,Stud Health Technol Inform,,PubMed,PMID: 34042671,http://www.ncbi.nlm.nih.gov/pubmed/34042671,"Breast Neoplasms; disease risk mitigation; Humans; Incidence; Knowledge Discovery; Knowledge graph; literature-based discovery; Pattern Recognition, Automated; Risk Factors; Semantics",,,PubMed:Query2
593,10.3389/fbioe.2014.00069,25540777,PMC4261811,A,OrientDB,OrientDB,"Bonnici, Vincenzo; Russo, Francesco; Bombieri, Nicola; Pulvirenti, Alfredo; Giugno, Rosalba",Comprehensive Reconstruction and Visualization of Non-Coding Regulatory Networks in Human,2014,Frontiers in Bioengineering and Biotechnology,,"Research attention has been powered to understand the functional roles of non-coding RNAs (ncRNAs). Many studies have demonstrated their deregulation in cancer and other human disorders. ncRNAs are also present in extracellular human body fluids such as serum and plasma, giving them a great potential as non-invasive biomarkers. However, non-coding RNAs have been relatively recently discovered and a comprehensive database including all of them is still missing. Reconstructing and visualizing the network of ncRNAs interactions are important steps to understand their regulatory mechanism in complex systems. This work presents ncRNA-DB, a NoSQL database that integrates ncRNAs data interactions from a large number of well established on-line repositories. The interactions involve RNA, DNA, proteins, and diseases. ncRNA-DB is available at http://ncrnadb.scienze.univr.it/ncrnadb/. It is equipped with three interfaces: web based, command-line, and a Cytoscape app called ncINetView. By accessing only one resource, users can search for ncRNAs and their interactions, build a network annotated with all known ncRNAs and associated diseases, and use all visual and mining features available in Cytoscape.",2014-12-10,2021-06-06 06:49:06; 2021-06-05 20:56:20; 2021-06-05 21:12:40,,,2,Front Bioeng Biotechnol,,PubMed Central,PMID: 25540777 PMCID: PMC4261811,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4261811/,,OrientDB,OrientDB,PMC:Query3; PMC:Query2; PMC:OrientDB
594,10.3389/fbioe.2015.00019,25759811,PMC4338824,,,,"Hucka, Michael; Nickerson, David P.; Bader, Gary D.; Bergmann, Frank T.; Cooper, Jonathan; Demir, Emek; Garny, Alan; Golebiewski, Martin; Myers, Chris J.; Schreiber, Falk; Waltemath, Dagmar; Le Novère, Nicolas",Promoting Coordinated Development of Community-Based Information Standards for Modeling in Biology: The COMBINE Initiative,2015,Frontiers in Bioengineering and Biotechnology,,"The Computational Modeling in Biology Network (COMBINE) is a consortium of groups involved in the development of open community standards and formats used in computational modeling in biology. COMBINE’s aim is to act as a coordinator, facilitator, and resource for different standardization efforts whose domains of use cover related areas of the computational biology space. In this perspective article, we summarize COMBINE, its general organization, and the community standards and other efforts involved in it. Our goals are to help guide readers toward standards that may be suitable for their research activities, as well as to direct interested readers to relevant communities where they can best expect to receive assistance in how to develop interoperable computational models.",2015-02-24,2021-06-05 21:12:40,,,3,Front Bioeng Biotechnol,Promoting Coordinated Development of Community-Based Information Standards for Modeling in Biology,PubMed Central,PMID: 25759811 PMCID: PMC4338824,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4338824/,,,,PMC:Query2
595,10.3389/fbioe.2019.00156,31334227,PMC6616276,A,Neo4j,Neo4j,"Sedler, Andrew R.; Mitchell, Cassie S.",SemNet: Using Local Features to Navigate the Biomedical Concept Graph,2019,Frontiers in Bioengineering and Biotechnology,,"Literature-Based Discovery (LBD) aims to connect scientists across silos by assembling models of the literature to reveal previously hidden connections. Unfortunately, LBD systems have been unable to achieve user adoption on a large scale. This work develops opens source software in Python to convert a database of semantic predications of all of PubMed's 27.9 million indexed abstracts into a semantic inference network and biomedical concept graph in Neo4j. The developed software, called SemNet, queries a modified version of the publicly available SemMedDB and computes feature vectors on source-target pairs. Each unique United Medical Language System (UMLS) concept is represented as a node and each predication as an edge. Each node is assigned one of 132 node labels (e.g., Amino Acid, Peptide, or Protein (AAPP); Gene or Genome (GG); etc.) and each edge is labeled with one of 58 predications (e.g. treats, causes, inhibits, etc.). SemNet computes a single feature value for each metapath, or sequence of node types, between a source node and user-specified target node(s). Several different types of metapath-based features (count, degree weighted path count, and HeteSim metric) are computed and vectorized. SemNet employs an unsupervised learning algorithm for rank aggregation (ULARA) to rank identified source nodes that are most relevant to the user-specified target nodes(s). Statistical analysis of correlation among identified source nodes or resultant literature network features are used to identify patterns that can guide future research. Analysis of high residual nodes is used to compare and contrast SemNet rankings between different targets of interest. An example SemNet use case is presented to assess ""the differential impact of smoking on cognition in males and females"" using the following target nodes: nicotine, learning, memory, tetrahydrocannabinol (THC), cigarette smoke, X chromosome, and Y chromosome. Detailed rankings are discussed. Overall results suggest a hypothesis where smoking negatively impacts cognition to a greater extent in females, but smoking has stronger cardiovascular impacts in males. In summary, SemNet provides an adoptable method for efficient LBD of PubMed that extends beyond omics-only relationships to true multi-scalar connections that can provide actionable insight for predictive medicine, research prioritization, and clinical care.; Literature-Based Discovery (LBD) aims to connect scientists across silos by assembling models of the literature to reveal previously hidden connections. Unfortunately, LBD systems have been unable to achieve user adoption on a large scale. This work develops opens source software in Python to convert a database of semantic predications of all of PubMed's 27.9 million indexed abstracts into a semantic inference network and biomedical concept graph in Neo4j. The developed software, called SemNet, queries a modified version of the publicly available SemMedDB and computes feature vectors on source-target pairs. Each unique United Medical Language System (UMLS) concept is represented as a node and each predication as an edge. Each node is assigned one of 132 node labels (e.g., Amino Acid, Peptide, or Protein (AAPP); Gene or Genome (GG); etc.) and each edge is labeled with one of 58 predications (e.g. treats, causes, inhibits, etc.). SemNet computes a single feature value for each metapath, or sequence of node types, between a source node and user-specified target node(s). Several different types of metapath-based features (count, degree weighted path count, and HeteSim metric) are computed and vectorized. SemNet employs an unsupervised learning algorithm for rank aggregation (ULARA) to rank identified source nodes that are most relevant to the user-specified target nodes(s). Statistical analysis of correlation among identified source nodes or resultant literature network features are used to identify patterns that can guide future research. Analysis of high residual nodes is used to compare and contrast SemNet rankings between different targets of interest. An example SemNet use case is presented to assess “the differential impact of smoking on cognition in males and females” using the following target nodes: nicotine, learning, memory, tetrahydrocannabinol (THC), cigarette smoke, X chromosome, and Y chromosome. Detailed rankings are discussed. Overall results suggest a hypothesis where smoking negatively impacts cognition to a greater extent in females, but smoking has stronger cardiovascular impacts in males. In summary, SemNet provides an adoptable method for efficient LBD of PubMed that extends beyond omics-only relationships to true multi-scalar connections that can provide actionable insight for predictive medicine, research prioritization, and clinical care.",2019; 2019-07-03,2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 21:10:37; 2021-06-05 20:55:01; 2021-06-05 21:24:28; 2021-06-05 20:36:32,156,,7,Front Bioeng Biotechnol,SemNet,PubMed; PubMed Central,PMID: 31334227 PMCID: PMC6616276,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6616276/; http://www.ncbi.nlm.nih.gov/pubmed/31334227,literature based discovery; natural language processing; Python; text mining; unsupervised learning,Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
596,10.3389/fcell.2020.00173,32266257,PMC7100381,,,,"Sobrido-Cameán, Daniel; Robledo, Diego; Romaus-Sanjurjo, Daniel; Pérez-Cedrón, Vanessa; Sánchez, Laura; Rodicio, María Celina; Barreiro-Iglesias, Antón",Inhibition of Gamma-Secretase Promotes Axon Regeneration After a Complete Spinal Cord Injury,2020,Frontiers in Cell and Developmental Biology,,"In a recent study, we showed that GABA and baclofen (a GABAB receptor agonist) inhibit caspase activation and promote axon regeneration in descending neurons of the sea lamprey brainstem after a complete spinal cord injury (). Now, we repeated these treatments and performed 2 independent Illumina RNA-Sequencing studies in the brainstems of control and GABA or baclofen treated animals. GABA treated larval sea lampreys with their controls were analyzed 29 days after a complete spinal cord injury and baclofen treated larvae with their controls 9 days after the injury. One of the most significantly downregulated genes after both treatments was a HES gene (HESB). HES proteins are transcription factors that are key mediators of the Notch signaling pathway and gamma-secretase activity is crucial for the activation of this pathway. So, based on the RNA-Seq results we subsequently treated spinal cord injured larval sea lampreys with a novel gamma-secretase inhibitor (PF-3804014). This treatment also reduced the expression of HESB in the brainstem and significantly enhanced the regeneration of individually identifiable descending neurons after a complete spinal cord injury. Our results show that gamma-secretase could be a novel target to promote axon regeneration after nervous system injuries.",2020-03-20,2021-06-05 21:10:08,,,8,Front Cell Dev Biol,,PubMed Central,PMID: 32266257 PMCID: PMC7100381,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7100381/,,,,PMC:Query2
597,10.3389/fchem.2020.00093,32133344,PMC7040036,,,,"de Souza Neto, Lauro Ribeiro; Moreira-Filho, José Teófilo; Neves, Bruno Junior; Maidana, Rocío Lucía Beatriz Riveros; Guimarães, Ana Carolina Ramos; Furnham, Nicholas; Andrade, Carolina Horta; Silva, Floriano Paes",In silico Strategies to Support Fragment-to-Lead Optimization in Drug Discovery,2020,Frontiers in Chemistry,,"Fragment-based drug (or lead) discovery (FBDD or FBLD) has developed in the last two decades to become a successful key technology in the pharmaceutical industry for early stage drug discovery and development. The FBDD strategy consists of screening low molecular weight compounds against macromolecular targets (usually proteins) of clinical relevance. These small molecular fragments can bind at one or more sites on the target and act as starting points for the development of lead compounds. In developing the fragments attractive features that can translate into compounds with favorable physical, pharmacokinetics and toxicity (ADMET—absorption, distribution, metabolism, excretion, and toxicity) properties can be integrated. Structure-enabled fragment screening campaigns use a combination of screening by a range of biophysical techniques, such as differential scanning fluorimetry, surface plasmon resonance, and thermophoresis, followed by structural characterization of fragment binding using NMR or X-ray crystallography. Structural characterization is also used in subsequent analysis for growing fragments of selected screening hits. The latest iteration of the FBDD workflow employs a high-throughput methodology of massively parallel screening by X-ray crystallography of individually soaked fragments. In this review we will outline the FBDD strategies and explore a variety of in silico approaches to support the follow-up fragment-to-lead optimization of either: growing, linking, and merging. These fragment expansion strategies include hot spot analysis, druggability prediction, SAR (structure-activity relationships) by catalog methods, application of machine learning/deep learning models for virtual screening and several de novo design methods for proposing synthesizable new compounds. Finally, we will highlight recent case studies in fragment-based drug discovery where in silico methods have successfully contributed to the development of lead compounds.",2020-02-18,2021-06-05 21:10:08,,,8,Front Chem,,PubMed Central,PMID: 32133344 PMCID: PMC7040036,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7040036/,,,,PMC:Query2
598,10.3389/fcimb.2017.00031,28224116,PMC5293770,,,,"Kamminga, Tjerko; Koehorst, Jasper J.; Vermeij, Paul; Slagman, Simen-Jan; Martins dos Santos, Vitor A. P.; Bijlsma, Jetta J. E.; Schaap, Peter J.",Persistence of Functional Protein Domains in Mycoplasma Species and their Role in Host Specificity and Synthetic Minimal Life,2017,Frontiers in Cellular and Infection Microbiology,,"Mycoplasmas are the smallest self-replicating organisms and obligate parasites of a specific vertebrate host. An in-depth analysis of the functional capabilities of mycoplasma species is fundamental to understand how some of simplest forms of life on Earth succeeded in subverting complex hosts with highly sophisticated immune systems. In this study we present a genome-scale comparison, focused on identification of functional protein domains, of 80 publically available mycoplasma genomes which were consistently re-annotated using a standardized annotation pipeline embedded in a semantic framework to keep track of the data provenance. We examined the pan- and core-domainome and studied predicted functional capability in relation to host specificity and phylogenetic distance. We show that the pan- and core-domainome of mycoplasma species is closed. A comparison with the proteome of the “minimal” synthetic bacterium JCVI-Syn3.0 allowed us to classify domains and proteins essential for minimal life. Many of those essential protein domains, essential Domains of Unknown Function (DUFs) and essential hypothetical proteins are not persistent across mycoplasma genomes suggesting that mycoplasma species support alternative domain configurations that bypass their essentiality. Based on the protein domain composition, we could separate mycoplasma species infecting blood and tissue. For selected genomes of tissue infecting mycoplasmas, we could also predict whether the host is ruminant, pig or human. Functionally closely related mycoplasma species, which have a highly similar protein domain repertoire, but different hosts could not be separated. This study provides a concise overview of the functional capabilities of mycoplasma species, which can be used as a basis to further understand host-pathogen interaction or to design synthetic minimal life.",2017-02-07,2021-06-05 21:12:01,,,7,Front Cell Infect Microbiol,,PubMed Central,PMID: 28224116 PMCID: PMC5293770,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5293770/,,,,PMC:Query2
599,10.3389/fdata.2020.00012,33693387,PMC7931944,,,,"Gharibi, Mohamed; Zachariah, Arun; Rao, Praveen",FoodKG: A Tool to Enrich Knowledge Graphs Using Machine Learning Techniques,2020,Frontiers in Big Data,,"While there exist a plethora of datasets on the Internet related to Food, Energy, and Water (FEW), there is a real lack of reliable methods and tools that can consume these resources. This hinders the development of novel decision-making applications utilizing knowledge graphs. In this paper, we introduce a novel software tool, called FoodKG, that enriches FEW knowledge graphs using advanced machine learning techniques. Our overarching goal is to improve decision-making and knowledge discovery as well as to provide improved search results for data scientists in the FEW domains. Given an input knowledge graph (constructed on raw FEW datasets), FoodKG enriches it with semantically related triples, relations, and images based on the original dataset terms and classes. FoodKG employs an existing graph embedding technique trained on a controlled vocabulary called AGROVOC, which is published by the Food and Agriculture Organization of the United Nations. AGROVOC includes terms and classes in the agriculture and food domains. As a result, FoodKG can enhance knowledge graphs with semantic similarity scores and relations between different classes, classify the existing entities, and allow FEW experts and researchers to use scientific terms for describing FEW concepts. The resulting model obtained after training on AGROVOC was evaluated against the state-of-the-art word embedding and knowledge graph embedding models that were trained on the same dataset. We observed that this model outperformed its competitors based on the Spearman Correlation Coefficient score.",2020-04-29,2021-06-05 21:10:08,,,3,Front Big Data,FoodKG,PubMed Central,PMID: 33693387 PMCID: PMC7931944,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7931944/,,,,PMC:Query2
600,10.3389/fdata.2020.556282,33693415,PMC7931882,,,,"Mabry, Patricia L.; Yan, Xiaoran; Pentchev, Valentin; Van Rennes, Robert; McGavin, Stephanie Hernandez; Wittenberg, Jamie V.","CADRE: A Collaborative, Cloud-Based Solution for Big Bibliographic Data Research in Academic Libraries",2020,Frontiers in Big Data,,"Big bibliographic datasets hold promise for revolutionizing the scientific enterprise when combined with state-of-the-science computational capabilities. Yet, hosting proprietary and open big bibliographic datasets poses significant difficulties for libraries, both large and small. Libraries face significant barriers to hosting such assets, including cost and expertise, which has limited their ability to provide stewardship for big datasets, and thus has hampered researchers' access to them. What is needed is a solution to address the libraries' and researchers’ joint needs. This article outlines the theoretical framework that underpins the Collaborative Archive and Data Research Environment project. We recommend a shared cloud-based infrastructure to address this need built on five pillars: 1) Community–a community of libraries and industry partners who support and maintain the platform and a community of researchers who use it; 2) Access–the sharing platform should be accessible and affordable to both proprietary data customers and the general public; 3) Data-Centric–the platform is optimized for efficient and high-quality bibliographic data services, satisfying diverse data needs; 4) Reproducibility–the platform should be designed to foster and encourage reproducible research; 5) Empowerment—the platform should empower researchers to perform big data analytics on the hosted datasets. In this article, we describe the many facets of the problem faced by American academic libraries and researchers wanting to work with big datasets. We propose a practical solution based on the five pillars: The Collaborative Archive and Data Research Environment. Finally, we address potential barriers to implementing this solution and strategies for overcoming them.",2020-11-20,2021-06-05 21:09:36,,,3,Front Big Data,CADRE,PubMed Central,PMID: 33693415 PMCID: PMC7931882,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7931882/,,,,PMC:Query2
601,10.3389/fgene.2018.00060,29535761,PMC5834486,A,Neo4j,Neo4j,"Haaland, Øystein A.; Lie, Rolv T.; Romanowska, Julia; Gjerdevik, Miriam; Gjessing, Håkon K.; Jugessur, Astanand",A Genome-Wide Search for Gene-Environment Effects in Isolated Cleft Lip with or without Cleft Palate Triads Points to an Interaction between Maternal Periconceptional Vitamin Use and Variants in ESRRG,2018,Frontiers in Genetics,,"Background: It is widely accepted that cleft lip with or without cleft palate (CL/P) results from the complex interplay between multiple genetic and environmental factors. However, a robust investigation of these gene-environment (GxE) interactions at a genome-wide level is still lacking for isolated CL/P., Materials and Methods: We used our R-package Haplin to perform a genome-wide search for GxE effects in isolated CL/P. From a previously published GWAS, genotypes and information on maternal periconceptional cigarette smoking, alcohol intake, and vitamin use were available on 1908 isolated CL/P triads of predominantly European or Asian ancestry. A GxE effect is present if the relative risk estimates for gene-effects in the offspring are different across exposure strata. We tested this using the relative risk ratio (RRR). Besides analyzing all ethnicities combined (“pooled analysis”), separate analyses were conducted on Europeans and Asians to investigate ethnicity-specific effects. To control for multiple testing, q-values were calculated from the p-values., Results: We identified significant GxVitamin interactions with three SNPs in “Estrogen-related receptor gamma” (ESRRG) in the pooled analysis. The RRRs (95% confidence intervals) were 0.56 (0.45–0.69) with rs1339221 (q = 0.011), 0.57 (0.46–0.70) with rs11117745 (q = 0.011), and 0.62 (0.50–0.76) with rs2099557 (q = 0.037). The associations were stronger when these SNPs were analyzed as haplotypes composed of two-SNP and three-SNP combinations. The strongest effect was with the “t-t-t” haplotype of the rs1339221-rs11117745-rs2099557 combination [RRR = 0.50 (0.40–0.64)], suggesting that the effects observed with the other SNP combinations, including those in the single-SNP analyses, were mainly driven by this haplotype. Although there were potential GxVitamin effects with rs17734557 and rs1316471 and GxAlcohol effects with rs9653456 and rs921876 in the European sample, respectively, none of the SNPs was located in or near genes with strong links to orofacial clefts. GxAlcohol and GxSmoke effects were not assessed in the Asian sample because of a lack of observations for these exposures., Discussion/Conclusion: We identified significant interactions between vitamin use and variants in ESRRG in the pooled analysis. These GxE effects are novel and warrant further investigations to elucidate their roles in orofacial clefting. If validated, they could provide prospects for exploring the impact of estrogens and vitamins on clefting, with potential translational applications.",2018-02-26,2021-06-05 20:55:40; 2021-06-05 21:11:16; 2021-06-05 20:36:32,,,9,Front Genet,,PubMed Central,PMID: 29535761 PMCID: PMC5834486,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5834486/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
602,10.3389/fgene.2019.00059,30847002,PMC6393361,A,Neo4j,Neo4j,"Miller, Ryan A.; Ehrhart, Friederike; Eijssen, Lars M. T.; Slenter, Denise N.; Curfs, Leopold M. G.; Evelo, Chris T.; Willighagen, Egon L.; Kutmon, Martina",Beyond Pathway Analysis: Identification of Active Subnetworks in Rett Syndrome,2019,Frontiers in Genetics,,"Pathway and network approaches are valuable tools in analysis and interpretation of large complex omics data. Even in the field of rare diseases, like Rett syndrome, omics data are available, and the maximum use of such data requires sophisticated tools for comprehensive analysis and visualization of the results. Pathway analysis with differential gene expression data has proven to be extremely successful in identifying affected processes in disease conditions. In this type of analysis, pathways from different databases like WikiPathways and Reactome are used as separate, independent entities. Here, we show for the first time how these pathway models can be used and integrated into one large network using the WikiPathways RDF containing all human WikiPathways and Reactome pathways, to perform network analysis on transcriptomics data. This network was imported into the network analysis tool Cytoscape to perform active submodule analysis. Using a publicly available Rett syndrome gene expression dataset from frontal and temporal cortex, classical enrichment analysis, including pathway and Gene Ontology analysis, revealed mainly immune response, neuron specific and extracellular matrix processes. Our active module analysis provided a valuable extension of the analysis prominently showing the regulatory mechanism of MECP2, especially on DNA maintenance, cell cycle, transcription, and translation. In conclusion, using pathway models for classical enrichment and more advanced network analysis enables a more comprehensive analysis of gene expression data and provides novel results.",2019-02-21,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,,,10,Front Genet,Beyond Pathway Analysis,PubMed Central,PMID: 30847002 PMCID: PMC6393361,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6393361/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
603,10.3389/fgene.2019.00557,31258549,PMC6588157,,,,"Musa, Aliyu; Tripathi, Shailesh; Dehmer, Matthias; Emmert-Streib, Frank",L1000 Viewer: A Search Engine and Web Interface for the LINCS Data Repository,2019,Frontiers in Genetics,,"The LINCS L1000 data repository contains almost two million gene expression profiles for thousands of small molecules and drugs. However, due to the complexity and the size of the data repository and a lack of an interoperable interface, the creation of pharmacologically meaningful workflows utilizing these data is severely hampered. In order to overcome this limitation, we developed the L1000 Viewer, a search engine and graphical web interface for the LINCS data repository. The web interface serves as an interactive platform allowing the user to select different forms of perturbation profiles, e.g., for specific cell lines, drugs, dosages, time points and combinations thereof. At its core, our method has a database we created from inferring and utilizing the intricate dependency graph structure among the data files. The L1000 Viewer is accessible via http://L1000viewer.bio-complexity.com/.",2019-06-14,2021-06-05 21:10:37,,,10,Front Genet,L1000 Viewer,PubMed Central,PMID: 31258549 PMCID: PMC6588157,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6588157/,,,,PMC:Query2
604,10.3389/fgene.2019.01366,32117417,PMC6989550,A,GraphDB,GraphDB,"Poncheewin, Wasin; Hermes, Gerben D. A.; van Dam, Jesse C. J.; Koehorst, Jasper J.; Smidt, Hauke; Schaap, Peter J.",NG-Tax 2.0: A Semantic Framework for High-Throughput Amplicon Analysis,2019; 2020,Frontiers in Genetics,,"NG-Tax 2.0 is a semantic framework for FAIR high-throughput analysis and classification of marker gene amplicon sequences including bacterial and archaeal 16S ribosomal RNA (rRNA), eukaryotic 18S rRNA and ribosomal intergenic transcribed spacer sequences. It can directly use single or merged reads, paired-end reads and unmerged paired-end reads from long range fragments as input to generate de novo amplicon sequence variants (ASV). Using the RDF data model, ASV's can be automatically stored in a graph database as objects that link ASV sequences with the full data-wise and element-wise provenance, thereby achieving the level of interoperability required to utilize such data to its full potential. The graph database can be directly queried, allowing for comparative analyses of over thousands of samples and is connected with an interactive Rshiny toolbox for analysis and visualization of (meta) data. Additionally, NG-Tax 2.0 exports an extended BIOM 1.0 (JSON) file as starting point for further analyses by other means. The extended BIOM file contains new attribute types to include information about the command arguments used, the sequences of the ASVs formed, classification confidence scores and is backwards compatible. The performance of NG-Tax 2.0 was compared with DADA2, using the plugin in the QIIME 2 analysis pipeline. Fourteen 16S rRNA gene amplicon mock community samples were obtained from the literature and evaluated. Precision of NG-Tax 2.0 was significantly higher with an average of 0.95 vs 0.58 for QIIME2-DADA2 while recall was comparable with an average of 0.85 and 0.77, respectively. NG-Tax 2.0 is written in Java. The code, the ontology, a Galaxy platform implementation, the analysis toolbox, tutorials and example SPARQL queries are freely available at http://wurssb.gitlab.io/ngtax under the MIT License.; NG-Tax 2.0 is a semantic framework for FAIR high-throughput analysis and classification of marker gene amplicon sequences including bacterial and archaeal 16S ribosomal RNA (rRNA), eukaryotic 18S rRNA and ribosomal intergenic transcribed spacer sequences. It can directly use single or merged reads, paired-end reads and unmerged paired-end reads from long range fragments as input to generate de novo amplicon sequence variants (ASV). Using the RDF data model, ASV’s can be automatically stored in a graph database as objects that link ASV sequences with the full data-wise and element-wise provenance, thereby achieving the level of interoperability required to utilize such data to its full potential. The graph database can be directly queried, allowing for comparative analyses of over thousands of samples and is connected with an interactive Rshiny toolbox for analysis and visualization of (meta) data. Additionally, NG-Tax 2.0 exports an extended BIOM 1.0 (JSON) file as starting point for further analyses by other means. The extended BIOM file contains new attribute types to include information about the command arguments used, the sequences of the ASVs formed, classification confidence scores and is backwards compatible. The performance of NG-Tax 2.0 was compared with DADA2, using the plugin in the QIIME 2 analysis pipeline. Fourteen 16S rRNA gene amplicon mock community samples were obtained from the literature and evaluated. Precision of NG-Tax 2.0 was significantly higher with an average of 0.95 vs 0.58 for QIIME2-DADA2 while recall was comparable with an average of 0.85 and 0.77, respectively. NG-Tax 2.0 is written in Java. The code, the ontology, a Galaxy platform implementation, the analysis toolbox, tutorials and example SPARQL queries are freely available at http://wurssb.gitlab.io/ngtax under the MIT License.",2019; 2020-01-23,2021-06-05 20:55:01; 2021-06-05 21:06:22; 2021-06-05 21:10:08; 2021-06-06 06:54:16,1366,,10,Front Genet,NG-Tax 2.0,PubMed; PubMed Central,PMID: 32117417 PMCID: PMC6989550,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6989550/; http://www.ncbi.nlm.nih.gov/pubmed/32117417,amplicon sequence variants; FAIR; ontology; operational taxonomic unit; RDF; semantic web; SPARQL; taxonomic classification,GraphDB,GraphDB,PMC:Query3; PMC:GraphDB; PubMed:Query2; PMC:Query2
605,10.3389/fgene.2020.00627,32774342,PMC7381335,,,,"Freeman, Dana M.; Wang, Zhibin",Epigenetic Vulnerability of Insulator CTCF Motifs at Parkinson’s Disease-Associated Genes in Response to Neurotoxicant Rotenone,2020,Frontiers in Genetics,,"CCCTC-binding factor (CTCF) is a regulatory protein that binds DNA to control spatial organization and transcription. The sequence-specific binding of CTCF is variable and is impacted by nearby epigenetic patterns. It has been demonstrated that non-coding genetic variants cluster with CTCF sites in topological associating domains and thus can affect CTCF activity on gene expression. Therefore, environmental factors that alter epigenetic patterns at CTCF binding sites may dictate the interaction of non-coding genetic variants with regulatory proteins. To test this mechanism, we treated human cell line HEK293 with rotenone for 24 h and characterized its effect on global epigenetic patterns specifically at regulatory regions of Parkinson’s disease (PD) risk loci. We used RNA sequencing to examine changes in global transcription and identified over 2000 differentially expressed genes (DEGs, >1.5-fold change, FDR < 0.05). Among these DEGs, 13 were identified as PD-associated genes according to Genome-wide association studies meta-data. We focused on eight genes that have non-coding risk variants and a prominent CTCF binding site. We analyzed methylation of a total of 165 CGs surrounding CTCF binding sites and detected differential methylation (|>1%|, q < 0.05) in 45 CGs at 7 PD-associated genes. Of these 45 CGs, 47% were hypomethylated and 53% were hypermethylated. Interestingly, 5 out of the 7 genes had correlated gene upregulation with CG hypermethylation at CTCF and gene downregulation with CG hypomethylation at CTCF. We also investigated active H3K27ac surrounding the same CTCF binding sites within these seven genes. We observed a significant increase in H3K27ac in four genes (FDR < 0.05). Three genes (PARK2, GPRIN3, FER) showed increased CTCF binding in response to rotenone. Our data indicate that rotenone alters regulatory regions of PD-associated genes through changes in epigenetic patterns, and these changes impact high-order chromatin organization to increase the influence of non-coding variants on genome integrity and cellular survival.",2020-07-07,2021-06-05 21:10:08,,,11,Front Genet,,PubMed Central,PMID: 32774342 PMCID: PMC7381335,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7381335/,,,,PMC:Query2
606,10.3389/fgene.2021.624307,33643385,PMC7902761,,,,"Zeng, Daojian; Zhao, Chao; Quan, Zhe",CID-GCN: An Effective Graph Convolutional Networks for Chemical-Induced Disease Relation Extraction,2021,Frontiers in Genetics,,"Automatic extraction of chemical-induced disease (CID) relation from unstructured text is of essential importance for disease treatment and drug development. In this task, some relational facts can only be inferred from the document rather than single sentence. Recently, researchers investigate graph-based approaches to extract relations across sentences. It iteratively combines the information from neighbor nodes to model the interactions in entity mentions that exist in different sentences. Despite their success, one severe limitation of the graph-based approaches is the over-smoothing problem, which decreases the model distinguishing ability. In this paper, we propose CID-GCN, an effective Graph Convolutional Networks (GCNs) with gating mechanism, for CID relation extraction. Specifically, we construct a heterogeneous graph which contains mention, sentence and entity nodes. Then, the graph convolution operation is employed to aggregate interactive information on the constructed graph. Particularly, we combine gating mechanism with the graph convolution operation to address the over-smoothing problem. The experimental results demonstrate that our approach significantly outperforms the baselines.",2021-02-10,2021-06-05 21:09:36,,,12,Front Genet,CID-GCN,PubMed Central,PMID: 33643385 PMCID: PMC7902761,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7902761/,,,,PMC:Query2
607,10.3389/fimmu.2019.00231,30828334,PMC6384242,A,Neo4j,Neo4j,"Meijerink, Marjolein; van den Broek, Tim; Dulos, Remon; Neergaard Jacobsen, Lotte; Staudt Kvistgaard, Anne; Garthoff, Jossie; Knippels, Léon; Knipping, Karen; Houben, Geert; Verschuren, Lars; van Bilsen, Jolanda",The Impact of Immune Interventions: A Systems Biology Strategy for Predicting Adverse and Beneficial Immune Effects,2019,Frontiers in Immunology,,"Despite scientific advances it remains difficult to predict the risk and benefit balance of immune interventions. Since a few years, network models have been built based on comprehensive datasets at multiple molecular/cellular levels (genes, gene products, metabolic intermediates, macromolecules, cells) to illuminate functional and structural relationships. Here we used a systems biology approach to identify key immune pathways involved in immune health endpoints and rank crucial candidate biomarkers to predict adverse and beneficial effects of nutritional immune interventions. First, a literature search was performed to select the molecular and cellular dynamics involved in hypersensitivity, autoimmunity and resistance to infection and cancer. Thereafter, molecular interaction between molecules and immune health endpoints was defined by connecting their relations by using database information. MeSH terms related to the immune health endpoints were selected resulting in the following selection: hypersensitivity (D006967: 184 genes), autoimmunity (D001327: 564 genes), infection (parasitic, bacterial, fungal and viral: 357 genes), and cancer (D009369: 3173 genes). In addition, a sequence of key processes was determined using Gene Ontology which drives the development of immune health disturbances resulting in the following selection: hypersensitivity (164 processes), autoimmunity (203 processes), infection (187 processes), and cancer (309 processes). Finally, an evaluation of the genes for each of the immune health endpoints was performed, which indicated that many genes played a role in multiple immune health endpoints, but also unique genes were observed for each immune health endpoint. This approach helps to build a screening/prediction tool which indicates the interaction of chemicals or food substances with immune health endpoint-related genes and suggests candidate biomarkers to evaluate risks and benefits. Several anti-cancer drugs and omega 3 fatty acids were evaluated as in silico test cases. To conclude, here we provide a systems biology approach to identify genes/molecules and their interaction with immune related disorders. Our examples illustrate that the prediction with our systems biology approach is promising and can be used to find both negatively and positively correlated interactions. This enables identification of candidate biomarkers to monitor safety and efficacy of therapeutic immune interventions.",2019-02-15,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,,,10,Front Immunol,The Impact of Immune Interventions,PubMed Central,PMID: 30828334 PMCID: PMC6384242,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6384242/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
608,10.3389/fimmu.2019.02672,31798593,PMC6863931,A,Neo4j,Neo4j,"Meijerink, Marjolein; van den Broek, Tim J.; Dulos, Remon; Garthoff, Jossie; Knippels, Léon; Knipping, Karen; Harthoorn, Lucien; Houben, Geert; Verschuren, Lars; van Bilsen, Jolanda",Network-Based Selection of Candidate Markers and Assays to Assess the Impact of Oral Immune Interventions on Gut Functions,2019,Frontiers in Immunology,,"To assess the safety and efficacy of oral immune interventions, it is important and required by regulation to assess the impact of those interventions not only on the immune system, but also on other organs such as the gut as the porte d'entrée. Despite clear indications that the immune system interacts with several physiological functions of the gut, it is still unknown which pathways and molecules are crucial to assessing the impact of nutritional immune interventions on gut functioning. Here we used a network-based systems biology approach to clarify the molecular relationships between immune system and gut functioning and to identify crucial biomarkers to assess effects on gut functions upon nutritional immune interventions. First, the different gut functionalities were categorized based on literature and EFSA guidance documents. Moreover, an overview of the current assays and methods to measure gut function was generated. Secondly, gut-function related biological processes and adverse events were selected and subsequently linked to the physiological functions of the GI tract. Thirdly, database terms and annotations from the Gene ontology database and the Comparative Toxicogenomics Database (CTD) related to the previously selected gut-function related processes were selected. Next, database terms and annotations were used to identify the pathways and genes involved in those gut functionalities. In parallel, information from CTD was used to identify immune disease related genes. The resulting lists of both gut and immune function genes showed an overlap of 753 genes out of 1,296 gut-function related genes indicating the close gut-immune relationship. Using bioinformatics enrichment tools DAVID and Panther, the identified gut-immune markers were predicted to be involved in motility, barrier function, the digestion and absorption of vitamins and fat, regulation of the digestive system and gastric acid, and protection from injurious or allergenic material. Concluding, here we provide a promising systems biology approach to identify genes that help to clarify the relationships between immune system and gut functioning, with the aim to identify candidate biomarkers to monitor nutritional immune intervention assays for safety and efficacy in the general population. This knowledge helps to optimize future study designs to predict effects of nutritional immune intervention on gut functionalities.",2019-11-13,2021-06-05 20:35:57; 2021-06-05 20:55:01; 2021-06-05 21:10:37,,,10,Front Immunol,,PubMed Central,PMID: 31798593 PMCID: PMC6863931,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6863931/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
609,10.3389/fimmu.2020.00644,32362896,PMC7182036,A,Neo4j,Neo4j,"van Bilsen, Jolanda H. M.; Dulos, Remon; van Stee, Mariël F.; Meima, Marie Y.; Rouhani Rankouhi, Tanja; Neergaard Jacobsen, Lotte; Staudt Kvistgaard, Anne; Garthoff, Jossie A.; Knippels, Léon M. J.; Knipping, Karen; Houben, Geert F.; Verschuren, Lars; Meijerink, Marjolein; Krishnan, Shaji",Seeking Windows of Opportunity to Shape Lifelong Immune Health: A Network-Based Strategy to Predict and Prioritize Markers of Early Life Immune Modulation,2020,Frontiers in Immunology,,"A healthy immune status is strongly conditioned during early life stages. Insights into the molecular drivers of early life immune development and function are prerequisite to identify strategies to enhance immune health. Even though several starting points for targeted immune modulation have been identified and are being developed into prophylactic or therapeutic approaches, there is no regulatory guidance on how to assess the risk and benefit balance of such interventions. Six early life immune causal networks, each compromising a different time period in early life (the 1st, 2nd, 3rd trimester of gestations, birth, newborn, and infant period), were generated. Thereto information was extracted and structured from early life literature using the automated text mining and machine learning tool: Integrated Network and Dynamical Reasoning Assembler (INDRA). The tool identified relevant entities (e.g., genes/proteins/metabolites/processes/diseases), extracted causal relationships among these entities, and assembled them into early life-immune causal networks. These causal early life immune networks were denoised using GeneMania, enriched with data from the gene-disease association database DisGeNET and Gene Ontology resource tools (GO/GO-SLIM), inferred missing relationships and added expert knowledge to generate information-dense early life immune networks. Analysis of the six early life immune networks by PageRank, not only confirmed the central role of the “commonly used immune markers” (e.g., chemokines, interleukins, IFN, TNF, TGFB, and other immune activation regulators (e.g., CD55, FOXP3, GATA3, CD79A, C4BPA), but also identified less obvious candidates (e.g., CYP1A2, FOXK2, NELFCD, RENBP). Comparison of the different early life periods resulted in the prediction of 11 key early life genes overlapping all early life periods (TNF, IL6, IL10, CD4, FOXP3, IL4, NELFCD, CD79A, IL5, RENBP, and IFNG), and also genes that were only described in certain early life period(s). Concluding, here we describe a network-based approach that provides a science-based and systematical method to explore the functional development of the early life immune system through time. This systems approach aids the generation of a testing strategy for the safety and efficacy of early life immune modulation by predicting the key candidate markers during different phases of early life immune development.",2020-04-17,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,,,11,Front Immunol,Seeking Windows of Opportunity to Shape Lifelong Immune Health,PubMed Central,PMID: 32362896 PMCID: PMC7182036,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7182036/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
610,10.3389/fimmu.2020.606338,33391273,PMC7775384,A,Neo4j,Neo4j,"Ruschil, Christoph; Gabernet, Gisela; Lepennetier, Gildas; Heumos, Simon; Kaminski, Miriam; Hracsko, Zsuzsanna; Irmler, Martin; Beckers, Johannes; Ziemann, Ulf; Nahnsen, Sven; Owens, Gregory P.; Bennett, Jeffrey L.; Hemmer, Bernhard; Kowarik, Markus C.",Specific Induction of Double Negative B Cells During Protective and Pathogenic Immune Responses,2020,Frontiers in Immunology,,"Double negative (DN) (CD19+CD20lowCD27-IgD-) B cells are expanded in patients with autoimmune and infectious diseases; however their role in the humoral immune response remains unclear. Using systematic flow cytometric analyses of peripheral blood B cell subsets, we observed an inflated DN B cell population in patients with variety of active inflammatory conditions: myasthenia gravis, Guillain-Barré syndrome, neuromyelitis optica spectrum disorder, meningitis/encephalitis, and rheumatic disorders. Furthermore, we were able to induce DN B cells in healthy subjects following vaccination against influenza and tick borne encephalitis virus. Transcriptome analysis revealed a gene expression profile in DN B cells that clustered with naïve B cells, memory B cells, and plasmablasts. Immunoglobulin VH transcriptome sequencing and analysis of recombinant antibodies revealed clonal expansion of DN B cells that were targeted against the vaccine antigen. Our study suggests that DN B cells are expanded in multiple inflammatory neurologic diseases and represent an inducible B cell population that responds to antigenic stimulation, possibly through an extra-follicular maturation pathway.",2020-12-18,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,,11,Front Immunol,,PubMed Central,PMID: 33391273 PMCID: PMC7775384,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7775384/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
611,10.3389/fnbeh.2017.00102,28611607,PMC5447672,,,,"Givon, Lev E.; Lazar, Aurel A.; Yeh, Chung-Heng",Generating Executable Models of the Drosophila Central Complex,2017,Frontiers in Behavioral Neuroscience,,"The central complex (CX) is a set of neuropils in the center of the fly brain that have been implicated as playing an important role in vision-mediated behavior and integration of spatial information with locomotor control. In contrast to currently available data regarding the neural circuitry of neuropils in the fly's vision and olfactory systems, comparable data for the CX neuropils is relatively incomplete; many categories of neurons remain only partly characterized, and the synaptic connectivity between CX neurons has yet to be fully determined. Successful modeling of the information processing functions of the CX neuropils therefore requires a means of easily constructing and testing a range of hypotheses regarding both the high-level structure of their neural circuitry and the properties of their constituent neurons and synapses. To this end, we have created a web application that enables simultaneous graphical querying and construction of executable models of the CX neural circuitry based upon currently available information regarding the geometry and polarity of the arborizations of identified local and projection neurons in the CX. The application's novel functionality is made possible by the Fruit Fly Brain Observatory, a platform for collaborative study and development of fruit fly brain models.",2017-05-30,2021-06-05 21:12:01,,,11,Front Behav Neurosci,,PubMed Central,PMID: 28611607 PMCID: PMC5447672,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5447672/,,,,PMC:Query2
612,10.3389/fnbot.2020.584192,33192439,PMC7652790,,,,"Pang, Ning; Tan, Zhen; Xu, Hao; Xiao, Weidong",Boosting Knowledge Base Automatically via Few-Shot Relation Classification,2020,Frontiers in Neurorobotics,,"Relation classification (RC) aims at extracting structural information, i.e., triplets of two entities with a relation, from free texts, which is pivotal for automatic knowledge base construction. In this paper, we investigate a fully automatic method to train a RC model which facilitates to boost the knowledge base. Traditional RC models cannot extract new relations unseen during training since they define RC as a multiclass classification problem. The recent development of few-shot learning (FSL) provides a feasible way to accommodate to fresh relation types with a handful of examples. However, it requires a moderately large amount of training data to learn a promising few-shot RC model, which consumes expensive human labor. This issue recalls a kind of weak supervision methods, dubbed distant supervision (DS), which can generate the training data automatically. To this end, we propose to investigate the task of few-shot relation classification under distant supervision. As DS naturally brings in mislabeled training instances, to alleviate the negative impact, we incorporate various multiple instance learning methods into the classic prototypical networks, which can achieve sentence-level noise reduction. In experiments, we evaluate our proposed model under the standard N-way K-shot setting of few-shot learning. The experiment results show that our proposal achieves better performance.",2020-10-27,2021-06-05 21:09:36,,,14,Front Neurorobot,,PubMed Central,PMID: 33192439 PMCID: PMC7652790,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7652790/,,,,PMC:Query2
613,10.3389/fncir.2018.00085,30374293,PMC6196278,A,Neo4j,Neo4j,"Scheffer, Louis K.",Analysis Tools for Large Connectomes,2018,Frontiers in Neural Circuits,,"New reconstruction techniques are generating connectomes of unprecedented size. These must be analyzed to generate human comprehensible results. The analyses being used fall into three general categories. The first is interactive tools used during reconstruction, to help guide the effort, look for possible errors, identify potential cell classes, and answer other preliminary questions. The second type of analysis is support for formal documents such as papers and theses. Scientific norms here require that the data be archived and accessible, and the analysis reproducible. In contrast to some other “omic” fields such as genomics, where a few specific analyses dominate usage, connectomics is rapidly evolving and the analyses used are often specific to the connectome being analyzed. These analyses are typically performed in a variety of conventional programming language, such as Matlab, R, Python, or C++, and read the connectomic data either from a file or through database queries, neither of which are standardized. In the short term we see no alternative to the use of specific analyses, so the best that can be done is to publish the analysis code, and the interface by which it reads connectomic data. A similar situation exists for archiving connectome data. Each group independently makes their data available, but there is no standardized format and long-term accessibility is neither enforced nor funded. In the long term, as connectomics becomes more common, a natural evolution would be a central facility for storing and querying connectomic data, playing a role similar to the National Center for Biotechnology Information for genomes. The final form of analysis is the import of connectome data into downstream tools such as neural simulation or machine learning. In this process, there are two main problems that need to be addressed. First, the reconstructed circuits contain huge amounts of detail, which must be intelligently reduced to a form the downstream tools can use. Second, much of the data needed for these downstream operations must be obtained by other methods (such as genetic or optical) and must be merged with the extracted connectome.",2018-10-15,2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:36:32,,,12,Front Neural Circuits,,PubMed Central,PMID: 30374293 PMCID: PMC6196278,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6196278/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
614,10.3389/fnhum.2014.00370,24917804,PMC4042686,A,Virtuoso,Virtuoso,"Zao, John K.; Gan, Tchin-Tze; You, Chun-Kai; Chung, Cheng-En; Wang, Yu-Te; Rodríguez Méndez, Sergio José; Mullen, Tim; Yu, Chieh; Kothe, Christian; Hsiao, Ching-Teng; Chu, San-Liang; Shieh, Ce-Kuen; Jung, Tzyy-Ping",Pervasive brain monitoring and data sharing based on multi-tier distributed computing and linked data technology,2014,Frontiers in Human Neuroscience,,"EEG-based Brain-computer interfaces (BCI) are facing basic challenges in real-world applications. The technical difficulties in developing truly wearable BCI systems that are capable of making reliable real-time prediction of users' cognitive states in dynamic real-life situations may seem almost insurmountable at times. Fortunately, recent advances in miniature sensors, wireless communication and distributed computing technologies offered promising ways to bridge these chasms. In this paper, we report an attempt to develop a pervasive on-line EEG-BCI system using state-of-art technologies including multi-tier Fog and Cloud Computing, semantic Linked Data search, and adaptive prediction/classification models. To verify our approach, we implement a pilot system by employing wireless dry-electrode EEG headsets and MEMS motion sensors as the front-end devices, Android mobile phones as the personal user interfaces, compact personal computers as the near-end Fog Servers and the computer clusters hosted by the Taiwan National Center for High-performance Computing (NCHC) as the far-end Cloud Servers. We succeeded in conducting synchronous multi-modal global data streaming in March and then running a multi-player on-line EEG-BCI game in September, 2013. We are currently working with the ARL Translational Neuroscience Branch to use our system in real-life personal stress monitoring and the UCSD Movement Disorder Center to conduct in-home Parkinson's disease patient monitoring experiments. We shall proceed to develop the necessary BCI ontology and introduce automatic semantic annotation and progressive model refinement capability to our system.",2014-06-03,2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-05 20:59:14,,,8,Front Hum Neurosci,,PubMed Central,PMID: 24917804 PMCID: PMC4042686,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4042686/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
615,10.3389/fninf.2012.00012,22654752,PMC3354345,,,,"Schwartz, Yannick; Barbot, Alexis; Thyreau, Benjamin; Frouin, Vincent; Varoquaux, Gaël; Siram, Aditya; Marcus, Daniel S.; Poline, Jean-Baptiste",PyXNAT: XNAT in Python,2012,Frontiers in Neuroinformatics,,"As neuroimaging databases grow in size and complexity, the time researchers spend investigating and managing the data increases to the expense of data analysis. As a result, investigators rely more and more heavily on scripting using high-level languages to automate data management and processing tasks. For this, a structured and programmatic access to the data store is necessary. Web services are a first step toward this goal. They however lack in functionality and ease of use because they provide only low-level interfaces to databases. We introduce here PyXNAT, a Python module that interacts with The Extensible Neuroimaging Archive Toolkit (XNAT) through native Python calls across multiple operating systems. The choice of Python enables PyXNAT to expose the XNAT Web Services and unify their features with a higher level and more expressive language. PyXNAT provides XNAT users direct access to all the scientific packages in Python. Finally PyXNAT aims to be efficient and easy to use, both as a back-end library to build XNAT clients and as an alternative front-end from the command line.",2012-05-24,2021-06-05 21:13:27,,,6,Front Neuroinform,PyXNAT,PubMed Central,PMID: 22654752 PMCID: PMC3354345,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3354345/,,,,PMC:Query2
616,10.3389/fninf.2019.00062,31611781,PMC6776611,,,,"Sprenger, Julia; Zehl, Lyuba; Pick, Jana; Sonntag, Michael; Grewe, Jan; Wachtler, Thomas; Grün, Sonja; Denker, Michael",odMLtables: A User-Friendly Approach for Managing Metadata of Neurophysiological Experiments,2019,Frontiers in Neuroinformatics,,"An essential aspect of scientific reproducibility is a coherent and complete acquisition of metadata along with the actual data of an experiment. The high degree of complexity and heterogeneity of neuroscience experiments requires a rigorous management of the associated metadata. The odML framework represents a solution to organize and store complex metadata digitally in a hierarchical format that is both human and machine readable. However, this hierarchical representation of metadata is difficult to handle when metadata entries need to be collected and edited manually during the daily routines of a laboratory. With odMLtables, we present an open-source software solution that enables users to collect, manipulate, visualize, and store metadata in tabular representations (in xls or csv format) by providing functionality to convert these tabular collections to the hierarchically structured metadata format odML, and to either extract or merge subsets of a complex metadata collection. With this, odMLtables bridges the gap between handling metadata in an intuitive way that integrates well with daily lab routines and commonly used software products on the one hand, and the implementation of a complete, well-defined metadata collection for the experiment in a standardized format on the other hand. We demonstrate usage scenarios of the odMLtables tools in common lab routines in the context of metadata acquisition and management, and show how the tool can assist in exploring published datasets that provide metadata in the odML format.",2019-09-27,2021-06-05 21:10:37,,,13,Front Neuroinform,odMLtables,PubMed Central,PMID: 31611781 PMCID: PMC6776611,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6776611/,,,,PMC:Query2
617,10.3389/fninf.2020.00036,33071769,PMC7531015,A,Neo4j,Neo4j,"Hedges, David M.; Hegman, John C.; Brown, Jefferson R.; Wilburn, Jack T.; Chapman, Brian E.; Butson, Christopher R.",The International Neuromodulation Registry: An Informatics Framework Supporting Cohort Discovery and Analysis,2020,Frontiers in Neuroinformatics,,"Background: Neuromodulation therapies, such as deep brain stimulation (DBS), spinal cord stimulation (SCS), responsive neurostimulation (RNS), transcranial magnetic stimulation (TMS), transcranial direct stimulation (tDCS), and vagus nerve stimulation (VNS) are used to treat neurological and psychiatric conditions for patients who have failed to benefit from other treatment approaches. Although generally effective, seemingly similar cases often have very different levels of effectiveness. While there is ongoing interest in developing predictors, it can be difficult to aggregate the necessary data from limited cohorts of patients at individual treatment centers. Objective: In order to increase the predictive power in neuromodulation studies, we created an informatics platform called the International Neuromodulation Registry (INR). The INR platform has a data flow process that will allow researchers to pool data across multiple centers to enable population health research. Methods: This custom informatics platform has a Neo4j graph database and includes a harmonization process that allows data from different studies to be aggregated and compared. Users of the INR can download deidentified patient imaging, patient demographic data, device settings, and medical rating scales. The INR supports complex network analysis and patient timeline visualization. Results: The INR currently houses and allows visualization of deidentified imaging and clinical data from hundreds of patients with a wide range of diagnoses and neuromodulation therapies. Conclusion: Ultimately, we believe that widespread adoption of the INR platform will improve population health research in neuromodulation therapy.; Background Neuromodulation therapies, such as deep brain stimulation (DBS), spinal cord stimulation (SCS), responsive neurostimulation (RNS), transcranial magnetic stimulation (TMS), transcranial direct stimulation (tDCS), and vagus nerve stimulation (VNS) are used to treat neurological and psychiatric conditions for patients who have failed to benefit from other treatment approaches. Although generally effective, seemingly similar cases often have very different levels of effectiveness. While there is ongoing interest in developing predictors, it can be difficult to aggregate the necessary data from limited cohorts of patients at individual treatment centers. Objective In order to increase the predictive power in neuromodulation studies, we created an informatics platform called the International Neuromodulation Registry (INR). The INR platform has a data flow process that will allow researchers to pool data across multiple centers to enable population health research. Methods This custom informatics platform has a Neo4j graph database and includes a harmonization process that allows data from different studies to be aggregated and compared. Users of the INR can download deidentified patient imaging, patient demographic data, device settings, and medical rating scales. The INR supports complex network analysis and patient timeline visualization. Results The INR currently houses and allows visualization of deidentified imaging and clinical data from hundreds of patients with a wide range of diagnoses and neuromodulation therapies. Conclusion Ultimately, we believe that widespread adoption of the INR platform will improve population health research in neuromodulation therapy.",2020-09-18; 2020,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08; 2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 21:24:28,36,,14,Front Neuroinform,The International Neuromodulation Registry,PubMed; PubMed Central,PMID: 33071769 PMCID: PMC7531015,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7531015/; http://www.ncbi.nlm.nih.gov/pubmed/33071769,deep brain stimulation; graph database; responsive neurostimulation; spinal cord stimulation; transcranial magnetic stimulation,Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
618,10.3389/fnut.2016.00005,26909350,PMC4754447,,,,"Verma, Meghna; Hontecillas, Raquel; Abedi, Vida; Leber, Andrew; Tubau-Juni, Nuria; Philipson, Casandra; Carbo, Adria; Bassaganya-Riera, Josep",Modeling-Enabled Systems Nutritional Immunology,2016,Frontiers in Nutrition,,"This review highlights the fundamental role of nutrition in the maintenance of health, the immune response, and disease prevention. Emerging global mechanistic insights in the field of nutritional immunology cannot be gained through reductionist methods alone or by analyzing a single nutrient at a time. We propose to investigate nutritional immunology as a massively interacting system of interconnected multistage and multiscale networks that encompass hidden mechanisms by which nutrition, microbiome, metabolism, genetic predisposition, and the immune system interact to delineate health and disease. The review sets an unconventional path to apply complex science methodologies to nutritional immunology research, discovery, and development through “use cases” centered around the impact of nutrition on the gut microbiome and immune responses. Our systems nutritional immunology analyses, which include modeling and informatics methodologies in combination with pre-clinical and clinical studies, have the potential to discover emerging systems-wide properties at the interface of the immune system, nutrition, microbiome, and metabolism.",2016-02-16,2021-06-05 21:12:40,,,3,Front Nutr,,PubMed Central,PMID: 26909350 PMCID: PMC4754447,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4754447/,,,,PMC:Query2
619,10.3389/fphar.2013.00038,23761761,PMC3669891,,,,"Maunz, Andreas; Gütlein, Martin; Rautenberg, Micha; Vorgrimmler, David; Gebele, Denis; Helma, Christoph",lazar: a modular predictive toxicology framework,2013,Frontiers in Pharmacology,,"lazar (lazy structure–activity relationships) is a modular framework for predictive toxicology. Similar to the read across procedure in toxicological risk assessment, lazar creates local QSAR (quantitative structure–activity relationship) models for each compound to be predicted. Model developers can choose between a large variety of algorithms for descriptor calculation and selection, chemical similarity indices, and model building. This paper presents a high level description of the lazar framework and discusses the performance of example classification and regression models.",2013-04-09,2021-06-05 21:13:27,,,4,Front Pharmacol,lazar,PubMed Central,PMID: 23761761 PMCID: PMC3669891,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3669891/,,,,PMC:Query2
620,10.3389/fphys.2018.00132,29527177,PMC5829089,A,Neo4j,Neo4j,"Morrison, Martine C.; Kleemann, Robert; van Koppen, Arianne; Hanemaaijer, Roeland; Verschuren, Lars",Key Inflammatory Processes in Human NASH Are Reflected in Ldlr−/−.Leiden Mice: A Translational Gene Profiling Study,2018,Frontiers in Physiology,,"Introduction: It is generally accepted that metabolic inflammation in the liver is an important driver of disease progression in NASH and associated matrix remodeling/fibrosis. However, the exact molecular inflammatory mechanisms are poorly defined in human studies. Investigation of key pathogenic mechanisms requires the use of pre-clinical models, for instance for time-resolved studies. Such models must reflect molecular disease processes of importance in patients. Herein we characterized inflammation in NASH patients on the molecular level by transcriptomics and investigated whether key human disease pathways can be recapitulated experimentally in Ldlr−/−.Leiden mice, an established pre-clinical model of NASH., Methods: Human molecular inflammatory processes were defined using a publicly available NASH gene expression profiling dataset (GSE48452) allowing the comparison of biopsy-confirmed NASH patients with normal controls. Gene profiling data from high-fat diet (HFD)-fed Ldlr−/−.Leiden mice (GSE109345) were used for assessment of the translational value of these mice., Results: In human NASH livers, we observed regulation of 65 canonical pathways of which the majority was involved in inflammation (32%), lipid metabolism (16%), and extracellular matrix/remodeling (12%). A similar distribution of pathways across these categories, inflammation (36%), lipid metabolism (24%) and extracellular matrix/remodeling (8%) was observed in HFD-fed Ldlr−/−.Leiden mice. Detailed evaluation of these pathways revealed that a substantial proportion (11 out of 13) of human NASH inflammatory pathways was recapitulated in Ldlr−/−.Leiden mice. Furthermore, the activation state of identified master regulators of inflammation (i.e., specific transcription factors, cytokines, and growth factors) in human NASH was largely reflected in Ldlr−/−.Leiden mice, further substantiating its translational value., Conclusion: Human NASH is characterized by upregulation of specific inflammatory processes (e.g., “Fcγ Receptor-mediated Phagocytosis in Macrophages and Monocytes,” “PI3K signaling in B Lymphocytes”) and master regulators (e.g., TNF, CSF2, TGFB1). The majority of these processes and regulators are modulated in the same direction in Ldlr−/−.Leiden mice fed HFD with a human-like macronutrient composition, thus demonstrating that specific experimental conditions recapitulate human disease on the molecular level of disease pathways and upstream/master regulators.",2018-02-23,2021-06-05 20:55:40; 2021-06-05 21:11:16; 2021-06-05 20:36:32,,,9,Front Physiol,Key Inflammatory Processes in Human NASH Are Reflected in Ldlr−/−.Leiden Mice,PubMed Central,PMID: 29527177 PMCID: PMC5829089,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5829089/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
621,10.3389/fpls.2016.00641,27433158,PMC4922217,A,Virtuoso,Virtuoso,"Rodríguez-Iglesias, Alejandro; Rodríguez-González, Alejandro; Irvine, Alistair G.; Sesma, Ane; Urban, Martin; Hammond-Kosack, Kim E.; Wilkinson, Mark D.",Publishing FAIR Data: An Exemplar Methodology Utilizing PHI-Base,2016,Frontiers in Plant Science,,"Pathogen-Host interaction data is core to our understanding of disease processes and their molecular/genetic bases. Facile access to such core data is particularly important for the plant sciences, where individual genetic and phenotypic observations have the added complexity of being dispersed over a wide diversity of plant species vs. the relatively fewer host species of interest to biomedical researchers. Recently, an international initiative interested in scholarly data publishing proposed that all scientific data should be “FAIR”—Findable, Accessible, Interoperable, and Reusable. In this work, we describe the process of migrating a database of notable relevance to the plant sciences—the Pathogen-Host Interaction Database (PHI-base)—to a form that conforms to each of the FAIR Principles. We discuss the technical and architectural decisions, and the migration pathway, including observations of the difficulty and/or fidelity of each step. We examine how multiple FAIR principles can be addressed simultaneously through careful design decisions, including making data FAIR for both humans and machines with minimal duplication of effort. We note how FAIR data publishing involves more than data reformatting, requiring features beyond those exhibited by most life science Semantic Web or Linked Data resources. We explore the value-added by completing this FAIR data transformation, and then test the result through integrative questions that could not easily be asked over traditional Web-based data resources. Finally, we demonstrate the utility of providing explicit and reliable access to provenance information, which we argue enhances citation rates by encouraging and facilitating transparent scholarly reuse of these valuable data holdings.",2016-05-12,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:59:14,,,7,Front Plant Sci,Publishing FAIR Data,PubMed Central,PMID: 27433158 PMCID: PMC4922217,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4922217/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
622,10.3389/fpls.2017.00184,28261241,PMC5306281,,,,"Contreras-Moreira, Bruno; Cantalapiedra, Carlos P.; García-Pereira, María J.; Gordon, Sean P.; Vogel, John P.; Igartua, Ernesto; Casas, Ana M.; Vinuesa, Pablo","Analysis of Plant Pan-Genomes and Transcriptomes with GET_HOMOLOGUES-EST, a Clustering Solution for Sequences of the Same Species",2017,Frontiers in Plant Science,,"The pan-genome of a species is defined as the union of all the genes and non-coding sequences found in all its individuals. However, constructing a pan-genome for plants with large genomes is daunting both in sequencing cost and the scale of the required computational analysis. A more affordable alternative is to focus on the genic repertoire by using transcriptomic data. Here, the software GET_HOMOLOGUES-EST was benchmarked with genomic and RNA-seq data of 19 Arabidopsis thaliana ecotypes and then applied to the analysis of transcripts from 16 Hordeum vulgare genotypes. The goal was to sample their pan-genomes and classify sequences as core, if detected in all accessions, or accessory, when absent in some of them. The resulting sequence clusters were used to simulate pan-genome growth, and to compile Average Nucleotide Identity matrices that summarize intra-species variation. Although transcripts were found to under-estimate pan-genome size by at least 10%, we concluded that clusters of expressed sequences can recapitulate phylogeny and reproduce two properties observed in A. thaliana gene models: accessory loci show lower expression and higher non-synonymous substitution rates than core genes. Finally, accessory sequences were observed to preferentially encode transposon components in both species, plus disease resistance genes in cultivated barleys, and a variety of protein domains from other families that appear frequently associated with presence/absence variation in the literature. These results demonstrate that pan-genome analyses are useful to explore germplasm diversity.",2017-02-14,2021-06-05 21:12:01,,,8,Front Plant Sci,,PubMed Central,PMID: 28261241 PMCID: PMC5306281,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5306281/,,,,PMC:Query2
623,10.3389/fpsyg.2014.00385,24860525,PMC4026710,A,Neo4j,Neo4j,"Jackson, Alice F.; Bolger, Donald J.",Using a high-dimensional graph of semantic space to model relationships among words,2014,Frontiers in Psychology,,"The GOLD model (Graph Of Language Distribution) is a network model constructed based on co-occurrence in a large corpus of natural language that may be used to explore what information may be present in a graph-structured model of language, and what information may be extracted through theoretically-driven algorithms as well as standard graph analysis methods. The present study will employ GOLD to examine two types of relationship between words: semantic similarity and associative relatedness. Semantic similarity refers to the degree of overlap in meaning between words, while associative relatedness refers to the degree to which two words occur in the same schematic context. It is expected that a graph structured model of language constructed based on co-occurrence should easily capture associative relatedness, because this type of relationship is thought to be present directly in lexical co-occurrence. However, it is hypothesized that semantic similarity may be extracted from the intersection of the set of first-order connections, because two words that are semantically similar may occupy similar thematic or syntactic roles across contexts and thus would co-occur lexically with the same set of nodes. Two versions the GOLD model that differed in terms of the co-occurence window, bigGOLD at the paragraph level and smallGOLD at the adjacent word level, were directly compared to the performance of a well-established distributional model, Latent Semantic Analysis (LSA). The superior performance of the GOLD models (big and small) suggest that a single acquisition and storage mechanism, namely co-occurrence, can account for associative and conceptual relationships between words and is more psychologically plausible than models using singular value decomposition (SVD).",2014-05-12,2021-06-05 21:13:27; 2021-06-05 20:56:20; 2021-06-05 20:37:08,,,5,Front Psychol,,PubMed Central,PMID: 24860525 PMCID: PMC4026710,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4026710/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
624,10.3389/frai.2020.00038,33733155,PMC7861323,,,,"Tanner, James; Sonderegger, Morgan; Stuart-Smith, Jane; Fruehwald, Josef",Toward “English” Phonetics: Variability in the Pre-consonantal Voicing Effect Across English Dialects and Speakers,2020,Frontiers in Artificial Intelligence,,"Recent advances in access to spoken-language corpora and development of speech processing tools have made possible the performance of “large-scale” phonetic and sociolinguistic research. This study illustrates the usefulness of such a large-scale approach—using data from multiple corpora across a range of English dialects, collected, and analyzed with the SPADE project—to examine how the pre-consonantal Voicing Effect (longer vowels before voiced than voiceless obstruents, in e.g., bead vs. beat) is realized in spontaneous speech, and varies across dialects and individual speakers. Compared with previous reports of controlled laboratory speech, the Voicing Effect was found to be substantially smaller in spontaneous speech, but still influenced by the expected range of phonetic factors. Dialects of English differed substantially from each other in the size of the Voicing Effect, whilst individual speakers varied little relative to their particular dialect. This study demonstrates the value of large-scale phonetic research as a means of developing our understanding of the structure of speech variability, and illustrates how large-scale studies, such as those carried out within SPADE, can be applied to other questions in phonetic and sociolinguistic research.",2020-05-29,2021-06-05 21:10:08,,,3,Front Artif Intell,Toward “English” Phonetics,PubMed Central,PMID: 33733155 PMCID: PMC7861323,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7861323/,,,,PMC:Query2
625,10.3389/frai.2021.625341,,PMC8089371,,,,"Church, Kenneth; Liberman, Mark",The Future of Computational Linguistics: On Beyond Alchemy,2021,Frontiers in Artificial Intelligence,,"Over the decades, fashions in Computational Linguistics have changed again and again, with major shifts in motivations, methods and applications. When digital computers first appeared, linguistic analysis adopted the new methods of information theory, which accorded well with the ideas that dominated psychology and philosophy. Then came formal language theory and the idea of AI as applied logic, in sync with the development of cognitive science. That was followed by a revival of 1950s-style empiricism—AI as applied statistics—which in turn was followed by the age of deep nets. There are signs that the climate is changing again, and we offer some thoughts about paths forward, especially for younger researchers who will soon be the leaders.",2021-04-19,2021-06-05 21:09:36,,,4,Front Artif Intell,The Future of Computational Linguistics,PubMed Central,PMID:  PMCID: PMC8089371,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8089371/,,,,PMC:Query2
626,10.3389/frma.2020.00003,33870041,PMC8028387,A,GraphDB; COVID19,GraphDB; COVID19,"Ambrosiano, John; Sims, Benjamin; Bartlow, Andrew W.; Rosenberger, William; Ressler, Mark; Fair, Jeanne M.",Ontology-Based Graphs of Research Communities: A Tool for Understanding Threat Reduction Networks,2020,Frontiers in Research Metrics and Analytics,,"Scientific research communities can be represented as heterogeneous or multidimensional networks encompassing multiple types of entities and relationships. These networks might include researchers, institutions, meetings, and publications, connected by relationships like authorship, employment, and attendance. We describe a method for efficiently and flexibly capturing, storing, and extracting information from multidimensional scientific networks using a graph database. The database structure is based on an ontology that captures allowable types of entities and relationships. This allows us to construct a variety of projections of the underlying multidimensional graph through database queries to answer specific research questions. We demonstrate this process through a study of the U.S. Biological Threat Reduction Program (BTRP), which seeks to develop Threat Reduction Networks to build and strengthen a sustainable international community of biosecurity, biosafety, and biosurveillance experts to address shared biological threat reduction challenges. Networks like these create connectional intelligence among researchers and institutions around the world, and are central to the concept of cooperative threat reduction. Our analysis focuses on a series of seven BTRP genome sequencing training workshops, showing how they created a growing network of participants and countries over time, which is also reflected in coauthorship relationships among attendees. By capturing concept and relationship hierarchies, our ontology-based approach allows us to pose general or specific questions about networks within the same framework. This approach can be applied to other research communities or multidimensional social networks to capture, analyze, and visualize different types of interactions and how they change over time.",2020-06-09; 2020,2021-06-05 21:35:36; 2021-06-05 20:54:31; 2021-06-05 21:10:08; 2021-06-05 21:06:22; 2021-06-06 06:54:16,3,,5,Front Res Metr Anal,Ontology-Based Graphs of Research Communities,PubMed; PubMed Central,PMID: 33870041 PMCID: PMC8028387,http://www.ncbi.nlm.nih.gov/pubmed/33870041; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8028387/,bioinformatics; collaboration; connectional intelligence; global health; ontology; social network; threat reduction network,GraphDB; COVID19,GraphDB; COVID19,PMC:Query2; PMC:Query3; PMC:COVID19; PMC:GraphDB; PubMed:Query2
627,10.3389/frma.2020.577131,33870050,PMC8028384,A,Neo4j,Neo4j,"Zhao, Wenxi; Korobskiy, Dmitriy; Chacko, George",Delayed Recognition: A Co-Citation Perspective,2020; 2021,Frontiers in Research Metrics and Analytics,,"A Sleeping Beauty is a publication that is apparently unrecognized by citation for some period of time before experiencing a burst of recognition. Various reasons, including resistance to new ideas, have been attributed to such delayed recognition. We study this phenomenon in the special case of co-citations, which represent new ideas generated through the combination of existing ones. Using relatively stringent selection criteria derived from the work of others, we analyze a very large dataset of over 940 million unique co-cited article pairs, and identify 1,196 cases of delayed co-citations. We further classify these 1,196 cases with respect to amplitude, rate of citation, and disciplinary origin.",2021-02-19; 2020,2021-06-05 20:35:57; 2021-06-05 21:06:22; 2021-06-05 20:54:31; 2021-06-05 21:09:36,577131,,5,Front Res Metr Anal,Delayed Recognition,PubMed; PubMed Central,PMID: 33870050 PMCID: PMC8028384,http://www.ncbi.nlm.nih.gov/pubmed/33870050; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8028384/,bibliometrics; co-citation; delayed recognition; graph database; sleeping beauty,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PubMed:Query2; PMC:Query2
628,10.3389/frma.2020.612442,33870065,PMC8025970,,,,"Payumo, Jane; He, Guangming; Manjunatha, Anusha Chintamani; Higgins, Devin; Calvert, Scout",Mapping Collaborations and Partnerships in SDG Research,2021,Frontiers in Research Metrics and Analytics,,"Collaboration has become an essential paradigm in sustainable development research and in strategies for meeting the United Nations Sustainable Development Goals (SDGs). This study uses bibliometric methods and network analysis to examine research output and collaboration supporting the SDGs and explores means to detect and analyze research collaboration beyond the traditional definition of multiple, one-time co-authorship. We employed two additional lenses of collaboration: repeat collaboration and collaboration time point to quantify and visualize co-authorship data sourced from Microsoft Academic Graph. Our results show an increased collaboration rate over time at the author and institutional levels; however they also indicate that the majority of collaborations in SDG-related research only happened once. We also found out that on average, repeat collaboration happens more frequently, but after a longer duration, at the institutional level than at the author level. For this reason, we further analyzed institutions and identified core institutions that could help influence more consistent collaboration and sustain or grow the SDG-related research network. Our results have implications for understanding sustainable partnerships in research related to SDGs and other global challenges.",2021-02-09,2021-06-05 21:09:36,,,5,Front Res Metr Anal,,PubMed Central,PMID: 33870065 PMCID: PMC8025970,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8025970/,,,,PMC:Query2
629,10.3389/frma.2021.690986,34027300,PMC8137970,,,,"Ajiferuke, Isola; Grácio, Maria Cláudia Cabrini; Yang, Siluo","Editorial: Research Collaboration and Networks: Characteristics, Evolution and Trends",2021,Frontiers in Research Metrics and Analytics,,,2021-05-07,2021-06-05 21:09:36,,,6,Front Res Metr Anal,Editorial,PubMed Central,PMID: 34027300 PMCID: PMC8137970,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8137970/,,,,PMC:Query2
630,10.3389/frobt.2018.00123,33501002,PMC7805659,A,GraphDB,GraphDB,"Vrochidis, Stefanos; Moumtzidou, Anastasia; Gialampoukidis, Ilias; Liparas, Dimitris; Casamayor, Gerard; Wanner, Leo; Heise, Nicolaus; Wagner, Tilman; Bilous, Andriy; Jamin, Emmanuel; Simeonov, Boyan; Alexiev, Vladimir; Busch, Reinhard; Arapakis, Ioannis; Kompatsiaris, Ioannis","A Multimodal Analytics Platform for Journalists Analyzing Large-Scale, Heterogeneous Multilingual, and Multimedia Content",2018,Frontiers in Robotics and AI,,"Analysts and journalists face the problem of having to deal with very large, heterogeneous, and multilingual data volumes that need to be analyzed, understood, and aggregated. Automated and simplified editorial and authoring process could significantly reduce time, labor, and costs. Therefore, there is a need for unified access to multilingual and multicultural news story material, beyond the level of a nation, ensuring context-aware, spatiotemporal, and semantic interpretation, correlating also and summarizing the interpreted material into a coherent gist. In this paper, we present a platform integrating multimodal analytics techniques, which are able to support journalists in handling large streams of real-time and diverse information. Specifically, the platform automatically crawls and indexes multilingual and multimedia information from heterogeneous resources. Textual information is automatically summarized and can be translated (on demand) into the language of the journalist. High-level information is extracted from both textual and multimedia content for fast inspection using concept clouds. The textual and multimedia content is semantically integrated and indexed using a common representation, to be accessible through a web-based search engine. The evaluation of the proposed platform was performed by several groups of journalists revealing satisfaction from the user side.",2018-10-29,2021-06-05 20:55:01; 2021-06-06 06:54:16; 2021-06-05 21:11:16,,,5,Front Robot AI,,PubMed Central,PMID: 33501002 PMCID: PMC7805659,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7805659/,,GraphDB,GraphDB,PMC:Query3; PMC:GraphDB; PMC:Query2
631,10.3389/frobt.2021.476084,33937343,PMC8082111,,,,"Thosar, Madhura; Mueller, Christian A.; Jäger, Georg; Schleiss, Johannes; Pulugu, Narender; Mallikarjun Chennaboina, Ravi; Rao Jeevangekar, Sai Vivek; Birk, Andreas; Pfingsthorn, Max; Zug, Sebastian",From Multi-Modal Property Dataset to Robot-Centric Conceptual Knowledge About Household Objects,2021,Frontiers in Robotics and AI,,"Conceptual knowledge about objects is essential for humans, as well as for animals, to interact with their environment. On this basis, the objects can be understood as tools, a selection process can be implemented and their usage can be planned in order to achieve a specific goal. The conceptual knowledge, in this case, is primarily concerned about the physical properties and functional properties observed in the objects. Similarly tool-use applications in robotics require such conceptual knowledge about objects for substitute selection among other purposes. State-of-the-art methods employ a top-down approach where hand-crafted symbolic knowledge, which is defined from a human perspective, is grounded into sensory data afterwards. However, due to different sensing and acting capabilities of robots, a robot's conceptual understanding of objects (e.g., light/heavy) will vary and therefore should be generated from the robot's perspective entirely, which entails robot-centric conceptual knowledge about objects. A similar bottom-up argument has been put forth in cognitive science that humans and animals alike develop conceptual understanding of objects based on their own perceptual experiences with objects. With this goal in mind, we propose an extensible property estimation framework which consists of estimations methods to obtain the quantitative measurements of physical properties (rigidity, weight, etc.) and functional properties (containment, support, etc.) from household objects. This property estimation forms the basis for our second contribution: Generation of robot-centric conceptual knowledge. Our approach employs unsupervised clustering methods to transform numerical property data into symbols, and Bivariate Joint Frequency Distributions and Sample Proportion to generate conceptual knowledge about objects using the robot-centric symbols. A preliminary implementation of the proposed framework is employed to acquire a dataset comprising six physical and four functional properties of 110 household objects. This Robot-Centric dataSet (RoCS) is used to evaluate the framework regarding the property estimation methods and the semantics of the considered properties within the dataset. Furthermore, the dataset includes the derived robot-centric conceptual knowledge using the proposed framework. The application of the conceptual knowledge about objects is then evaluated by examining its usefulness in a tool substitution scenario.",2021-04-15,2021-06-05 21:09:36,,,8,Front Robot AI,,PubMed Central,PMID: 33937343 PMCID: PMC8082111,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8082111/,,,,PMC:Query2
632,10.3390/brainsci9020024,30682814,PMC6406638,,,,"Baig, Muhammad Zeeshan; Kavakli, Manolya",Connectivity Analysis Using Functional Brain Networks to Evaluate Cognitive Activity during 3D Modelling,2019,Brain Sciences,,"Modelling 3D objects in CAD software requires special skills which require a novice user to undergo a series of training exercises to obtain. To minimize the training time for a novice user, the user-dependent factors must be studied. we have presented a comparative analysis of novice/expert information flow patterns. We have used Normalized Transfer Entropy (NTE) and Electroencephalogram (EEG) to investigate the differences. The experiment was divided into three cognitive states i.e., rest, drawing, and manipulation. We applied classification algorithms on NTE matrices and graph theory measures to see the effectiveness of NTE. The results revealed that the experts show approximately the same cognitive activation in drawing and manipulation states, whereas for novices the brain activation is more in manipulation state than drawing state. The hemisphere- and lobe-wise analysis showed that expert users have developed an ability to control the information flow in various brain regions. On the other hand, novice users have shown a continuous increase in information flow activity in almost all regions when doing drawing and manipulation tasks. A classification accuracy of more than 90% was achieved with a simple K-nearest neighbors (k-NN) to classify novice and expert users. The results showed that the proposed technique can be used to develop adaptive 3D modelling systems.",2019-01-24,2021-06-05 21:10:37,,2,9,Brain Sci,,PubMed Central,PMID: 30682814 PMCID: PMC6406638,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6406638/,,,,PMC:Query2
633,10.3390/e21090883,,PMC7515412,,,,"Esteves, Luis Gustavo; Izbicki, Rafael; Stern, Julio Michael; Stern, Rafael Bassi",Pragmatic Hypotheses in the Evolution of Science,2019,Entropy,,"This paper introduces pragmatic hypotheses and relates this concept to the spiral of scientific evolution. Previous works determined a characterization of logically consistent statistical hypothesis tests and showed that the modal operators obtained from this test can be represented in the hexagon of oppositions. However, despite the importance of precise hypothesis in science, they cannot be accepted by logically consistent tests. Here, we show that this dilemma can be overcome by the use of pragmatic versions of precise hypotheses. These pragmatic versions allow a level of imprecision in the hypothesis that is small relative to other experimental conditions. The introduction of pragmatic hypotheses allows the evolution of scientific theories based on statistical hypothesis testing to be interpreted using the narratological structure of hexagonal spirals, as defined by Pierre Gallais.",2019-09-11,2021-06-05 21:10:37,,9,21,Entropy (Basel),,PubMed Central,PMID:  PMCID: PMC7515412,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7515412/,,,,PMC:Query2
634,10.3390/e21090891,,PMC7515427,,,,"Xiong, Siqi; Zhu, Feng; Yao, Yiping; Tang, Wenjie; Xiao, Yuhao",Service-Oriented Model Encapsulation and Selection Method for Complex System Simulation Based on Cloud Architecture,2019,Entropy,,"With the rise in cloud computing architecture, the development of service-oriented simulation models has gradually become a prominent topic in the field of complex system simulation. In order to support the distributed sharing of the simulation models with large computational requirements and to select the optimal service model to construct complex system simulation applications, this paper proposes a service-oriented model encapsulation and selection method. This method encapsulates models into shared simulation services, supports the distributed scheduling of model services in the network, and designs a semantic search framework which can support users in searching models according to model correlation. An optimization selection algorithm based on quality of service (QoS) is proposed to support users in customizing the weights of QoS indices and obtaining the ordered candidate model set by weighted comparison. The experimental results showed that the parallel operation of service models can effectively improve the execution efficiency of complex system simulation applications, and the performance was increased by 19.76% compared with that of scatter distribution strategy. The QoS weighted model selection method based on semantic search can support the effective search and selection of simulation models in the cloud environment according to the user’s preferences.",2019-09-14,2021-06-05 21:10:37,,9,21,Entropy (Basel),,PubMed Central,PMID:  PMCID: PMC7515427,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7515427/,,,,PMC:Query2
635,10.3390/e21111083,,PMC7514427,,,,"Zhao, Yu; Feng, Huali; Gallinari, Patrick",Embedding Learning with Triple Trustiness on Noisy Knowledge Graph,2019,Entropy,,"Embedding learning on knowledge graphs (KGs) aims to encode all entities and relationships into a continuous vector space, which provides an effective and flexible method to implement downstream knowledge-driven artificial intelligence (AI) and natural language processing (NLP) tasks. Since KG construction usually involves automatic mechanisms with less human supervision, it inevitably brings in plenty of noises to KGs. However, most conventional KG embedding approaches inappropriately assume that all facts in existing KGs are completely correct and ignore noise issues, which brings about potentially serious errors. To address this issue, in this paper we propose a novel approach to learn embeddings with triple trustiness on KGs, which takes possible noises into consideration. Specifically, we calculate the trustiness value of triples according to the rich and relatively reliable information from large amounts of entity type instances and entity descriptions in KGs. In addition, we present a cross-entropy based loss function for model optimization. In experiments, we evaluate our models on KG noise detection, KG completion and classification. Through extensive experiments on three datasets, we demonstrate that our proposed model can learn better embeddings than all baselines on noisy KGs.",2019-11-06,2021-06-05 21:10:37,,11,21,Entropy (Basel),,PubMed Central,PMID:  PMCID: PMC7514427,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7514427/,,,,PMC:Query2
636,10.3390/e23030374,33804746,PMC8003965,A,Neo4j,Neo4j,"Villalba-Diez, Javier; Losada, Juan Carlos; Benito, Rosa María; González-Marcos, Ana",Industry 4.0 Quantum Strategic Organizational Design Configurations. The Case of 3 Qubits: One Reports to Two,2021,Entropy,,"In this work we explore how the relationship between one subordinate reporting to two leaders influences the alignment of the latter with the company’s strategic objectives in an Industry 4.0 environment. We do this through the implementation of quantum circuits that represent decision networks. This is done for two cases: One in which the leaders do not communicate with each other, and one in which they do. Through the quantum simulation of strategic organizational design configurations (QSOD) through 500 quantum circuit simulations, we conclude that in the first case both leaders are not simultaneously in alignment, and in the second case that both reporting nodes need to have an alignment probability higher than 90% to support the leader node.",2021-03-20,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,3,23,Entropy (Basel),Industry 4.0 Quantum Strategic Organizational Design Configurations. The Case of 3 Qubits,PubMed Central,PMID: 33804746 PMCID: PMC8003965,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8003965/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
637,10.3390/e23040426,33916662,PMC8065959,A,Neo4j,Neo4j,"Villalba-Diez, Javier; Losada, Juan Carlos; Benito, Rosa María; Schmidt, Daniel",Industry 4.0 Quantum Strategic Organizational Design Configurations. The Case of 3 Qubits: Two Report to One,2021,Entropy,,"The goal of this work is to explore how the relationship between two subordinates reporting to a leader influences the alignment of the latter with the company’s strategic objectives in an Industry 4.0 environment. We do this through the implementation of quantum circuits that represent decision networks. In fact, through the quantum simulation of strategic organizational design configurations (QSOD) through five hundred quantum circuit simulations. We conclude that the alignment probability of the leader is never higher than the average alignment value of his subordinates, i.e., the leader never has a better alignment than his subordinates. In other words, the leader cannot present asymptotic stability better than that of his subordinates. The most relevant conclusion of this work is the clear recommendation to the leaders of Industry 4.0 not to add hierarchical levels to their organization if they have not achieved high levels of stability in the lower levels.",2021-04-03,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,4,23,Entropy (Basel),Industry 4.0 Quantum Strategic Organizational Design Configurations. The Case of 3 Qubits,PubMed Central,PMID: 33916662 PMCID: PMC8065959,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8065959/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
638,10.3390/e23050502,33922279,PMC8146345,A,Neo4j,Neo4j,"Jung, Hohyun; Phoa, Frederick Kin Hing",A Mixture Model of Truncated Zeta Distributions with Applications to Scientific Collaboration Networks,2021,Entropy,,"The degree distribution has attracted considerable attention from network scientists in the last few decades to have knowledge of the topological structure of networks. It is widely acknowledged that many real networks have power-law degree distributions. However, the deviation from such a behavior often appears when the range of degrees is small. Even worse, the conventional employment of the continuous power-law distribution usually causes an inaccurate inference as the degree should be discrete-valued. To remedy these obstacles, we propose a finite mixture model of truncated zeta distributions for a broad range of degrees that disobeys a power-law behavior in the range of small degrees while maintaining the scale-free behavior. The maximum likelihood algorithm alongside the model selection method is presented to estimate model parameters and the number of mixture components. The validity of the suggested algorithm is evidenced by Monte Carlo simulations. We apply our method to five disciplines of scientific collaboration networks with remarkable interpretations. The proposed model outperforms the other alternatives in terms of the goodness-of-fit.",2021-04-22,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,5,23,Entropy (Basel),,PubMed Central,PMID: 33922279 PMCID: PMC8146345,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8146345/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
639,10.3390/e23050602,34068208,PMC8153108,,,,"Zhu, Hongming; Wang, Xiaowen; Jiang, Yizhi; Fan, Hongfei; Du, Bowen; Liu, Qin",FTRLIM: Distributed Instance Matching Framework for Large-Scale Knowledge Graph Fusion,2021,Entropy,,"Instance matching is a key task in knowledge graph fusion, and it is critical to improving the efficiency of instance matching, given the increasing scale of knowledge graphs. Blocking algorithms selecting candidate instance pairs for comparison is one of the effective methods to achieve the goal. In this paper, we propose a novel blocking algorithm named MultiObJ, which constructs indexes for instances based on the Ordered Joint of Multiple Objects’ features to limit the number of candidate instance pairs. Based on MultiObJ, we further propose a distributed framework named Follow-the-Regular-Leader Instance Matching (FTRLIM), which matches instances between large-scale knowledge graphs with approximately linear time complexity. FTRLIM has participated in OAEI 2019 and achieved the best matching quality with significantly efficiency. In this research, we construct three data collections based on a real-world large-scale knowledge graph. Experiment results on the constructed data collections and two real-world datasets indicate that MultiObJ and FTRLIM outperform other state-of-the-art methods.",2021-05-13,2021-06-05 21:09:36,,5,23,Entropy (Basel),FTRLIM,PubMed Central,PMID: 34068208 PMCID: PMC8153108,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8153108/,,,,PMC:Query2
640,10.3390/genes10020076,30678090,PMC6410296,A,Neo4j,Neo4j,"Romanowska, Julia; Joshi, Anagha",From Genotype to Phenotype: Through Chromatin,2019,Genes,,"Advances in sequencing technologies have enabled the exploration of the genetic basis for several clinical disorders by allowing identification of causal mutations in rare genetic diseases. Sequencing technology has also facilitated genome-wide association studies to gather single nucleotide polymorphisms in common diseases including cancer and diabetes. Sequencing has therefore become common in the clinic for both prognostics and diagnostics. The success in follow-up steps, i.e., mapping mutations to causal genes and therapeutic targets to further the development of novel therapies, has nevertheless been very limited. This is because most mutations associated with diseases lie in inter-genic regions including the so-called regulatory genome. Additionally, no genetic causes are apparent for many diseases including neurodegenerative disorders. A complementary approach is therefore gaining interest, namely to focus on epigenetic control of the disease to generate more complete functional genomic maps. To this end, several recent studies have generated large-scale epigenetic datasets in a disease context to form a link between genotype and phenotype. We focus DNA methylation and important histone marks, where recent advances have been made thanks to technology improvements, cost effectiveness, and large meta-scale epigenome consortia efforts. We summarize recent studies unravelling the mechanistic understanding of epigenetic processes in disease development and progression. Moreover, we show how methodology advancements enable causal relationships to be established, and we pinpoint the most important issues to be addressed by future research.",2019-01-23,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,,2,10,Genes (Basel),From Genotype to Phenotype,PubMed Central,PMID: 30678090 PMCID: PMC6410296,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6410296/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
641,10.3390/healthcare8040466,33171711,PMC7712438,,,,"Mukhtar, Hamid; Ahmad, Hafiz Farooq; Khan, Muhammad Zahid; Ullah, Nasim",Analysis and Evaluation of COVID-19 Web Applications for Health Professionals: Challenges and Opportunities,2020,Healthcare,,"The multidisciplinary nature of the work required for research in the COVID-19 pandemic has created new challenges for health professionals in the battle against the virus. They need to be equipped with novel tools, applications, and resources—that have emerged during the pandemic—to gain access to breakthrough findings; know the latest developments; and to address their specific needs for rapid data acquisition, analysis, evaluation, and reporting. Because of the complex nature of the virus, healthcare systems worldwide are severely impacted as the treatment and the vaccine for COVID-19 disease are not yet discovered. This leads to frequent changes in regulations and policies by governments and international organizations. Our analysis suggests that given the abundance of information sources, finding the most suitable application for analysis, evaluation, or reporting, is one of such challenges. However, health professionals and policy-makers need access to the most relevant, reliable, trusted, and latest information and applications that can be used in their day-to-day tasks of COVID-19 research and analysis. In this article, we present our analysis of various novel and important web-based applications that have been specifically developed during the COVID-19 pandemic and that can be used by the health professionals community to help in advancing their analysis and research. These applications comprise search portals and their associated information repositories for literature and clinical trials, data sources, tracking dashboards, and forecasting models. We present a list of the minimally essential online, web-based applications to serve a multitude of purposes, from hundreds of those developed since the beginning of the pandemic. A critical analysis is provided for the selected applications based on 17 features that can be useful for researchers and analysts for their evaluations. These features make up our evaluation framework and have not been used previously for analysis and evaluation. Therefore, knowledge of these applications will not only increase productivity but will also allow us to explore new dimensions for using existing applications with more control, better management, and greater outcome of their research. In addition, the features used in our framework can be applied for future evaluations of similar applications and health professionals can adapt them for evaluation of other applications not covered in this analysis.",2020-11-07,2021-06-05 21:09:36,,4,8,Healthcare (Basel),Analysis and Evaluation of COVID-19 Web Applications for Health Professionals,PubMed Central,PMID: 33171711 PMCID: PMC7712438,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7712438/,,,,PMC:Query2
642,10.3390/ijerph13010142,26797628,PMC4730533,A,Neo4j,Neo4j,"Palomino, Marco; Taylor, Tim; Göker, Ayse; Isaacs, John; Warber, Sara",The Online Dissemination of Nature–Health Concepts: Lessons from Sentiment Analysis of Social Media Relating to “Nature-Deficit Disorder”,2016,International Journal of Environmental Research and Public Health,,"Evidence continues to grow supporting the idea that restorative environments, green exercise, and nature-based activities positively impact human health. Nature-deficit disorder, a journalistic term proposed to describe the ill effects of people’s alienation from nature, is not yet formally recognized as a medical diagnosis. However, over the past decade, the phrase has been enthusiastically taken up by some segments of the lay public. Social media, such as Twitter, with its opportunities to gather “big data” related to public opinions, offers a medium for exploring the discourse and dissemination around nature-deficit disorder and other nature–health concepts. In this paper, we report our experience of collecting more than 175,000 tweets, applying sentiment analysis to measure positive, neutral or negative feelings, and preliminarily mapping the impact on dissemination. Sentiment analysis is currently used to investigate the repercussions of events in social networks, scrutinize opinions about products and services, and understand various aspects of the communication in Web-based communities. Based on a comparison of nature-deficit-disorder “hashtags” and more generic nature hashtags, we make recommendations for the better dissemination of public health messages through changes to the framing of messages. We show the potential of Twitter to aid in better understanding the impact of the natural environment on human health and wellbeing.",2016-01,2021-06-05 20:55:40; 2021-06-05 21:12:40; 2021-06-05 20:37:08,,1,13,Int J Environ Res Public Health,The Online Dissemination of Nature–Health Concepts,PubMed Central,PMID: 26797628 PMCID: PMC4730533,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4730533/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
643,10.3390/ijerph17031066,32046238,PMC7037767,A,Neo4j,Neo4j,"Lara-Navarra, Pablo; Falciani, Hervé; Sánchez-Pérez, Enrique A.; Ferrer-Sapena, Antonia",Information Management in Healthcare and Environment: Towards an Automatic System for Fake News Detection,2020,International Journal of Environmental Research and Public Health,,"Comments and information appearing on the internet and on different social media sway opinion concerning potential remedies for diagnosing and curing diseases. In many cases, this has an impact on citizens' health and affects medical professionals, who find themselves having to defend their diagnoses as well as the treatments they propose against ill-informed patients. The propagation of these opinions follows the same pattern as the dissemination of fake news about other important topics, such as the environment, via social media networks, which we use as a testing ground for checking our procedure. In this article, we present an algorithm to analyse the behaviour of users of Twitter, the most important social network with respect to this issue, as well as a dynamic knowledge graph construction method based on information gathered from Twitter and other open data sources such as web pages. To show our methodology, we present a concrete example of how the associated graph structure of the tweets related to World Environment Day 2019 is used to develop a heuristic analysis of the validity of the information. The proposed analytical scheme is based on the interaction between the computer tool-a database implemented with Neo4j-and the analyst, who must ask the right questions to the tool, allowing to follow the line of any doubtful data. We also show how this method can be used. We also present some methodological guidelines on how our system could allow, in the future, an automation of the procedures for the construction of an autonomous algorithm for the detection of false news on the internet related to health.; Comments and information appearing on the internet and on different social media sway opinion concerning potential remedies for diagnosing and curing diseases. In many cases, this has an impact on citizens’ health and affects medical professionals, who find themselves having to defend their diagnoses as well as the treatments they propose against ill-informed patients. The propagation of these opinions follows the same pattern as the dissemination of fake news about other important topics, such as the environment, via social media networks, which we use as a testing ground for checking our procedure. In this article, we present an algorithm to analyse the behaviour of users of Twitter, the most important social network with respect to this issue, as well as a dynamic knowledge graph construction method based on information gathered from Twitter and other open data sources such as web pages. To show our methodology, we present a concrete example of how the associated graph structure of the tweets related to World Environment Day 2019 is used to develop a heuristic analysis of the validity of the information. The proposed analytical scheme is based on the interaction between the computer tool—a database implemented with Neo4j—and the analyst, who must ask the right questions to the tool, allowing to follow the line of any doubtful data. We also show how this method can be used. We also present some methodological guidelines on how our system could allow, in the future, an automation of the procedures for the construction of an autonomous algorithm for the detection of false news on the internet related to health.",2020-02-08; 2020-02,2021-06-05 20:35:57; 2021-06-05 21:10:08; 2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 20:55:01; 2021-06-05 21:24:28,,3,17,Int J Environ Res Public Health,Information Management in Healthcare and Environment,PubMed; PubMed Central,PMID: 32046238 PMCID: PMC7037767,http://www.ncbi.nlm.nih.gov/pubmed/32046238; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7037767/,Algorithms; Communications Media; Consumer Health Information; environment; Environmental Health; fake news; Global Health; graph; Health Behavior; Health Literacy; healthcare; Humans; Information Management; Internet; Online Social Networking; reinforcement learning; Social Media,Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
644,10.3390/ijerph17176161,32854265,PMC7503476,,,,"Jia, Qiong; Guo, Yue; Wang, Guanlin; Barnes, Stuart J.",Big Data Analytics in the Fight against Major Public Health Incidents (Including COVID-19): A Conceptual Framework,2020,International Journal of Environmental Research and Public Health,,"Major public health incidents such as COVID-19 typically have characteristics of being sudden, uncertain, and hazardous. If a government can effectively accumulate big data from various sources and use appropriate analytical methods, it may quickly respond to achieve optimal public health decisions, thereby ameliorating negative impacts from a public health incident and more quickly restoring normality. Although there are many reports and studies examining how to use big data for epidemic prevention, there is still a lack of an effective review and framework of the application of big data in the fight against major public health incidents such as COVID-19, which would be a helpful reference for governments. This paper provides clear information on the characteristics of COVID-19, as well as key big data resources, big data for the visualization of pandemic prevention and control, close contact screening, online public opinion monitoring, virus host analysis, and pandemic forecast evaluation. A framework is provided as a multidimensional reference for the effective use of big data analytics technology to prevent and control epidemics (or pandemics). The challenges and suggestions with respect to applying big data for fighting COVID-19 are also discussed.",2020-09,2021-06-05 21:10:08,,17,17,Int J Environ Res Public Health,Big Data Analytics in the Fight against Major Public Health Incidents (Including COVID-19),PubMed Central,PMID: 32854265 PMCID: PMC7503476,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7503476/,,,,PMC:Query2
645,10.3390/ijerph17176406,32887508,PMC7504366,A,Neo4j; COVID19,Neo4j; COVID19,"Fischer, Tatjana; Jobst, Markus",Capturing the Spatial Relatedness of Long-Distance Caregiving: A Mixed-Methods Approach,2020,International Journal of Environmental Research and Public Health,,"Long-distance caregiving (LDC) is an issue of growing importance in the context of assessing the future of elder care and the maintenance of health and well-being of both the cared-for persons and the long-distance caregivers. Uncertainty in the international discussion relates to the relevance of spatially related aspects referring to the burdens of the long-distance caregiver and their (longer-term) willingness and ability to provide care for their elderly relatives. This paper is the result of a first attempt to operationalize and comprehensively analyze the spatial relatedness of long-distance caregiving against the background of the international literature by combining a longitudinal single case study of long-distance caregiving person and semantic hierarchies. In the cooperation of spatial sciences and geoinformatics an analysis grid based on a graph-theoretical model was developed. The elaborated conceptual framework should stimulate a more detailed and precise interdisciplinary discussion on the spatial relatedness of long-distance caregiving and, thus, is open for further refinement in order to become a decision-support tool for policy-makers responsible for social and elder care and health promotion. Moreover, it may serve as a starting point for the development of a method for the numerical determination of the long-distance caregivers on different spatial reference scales.",2020-09,2021-06-05 20:35:57; 2021-06-05 21:35:36; 2021-06-05 20:54:31; 2021-06-05 21:10:08,,17,17,Int J Environ Res Public Health,Capturing the Spatial Relatedness of Long-Distance Caregiving,PubMed Central,PMID: 32887508 PMCID: PMC7504366,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7504366/,,Neo4j; COVID19,Neo4j; COVID19,PMC:Query3; PMC:Neo4j; PMC:COVID19; PMC:Query2
646,10.3390/ijms20112813,31181796,PMC6600575,A,Neo4j,Neo4j,"Kwon, Sujin; Kim, Susan S.; Nebeck, Howard E.; Ahn, Eun Hyun",Immortalization of Different Breast Epithelial Cell Types Results in Distinct Mitochondrial Mutagenesis,2019,International Journal of Molecular Sciences,,"Different phenotypes of normal cells might influence genetic profiles, epigenetic profiles, and tumorigenicities of their transformed derivatives. In this study, we investigate whether the whole mitochondrial genome of immortalized cells can be attributed to the different phenotypes (stem vs. non-stem) of their normal epithelial cell originators. To accurately determine mutations, we employed Duplex Sequencing, which exhibits the lowest error rates among currently-available DNA sequencing methods. Our results indicate that the vast majority of the observed mutations of the whole mitochondrial DNA occur at low-frequency (rare mutations). The most prevalent rare mutation types are C→T/G→A and A→G/T→C transitions. Frequencies and spectra of homoplasmic point mutations are virtually identical between stem cell-derived immortalized (SV1) cells and non-stem cell-derived immortalized (SV22) cells, verifying that both cell types were derived from the same woman. However, frequencies of rare point mutations are significantly lower in SV1 cells (5.79 × 10−5) than in SV22 cells (1.16 × 10−4). The significantly lower frequencies of rare mutations are aligned with a finding of longer average distances to adjacent mutations in SV1 cells than in SV22 cells. Additionally, the predicted pathogenicity for rare mutations in the mitochondrial tRNA genes tends to be lower (by 2.5-fold) in SV1 cells than in SV22 cells. While four known/confirmed pathogenic mt-tRNA mutations (m.5650 G>A, m.5521 G>A, m.5690 A>G, m.1630 A>G) were identified in SV22 cells, no such mutations were observed in SV1 cells. Our findings suggest that the immortalization of normal cells with stem cell features leads to decreased mitochondrial mutagenesis, particularly in RNA gene regions. The mutation spectra and mutations specific to stem cell-derived immortalized cells (vs. non-stem cell derived) have implications in characterizing the heterogeneity of tumors and understanding the role of mitochondrial mutations in the immortalization and transformation of human cells.",2019-06-08,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,,11,20,Int J Mol Sci,,PubMed Central,PMID: 31181796 PMCID: PMC6600575,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6600575/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
647,10.3390/ijms20133174,31261733,PMC6651053,,,,"Valdés-Jiménez, Alejandro; Larriba-Pey, Josep-L.; Núñez-Vivanco, Gabriel; Reyes-Parada, Miguel",3D-PP: A Tool for Discovering Conserved Three-Dimensional Protein Patterns,2019,International Journal of Molecular Sciences,,"Discovering conserved three-dimensional (3D) patterns among protein structures may provide valuable insights into protein classification, functional annotations or the rational design of multi-target drugs. Thus, several computational tools have been developed to discover and compare protein 3D-patterns. However, most of them only consider previously known 3D-patterns such as orthosteric binding sites or structural motifs. This fact makes necessary the development of new methods for the identification of all possible 3D-patterns that exist in protein structures (allosteric sites, enzyme-cofactor interaction motifs, among others). In this work, we present 3D-PP, a new free access web server for the discovery and recognition all similar 3D amino acid patterns among a set of proteins structures (independent of their sequence similarity). This new tool does not require any previous structural knowledge about ligands, and all data are organized in a high-performance graph database. The input can be a text file with the PDB access codes or a zip file of PDB coordinates regardless of the origin of the structural data: X-ray crystallographic experiments or in silico homology modeling. The results are presented as lists of sequence patterns that can be further analyzed within the web page. We tested the accuracy and suitability of 3D-PP using two sets of proteins coming from the Protein Data Bank: (a) Zinc finger containing and (b) Serotonin target proteins. We also evaluated its usefulness for the discovering of new 3D-patterns, using a set of protein structures coming from in silico homology modeling methodologies, all of which are overexpressed in different types of cancer. Results indicate that 3D-PP is a reliable, flexible and friendly-user tool to identify conserved structural motifs, which could be relevant to improve the knowledge about protein function or classification. The web server can be freely utilized at https://appsbio.utalca.cl/3d-pp/.",2019-06-28,2021-06-05 21:10:37; 2021-06-05 21:06:22,,13,20,Int J Mol Sci,3D-PP,PubMed; PubMed Central,PMID: 31261733 PMCID: PMC6651053,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6651053/; http://www.ncbi.nlm.nih.gov/pubmed/31261733,"3D-patterns; Allosteric Site; Amino Acid Sequence; Animals; conserved patterns; Conserved Sequence; Humans; Protein Conformation; Sequence Analysis, Protein; similarity; Software",,,PubMed:Query2; PMC:Query2
648,10.3390/ijms22020789,33466789,PMC7830561,A,Neo4j,Neo4j,"Klees, Selina; Lange, Thomas Martin; Bertram, Hendrik; Rajavel, Abirami; Schlüter, Johanna-Sophie; Lu, Kun; Schmitt, Armin Otto; Gültas, Mehmet","In Silico Identification of the Complex Interplay between Regulatory SNPs, Transcription Factors, and Their Related Genes in Brassica napus L. Using Multi-Omics Data",2021,International Journal of Molecular Sciences,,"Regulatory SNPs (rSNPs) are a special class of SNPs which have a high potential to affect the phenotype due to their impact on DNA-binding of transcription factors (TFs). Thus, the knowledge about such rSNPs and TFs could provide essential information regarding different genetic programs, such as tissue development or environmental stress responses. In this study, we use a multi-omics approach by combining genomics, transcriptomics, and proteomics data of two different Brassica napus L. cultivars, namely Zhongshuang11 (ZS11) and Zhongyou821 (ZY821), with high and low oil content, respectively, to monitor the regulatory interplay between rSNPs, TFs and their corresponding genes in the tissues flower, leaf, stem, and root. By predicting the effect of rSNPs on TF-binding and by measuring their association with the cultivars, we identified a total of 41,117 rSNPs, of which 1141 are significantly associated with oil content. We revealed several enriched members of the TF families DOF, MYB, NAC, or TCP, which are important for directing transcriptional programs regulating differential expression of genes within the tissues. In this work, we provide the first genome-wide collection of rSNPs for B. napus and their impact on the regulation of gene expression in vegetative and floral tissues, which will be highly valuable for future studies on rSNPs and gene regulation.",2021-01-14,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,2,22,Int J Mol Sci,,PubMed Central,PMID: 33466789 PMCID: PMC7830561,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7830561/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
649,10.3390/ijms22062819,33802212,PMC8001778,,,,"Baldelli, Elisa; Subramanian, Mahalakshmi; Alsubaie, Abduljalil M.; Oldaker, Guy; Emelianenko, Maria; El Gazzah, Emna; Baglivo, Sara; Hodge, Kimberley A.; Bianconi, Fortunato; Ludovini, Vienna; Crino’, Lucio; Petricoin, Emanuel F.; Pierobon, Mariaelena",Heterogeneous Off-Target Effects of Ultra-Low Dose Dimethyl Sulfoxide (DMSO) on Targetable Signaling Events in Lung Cancer In Vitro Models,2021,International Journal of Molecular Sciences,,"Targetable alterations in cancer offer novel opportunities to the drug discovery process. However, pre-clinical testing often requires solubilization of these drugs in cosolvents like dimethyl sulfoxide (DMSO). Using a panel of cell lines commonly used for in vitro drug screening and pre-clinical testing, we explored the DMSO off-target effects on functional signaling networks, drug targets, and downstream substrates. Eight Non-Small Cell Lung Cancer (NSCLC) cell lines were incubated with three concentrations of DMSO (0.0008%, 0.002%, and 0.004% v/v) over time. Expression and activation levels of 187 proteins, of which 137 were kinases and downstream substrates, were captured using the Reverse Phase Protein Array (RPPA). The DMSO effect was heterogeneous across cell lines and varied based on concentration, exposure time, and cell line. Of the 187 proteins measured, all were statistically different in at least one comparison at the highest DMSO concentration, followed by 99.5% and 98.9% at lower concentrations. Only 46% of the proteins were found to be statistically different in more than 5 cell lines, indicating heterogeneous response across models. These cell line specific alterations modulate response to in vitro drug screening. Ultra-low DMSO concentrations have broad and heterogeneous effects on targetable signaling proteins. Off-target effects need to be carefully evaluated in pre-clinical drug screening and testing.",2021-03-10,2021-06-05 21:09:36,,6,22,Int J Mol Sci,,PubMed Central,PMID: 33802212 PMCID: PMC8001778,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8001778/,,,,PMC:Query2
650,10.3390/ijms22094888,,PMC8125194,,,,"McEvoy, Malgorzata J.; Sinderewicz, Emilia; Creedon, Leo; McAfee, Marion; Jonczyk, Agnieszka W.; Piotrowska-Tomala, Katarzyna K.; Skarzynski, Dariusz J.",Death Processes in Bovine Theca and Granulosa Cells Modelled and Analysed Using a Systems Biology Approach,2021,International Journal of Molecular Sciences,,"In this paper, newly discovered mechanisms of atresia and cell death processes in bovine ovarian follicles are investigated. For this purpose the mRNA expression of receptor interacting protein kinases 1 and 3 (RIPK1 and RIPK3) of the granulosa and theca cells derived from healthy and atretic follicles are studied. The follicles were assigned as either healthy or atretic based on the estradiol to progesterone ratio. A statistically significant difference was recorded for the mRNA expression of a RIPK1 and RIPK3 between granulosa cells from healthy and atretic follicles. To further investigate this result a systems biology approach was used. The genes playing roles in necroptosis, apoptosis and atresia were chosen and a network was created based on human genes annotated by the IMEx database in Cytoscape to identify hubs and bottle-necks. Moreover, correlation networks were built in the Cluepedia plug-in. The networks were created separately for terms describing apoptosis and programmed cell death. We demonstrate that necroptosis (RIPK—dependent cell death pathway) is an alternative mechanism responsible for death of bovine granulosa and theca cells. We conclude that both apoptosis and necroptosis occur in the granulosa cells of dominant follicles undergoing luteinisation and in the theca cells from newly selected follicles.",2021-05-05,2021-06-05 21:09:36,,9,22,Int J Mol Sci,,PubMed Central,PMID:  PMCID: PMC8125194,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8125194/,,,,PMC:Query2
651,10.3390/jpm11040300,33919882,PMC8070774,A,Neo4j; COVID19,Neo4j; COVID19,"Chatterjee, Avishek; Nardi, Cosimo; Oberije, Cary; Lambin, Philippe",Knowledge Graphs for COVID-19: An Exploratory Review of the Current Landscape,2021,Journal of Personalized Medicine,,"Background: Searching through the COVID-19 research literature to gain actionable clinical insight is a formidable task, even for experts. The usefulness of this corpus in terms of improving patient care is tied to the ability to see the big picture that emerges when the studies are seen in conjunction rather than in isolation. When the answer to a search query requires linking together multiple pieces of information across documents, simple keyword searches are insufficient. To answer such complex information needs, an innovative artificial intelligence (AI) technology named a knowledge graph (KG) could prove to be effective. Methods: We conducted an exploratory literature review of KG applications in the context of COVID-19. The search term used was “covid-19 knowledge graph”. In addition to PubMed, the first five pages of search results for Google Scholar and Google were considered for inclusion. Google Scholar was used to include non-peer-reviewed or non-indexed articles such as pre-prints and conference proceedings. Google was used to identify companies or consortiums active in this domain that have not published any literature, peer-reviewed or otherwise. Results: Our search yielded 34 results on PubMed and 50 results each on Google and Google Scholar. We found KGs being used for facilitating literature search, drug repurposing, clinical trial mapping, and risk factor analysis. Conclusions: Our synopses of these works make a compelling case for the utility of this nascent field of research.",2021-04-14,2021-06-05 20:35:57; 2021-06-05 21:35:36; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,4,11,J Pers Med,Knowledge Graphs for COVID-19,PubMed Central,PMID: 33919882 PMCID: PMC8070774,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8070774/,,Neo4j; COVID19,Neo4j; COVID19,PMC:Query3; PMC:Neo4j; PMC:COVID19; PMC:Query2
652,10.3390/ma13183964,32906837,PMC7558572,A,,,"Fahimi, Ario; Zanoletti, Alessandra; Federici, Stefania; Assi, Ahmad; Bilo, Fabjola; Depero, Laura Eleonora; Bontempi, Elza",New Eco-Materials Derived from Waste for Emerging Pollutants Adsorption: The Case of Diclofenac,2020,"Materials (Basel, Switzerland)",,"This work proposes new eco-materials for the adsorption of diclofenac (DCF). The large consumption of this nonsteroidal anti-inflammatory drug combined with the inefficiency of wastewater treatment plants (WWTPs) leads to its presence in aquatic environments as an emerging pollutant. The adsorption technique is widely used for pharmaceutical removal. Moreover, due to the large effect of commercial adsorbents, in the frame of the Azure Chemistry approach, new sustainable materials are mandatory for removal as emerging pollutants. The work proposes three adsorbents that were obtained from different stabilization methods of fly ash derived from an incinerator plant; the stabilization techniques involved the use of various industrial by-products such as bottom ash, flue gas desulphurization residues, coal fly ash, and silica fume. The best performance, although less than activated carbon, was obtained by COSMOS (COlloidal Silica Medium to Obtain Safe inert: the case of incinerator fly ash), with a removal efficacy of approximately 76% with 15 g/L of material. Several advantages are expected not only from the DCF removal but also from an economic perspective (the newly obtained adsorbents are eco-materials, so they are cheaper in comparison to conventional adsorbents) and in terms of sustainability (no toxic reagents and no heating treatment are involved). This work highlights the adsorption performance of the new eco-materials and their potential use in WWTPs.",2020-09-07,2021-06-05 21:24:28; 2021-06-05 21:06:22,,18,13,Materials (Basel),New Eco-Materials Derived from Waste for Emerging Pollutants Adsorption,PubMed,PMID: 32906837 PMCID: PMC7558572,http://www.ncbi.nlm.nih.gov/pubmed/32906837,adsorption; diclofenac; eco-material; emerging pollutants; fly ash; sustainability; waste valorization,,,PubMed:Query3; PubMed:Query2
653,10.3390/metabo11020103,33670102,PMC7916825,A,Neo4j,Neo4j,"McLuskey, Karen; Wandy, Joe; Vincent, Isabel; van der Hooft, Justin J. J.; Rogers, Simon; Burgess, Karl; Daly, Rónán",Ranking Metabolite Sets by Their Activity Levels,2021,Metabolites,,"Related metabolites can be grouped into sets in many ways, e.g., by their participation in series of chemical reactions (forming metabolic pathways), or based on fragmentation spectral similarities or shared chemical substructures. Understanding how such metabolite sets change in relation to experimental factors can be incredibly useful in the interpretation and understanding of complex metabolomics data sets. However, many of the available tools that are used to perform this analysis are not entirely suitable for the analysis of untargeted metabolomics measurements. Here, we present PALS (Pathway Activity Level Scoring), a Python library, command line tool, and Web application that performs the ranking of significantly changing metabolite sets over different experimental conditions. The main algorithm in PALS is based on the pathway level analysis of gene expression (PLAGE) factorisation method and is denoted as mPLAGE (PLAGE for metabolomics). As an example of an application, PALS is used to analyse metabolites grouped as metabolic pathways and by shared tandem mass spectrometry fragmentation patterns. A comparison of mPLAGE with two other commonly used methods (overrepresentation analysis (ORA) and gene set enrichment analysis (GSEA)) is also given and reveals that mPLAGE is more robust to missing features and noisy data than the alternatives. As further examples, PALS is also applied to human African trypanosomiasis, Rhamnaceae, and American Gut Project data. In addition, normalisation can have a significant impact on pathway analysis results, and PALS offers a framework to further investigate this. PALS is freely available from our project Web site.",2021-02-11,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,2,11,Metabolites,,PubMed Central,PMID: 33670102 PMCID: PMC7916825,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7916825/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
654,10.3390/metabo9120308,31861212,PMC6950334,,,,"Ivanisevic, Julijana; Want, Elizabeth J.",From Samples to Insights into Metabolism: Uncovering Biologically Relevant Information in LC-HRMS Metabolomics Data,2019,Metabolites,,"Untargeted metabolomics (including lipidomics) is a holistic approach to biomarker discovery and mechanistic insights into disease onset and progression, and response to intervention. Each step of the analytical and statistical pipeline is crucial for the generation of high-quality, robust data. Metabolite identification remains the bottleneck in these studies; therefore, confidence in the data produced is paramount in order to maximize the biological output. Here, we outline the key steps of the metabolomics workflow and provide details on important parameters and considerations. Studies should be designed carefully to ensure appropriate statistical power and adequate controls. Subsequent sample handling and preparation should avoid the introduction of bias, which can significantly affect downstream data interpretation. It is not possible to cover the entire metabolome with a single platform; therefore, the analytical platform should reflect the biological sample under investigation and the question(s) under consideration. The large, complex datasets produced need to be pre-processed in order to extract meaningful information. Finally, the most time-consuming steps are metabolite identification, as well as metabolic pathway and network analysis. Here we discuss some widely used tools and the pitfalls of each step of the workflow, with the ultimate aim of guiding the reader towards the most efficient pipeline for their metabolomics studies.",2019-12-17,2021-06-05 21:10:37,,12,9,Metabolites,From Samples to Insights into Metabolism,PubMed Central,PMID: 31861212 PMCID: PMC6950334,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6950334/,,,,PMC:Query2
655,10.3390/molecules24081604,31018579,PMC6515292,,,,"Cooper, Daniel J.; Schürer, Stephan",Improving the Utility of the Tox21 Dataset by Deep Metadata Annotations and Constructing Reusable Benchmarked Chemical Reference Signatures,2019,Molecules,,"The Toxicology in the 21st Century (Tox21) project seeks to develop and test methods for high-throughput examination of the effect certain chemical compounds have on biological systems. Although primary and toxicity assay data were readily available for multiple reporter gene modified cell lines, extensive annotation and curation was required to improve these datasets with respect to how FAIR (Findable, Accessible, Interoperable, and Reusable) they are. In this study, we fully annotated the Tox21 published data with relevant and accepted controlled vocabularies. After removing unreliable data points, we aggregated the results and created three sets of signatures reflecting activity in the reporter gene assays, cytotoxicity, and selective reporter gene activity, respectively. We benchmarked these signatures using the chemical structures of the tested compounds and obtained generally high receiver operating characteristic (ROC) scores, suggesting good quality and utility of these signatures and the underlying data. We analyzed the results to identify promiscuous individual compounds and chemotypes for the three signature categories and interpreted the results to illustrate the utility and re-usability of the datasets. With this study, we aimed to demonstrate the importance of data standards in reporting screening results and high-quality annotations to enable re-use and interpretation of these data. To improve the data with respect to all FAIR criteria, all assay annotations, cleaned and aggregate datasets, and signatures were made available as standardized dataset packages (Aggregated Tox21 bioactivity data, 2019).",2019-04-23,2021-06-05 21:10:37,,8,24,Molecules,,PubMed Central,PMID: 31018579 PMCID: PMC6515292,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6515292/,,,,PMC:Query2
656,10.3390/molecules25184262,32957592,PMC7570653,,,,"Poitevin, Frédéric; Kushner, Artem; Li, Xinpei; Dao Duc, Khanh",Structural Heterogeneities of the Ribosome: New Frontiers and Opportunities for Cryo-EM,2020,Molecules,,"The extent of ribosomal heterogeneity has caught increasing interest over the past few years, as recent studies have highlighted the presence of structural variations of the ribosome. More precisely, the heterogeneity of the ribosome covers multiple scales, including the dynamical aspects of ribosomal motion at the single particle level, specialization at the cellular and subcellular scale, or evolutionary differences across species. Upon solving the ribosome atomic structure at medium to high resolution, cryogenic electron microscopy (cryo-EM) has enabled investigating all these forms of heterogeneity. In this review, we present some recent advances in quantifying ribosome heterogeneity, with a focus on the conformational and evolutionary variations of the ribosome and their functional implications. These efforts highlight the need for new computational methods and comparative tools, to comprehensively model the continuous conformational transition pathways of the ribosome, as well as its evolution. While developing these methods presents some important challenges, it also provides an opportunity to extend our interpretation and usage of cryo-EM data, which would more generally benefit the study of molecular dynamics and evolution of proteins and other complexes.",2020-09-17,2021-06-05 21:10:08,,18,25,Molecules,Structural Heterogeneities of the Ribosome,PubMed Central,PMID: 32957592 PMCID: PMC7570653,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7570653/,,,,PMC:Query2
657,10.3390/s120505502,22778598,PMC3386697,,,,"Páez, Diego Gachet; Aparicio, Fernando; de Buenaga, Manuel; Padrón, Víctor",Personalized Health Care System with Virtual Reality Rehabilitation and Appropriate Information for Seniors,2012,"Sensors (Basel, Switzerland)",,"The concept of the information society is now a common one, as opposed to the industrial society that dominated the economy during the last years. It is assumed that all sectors should have access to information and reap its benefits. Elderly people are, in this respect, a major challenge, due to their lack of interest in technological progress and their lack of knowledge regarding the potential benefits that information society technologies might have on their lives. The Naviga Project (An Open and Adaptable Platform for the Elderly and Persons with Disability to Access the Information Society) is a European effort, whose main goal is to design and develop a technological platform allowing elder people and persons with disability to access the internet and the information society. Naviga also allows the creation of services targeted to social networks, mind training and personalized health care. In this paper we focus on the health care and information services designed on the project, the technological platform developed and details of two representative elements, the virtual reality hand rehabilitation and the health information intelligent system.",2012-04-30,2021-06-05 21:13:27,5502-5516,5,12,Sensors (Basel),,PubMed Central,PMID: 22778598 PMCID: PMC3386697,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3386697/,,,,PMC:Query2
658,10.3390/s150305032,25738763,PMC4435204,,,,"Qian, Jiuchao; Pei, Ling; Ma, Jiabin; Ying, Rendong; Liu, Peilin",Vector Graph Assisted Pedestrian Dead Reckoning Using an Unconstrained Smartphone,2015,"Sensors (Basel, Switzerland)",,"The paper presents a hybrid indoor positioning solution based on a pedestrian dead reckoning (PDR) approach using built-in sensors on a smartphone. To address the challenges of flexible and complex contexts of carrying a phone while walking, a robust step detection algorithm based on motion-awareness has been proposed. Given the fact that step length is influenced by different motion states, an adaptive step length estimation algorithm based on motion recognition is developed. Heading estimation is carried out by an attitude acquisition algorithm, which contains a two-phase filter to mitigate the distortion of magnetic anomalies. In order to estimate the heading for an unconstrained smartphone, principal component analysis (PCA) of acceleration is applied to determine the offset between the orientation of smartphone and the actual heading of a pedestrian. Moreover, a particle filter with vector graph assisted particle weighting is introduced to correct the deviation in step length and heading estimation. Extensive field tests, including four contexts of carrying a phone, have been conducted in an office building to verify the performance of the proposed algorithm. Test results show that the proposed algorithm can achieve sub-meter mean error in all contexts.",2015-03-02,2021-06-05 21:12:40,5032-5057,3,15,Sensors (Basel),,PubMed Central,PMID: 25738763 PMCID: PMC4435204,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4435204/,,,,PMC:Query2
659,10.3390/s150924054,26393609,PMC4610558,,,,"Kibria, Muhammad Golam; Fattah, Sheik Mohammad Mostakim; Jeong, Kwanghyeon; Chong, Ilyoung; Jeong, Youn-Kwae",A User-Centric Knowledge Creation Model in a Web of Object-Enabled Internet of Things Environment,2015,"Sensors (Basel, Switzerland)",,"User-centric service features in a Web of Object-enabled Internet of Things environment can be provided by using a semantic ontology that classifies and integrates objects on the World Wide Web as well as shares and merges context-aware information and accumulated knowledge. The semantic ontology is applied on a Web of Object platform to virtualize the real world physical devices and information to form virtual objects that represent the features and capabilities of devices in the virtual world. Detailed information and functionalities of multiple virtual objects are combined with service rules to form composite virtual objects that offer context-aware knowledge-based services, where context awareness plays an important role in enabling automatic modification of the system to reconfigure the services based on the context. Converting the raw data into meaningful information and connecting the information to form the knowledge and storing and reusing the objects in the knowledge base can both be expressed by semantic ontology. In this paper, a knowledge creation model that synchronizes a service logistic model and a virtual world knowledge model on a Web of Object platform has been proposed. To realize the context-aware knowledge-based service creation and execution, a conceptual semantic ontology model has been developed and a prototype has been implemented for a use case scenario of emergency service.",2015-09-18,2021-06-05 21:12:40,24054-24086,9,15,Sensors (Basel),,PubMed Central,PMID: 26393609 PMCID: PMC4610558,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4610558/,,,,PMC:Query2
660,10.3390/s16050600,27128918,PMC4883291,A,Virtuoso,Virtuoso,"Zhou, Yuchao; De, Suparna; Wang, Wei; Moessner, Klaus",Search Techniques for the Web of Things: A Taxonomy and Survey,2016,"Sensors (Basel, Switzerland)",,"The Web of Things aims to make physical world objects and their data accessible through standard Web technologies to enable intelligent applications and sophisticated data analytics. Due to the amount and heterogeneity of the data, it is challenging to perform data analysis directly; especially when the data is captured from a large number of distributed sources. However, the size and scope of the data can be reduced and narrowed down with search techniques, so that only the most relevant and useful data items are selected according to the application requirements. Search is fundamental to the Web of Things while challenging by nature in this context, e.g., mobility of the objects, opportunistic presence and sensing, continuous data streams with changing spatial and temporal properties, efficient indexing for historical and real time data. The research community has developed numerous techniques and methods to tackle these problems as reported by a large body of literature in the last few years. A comprehensive investigation of the current and past studies is necessary to gain a clear view of the research landscape and to identify promising future directions. This survey reviews the state-of-the-art search methods for the Web of Things, which are classified according to three different viewpoints: basic principles, data/knowledge representation, and contents being searched. Experiences and lessons learned from the existing work and some EU research projects related to Web of Things are discussed, and an outlook to the future research is presented.",2016-04-27,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:59:14,,5,16,Sensors (Basel),Search Techniques for the Web of Things,PubMed Central,PMID: 27128918 PMCID: PMC4883291,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4883291/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
661,10.3390/s16071053,27399717,PMC4970100,A,Virtuoso,Virtuoso,"Yoo, Min-Jung; Grozel, Clément; Kiritsis, Dimitris",Closed-Loop Lifecycle Management of Service and Product in the Internet of Things: Semantic Framework for Knowledge Integration,2016,"Sensors (Basel, Switzerland)",,"This paper describes our conceptual framework of closed-loop lifecycle information sharing for product-service in the Internet of Things (IoT). The framework is based on the ontology model of product-service and a type of IoT message standard, Open Messaging Interface (O-MI) and Open Data Format (O-DF), which ensures data communication. (1) Background: Based on an existing product lifecycle management (PLM) methodology, we enhanced the ontology model for the purpose of integrating efficiently the product-service ontology model that was newly developed; (2) Methods: The IoT message transfer layer is vertically integrated into a semantic knowledge framework inside which a Semantic Info-Node Agent (SINA) uses the message format as a common protocol of product-service lifecycle data transfer; (3) Results: The product-service ontology model facilitates information retrieval and knowledge extraction during the product lifecycle, while making more information available for the sake of service business creation. The vertical integration of IoT message transfer, encompassing all semantic layers, helps achieve a more flexible and modular approach to knowledge sharing in an IoT environment; (4) Contribution: A semantic data annotation applied to IoT can contribute to enhancing collected data types, which entails a richer knowledge extraction. The ontology-based PLM model enables as well the horizontal integration of heterogeneous PLM data while breaking traditional vertical information silos; (5) Conclusion: The framework was applied to a fictive case study with an electric car service for the purpose of demonstration. For the purpose of demonstrating the feasibility of the approach, the semantic model is implemented in Sesame APIs, which play the role of an Internet-connected Resource Description Framework (RDF) database.",2016-07-08,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:59:14,,7,16,Sensors (Basel),Closed-Loop Lifecycle Management of Service and Product in the Internet of Things,PubMed Central,PMID: 27399717 PMCID: PMC4970100,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4970100/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
662,10.3390/s16091510,27649192,PMC5038783,,,,"Basiri, Anahid; Amirian, Pouria; Mooney, Peter",Using Crowdsourced Trajectories for Automated OSM Data Entry Approach,2016,"Sensors (Basel, Switzerland)",,"The concept of crowdsourcing is nowadays extensively used to refer to the collection of data and the generation of information by large groups of users/contributors. OpenStreetMap (OSM) is a very successful example of a crowd-sourced geospatial data project. Unfortunately, it is often the case that OSM contributor inputs (including geometry and attribute data inserts, deletions and updates) have been found to be inaccurate, incomplete, inconsistent or vague. This is due to several reasons which include: (1) many contributors with little experience or training in mapping and Geographic Information Systems (GIS); (2) not enough contributors familiar with the areas being mapped; (3) contributors having different interpretations of the attributes (tags) for specific features; (4) different levels of enthusiasm between mappers resulting in different number of tags for similar features and (5) the user-friendliness of the online user-interface where the underlying map can be viewed and edited. This paper suggests an automatic mechanism, which uses raw spatial data (trajectories of movements contributed by contributors to OSM) to minimise the uncertainty and impact of the above-mentioned issues. This approach takes the raw trajectory datasets as input and analyses them using data mining techniques. In addition, we extract some patterns and rules about the geometry and attributes of the recognised features for the purpose of insertion or editing of features in the OSM database. The underlying idea is that certain characteristics of user trajectories are directly linked to the geometry and the attributes of geographic features. Using these rules successfully results in the generation of new features with higher spatial quality which are subsequently automatically inserted into the OSM database.",2016-09-15,2021-06-05 21:12:01,,9,16,Sensors (Basel),,PubMed Central,PMID: 27649192 PMCID: PMC5038783,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5038783/,,,,PMC:Query2
663,10.3390/s16111884,27834862,PMC5134543,,,,"Jayaraman, Prem Prakash; Yavari, Ali; Georgakopoulos, Dimitrios; Morshed, Ahsan; Zaslavsky, Arkady",Internet of Things Platform for Smart Farming: Experiences and Lessons Learnt,2016,"Sensors (Basel, Switzerland)",,"Improving farm productivity is essential for increasing farm profitability and meeting the rapidly growing demand for food that is fuelled by rapid population growth across the world. Farm productivity can be increased by understanding and forecasting crop performance in a variety of environmental conditions. Crop recommendation is currently based on data collected in field-based agricultural studies that capture crop performance under a variety of conditions (e.g., soil quality and environmental conditions). However, crop performance data collection is currently slow, as such crop studies are often undertaken in remote and distributed locations, and such data are typically collected manually. Furthermore, the quality of manually collected crop performance data is very low, because it does not take into account earlier conditions that have not been observed by the human operators but is essential to filter out collected data that will lead to invalid conclusions (e.g., solar radiation readings in the afternoon after even a short rain or overcast in the morning are invalid, and should not be used in assessing crop performance). Emerging Internet of Things (IoT) technologies, such as IoT devices (e.g., wireless sensor networks, network-connected weather stations, cameras, and smart phones) can be used to collate vast amount of environmental and crop performance data, ranging from time series data from sensors, to spatial data from cameras, to human observations collected and recorded via mobile smart phone applications. Such data can then be analysed to filter out invalid data and compute personalised crop recommendations for any specific farm. In this paper, we present the design of SmartFarmNet, an IoT-based platform that can automate the collection of environmental, soil, fertilisation, and irrigation data; automatically correlate such data and filter-out invalid data from the perspective of assessing crop performance; and compute crop forecasts and personalised crop recommendations for any particular farm. SmartFarmNet can integrate virtually any IoT device, including commercially available sensors, cameras, weather stations, etc., and store their data in the cloud for performance analysis and recommendations. An evaluation of the SmartFarmNet platform and our experiences and lessons learnt in developing this system concludes the paper. SmartFarmNet is the first and currently largest system in the world (in terms of the number of sensors attached, crops assessed, and users it supports) that provides crop performance analysis and recommendations.",2016-11-09,2021-06-05 21:12:01,,11,16,Sensors (Basel),Internet of Things Platform for Smart Farming,PubMed Central,PMID: 27834862 PMCID: PMC5134543,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5134543/,,,,PMC:Query2
664,10.3390/s17020403,28230725,PMC5335945,A,Neo4j,Neo4j,"Wu, Zhenyu; Xu, Yuan; Yang, Yunong; Zhang, Chunhong; Zhu, Xinning; Ji, Yang","Towards a Semantic Web of Things: A Hybrid Semantic Annotation, Extraction, and Reasoning Framework for Cyber-Physical System",2017,"Sensors (Basel, Switzerland)",,"Web of Things (WoT) facilitates the discovery and interoperability of Internet of Things (IoT) devices in a cyber-physical system (CPS). Moreover, a uniform knowledge representation of physical resources is quite necessary for further composition, collaboration, and decision-making process in CPS. Though several efforts have integrated semantics with WoT, such as knowledge engineering methods based on semantic sensor networks (SSN), it still could not represent the complex relationships between devices when dynamic composition and collaboration occur, and it totally depends on manual construction of a knowledge base with low scalability. In this paper, to addresses these limitations, we propose the semantic Web of Things (SWoT) framework for CPS (SWoT4CPS). SWoT4CPS provides a hybrid solution with both ontological engineering methods by extending SSN and machine learning methods based on an entity linking (EL) model. To testify to the feasibility and performance, we demonstrate the framework by implementing a temperature anomaly diagnosis and automatic control use case in a building automation system. Evaluation results on the EL method show that linking domain knowledge to DBpedia has a relative high accuracy and the time complexity is at a tolerant level. Advantages and disadvantages of SWoT4CPS with future work are also discussed.",2017-02-20,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:37:08,,2,17,Sensors (Basel),Towards a Semantic Web of Things,PubMed Central,PMID: 28230725 PMCID: PMC5335945,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5335945/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
665,10.3390/s17050977,28448469,PMC5464689,,,,"Cruz Huacarpuma, Ruben; de Sousa Junior, Rafael Timoteo; de Holanda, Maristela Terto; de Oliveira Albuquerque, Robson; García Villalba, Luis Javier; Kim, Tai-Hoon",Distributed Data Service for Data Management in Internet of Things Middleware,2017,"Sensors (Basel, Switzerland)",,"The development of the Internet of Things (IoT) is closely related to a considerable increase in the number and variety of devices connected to the Internet. Sensors have become a regular component of our environment, as well as smart phones and other devices that continuously collect data about our lives even without our intervention. With such connected devices, a broad range of applications has been developed and deployed, including those dealing with massive volumes of data. In this paper, we introduce a Distributed Data Service (DDS) to collect and process data for IoT environments. One central goal of this DDS is to enable multiple and distinct IoT middleware systems to share common data services from a loosely-coupled provider. In this context, we propose a new specification of functionalities for a DDS and the conception of the corresponding techniques for collecting, filtering and storing data conveniently and efficiently in this environment. Another contribution is a data aggregation component that is proposed to support efficient real-time data querying. To validate its data collecting and querying functionalities and performance, the proposed DDS is evaluated in two case studies regarding a simulated smart home system, the first case devoted to evaluating data collection and aggregation when the DDS is interacting with the UIoT middleware, and the second aimed at comparing the DDS data collection with this same functionality implemented within the Kaa middleware.",2017-04-27,2021-06-05 21:12:01,,5,17,Sensors (Basel),,PubMed Central,PMID: 28448469 PMCID: PMC5464689,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5464689/,,,,PMC:Query2
666,10.3390/s17102180,28937590,PMC5677453,,,,"Kibria, Muhammad Golam; Ali, Sajjad; Jarwar, Muhammad Aslam; Kumar, Sunil; Chong, Ilyoung",Logistic Model to Support Service Modularity for the Promotion of Reusability in a Web Objects-Enabled IoT Environment,2017,"Sensors (Basel, Switzerland)",,"Due to a very large number of connected virtual objects in the surrounding environment, intelligent service features in the Internet of Things requires the reuse of existing virtual objects and composite virtual objects. If a new virtual object is created for each new service request, then the number of virtual object would increase exponentially. The Web of Objects applies the principle of service modularity in terms of virtual objects and composite virtual objects. Service modularity is a key concept in the Web Objects-Enabled Internet of Things (IoT) environment which allows for the reuse of existing virtual objects and composite virtual objects in heterogeneous ontologies. In the case of similar service requests occurring at the same, or different locations, the already-instantiated virtual objects and their composites that exist in the same, or different ontologies can be reused. In this case, similar types of virtual objects and composite virtual objects are searched and matched. Their reuse avoids duplication under similar circumstances, and reduces the time it takes to search and instantiate them from their repositories, where similar functionalities are provided by similar types of virtual objects and their composites. Controlling and maintaining a virtual object means controlling and maintaining a real-world object in the real world. Even though the functional costs of virtual objects are just a fraction of those for deploying and maintaining real-world objects, this article focuses on reusing virtual objects and composite virtual objects, as well as discusses similarity matching of virtual objects and composite virtual objects. This article proposes a logistic model that supports service modularity for the promotion of reusability in the Web Objects-enabled IoT environment. Necessary functional components and a flowchart of an algorithm for reusing composite virtual objects are discussed. Also, to realize the service modularity, a use case scenario is studied and implemented.",2017-09-22,2021-06-05 21:12:01,,10,17,Sensors (Basel),,PubMed Central,PMID: 28937590 PMCID: PMC5677453,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5677453/,,,,PMC:Query2
667,10.3390/s18040965,29587366,PMC5948496,A,Neo4j,Neo4j,"Murdani, Muhammad Harist; Kwon, Joonho; Choi, Yoon-Ho; Hong, Bonghee",Efficient Proximity Computation Techniques Using ZIP Code Data for Smart Cities,2018,"Sensors (Basel, Switzerland)",,"In this paper, we are interested in computing ZIP code proximity from two perspectives, proximity between two ZIP codes (Ad-Hoc) and neighborhood proximity (Top-K). Such a computation can be used for ZIP code-based target marketing as one of the smart city applications. A naïve approach to this computation is the usage of the distance between ZIP codes. We redefine a distance metric combining the centroid distance with the intersecting road network between ZIP codes by using a weighted sum method. Furthermore, we prove that the results of our combined approach conform to the characteristics of distance measurement. We have proposed a general and heuristic approach for computing Ad-Hoc proximity, while for computing Top-K proximity, we have proposed a general approach only. Our experimental results indicate that our approaches are verifiable and effective in reducing the execution time and search space.",2018-03-24,2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:36:32,,4,18,Sensors (Basel),,PubMed Central,PMID: 29587366 PMCID: PMC5948496,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5948496/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
668,10.3390/s18114020,30453676,PMC6263475,,,,"Bok, Kyoungsoo; Jeong, Jaeyun; Choi, Dojin; Yoo, Jaesoo",Detecting Incremental Frequent Subgraph Patterns in IoT Environments,2018,"Sensors (Basel, Switzerland)",,"As graph stream data are continuously generated in Internet of Things (IoT) environments, many studies on the detection and analysis of changes in graphs have been conducted. In this paper, we propose a method that incrementally detects frequent subgraph patterns by using frequent subgraph pattern information generated in previous sliding window. To reduce the computation cost for subgraph patterns that occur consecutively in a graph stream, the proposed method determines whether subgraph patterns occur within a sliding window. In addition, subgraph patterns that are more meaningful can be detected by recognizing only the patterns that are connected to each other via edges as one pattern. In order to prove the superiority of the proposed method, various performance evaluations were conducted.",2018-11-18,2021-06-05 21:10:37,,11,18,Sensors (Basel),,PubMed Central,PMID: 30453676 PMCID: PMC6263475,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6263475/,,,,PMC:Query2
669,10.3390/s18114029,30463199,PMC6263431,A,OrientDB,OrientDB,"Wu, Jiaxuan; Feng, Yunfei; Sun, Peng",Sensor Fusion for Recognition of Activities of Daily Living,2018,"Sensors (Basel, Switzerland)",,"Activity of daily living (ADL) is a significant predictor of the independence and functional capabilities of an individual. Measurements of ADLs help to indicate one’s health status and capabilities of quality living. Recently, the most common ways to capture ADL data are far from automation, including a costly 24/7 observation by a designated caregiver, self-reporting by the user laboriously, or filling out a written ADL survey. Fortunately, ubiquitous sensors exist in our surroundings and on electronic devices in the Internet of Things (IoT) era. We proposed the ADL Recognition System that utilizes the sensor data from a single point of contact, such as smartphones, and conducts time-series sensor fusion processing. Raw data is collected from the ADL Recorder App constantly running on a user’s smartphone with multiple embedded sensors, including the microphone, Wi-Fi scan module, heading orientation of the device, light proximity, step detector, accelerometer, gyroscope, magnetometer, etc. Key technologies in this research cover audio processing, Wi-Fi indoor positioning, proximity sensing localization, and time-series sensor data fusion. By merging the information of multiple sensors, with a time-series error correction technique, the ADL Recognition System is able to accurately profile a person’s ADLs and discover his life patterns. This paper is particularly concerned with the care for the older adults who live independently.",2018-11-19,2021-06-06 06:49:06; 2021-06-05 20:55:01; 2021-06-05 21:10:37,,11,18,Sensors (Basel),,PubMed Central,PMID: 30463199 PMCID: PMC6263431,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6263431/,,OrientDB,OrientDB,PMC:Query3; PMC:Query2; PMC:OrientDB
670,10.3390/s18124486,30567395,PMC6308571,,,,"Li, Mohan; Sun, Yanbin; Jiang, Yu; Tian, Zhihong",Answering the Min-Cost Quality-Aware Query on Multi-Sources in Sensor-Cloud Systems,2018,"Sensors (Basel, Switzerland)",,"In sensor-based systems, the data of an object is often provided by multiple sources. Since the data quality of these sources might be different, when querying the observations, it is necessary to carefully select the sources to make sure that high quality data is accessed. A solution is to perform a quality evaluation in the cloud and select a set of high-quality, low-cost data sources (i.e., sensors or small sensor networks) that can answer queries. This paper studies the problem of min-cost quality-aware query which aims to find high quality results from multi-sources with the minimized cost. The measurement of the query results is provided, and two methods for answering min-cost quality-aware query are proposed. How to get a reasonable parameter setting is also discussed. Experiments on real-life data verify that the proposed techniques are efficient and effective.",2018-12-18,2021-06-05 21:10:37,,12,18,Sensors (Basel),,PubMed Central,PMID: 30567395 PMCID: PMC6308571,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6308571/,,,,PMC:Query2
671,10.3390/s19040869,30791498,PMC6412853,,,,"Lanza, Jorge; Sánchez, Luis; Gómez, David; Santana, Juan Ramón; Sotres, Pablo",A Semantic-Enabled Platform for Realizing an Interoperable Web of Things,2019,"Sensors (Basel, Switzerland)",,"Nowadays, the Internet of Things (IoT) ecosystem is experiencing a lack of interoperability across the multiple competing platforms that are available. Consequently, service providers can only access vertical data silos that imply high costs and jeopardize their solutions market potential. It is necessary to transform the current situation with competing non-interoperable IoT platforms into a common ecosystem enabling the emergence of cross-platform, cross-standard, and cross-domain IoT services and applications. This paper presents a platform that has been implemented for realizing this vision. It leverages semantic web technologies to address the two key challenges in expanding the IoT beyond product silos into web-scale open ecosystems: data interoperability and resources identification and discovery. The paper provides extensive description of the proposed solution and its implementation details. Regarding the implementation details, it is important to highlight that the platform described in this paper is currently supporting the federation of eleven IoT deployments (from heterogeneous application domains) with over 10,000 IoT devices overall which produce hundreds of thousands of observations per day.",2019-02-19,2021-06-05 21:10:37,,4,19,Sensors (Basel),,PubMed Central,PMID: 30791498 PMCID: PMC6412853,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6412853/,,,,PMC:Query2
672,10.3390/s19071565,30939722,PMC6480280,,,,"Kim, Beom-Su; Kim, Ki-Il; Shah, Babar; Chow, Francis; Kim, Kyong Hoon",Wireless Sensor Networks for Big Data Systems,2019,"Sensors (Basel, Switzerland)",,"Before discovering meaningful knowledge from big data systems, it is first necessary to build a data-gathering infrastructure. Among many feasible data sources, wireless sensor networks (WSNs) are rich big data sources: a large amount of data is generated by various sensor nodes in large-scale networks. However, unlike typical wireless networks, WSNs have serious deficiencies in terms of data reliability and communication owing to the limited capabilities of the nodes. Moreover, a considerable amount of sensed data are of no interest, meaningless, and redundant when a large number of sensor nodes is densely deployed. Many studies address the existing problems and propose methods to overcome the limitations when constructing big data systems with WSN. However, a published paper that provides deep insight into this research area remains lacking. To address this gap in the literature, we present a comprehensive survey that investigates state-of-the-art research work on introducing WSN in big data systems. Potential applications and technical challenges of networks and infrastructure are presented and explained in accordance with the research areas and objectives. Finally, open issues are presented to discuss promising directions for further research.",2019-04-01,2021-06-05 21:10:37,,7,19,Sensors (Basel),,PubMed Central,PMID: 30939722 PMCID: PMC6480280,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6480280/,,,,PMC:Query2
673,10.3390/s19132956,31277486,PMC6650851,A,Neo4j,Neo4j,"Lo Giudice, Paolo; Nocera, Antonino; Ursino, Domenico; Virgili, Luca",Building Topic-Driven Virtual IoTs in a Multiple IoTs Scenario,2019,"Sensors (Basel, Switzerland)",,"In the last years, several attempts to combine the Internet of Things (IoT) and social networking have been made. In the meantime, things involved in IoT are becoming increasingly sophisticated and intelligent, showing a behavior that tends to look like the one of users in social networks. Therefore, it is not out of place to talk about profiles of things and about information and topics exchanged among them. In such a context, constructing topic-driven virtual communities starting from the real ones operating in a Multi-IoT scenario is an extremely challenging issue. This paper aims at providing some contributions in this setting. First of all, it presents the concept of profile of a thing. Then, it introduces the concept of topic-guided virtual IoT. Finally, it illustrates two approaches (one supervised and one unsupervised) to constructing topic-guided virtual IoTs in a Multi-IoT scenario.",2019-07-04,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,,13,19,Sensors (Basel),,PubMed Central,PMID: 31277486 PMCID: PMC6650851,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6650851/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
674,10.3390/s19183987,31540187,PMC6767246,A,Neo4j,Neo4j,"Villalba-Diez, Javier; Schmidt, Daniel; Gevers, Roman; Ordieres-Meré, Joaquín; Buchwitz, Martin; Wellbrock, Wanja",Deep Learning for Industrial Computer Vision Quality Control in the Printing Industry 4.0,2019,"Sensors (Basel, Switzerland)",,"Rapid and accurate industrial inspection to ensure the highest quality standards at a competitive price is one of the biggest challenges in the manufacturing industry. This paper shows an application of how a Deep Learning soft sensor application can be combined with a high-resolution optical quality control camera to increase the accuracy and reduce the cost of an industrial visual inspection process in the Printing Industry 4.0. During the process of producing gravure cylinders, mistakes like holes in the printing cylinder are inevitable. In order to improve the defect detection performance and reduce quality inspection costs by process automation, this paper proposes a deep neural network (DNN) soft sensor that compares the scanned surface to the used engraving file and performs an automatic quality control process by learning features through exposure to training data. The DNN sensor developed achieved a fully automated classification accuracy rate of 98.4%. Further research aims to use these results to three ends. Firstly, to predict the amount of errors a cylinder has, to further support the human operation by showing the error probability to the operator, and finally to decide autonomously about product quality without human involvement.",2019-09-15,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,,18,19,Sensors (Basel),,PubMed Central,PMID: 31540187 PMCID: PMC6767246,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6767246/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
675,10.3390/s19204362,31600957,PMC6832792,A,Virtuoso; Neo4j; AllegroGraph,Virtuoso; Neo4j; AllegroGraph,"Nguyen Mau Quoc, Hoan; Serrano, Martin; Mau Nguyen, Han; G. Breslin, John; Le-Phuoc, Danh",EAGLE—A Scalable Query Processing Engine for Linked Sensor Data,2019,"Sensors (Basel, Switzerland)",,"Recently, many approaches have been proposed to manage sensor data using semantic web technologies for effective heterogeneous data integration. However, our empirical observations revealed that these solutions primarily focused on semantic relationships and unfortunately paid less attention to spatio–temporal correlations. Most semantic approaches do not have spatio–temporal support. Some of them have attempted to provide full spatio–temporal support, but have poor performance for complex spatio–temporal aggregate queries. In addition, while the volume of sensor data is rapidly growing, the challenge of querying and managing the massive volumes of data generated by sensing devices still remains unsolved. In this article, we introduce EAGLE, a spatio–temporal query engine for querying sensor data based on the linked data model. The ultimate goal of EAGLE is to provide an elastic and scalable system which allows fast searching and analysis with respect to the relationships of space, time and semantics in sensor data. We also extend SPARQL with a set of new query operators in order to support spatio–temporal computing in the linked sensor data context.",2019-10-09,2021-06-06 06:38:41; 2021-06-05 20:59:14; 2021-06-05 21:10:37; 2021-06-05 20:55:01; 2021-06-05 20:36:32,,20,19,Sensors (Basel),,PubMed Central,PMID: 31600957 PMCID: PMC6832792,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6832792/,,Virtuoso; Neo4j; AllegroGraph,Virtuoso; Neo4j; AllegroGraph,PMC:AllegroGraph; PMC:Query2; PMC:Query3; PMC:Neo4j; PMC:Virtuoso
676,10.3390/s19224855,31703427,PMC6891746,,,,"Zhou, Bin; Duan, Xuemei; Ye, Dongjun; Wei, Wei; Woźniak, Marcin; Połap, Dawid; Damaševičius, Robertas",Multi-Level Features Extraction for Discontinuous Target Tracking in Remote Sensing Image Monitoring,2019,"Sensors (Basel, Switzerland)",,"Many techniques have been developed for computer vision in the past years. Features extraction and matching are the basis of many high-level applications. In this paper, we propose a multi-level features extraction for discontinuous target tracking in remote sensing image monitoring. The features of the reference image are pre-extracted at different levels. The first-level features are used to roughly check the candidate targets and other levels are used for refined matching. With Gaussian weight function introduced, the support of matching features is accumulated to make a final decision. Adaptive neighborhood and principal component analysis are used to improve the description of the feature. Experimental results verify the efficiency and accuracy of the proposed method.",2019-11-07,2021-06-05 21:10:37,,22,19,Sensors (Basel),,PubMed Central,PMID: 31703427 PMCID: PMC6891746,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6891746/,,,,PMC:Query2
677,10.3390/s20030763,32019148,PMC7038400,A,Neo4j,Neo4j,"Villalba-Díez, Javier; Molina, Martin; Ordieres-Meré, Joaquín; Sun, Shengjing; Schmidt, Daniel; Wellbrock, Wanja",Geometric Deep Lean Learning: Deep Learning in Industry 4.0 Cyber–Physical Complex Networks,2020,"Sensors (Basel, Switzerland)",,"In the near future, value streams associated with Industry 4.0 will be formed by interconnected cyber–physical elements forming complex networks that generate huge amounts of data in real time. The success or failure of industry leaders interested in the continuous improvement of lean management systems in this context is determined by their ability to recognize behavioral patterns in these big data structured within non-Euclidean domains, such as these dynamic sociotechnical complex networks. We assume that artificial intelligence in general and deep learning in particular may be able to help find useful patterns of behavior in 4.0 industrial environments in the lean management of cyber–physical systems. However, although these technologies have meant a paradigm shift in the resolution of complex problems in the past, the traditional methods of deep learning, focused on image or video analysis, both with regular structures, are not able to help in this specific field. This is why this work focuses on proposing geometric deep lean learning, a mathematical methodology that describes deep-lean-learning operations such as convolution and pooling on cyber–physical Industry 4.0 graphs. Geometric deep lean learning is expected to positively support sustainable organizational growth because customers and suppliers ought to be able to reach new levels of transparency and traceability on the quality and efficiency of processes that generate new business for both, hence generating new products, services, and cooperation opportunities in a cyber–physical environment.",2020-01-30,2021-06-05 20:35:57; 2021-06-05 20:55:01; 2021-06-05 21:10:08,,3,20,Sensors (Basel),Geometric Deep Lean Learning,PubMed Central,PMID: 32019148 PMCID: PMC7038400,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7038400/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
678,10.3390/s20030822,32033027,PMC7038691,A,GraphDB,GraphDB,"Cimmino, Andrea; Poveda-Villalón, María; García-Castro, Raúl",eWoT: A Semantic Interoperability Approach for Heterogeneous IoT Ecosystems Based on the Web of Things,2020,"Sensors (Basel, Switzerland)",,"With the constant growth of Internet of Things (IoT) ecosystems, allowing them to interact transparently has become a major issue for both the research and the software development communities. In this paper we propose a novel approach that builds semantically interoperable ecosystems of IoT devices. The approach provides a SPARQL query-based mechanism to transparently discover and access IoT devices that publish heterogeneous data. The approach was evaluated in order to prove that it provides complete and correct answers without affecting the response time and that it scales linearly in large ecosystems.",2020-02-04,2021-06-05 20:55:01; 2021-06-06 06:54:16; 2021-06-05 21:10:08,,3,20,Sensors (Basel),eWoT,PubMed Central,PMID: 32033027 PMCID: PMC7038691,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7038691/,,GraphDB,GraphDB,PMC:Query3; PMC:GraphDB; PMC:Query2
679,10.3390/s20102788,32422961,PMC7284853,A,Virtuoso,Virtuoso,"Le-Tuan, Anh; Hayes, Conor; Hauswirth, Manfred; Le-Phuoc, Danh",Pushing the Scalability of RDF Engines on IoT Edge Devices,2020,"Sensors (Basel, Switzerland)",,"Semantic interoperability for the Internet of Things (IoT) is enabled by standards and technologies from the Semantic Web. As recent research suggests a move towards decentralised IoT architectures, we have investigated the scalability and robustness of RDF (Resource Description Framework)engines that can be embedded throughout the architecture, in particular at edge nodes. RDF processing at the edge facilitates the deployment of semantic integration gateways closer to low-level devices. Our focus is on how to enable scalable and robust RDF engines that can operate on lightweight devices. In this paper, we have first carried out an empirical study of the scalability and behaviour of solutions for RDF data management on standard computing hardware that have been ported to run on lightweight devices at the network edge. The findings of our study shows that these RDF store solutions have several shortcomings on commodity ARM (Advanced RISC Machine) boards that are representative of IoT edge node hardware. Consequently, this has inspired us to introduce a lightweight RDF engine, which comprises an RDF storage and a SPARQL processor for lightweight edge devices, called RDF4Led. RDF4Led follows the RISC-style (Reduce Instruction Set Computer) design philosophy. The design constitutes a flash-aware storage structure, an indexing scheme, an alternative buffer management technique and a low-memory-footprint join algorithm that demonstrates improved scalability and robustness over competing solutions. With a significantly smaller memory footprint, we show that RDF4Led can handle 2 to 5 times more data than popular RDF engines such as Jena TDB (Tuple Database) and RDF4J, while consuming the same amount of memory. In particular, RDF4Led requires 10%–30% memory of its competitors to operate on datasets of up to 50 million triples. On memory-constrained ARM boards, it can perform faster updates and can scale better than Jena TDB and Virtuoso. Furthermore, we demonstrate considerably faster query operations than Jena TDB and RDF4J.",2020-05-14,2021-06-05 21:10:08; 2021-06-05 20:54:31; 2021-06-05 20:59:14,,10,20,Sensors (Basel),,PubMed Central,PMID: 32422961 PMCID: PMC7284853,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7284853/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
680,10.3390/s20102899,32443807,PMC7287682,A,Neo4j,Neo4j,"Velásquez, Washington; Alvarez-Alvarado, Manuel S.; Munoz-Arcentales, Andres; López-Pernas, Sonsoles; Salvachúa, Joaquín",Body Mass Index in Human Gait for Building Risk Assessment Using Graph Theory,2020,"Sensors (Basel, Switzerland)",,"This article presents a comprehensive study of human physiology to determine the impact of body mass index (BMI) on human gait. The approach followed in this study consists of a mathematical model based on the centre of mass of the human body, the inertia of a person in motion and the human gait speed. Moreover, the study includes the representation of a building using graph theory and emulates the presence of a person inside the building when an emergency takes place. The optimal evacuation route is obtained using the breadth-first search (BFS) algorithm, and the evacuation time prediction is calculated using a Gaussian process model. Then, the risk of the building is quantified by using a non-sequential Monte Carlo simulation. The results open up a new horizon for developing a more realistic model for the assessment of civil safety.",2020-05-20,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,,10,20,Sensors (Basel),,PubMed Central,PMID: 32443807 PMCID: PMC7287682,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7287682/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
681,10.3390/s20113166,32503145,PMC7308861,A,Neo4j,Neo4j,"Akanbi, Adeyinka; Masinde, Muthoni",A Distributed Stream Processing Middleware Framework for Real-Time Analysis of Heterogeneous Data on Big Data Platform: Case of Environmental Monitoring,2020,"Sensors (Basel, Switzerland)",,"In recent years, the application and wide adoption of Internet of Things (IoT)-based technologies have increased the proliferation of monitoring systems, which has consequently exponentially increased the amounts of heterogeneous data generated. Processing and analysing the massive amount of data produced is cumbersome and gradually moving from classical ‘batch’ processing—extract, transform, load (ETL) technique to real-time processing. For instance, in environmental monitoring and management domain, time-series data and historical dataset are crucial for prediction models. However, the environmental monitoring domain still utilises legacy systems, which complicates the real-time analysis of the essential data, integration with big data platforms and reliance on batch processing. Herein, as a solution, a distributed stream processing middleware framework for real-time analysis of heterogeneous environmental monitoring and management data is presented and tested on a cluster using open source technologies in a big data environment. The system ingests datasets from legacy systems and sensor data from heterogeneous automated weather systems irrespective of the data types to Apache Kafka topics using Kafka Connect APIs for processing by the Kafka streaming processing engine. The stream processing engine executes the predictive numerical models and algorithms represented in event processing (EP) languages for real-time analysis of the data streams. To prove the feasibility of the proposed framework, we implemented the system using a case study scenario of drought prediction and forecasting based on the Effective Drought Index (EDI) model. Firstly, we transform the predictive model into a form that could be executed by the streaming engine for real-time computing. Secondly, the model is applied to the ingested data streams and datasets to predict drought through persistent querying of the infinite streams to detect anomalies. As a conclusion of this study, a performance evaluation of the distributed stream processing middleware infrastructure is calculated to determine the real-time effectiveness of the framework.",2020-06-03,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,,11,20,Sensors (Basel),A Distributed Stream Processing Middleware Framework for Real-Time Analysis of Heterogeneous Data on Big Data Platform,PubMed Central,PMID: 32503145 PMCID: PMC7308861,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7308861/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
682,10.3390/s20205856,33081193,PMC7594090,A,Neo4j,Neo4j,"Villalba-Diez, Javier; Zheng, Xiaochen",Quantum Strategic Organizational Design: Alignment in Industry 4.0 Complex-Networked Cyber-Physical Lean Management Systems,2020,"Sensors (Basel, Switzerland)",,"The strategic design of organizations in an environment where complexity is constantly increasing, as in the cyber-physical systems typical of Industry 4.0, is a process full of uncertainties. Leaders are forced to make decisions that affect other organizational units without being sure that their decisions are the right ones. Previously to this work, genetic algorithms were able to calculate the state of alignment of industrial processes that were measured through certain key performance indicators (KPIs) to ensure that the leaders of the Industry 4.0 make decisions that are aligned with the strategic objectives of the organization. However, the computational cost of these algorithms increases exponentially with the number of KPIs. That is why this work makes use of the principles of quantum computing to present the strategic design of organizations from a novel point of view: Quantum Strategic Organizational Design (QSOD). The effectiveness of the application of these principles is shown with a real case study, in which the computing time is reduced from hundreds of hours to seconds. This has very powerful practical applications for industry leaders, since, with this new approach, they can potentially allow a better understanding of the complex processes underlying the strategic design of organizations and, above all, make decisions in real-time.",2020-10-16,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,20,20,Sensors (Basel),Quantum Strategic Organizational Design,PubMed Central,PMID: 33081193 PMCID: PMC7594090,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7594090/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
683,10.3390/s20216270,33153237,PMC7662437,,,,"Ryu, Hyejeong",Graph Search-Based Exploration Method Using a Frontier-Graph Structure for Mobile Robots,2020,"Sensors (Basel, Switzerland)",,"This paper describes a graph search-based exploration method. Segmented frontier nodes and their relative transformations constitute a frontier-graph structure. Frontier detection and segmentation are performed using local grid maps of adjacent nodes. The proposed frontier-graph structure can systematically manage local information according to the exploration state and overcome the problem caused by updating a single global grid map. The robot selects the next target using breadth-first search (BFS) exploration of the frontier-graph. The BFS exploration is improved to generate an efficient loop-closing sequence between adjacent nodes. We verify that our BFS-based exploration method can gradually extend the frontier-graph structure and efficiently map the entire environment, regardless of the starting position.",2020-11-03,2021-06-05 21:09:36,,21,20,Sensors (Basel),,PubMed Central,PMID: 33153237 PMCID: PMC7662437,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7662437/,,,,PMC:Query2
684,10.3390/s20236977,33291340,PMC7730965,A,Neo4j,Neo4j,"Villalba-Diez, Javier; Benito, Rosa María; Losada, Juan Carlos",Industry 4.0 Quantum Strategic Organizational Design Configurations. The Case of Two Qubits: One Reports to One,2020,"Sensors (Basel, Switzerland)",,"In this paper we investigate how the relationship with a subordinate who reports to him influences the alignment of an Industry 4.0 leader. We do this through the implementation of quantum circuits that represent decision networks. In fact, through the quantum simulation of strategic organizational design configurations (QSOD) through five hundred simulations of quantum circuits, we conclude that there is an influence of the subordinate on the leader that resembles that of a harmonic under-damped oscillator around the value of 50% probability of alignment for the leader. Likewise, we have observed a fractal behavior in this type of relationship, which seems to conjecture that there is an exchange of energy between the two agents that oscillates with greater or lesser amplitude depending on certain parameters of interdependence. Fractality in this QSOD context allows for a quantification of these complex dynamics and its pervasive effect offers robustness and resilience to the two-qubit interaction.",2020-12-06,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,23,20,Sensors (Basel),Industry 4.0 Quantum Strategic Organizational Design Configurations. The Case of Two Qubits,PubMed Central,PMID: 33291340 PMCID: PMC7730965,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7730965/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
685,10.3390/s20237000,33297506,PMC7731156,A,Neo4j; COVID19,Neo4j; COVID19,"Jeong, Seungmyeong; Kim, Seongyun; Kim, Jaeho",City Data Hub: Implementation of Standard-Based Smart City Data Platform for Interoperability,2020,"Sensors (Basel, Switzerland)",,"Like what happened to the Internet of Things (IoT), smart cities have become abundant in our lives as well. One of the smart city definitions commonly used is that smart cities solve city problems to enhance citizens’ life quality and make cities sustainable. From the perspective of information and communication technologies (ICT), we think this can be done by collecting and analyzing data to generate insights. The City Data Hub, which is a standard-based city data platform that has been developed, and a couple of problem-solving examples have been demonstrated. The key elements for smart city platforms have been chosen and they have been included in the core architecture principles and implemented as a platform. It has been proven that standard application programming interfaces (APIs) and common data models with data marketplaces, which are the keys, increase interoperability and guarantee ecosystem extensibility.",2020-12-07,2021-06-05 20:35:57; 2021-06-05 21:35:36; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,23,20,Sensors (Basel),City Data Hub,PubMed Central,PMID: 33297506 PMCID: PMC7731156,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7731156/,,Neo4j; COVID19,Neo4j; COVID19,PMC:Query3; PMC:Neo4j; PMC:COVID19; PMC:Query2
686,10.3390/s21020435,33435451,PMC7827260,,,,"Bellini, Emanuele; Bellini, Pierfrancesco; Cenni, Daniele; Nesi, Paolo; Pantaleo, Gianni; Paoli, Irene; Paolucci, Michela",An IoE and Big Multimedia Data Approach for Urban Transport System Resilience Management in Smart Cities,2021,"Sensors (Basel, Switzerland)",,"Today, the complexity of urban systems combined with existing and emerging threats constrains administrations to consider smart technologies and related huge amounts of data generated as a means to take timely and informed decisions. The smart city needs to be prepared for both expected and unexpected situations, and the possibility to mitigate the effect of the uncertainty behind the causes of disruptions through the analysis of all the possible data generated by the city open new possibility for resilience operationalization. This article aims at introducing a new conceptualization for resilience and presenting an innovative full stack solution to exploit Internet of Everything (IoE) and big multimedia data in smart cities to manage resilience of urban transport systems (UTS), which is one of the most critical infrastructures of the city. The approach is based on a novel data driven approach to resilience engineering and functional resonance analysis method (FRAM), to understand and model an UTS in the context of smart cities and to support evidence driven decision making. The paper proposes an architecture taking into account: (a) different kinds of available data generated in the smart city, (b) big data collection and semantic aggregation and enrichment; (c) data sense-making process composed by analytics of different data sources like social media, communication networks, IoT, user behavior; (d) tools for knowledge driven decisions able to combine different information generated by analytics, experience, and structural information of the city into a comprehensive and evidence driven decision model. The solution has been applied in Florence metropolitan city in the context of RESOLUTE H2020 research project of the European Commission.",2021-01-09,2021-06-05 21:09:36,,2,21,Sensors (Basel),,PubMed Central,PMID: 33435451 PMCID: PMC7827260,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7827260/,,,,PMC:Query2
687,10.3390/s21051594,33668773,PMC7956727,,,,"Stojanović, Branka; Božić, Josip; Hofer-Schmitz, Katharina; Nahrgang, Kai; Weber, Andreas; Badii, Atta; Sundaram, Maheshkumar; Jordan, Elliot; Runevic, Joel",Follow the Trail: Machine Learning for Fraud Detection in Fintech Applications,2021,"Sensors (Basel, Switzerland)",,"Financial technology, or Fintech, represents an emerging industry on the global market. With online transactions on the rise, the use of IT for automation of financial services is of increasing importance. Fintech enables institutions to deliver services to customers worldwide on a 24/7 basis. Its services are often easy to access and enable customers to perform transactions in real-time. In fact, advantages such as these make Fintech increasingly popular among clients. However, since Fintech transactions are made up of information, ensuring security becomes a critical issue. Vulnerabilities in such systems leave them exposed to fraudulent acts, which cause severe damage to clients and providers alike. For this reason, techniques from the area of Machine Learning (ML) are applied to identify anomalies in Fintech applications. They target suspicious activity in financial datasets and generate models in order to anticipate future frauds. We contribute to this important issue and provide an evaluation on anomaly detection methods for this matter. Experiments were conducted on several fraudulent datasets from real-world and synthetic databases, respectively. The obtained results confirm that ML methods contribute to fraud detection with varying success. Therefore, we discuss the effectiveness of the individual methods with regard to the detection rate. In addition, we provide an analysis on the influence of selected features on their performance. Finally, we discuss the impact of the observed results for the security of Fintech applications in the future.",2021-02-25,2021-06-05 21:09:36,,5,21,Sensors (Basel),Follow the Trail,PubMed Central,PMID: 33668773 PMCID: PMC7956727,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7956727/,,,,PMC:Query2
688,10.3390/s21092911,33919196,PMC8122639,,,,"Lee, JaeYun; Kim, Incheol",Vision–Language–Knowledge Co-Embedding for Visual Commonsense Reasoning,2021,"Sensors (Basel, Switzerland)",,"Visual commonsense reasoning is an intelligent task performed to decide the most appropriate answer to a question while providing the rationale or reason for the answer when an image, a natural language question, and candidate responses are given. For effective visual commonsense reasoning, both the knowledge acquisition problem and the multimodal alignment problem need to be solved. Therefore, we propose a novel Vision–Language–Knowledge Co-embedding (ViLaKC) model that extracts knowledge graphs relevant to the question from an external knowledge base, ConceptNet, and uses them together with the input image to answer the question. The proposed model uses a pretrained vision–language–knowledge embedding module, which co-embeds multimodal data including images, natural language texts, and knowledge graphs into a single feature vector. To reflect the structural information of the knowledge graph, the proposed model uses the graph convolutional neural network layer to embed the knowledge graph first and then uses multi-head self-attention layers to co-embed it with the image and natural language question. The effectiveness and performance of the proposed model are experimentally validated using the VCR v1.0 benchmark dataset.",2021-04-21,2021-06-05 21:09:36,,9,21,Sensors (Basel),,PubMed Central,PMID: 33919196 PMCID: PMC8122639,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8122639/,,,,PMC:Query2
689,10.3390/s21093223,,PMC8125783,,,,"Xin, Yunxing; Cao, Lei; Wang, Xin; He, Xiaohao; Feng, Ling",Generating Instructive Questions from Multiple Articles to Guide Reading in E-Bibliotherapy,2021,"Sensors (Basel, Switzerland)",,"E-Bibliotherapy deals with adolescent psychological stress by manually or automatically recommending multiple reading articles around their stressful events, using electronic devices as a medium. To make E-Bibliotherapy really useful, generating instructive questions before their reading is an important step. Such a question shall (a) attract teens’ attention; (b) convey the essential message of the reading materials so as to improve teens’ active comprehension; and most importantly (c) highlight teens’ stress to enable them to generate emotional resonance and thus willingness to pursue the reading. Therefore in this paper, we propose to generate instructive questions from the multiple recommended articles to guide teens to read. Four solutions based on the neural encoder-decoder model are presented to tackle the task. For model training and testing, we construct a novel large-scale QA dataset named TeenQA, which is specific to adolescent stress. Due to the extensibility of question expressions, we incorporate three groups of automatic evaluation metrics as well as one group of human evaluation metrics to examine the quality of the generated questions. The experimental results show that the proposed Encoder-Decoder with Summary on Contexts with Feature-rich embeddings (ED-SoCF) solution can generate good questions for guiding reading, achieving comparable performance on some semantic similarity metrics with that of humans.",2021-05-06,2021-06-05 21:09:36,,9,21,Sensors (Basel),,PubMed Central,PMID:  PMCID: PMC8125783,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8125783/,,,,PMC:Query2
690,10.3402/jev.v3.24247,25317275,PMC4172698,A,Neo4j,Neo4j,"Butler, William E.; Atai, Nadia; Carter, Bob; Hochberg, Fred",Informatic system for a global tissue–fluid biorepository with a graph theory–oriented graphical user interface,2014,Journal of Extracellular Vesicles,,"The Richard Floor Biorepository supports collaborative studies of extracellular vesicles (EVs) found in human fluids and tissue specimens. The current emphasis is on biomarkers for central nervous system neoplasms but its structure may serve as a template for collaborative EV translational studies in other fields. The informatic system provides specimen inventory tracking with bar codes assigned to specimens and containers and projects, is hosted on globalized cloud computing resources, and embeds a suite of shared documents, calendars, and video-conferencing features. Clinical data are recorded in relation to molecular EV attributes and may be tagged with terms drawn from a network of externally maintained ontologies thus offering expansion of the system as the field matures. We fashioned the graphical user interface (GUI) around a web-based data visualization package. This system is now in an early stage of deployment, mainly focused on specimen tracking and clinical, laboratory, and imaging data capture in support of studies to optimize detection and analysis of brain tumour–specific mutations. It currently includes 4,392 specimens drawn from 611 subjects, the majority with brain tumours. As EV science evolves, we plan biorepository changes which may reflect multi-institutional collaborations, proteomic interfaces, additional biofluids, changes in operating procedures and kits for specimen handling, novel procedures for detection of tumour-specific EVs, and for RNA extraction and changes in the taxonomy of EVs. We have used an ontology-driven data model and web-based architecture with a graph theory–driven GUI to accommodate and stimulate the semantic web of EV science.",2014-09-22,2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-05 20:37:08,,,3,J Extracell Vesicles,,PubMed Central,PMID: 25317275 PMCID: PMC4172698,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4172698/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
691,10.3414/ME18-02-0002,30016813,PMC6193407,,,,"Haarbrandt, Birger; Schreiweis, Björn; Rey, Sabine; Sax, Ulrich; Scheithauer, Simone; Rienhoff, Otto; Knaup-Gregori, Petra; Bavendiek, Udo; Dieterich, Christoph; Brors, Benedikt; Kraus, Inga; Thoms, Caroline Marieken; Jäger, Dirk; Ellenrieder, Volker; Bergh, Björn; Yahyapour, Ramin; Eils, Roland; Consortium, HiGHmed; Marschollek, Michael",HiGHmed – An Open Platform Approach to Enhance Care and Research across Institutional Boundaries,2018,Methods of Information in Medicine,,"Introduction: This article is part of the Focus Theme of Methods of Information in Medicine on the German Medical Informatics Initiative. HiGHmed brings together 24 partners from academia and industry, aiming at improvements in care provision, biomedical research and epidemiology. By establishing a shared information governance framework, data integration centers and an open platform architecture in cooperation with independent healthcare providers, the meaningful reuse of data will be facilitated. Complementary, HiGHmed integrates a total of seven Medical Informatics curricula to develop collaborative structures and processes to train medical informatics professionals, physicians and researchers in new forms of data analytics. ,  Governance and Policies: We describe governance structures and policies that have proven effective during the conceptual phase. These were further adapted to take into account the specific needs of the development and networking phase, such as roll-out, carerelated aspects and our focus on curricula development in Medical Inform atics. ,  Architectural Framework and Methodology: To address the challenges of organizational, technical and semantic interoperability, a concept for a scalable platform architecture, the HiGHmed Platform, was developed. We outline the basic principles and design goals of the open platform approach as well as the roles of standards and specifications such as IHE XDS, openEHR, SNOMED CT and HL7 FHIR. A shared governance framework provides the semantic artifacts which are needed to establish semantic interoperability. ,  Use Cases: Three use cases in the fields of oncology, cardiology and infection control will demonstrate the capabilities of the HiGHmed approach. Each of the use cases entails diverse challenges in terms of data protection, privacy and security, including clinical use of genome sequencing data (oncology), continuous longitudinal monitoring of physical activity (cardiology) and cross-site analysis of patient movement data (infection control). ,  Discussion: Besides the need for a shared governance framework and a technical infrastructure, backing from clinical leaders is a crucial factor. Moreover, firm and sustainable commitment by participating organizations to collaborate in further development of their information system architectures is needed. Other challenges including topics such as data quality, privacy regulations, and patient consent will be addressed throughout the project.",2018-07,2021-06-05 21:11:16,e66-e81,Suppl 1,57,Methods Inf Med,,PubMed Central,PMID: 30016813 PMCID: PMC6193407,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6193407/,,,,PMC:Query2
692,10.3892/ijo.2019.4953,31894325,PMC6959459,,,,"Park, Soonbum; Lim, Jin-Muk; Chun, Jung Nyeo; Lee, Sanghoon; Kim, Tae Min; Kim, Dong-Wan; Kim, Sang-Yeob; Bae, Dong-Jun; Bae, Sang-Mun; So, Insuk; Kim, Hong-Gee; Choi, Ji-Yeob; Jeon, Ju-Hong",Altered expression of fucosylation pathway genes is associated with poor prognosis and tumor metastasis in non-small cell lung cancer,2019,International Journal of Oncology,,"Fucosylation is a post-translational modification that attaches fucose residues to protein- or lipid-bound oligosaccharides. Certain fucosylation pathway genes are aberrantly expressed in several types of cancer, including non-small cell lung cancer (NSCLC), and this aberrant expression is associated with poor prognosis in patients with cancer. However, the molecular mechanism by which these fucosylation pathway genes promote tumor progression has not been well-characterized. The present study analyzed public microarray data obtained from NSCLC samples. Multivariate analysis revealed that altered expression of fucosylation pathway genes, including fucosyltransferase 1 (FUT1), FUT2, FUT3, FUT6, FUT8 and GDP-L-fucose synthase (TSTA3), correlated with poor survival in patients with NSCLC. Inhibition of FUTs by 2F-peracetyl-fucose (2F-PAF) suppressed transforming growth factor β (TGFβ)-mediated Smad3 phosphorylation and nuclear translocation in NSCLC cells. In addition, wound-healing and Transwell migration assays demonstrated that 2F-PAF inhibited TGFβ-induced NSCLC cell migration and invasion. Furthermore, in vivo bioluminescence imaging analysis revealed that 2F-PAF attenuated the metastatic capacity of NSCLC cells. These results may help characterize the oncogenic role of fucosylation in NSCLC biology and highlight its potential for developing cancer therapeutics.",2019-12-24,2021-06-05 21:10:08,559-567,2,56,Int J Oncol,,PubMed Central,PMID: 31894325 PMCID: PMC6959459,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6959459/,,,,PMC:Query2
693,10.3897/BDJ.2.e1125,25057255,PMC4092319,A,Neo4j,Neo4j,"Vos, Rutger Aldo; Biserkov, Jordan Valkov; Balech, Bachir; Beard, Niall; Blissett, Matthew; Brenninkmeijer, Christian; van Dooren, Tom; Eades, David; Gosline, George; Groom, Quentin John; Hamann, Thomas D.; Hettling, Hannes; Hoehndorf, Robert; Holleman, Ayco; Hovenkamp, Peter; Kelbert, Patricia; King, David; Kirkup, Don; Lammers, Youri; DeMeulemeester, Thibaut; Mietchen, Daniel; Miller, Jeremy A.; Mounce, Ross; Nicolson, Nicola; Page, Rod; Pawlik, Aleksandra; Pereira, Serrano; Penev, Lyubomir; Richards, Kevin; Sautter, Guido; Shorthouse, David Peter; Tähtinen, Marko; Weiland, Claus; Williams, Alan R.; Sierra, Soraya",Enriched biodiversity data as a resource and service,2014,Biodiversity Data Journal,,"Background: Recent years have seen a surge in projects that produce large volumes of structured, machine-readable biodiversity data. To make these data amenable to processing by generic, open source “data enrichment” workflows, they are increasingly being represented in a variety of standards-compliant interchange formats. Here, we report on an initiative in which software developers and taxonomists came together to address the challenges and highlight the opportunities in the enrichment of such biodiversity data by engaging in intensive, collaborative software development: The Biodiversity Data Enrichment Hackathon., Results: The hackathon brought together 37 participants (including developers and taxonomists, i.e. scientific professionals that gather, identify, name and classify species) from 10 countries: Belgium, Bulgaria, Canada, Finland, Germany, Italy, the Netherlands, New Zealand, the UK, and the US. The participants brought expertise in processing structured data, text mining, development of ontologies, digital identification keys, geographic information systems, niche modeling, natural language processing, provenance annotation, semantic integration, taxonomic name resolution, web service interfaces, workflow tools and visualisation. Most use cases and exemplar data were provided by taxonomists., One goal of the meeting was to facilitate re-use and enhancement of biodiversity knowledge by a broad range of stakeholders, such as taxonomists, systematists, ecologists, niche modelers, informaticians and ontologists. The suggested use cases resulted in nine breakout groups addressing three main themes: i) mobilising heritage biodiversity knowledge; ii) formalising and linking concepts; and iii) addressing interoperability between service platforms. Another goal was to further foster a community of experts in biodiversity informatics and to build human links between research projects and institutions, in response to recent calls to further such integration in this research domain., Conclusions: Beyond deriving prototype solutions for each use case, areas of inadequacy were discussed and are being pursued further. It was striking how many possible applications for biodiversity data there were and how quickly solutions could be put together when the normal constraints to collaboration were broken down for a week. Conversely, mobilising biodiversity knowledge from their silos in heritage literature and natural history collections will continue to require formalisation of the concepts (and the links between them) that define the research domain, as well as increased interoperability between the software platforms that operate on these concepts.",2014-06-16,2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-05 20:37:08,,2,,Biodivers Data J,,PubMed Central,PMID: 25057255 PMCID: PMC4092319,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4092319/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
694,10.3897/BDJ.4.e8443,27932908,PMC5136645,A,Virtuoso,Virtuoso,"Minadakis, Nikos; Marketakis, Yannis; Doerr, Martin; Bekiari, Chryssoula; Papadakos, Panagiotis; Gougousis, Alexandros; Bailly, Nicolas; Arvanitidis, Christos",LifeWatch Greece data-services: Discovering Biodiversity Data using Semantic Web Technologies,2016,Biodiversity Data Journal,,"Background Biodiversity data is characterized by its cross-disciplinary character, the extremely broad range of data types and structures, and the variety of semantic concepts that it encompasses. Furthermore there is a plethora of different data sources providing resources for the same piece of information in a heterogeneous way. Even if we restrict our attention to Greek biodiversity domain, it is easy to see that biodiversity data remains unconnected and widely distributed among different sources. New information To cope with these issues, in the context of the LifeWatch Greece project, i) we supported cataloguing and publishing of all the relevant metadata information of the Greek biodiversity domain, ii) we integrated data from heterogeneous sources by supporting the definitions of appropriate models, iii) we provided means for efficiently discovering biodiversity data of interest and iv) we enabled the answering of complex queries that could not be answered from the individual sources. This work has been exploited, evaluated and scientificaly confirmed by the biodiversity community through the services provided by the LifeWatch Greece portal.",2016-11-01,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:59:14,,4,,Biodivers Data J,LifeWatch Greece data-services,PubMed Central,PMID: 27932908 PMCID: PMC5136645,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5136645/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
695,10.4056/sigs.5279417,,PMC4149000,,,,"Waltemath, Dagmar; Bergmann, Frank T.; Chaouiya, Claudine; Czauderna, Tobias; Gleeson, Padraig; Goble, Carole; Golebiewski, Martin; Hucka, Michael; Juty, Nick; Krebs, Olga; Le Novère, Nicolas; Mi, Huaiyu; Moraru, Ion I.; Myers, Chris J.; Nickerson, David; Olivier, Brett G.; Rodriguez, Nicolas; Schreiber, Falk; Smith, Lucian; Zhang, Fengkai; Bonnet, Eric",Meeting report from the fourth meeting of the Computational Modeling in Biology Network (COMBINE),2014,Standards in Genomic Sciences,,"The Computational Modeling in Biology Network (COMBINE) is an initiative to coordinate the development of community standards and formats in computational systems biology and related fields. This report summarizes the topics and activities of the fourth edition of the annual COMBINE meeting, held in Paris during September 16-20 2013, and attended by a total of 96 people. This edition pioneered a first day devoted to modeling approaches in biology, which attracted a broad audience of scientists thanks to a panel of renowned speakers. During subsequent days, discussions were held on many subjects including the introduction of new features in the various COMBINE standards, new software tools that use the standards, and outreach efforts. Significant emphasis went into work on extensions of the SBML format, and also into community-building. This year’s edition once again demonstrated that the COMBINE community is thriving, and still manages to help coordinate activities between different standards in computational systems biology.",2014-03-15,2021-06-05 21:13:27,1285-1301,3,9,Stand Genomic Sci,,PubMed Central,PMID:  PMCID: PMC4149000,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4149000/,,,,PMC:Query2
696,10.4103/0366-6999.207468,28584215,PMC5463482,,,,"Wu, Tao; Gao, Chang-Chun; Lin, Jing-Sheng; Zha, Jia-Ling",Active Monitoring of Adverse Drug Reactions with Neural Network Technology,2017,Chinese Medical Journal,,,2017-06-20,2021-06-05 21:12:01,1498-1501,12,130,Chin Med J (Engl),,PubMed Central,PMID: 28584215 PMCID: PMC5463482,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5463482/,,,,PMC:Query2
697,10.4103/jpi.jpi_29_17,28828200,PMC5545777,A,Neo4j,Neo4j,"Shin, Dmitriy; Kovalenko, Mikhail; Ersoy, Ilker; Li, Yu; Doll, Donald; Shyu, Chi-Ren; Hammer, Richard",PathEdEx – Uncovering High-explanatory Visual Diagnostics Heuristics Using Digital Pathology and Multiscale Gaze Data,2017,Journal of Pathology Informatics,,"Background: Visual heuristics of pathology diagnosis is a largely unexplored area where reported studies only provided a qualitative insight into the subject. Uncovering and quantifying pathology visual and nonvisual diagnostic patterns have great potential to improve clinical outcomes and avoid diagnostic pitfalls. Methods: Here, we present PathEdEx, an informatics computational framework that incorporates whole-slide digital pathology imaging with multiscale gaze-tracking technology to create web-based interactive pathology educational atlases and to datamine visual and nonvisual diagnostic heuristics. Results: We demonstrate the capabilities of PathEdEx for mining visual and nonvisual diagnostic heuristics using the first PathEdEx volume of a hematopathology atlas. We conducted a quantitative study on the time dynamics of zooming and panning operations utilized by experts and novices to come to the correct diagnosis. We then performed association rule mining to determine sets of diagnostic factors that consistently result in a correct diagnosis, and studied differences in diagnostic strategies across different levels of pathology expertise using Markov chain (MC) modeling and MC Monte Carlo simulations. To perform these studies, we translated raw gaze points to high-explanatory semantic labels that represent pathology diagnostic clues. Therefore, the outcome of these studies is readily transformed into narrative descriptors for direct use in pathology education and practice. Conclusion: PathEdEx framework can be used to capture best practices of pathology visual and nonvisual diagnostic heuristics that can be passed over to the next generation of pathologists and have potential to streamline implementation of precision diagnostics in precision medicine settings.",2017-07-25,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:36:32,,,8,J Pathol Inform,,PubMed Central,PMID: 28828200 PMCID: PMC5545777,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5545777/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
698,10.4137/BMI.S29511,26396492,PMC4562606,A,Neo4j,Neo4j,"Wanichthanarak, Kwanjeera; Fahrmann, Johannes F; Grapov, Dmitry","Genomic, Proteomic, and Metabolomic Data Integration Strategies",2015,Biomarker Insights,,"Robust interpretation of experimental results measuring discreet biological domains remains a significant challenge in the face of complex biochemical regulation processes such as organismal versus tissue versus cellular metabolism, epigenetics, and protein post-translational modification. Integration of analyses carried out across multiple measurement or omic platforms is an emerging approach to help address these challenges. This review focuses on select methods and tools for the integration of metabolomic with genomic and proteomic data using a variety of approaches including biochemical pathway-, ontology-, network-, and empirical-correlation-based methods.",2015-09-07,2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-05 20:37:08,1-6,Suppl 4,10,Biomark Insights,,PubMed Central,PMID: 26396492 PMCID: PMC4562606,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4562606/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
699,10.4137/CIN.S13895,25520553,PMC4260769,A,Neo4j,Neo4j,"Johnson, David; Connor, Anthony J; McKeever, Steve; Wang, Zhihui; Deisboeck, Thomas S; Quaiser, Tom; Shochat, Eliezer; Johnson, David; Connor, Anthony J.; McKeever, Steve; Wang, Zhihui; Deisboeck, Thomas S.; Quaiser, Tom; Shochat, Eliezer",Semantically linking in silico cancer models; Semantically Linking In Silico Cancer Models,2014,Cancer Informatics,,"Multiscale models are commonplace in cancer modeling, where individual models acting on different biological scales are combined within a single, cohesive modeling framework. However, model composition gives rise to challenges in understanding interfaces and interactions between them. Based on specific domain expertise, typically these computational models are developed by separate research groups using different methodologies, programming languages, and parameters. This paper introduces a graph-based model for semantically linking computational cancer models via domain graphs that can help us better understand and explore combinations of models spanning multiple biological scales. We take the data model encoded by TumorML, an XML-based markup language for storing cancer models in online repositories, and transpose its model description elements into a graph-based representation. By taking such an approach, we can link domain models, such as controlled vocabularies, taxonomic schemes, and ontologies, with cancer model descriptions to better understand and explore relationships between models. The union of these graphs creates a connected property graph that links cancer models by categorizations, by computational compatibility, and by semantic interoperability, yielding a framework in which opportunities for exploration and discovery of combinations of models become possible.",2014; 2014-12-08,2021-06-05 21:06:22; 2021-06-05 21:12:40; 2021-06-05 21:16:51; 2021-06-05 20:37:08; 2021-06-05 20:56:20; 2021-06-05 21:24:28,133-143,Suppl 1,13,Cancer Inform,,PubMed; PubMed Central,PMID: 25520553 PMCID: PMC4260769,http://www.ncbi.nlm.nih.gov/pubmed/25520553; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4260769/,in silico oncology; model exploration; neo4j; property graphs; tumor modeling,Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
700,10.4137/CIN.S16344,25983539,PMC4412427,,,,"Agarwal, Pankaj; Owzar, Kouros",Next Generation Distributed Computing for Cancer Research,2015,Cancer Informatics,,"Advances in next generation sequencing (NGS) and mass spectrometry (MS) technologies have provided many new opportunities and angles for extending the scope of translational cancer research while creating tremendous challenges in data management and analysis. The resulting informatics challenge is invariably not amenable to the use of traditional computing models. Recent advances in scalable computing and associated infrastructure, particularly distributed computing for Big Data, can provide solutions for addressing these challenges. In this review, the next generation of distributed computing technologies that can address these informatics problems is described from the perspective of three key components of a computational platform, namely computing, data storage and management, and networking. A broad overview of scalable computing is provided to set the context for a detailed description of Hadoop, a technology that is being rapidly adopted for large-scale distributed computing. A proof-of-concept Hadoop cluster, set up for performance benchmarking of NGS read alignment, is described as an example of how to work with Hadoop. Finally, Hadoop is compared with a number of other current technologies for distributed computing.",2015-04-27,2021-06-05 21:12:40,97-109,Suppl 7,13,Cancer Inform,,PubMed Central,PMID: 25983539 PMCID: PMC4412427,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4412427/,,,,PMC:Query2
701,10.5195/jmla.2019.595,31258444,PMC6579601,,,,"Ragon, Bart",Alignment of library services with the research lifecycle,2019,Journal of the Medical Library Association : JMLA,,Objectives This study sought to understand the needs of biomedical researchers related to the research lifecycle and the present state of library support for biomedical research. Methods Qualitative interview data were collected from biomedical researchers who were asked to describe their research activities from identifying a problem to measuring the impact of their findings. Health sciences library leaders were surveyed about the services that they currently provide or plan to provide in supporting biomedical research. Results Library services were strongest at the beginning and end of the research lifecycle but were weaker in the conducting phase of research. Co-occurrence of codes from the qualitative data suggests that library services are on the fringe of rather than integrated into the research lifecycle. Discussion Findings from this study suggest that tradition-based service models of health sciences libraries are insufficient to meet the needs of biomedical researchers. Investments by libraries in services that integrate with the conducting phase of research are needed for libraries to remain relevant in their support of the research lifecycle.,2019-07,2021-06-05 21:10:37,384-393,3,107,J Med Libr Assoc,,PubMed Central,PMID: 31258444 PMCID: PMC6579601,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6579601/,,,,PMC:Query2
702,10.5210/ojphi.v6i1.5142,,PMC4050774,,,,"Pullum, Laura; Ramanathan, Arvind",ORBiT – The Oak Ridge Biosurveillance Toolkit,2014,Online Journal of Public Health Informatics,,,2014-04-29,2021-06-05 21:13:27,,1,6,Online J Public Health Inform,,PubMed Central,PMID:  PMCID: PMC4050774,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4050774/,,,,PMC:Query2
703,10.5441/002/edbt.2015.29,27064397,PMC4825692,A,Neo4j,Neo4j,"Kuck, Jonathan; Zhuang, Honglei; Yan, Xifeng; Cam, Hasan; Han, Jiawei",Query-Based Outlier Detection in Heterogeneous Information Networks,2015,Advances in database technology : proceedings. International Conference on Extending Database Technology,,"Outlier or anomaly detection in large data sets is a fundamental task in data science, with broad applications. However, in real data sets with high-dimensional space, most outliers are hidden in certain dimensional combinations and are relative to a user’s search space and interest. It is often more effective to give power to users and allow them to specify outlier queries flexibly, and the system will then process such mining queries efficiently. In this study, we introduce the concept of query-based outlier in heterogeneous information networks, design a query language to facilitate users to specify such queries flexibly, define a good outlier measure in heterogeneous networks, and study how to process outlier queries efficiently in large data sets. Our experiments on real data sets show that following such a methodology, interesting outliers can be defined and uncovered flexibly and effectively in large heterogeneous networks.",2015-03,2021-06-05 20:56:20; 2021-06-05 21:12:40; 2021-06-05 20:37:08,325-336,,2015,Adv Database Technol,,PubMed Central,PMID: 27064397 PMCID: PMC4825692,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4825692/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
704,10.5808/GI.2017.15.1.19,28416946,PMC5389944,A,Neo4j,Neo4j,"Yoon, Byoung-Ha; Kim, Seon-Kyu; Kim, Seon-Young",Use of Graph Database for the Integration of Heterogeneous Biological Data,2017,Genomics & Informatics,,"Understanding complex relationships among heterogeneous biological data is one of the fundamental goals in biology. In most cases, diverse biological data are stored in relational databases, such as MySQL and Oracle, which store data in multiple tables and then infer relationships by multiple-join statements. Recently, a new type of database, called the graph-based database, was developed to natively represent various kinds of complex relationships, and it is widely used among computer science communities and IT industries. Here, we demonstrate the feasibility of using a graph-based database for complex biological relationships by comparing the performance between MySQL and Neo4j, one of the most widely used graph databases. We collected various biological data (protein-protein interaction, drug-target, gene-disease, etc.) from several existing sources, removed duplicate and redundant data, and finally constructed a graph database containing 114,550 nodes and 82,674,321 relationships. When we tested the query execution performance of MySQL versus Neo4j, we found that Neo4j outperformed MySQL in all cases. While Neo4j exhibited a very fast response for various queries, MySQL exhibited latent or unfinished responses for complex queries with multiple-join statements. These results show that using graph-based databases, such as Neo4j, is an efficient way to store complex biological relationships. Moreover, querying a graph database in diverse ways has the potential to reveal novel relationships among heterogeneous biological data.",2017-03,2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 21:12:01; 2021-06-05 20:55:40; 2021-06-05 21:24:28; 2021-06-05 20:36:32,19-27,1,15,Genomics Inform,,PubMed; PubMed Central,PMID: 28416946 PMCID: PMC5389944,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5389944/; http://www.ncbi.nlm.nih.gov/pubmed/28416946,biological network; data mining; graph database; heterogeneous biological data; Neo4j; query performance,Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
705,10.7554/eLife.26726,28936969,PMC5640425,A,Neo4j,Neo4j,"Himmelstein, Daniel Scott; Lizee, Antoine; Hessler, Christine; Brueggeman, Leo; Chen, Sabrina L; Hadley, Dexter; Green, Ari; Khankhanian, Pouya; Baranzini, Sergio E; Himmelstein, Daniel Scott; Lizee, Antoine; Hessler, Christine; Brueggeman, Leo; Chen, Sabrina L.; Hadley, Dexter; Green, Ari; Khankhanian, Pouya; Baranzini, Sergio E.",Systematic integration of biomedical knowledge prioritizes drugs for repurposing,2017,eLife,,"The ability to computationally predict whether a compound treats a disease would improve the economy and success rate of drug approval. This study describes Project Rephetio to systematically model drug efficacy based on 755 existing treatments. First, we constructed Hetionet (neo4j.het.io), an integrative network encoding knowledge from millions of biomedical studies. Hetionet v1.0 consists of 47,031 nodes of 11 types and 2,250,197 relationships of 24 types. Data were integrated from 29 public resources to connect compounds, diseases, genes, anatomies, pathways, biological processes, molecular functions, cellular components, pharmacologic classes, side effects, and symptoms. Next, we identified network patterns that distinguish treatments from non-treatments. Then, we predicted the probability of treatment for 209,168 compound–disease pairs (het.io/repurpose). Our predictions validated on two external sets of treatment and provided pharmacological insights on epilepsy, suggesting they will help prioritize drug repurposing candidates. This study was entirely open and received realtime feedback from 40 community members., Of all the data in the world today, 90% was created in the last two years. However, taking advantage of this data in order to advance our knowledge is restricted by how quickly we can access it and analyze it in a proper context., In biomedical research, data is largely fragmented and stored in databases that typically do not “talk” to each other, thus hampering progress. One particular problem in medicine today is that the process of making a new therapeutic drug from scratch is incredibly expensive and inefficient, making it a risky business. Given the low success rate in drug discovery, there is an economic incentive in trying to repurpose an existing drug that has already been shown to be safe and effective towards a new disease or condition., Himmelstein et al. used a computational approach to analyze 50,000 data points – including drugs, diseases, genes and symptoms – from 19 different public databases. This approach made it possible to create more than two million relationships among the data points, which could be used to develop models that predict which drugs currently in use by doctors might be best suited to treat any of 136 common diseases. For example, Himmelstein et al. identified specific drugs currently used to treat depression and alcoholism that could be repurposed to treat smoking addition and epilepsy., These findings provide a new and powerful way to study drug repurposing. While this work was exclusively performed with public data, an expanded and potentially stronger set of predictions could be obtained if data owned by pharmaceutical companies were incorporated. Additional studies will be needed to test the predictions made by the models.; The ability to computationally predict whether a compound treats a disease would improve the economy and success rate of drug approval. This study describes Project Rephetio to systematically model drug efficacy based on 755 existing treatments. First, we constructed Hetionet (neo4j.het.io), an integrative network encoding knowledge from millions of biomedical studies. Hetionet v1.0 consists of 47,031 nodes of 11 types and 2,250,197 relationships of 24 types. Data were integrated from 29 public resources to connect compounds, diseases, genes, anatomies, pathways, biological processes, molecular functions, cellular components, pharmacologic classes, side effects, and symptoms. Next, we identified network patterns that distinguish treatments from non-treatments. Then, we predicted the probability of treatment for 209,168 compound-disease pairs (het.io/repurpose). Our predictions validated on two external sets of treatment and provided pharmacological insights on epilepsy, suggesting they will help prioritize drug repurposing candidates. This study was entirely open and received realtime feedback from 40 community members.",2017-09-22,2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 21:12:01; 2021-06-05 20:55:40; 2021-06-05 21:24:28; 2021-06-05 20:36:32,,,6,eLife; Elife,,PubMed; PubMed Central,PMID: 28936969 PMCID: PMC5640425,http://www.ncbi.nlm.nih.gov/pubmed/28936969; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5640425/,"computational biology; Computational Biology; Drug Discovery; Drug Repositioning; drug repurposing; heterogeneous networks; human; Humans; machine learning; Models, Biological; systems biology; Systems Biology",Neo4j,Neo4j,PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
706,10.7554/eLife.42866,31184303,PMC6559788,A,Neo4j,Neo4j,"Guthrie, Leah; Wolfson, Sarah; Kelly, Libusha",The human gut chemical landscape predicts microbe-mediated biotransformation of foods and drugs,,eLife,,"Microbes are nature’s chemists, capable of producing and metabolizing a diverse array of compounds. In the human gut, microbial biochemistry can be beneficial, for example vitamin production and complex carbohydrate breakdown; or detrimental, such as the reactivation of an inactive drug metabolite leading to patient toxicity. Identifying clinically relevant microbiome metabolism requires linking microbial biochemistry and ecology with patient outcomes. Here we present MicrobeFDT, a resource which clusters chemically similar drug and food compounds and links these compounds to microbial enzymes and known toxicities. We demonstrate that compound structural similarity can serve as a proxy for toxicity, enzyme sharing, and coarse-grained functional similarity. MicrobeFDT allows users to flexibly interrogate microbial metabolism, compounds of interest, and toxicity profiles to generate novel hypotheses of microbe-diet-drug-phenotype interactions that influence patient outcomes. We validate one such hypothesis experimentally, using MicrobeFDT to reveal unrecognized gut microbiome metabolism of the ovarian cancer drug altretamine., Microbes in the human gut can play helpful roles by producing vitamins or breaking down complex carbohydrates. Collectively, gut microbes carry out these roles using a large toolkit of enzymes that catalyze a diverse range of chemical reactions, some of which cannot be carried out by human enzymes. However, these microbial enzymes can also cause harm if they alter drugs in a way that makes them toxic or prevents them from working. Little is known about which microbial enzymes interact with which foods and drugs, or how these interactions affect human health., Guthrie et al. have now developed and tested a tool called MicrobeFDT that can help researchers to understand these complex interactions. In MicrobeFDT, 10,000 compounds produced by the human body or found in food or drugs are grouped based on their structure. Compounds are linked to the microbial enzymes that interact with them and drugs are annotated with information on known toxicities. The result is a network where compounds with similar structure are linked to each other., If a microbial enzyme interacts with one compound in a group, it may interact with related compounds as well, potentially causing similar effects on human health. The network makes it easier for researchers to work out which compounds are affected by particular gut microbes. For example, MicrobeFDT suggested how gut microbes might alter the structure of an ovarian cancer drug called altretamine, which can cause diarrhea and kidney damage as side effects. Experiments confirmed that the predicted structural change does occur in human feces., MicrobeFDT may increase how quickly researchers can assess harmful interactions between gut microbes, food, and drugs. It also may help them to develop new strategies to improve human health based on how microbial enzymes interact with food and drugs.",,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,,,8,eLife,,PubMed Central,PMID: 31184303 PMCID: PMC6559788,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6559788/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
707,10.7554/eLife.57443,32880371,PMC7546738,A,Neo4j,Neo4j,"Scheffer, Louis K; Xu, C Shan; Januszewski, Michal; Lu, Zhiyuan; Takemura, Shin-ya; Hayworth, Kenneth J; Huang, Gary B; Shinomiya, Kazunori; Maitlin-Shepard, Jeremy; Berg, Stuart; Clements, Jody; Hubbard, Philip M; Katz, William T; Umayam, Lowell; Zhao, Ting; Ackerman, David; Blakely, Tim; Bogovic, John; Dolafi, Tom; Kainmueller, Dagmar; Kawase, Takashi; Khairy, Khaled A; Leavitt, Laramie; Li, Peter H; Lindsey, Larry; Neubarth, Nicole; Olbris, Donald J; Otsuna, Hideo; Trautman, Eric T; Ito, Masayoshi; Bates, Alexander S; Goldammer, Jens; Wolff, Tanya; Svirskas, Robert; Schlegel, Philipp; Neace, Erika; Knecht, Christopher J; Alvarado, Chelsea X; Bailey, Dennis A; Ballinger, Samantha; Borycz, Jolanta A; Canino, Brandon S; Cheatham, Natasha; Cook, Michael; Dreher, Marisa; Duclos, Octave; Eubanks, Bryon; Fairbanks, Kelli; Finley, Samantha; Forknall, Nora; Francis, Audrey; Hopkins, Gary Patrick; Joyce, Emily M; Kim, SungJin; Kirk, Nicole A; Kovalyak, Julie; Lauchie, Shirley A; Lohff, Alanna; Maldonado, Charli; Manley, Emily A; McLin, Sari; Mooney, Caroline; Ndama, Miatta; Ogundeyi, Omotara; Okeoma, Nneoma; Ordish, Christopher; Padilla, Nicholas; Patrick, Christopher M; Paterson, Tyler; Phillips, Elliott E; Phillips, Emily M; Rampally, Neha; Ribeiro, Caitlin; Robertson, Madelaine K; Rymer, Jon Thomson; Ryan, Sean M; Sammons, Megan; Scott, Anne K; Scott, Ashley L; Shinomiya, Aya; Smith, Claire; Smith, Kelsey; Smith, Natalie L; Sobeski, Margaret A; Suleiman, Alia; Swift, Jackie; Takemura, Satoko; Talebi, Iris; Tarnogorska, Dorota; Tenshaw, Emily; Tokhi, Temour; Walsh, John J; Yang, Tansy; Horne, Jane Anne; Li, Feng; Parekh, Ruchi; Rivlin, Patricia K; Jayaraman, Vivek; Costa, Marta; Jefferis, Gregory SXE; Ito, Kei; Saalfeld, Stephan; George, Reed; Meinertzhagen, Ian A; Rubin, Gerald M; Hess, Harald F; Jain, Viren; Plaza, Stephen M",A connectome and analysis of the adult Drosophila central brain,,eLife,,"The neural circuits responsible for animal behavior remain largely unknown. We summarize new methods and present the circuitry of a large fraction of the brain of the fruit fly Drosophila melanogaster. Improved methods include new procedures to prepare, image, align, segment, find synapses in, and proofread such large data sets. We define cell types, refine computational compartments, and provide an exhaustive atlas of cell examples and types, many of them novel. We provide detailed circuits consisting of neurons and their chemical synapses for most of the central brain. We make the data public and simplify access, reducing the effort needed to answer circuit questions, and provide procedures linking the neurons defined by our analysis with genetic reagents. Biologically, we examine distributions of connection strengths, neural motifs on different scales, electrical consequences of compartmentalization, and evidence that maximizing packing density is an important criterion in the evolution of the fly’s brain., Animal brains of all sizes, from the smallest to the largest, work in broadly similar ways. Studying the brain of any one animal in depth can thus reveal the general principles behind the workings of all brains. The fruit fly Drosophila is a popular choice for such research. With about 100,000 neurons – compared to some 86 billion in humans – the fly brain is small enough to study at the level of individual cells. But it nevertheless supports a range of complex behaviors, including navigation, courtship and learning., Thanks to decades of research, scientists now have a good understanding of which parts of the fruit fly brain support particular behaviors. But exactly how they do this is often unclear. This is because previous studies showing the connections between cells only covered small areas of the brain. This is like trying to understand a novel when all you can see is a few isolated paragraphs., To solve this problem, Scheffer, Xu, Januszewski, Lu, Takemura, Hayworth, Huang, Shinomiya et al. prepared the first complete map of the entire central region of the fruit fly brain. The central brain consists of approximately 25,000 neurons and around 20 million connections. To prepare the map – or connectome – the brain was cut into very thin 8nm slices and photographed with an electron microscope. A three-dimensional map of the neurons and connections in the brain was then reconstructed from these images using machine learning algorithms. Finally, Scheffer et al. used the new connectome to obtain further insights into the circuits that support specific fruit fly behaviors., The central brain connectome is freely available online for anyone to access. When used in combination with existing methods, the map will make it easier to understand how the fly brain works, and how and why it can fail to work correctly. Many of these findings will likely apply to larger brains, including our own. In the long run, studying the fly connectome may therefore lead to a better understanding of the human brain and its disorders. Performing a similar analysis on the brain of a small mammal, by scaling up the methods here, will be a likely next step along this path.",,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,,,9,eLife,,PubMed Central,PMID: 32880371 PMCID: PMC7546738,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7546738/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
708,10.7554/eLife.62362,33616035,PMC8016480,A,OrientDB; Neo4j; COVID19,OrientDB; Neo4j; COVID19,"Lazar, Aurel A; Liu, Tingkai; Turkcan, Mehmet Kerem; Zhou, Yiyin",Accelerating with FlyBrainLab the discovery of the functional logic of the Drosophila brain in the connectomic and synaptomic era,,eLife,,"In recent years, a wealth of Drosophila neuroscience data have become available including cell type and connectome/synaptome datasets for both the larva and adult fly. To facilitate integration across data modalities and to accelerate the understanding of the functional logic of the fruit fly brain, we have developed FlyBrainLab, a unique open-source computing platform that integrates 3D exploration and visualization of diverse datasets with interactive exploration of the functional logic of modeled executable brain circuits. FlyBrainLab’s User Interface, Utilities Libraries and Circuit Libraries bring together neuroanatomical, neurogenetic and electrophysiological datasets with computational models of different researchers for validation and comparison within the same platform. Seeking to transcend the limitations of the connectome/synaptome, FlyBrainLab also provides libraries for molecular transduction arising in sensory coding in vision/olfaction. Together with sensory neuron activity data, these libraries serve as entry points for the exploration, analysis, comparison, and evaluation of circuit functions of the fruit fly brain.",,2021-06-05 20:35:57; 2021-06-05 21:35:36; 2021-06-05 20:54:31; 2021-06-05 21:09:36; 2021-06-06 06:49:06,,,10,eLife,,PubMed Central,PMID: 33616035 PMCID: PMC8016480,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8016480/,,OrientDB; Neo4j; COVID19,OrientDB; Neo4j; COVID19,PMC:Query2; PMC:OrientDB; PMC:Query3; PMC:Neo4j; PMC:COVID19
709,10.7554/eLife.62576,33315010,PMC7909955,A,Neo4j,Neo4j,"Li, Feng; Lindsey, Jack W; Marin, Elizabeth C; Otto, Nils; Dreher, Marisa; Dempsey, Georgia; Stark, Ildiko; Bates, Alexander S; Pleijzier, Markus William; Schlegel, Philipp; Nern, Aljoscha; Takemura, Shin-ya; Eckstein, Nils; Yang, Tansy; Francis, Audrey; Braun, Amalia; Parekh, Ruchi; Costa, Marta; Scheffer, Louis K; Aso, Yoshinori; Jefferis, Gregory SXE; Abbott, Larry F; Litwin-Kumar, Ashok; Waddell, Scott; Rubin, Gerald M",The connectome of the adult Drosophila mushroom body provides insights into function,,eLife,,"Making inferences about the computations performed by neuronal circuits from synapse-level connectivity maps is an emerging opportunity in neuroscience. The mushroom body (MB) is well positioned for developing and testing such an approach due to its conserved neuronal architecture, recently completed dense connectome, and extensive prior experimental studies of its roles in learning, memory, and activity regulation. Here, we identify new components of the MB circuit in Drosophila, including extensive visual input and MB output neurons (MBONs) with direct connections to descending neurons. We find unexpected structure in sensory inputs, in the transfer of information about different sensory modalities to MBONs, and in the modulation of that transfer by dopaminergic neurons (DANs). We provide insights into the circuitry used to integrate MB outputs, connectivity between the MB and the central complex and inputs to DANs, including feedback from MBONs. Our results provide a foundation for further theoretical and experimental work.",,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,,9,eLife,,PubMed Central,PMID: 33315010 PMCID: PMC7909955,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7909955/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
710,10.7717/peerj-cs.235,33816888,PMC7924697,A,Neo4j,Neo4j,"Thilakaratne, Menasha; Falkner, Katrina; Atapattu, Thushari",A systematic review on literature-based discovery workflow,2019,PeerJ Computer Science,,"As scientific publication rates increase, knowledge acquisition and the research development process have become more complex and time-consuming. Literature-Based Discovery (LBD), supporting automated knowledge discovery, helps facilitate this process by eliciting novel knowledge by analysing existing scientific literature. This systematic review provides a comprehensive overview of the LBD workflow by answering nine research questions related to the major components of the LBD workflow (i.e., input, process, output, and evaluation). With regards to the input component, we discuss the data types and data sources used in the literature. The process component presents filtering techniques, ranking/thresholding techniques, domains, generalisability levels, and resources. Subsequently, the output component focuses on the visualisation techniques used in LBD discipline. As for the evaluation component, we outline the evaluation techniques, their generalisability, and the quantitative measures used to validate results. To conclude, we summarise the findings of the review for each component by highlighting the possible future research directions.",2019-11-18,2021-06-05 20:35:57; 2021-06-05 20:55:01; 2021-06-05 21:10:37,,,5,PeerJ Comput Sci,,PubMed Central,PMID: 33816888 PMCID: PMC7924697,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7924697/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
711,10.7717/peerj-cs.297,33816948,PMC7924412,A,Neo4j; COVID19; OrientDB; AllegroGraph,Neo4j; COVID19; OrientDB; AllegroGraph,"ElDahshan, Kamal A.; AlHabshy, AbdAllah A.; Abutaleb, Gaber E.",Data in the time of COVID-19: a general methodology to select and secure a NoSQL DBMS for medical data,2020,PeerJ Computer Science,,"Background As the COVID-19 crisis endures and the virus continues to spread globally, the need for collecting epidemiological data and patient information also grows exponentially. The race against the clock to find a cure and a vaccine to the disease means researchers require storage of increasingly large and diverse types of information; for doctors following patients, recording symptoms and reactions to treatments, the need for storage flexibility is only surpassed by the necessity of storage security. The volume, variety, and variability of COVID-19 patient data requires storage in NoSQL database management systems (DBMSs). But with a multitude of existing NoSQL DBMSs, there is no straightforward way for institutions to select the most appropriate. And more importantly, they suffer from security flaws that would render them inappropriate for the storage of confidential patient data. Motivation This paper develops an innovative solution to remedy the aforementioned shortcomings. COVID-19 patients, as well as medical professionals, could be subjected to privacy-related risks, from abuse of their data to community bullying regarding their medical condition. Thus, in addition to being appropriately stored and analyzed, their data must imperatively be highly protected against misuse. Methods This paper begins by explaining the five most popular categories of NoSQL databases. It also introduces the most popular NoSQL DBMS types related to each one of them. Moreover, this paper presents a comparative study of the different types of NoSQL DBMS, according to their strengths and weaknesses. This paper then introduces an algorithm that would assist hospitals, and medical and scientific authorities to choose the most appropriate type for storing patients’ information. This paper subsequently presents a set of functions, based on web services, offering a set of endpoints that include authentication, authorization, auditing, and encryption of information. These functions are powerful and effective, making them appropriate to store all the sensitive data related to patients. Results and Contributions This paper presents an algorithm to select the most convenient NoSQL DBMS for COVID-19 patients, medical staff, and organizations data. In addition, the paper proposes innovative security solutions that eliminate the barriers to utilizing NoSQL DBMSs to store patients’ data. The proposed solutions resolve several security problems including authentication, authorization, auditing, and encryption. After implementing these security solutions, the use of NoSQL DBMSs will become a much more appropriate, safer, and affordable solution to storing and analyzing patients’ data, which would contribute greatly to the medical and research effort against COVID-19. This solution can be implemented for all types of NoSQL DBMSs; implementing it would result in highly securing patients’ data, and protecting them from any downsides related to data leakage.",2020-09-10,2021-06-05 20:35:57; 2021-06-05 21:35:36; 2021-06-05 20:54:31; 2021-06-05 21:10:08; 2021-06-06 06:49:06; 2021-06-06 06:38:41,,,6,PeerJ Comput Sci,Data in the time of COVID-19,PubMed Central,PMID: 33816948 PMCID: PMC7924412,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7924412/,,Neo4j; COVID19; OrientDB; AllegroGraph,Neo4j; COVID19; OrientDB; AllegroGraph,PMC:AllegroGraph; PMC:Query2; PMC:OrientDB; PMC:Query3; PMC:Neo4j; PMC:COVID19
712,10.7717/peerj-cs.341,33816992,PMC7959619,,,,"Alshahrani, Mona; Thafar, Maha A.; Essack, Magbubah",Application and evaluation of knowledge graph embeddings in biomedical data,2021,PeerJ Computer Science,,"Linked data and bio-ontologies enabling knowledge representation, standardization, and dissemination are an integral part of developing biological and biomedical databases. That is, linked data and bio-ontologies are employed in databases to maintain data integrity, data organization, and to empower search capabilities. However, linked data and bio-ontologies are more recently being used to represent information as multi-relational heterogeneous graphs, “knowledge graphs”. The reason being, entities and relations in the knowledge graph can be represented as embedding vectors in semantic space, and these embedding vectors have been used to predict relationships between entities. Such knowledge graph embedding methods provide a practical approach to data analytics and increase chances of building machine learning models with high prediction accuracy that can enhance decision support systems. Here, we present a comparative assessment and a standard benchmark for knowledge graph-based representation learning methods focused on the link prediction task for biological relations. We systematically investigated and compared state-of-the-art embedding methods based on the design settings used for training and evaluation. We further tested various strategies aimed at controlling the amount of information related to each relation in the knowledge graph and its effects on the final performance. We also assessed the quality of the knowledge graph features through clustering and visualization and employed several evaluation metrics to examine their uses and differences. Based on this systematic comparison and assessments, we identify and discuss the limitations of knowledge graph-based representation learning methods and suggest some guidelines for the development of more improved methods.",2021-02-18,2021-06-05 21:09:36,,,7,PeerJ Comput Sci,,PubMed Central,PMID: 33816992 PMCID: PMC7959619,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7959619/,,,,PMC:Query2
713,10.7717/peerj-cs.516,34084926,PMC8157081,,,,"Ali, Ahmad; Ahmed, Mansoor; Khan, Abid; Anjum, Adeel; Ilyas, Muhammad; Helfert, Markus",VisTAS: blockchain-based visible and trusted remote authentication system,2021,PeerJ Computer Science,,"The information security domain focuses on security needs at all levels in a computing environment in either the Internet of Things, Cloud Computing, Cloud of Things, or any other implementation. Data, devices, services, or applications and communication are required to be protected and provided by information security shields at all levels and in all working states. Remote authentication is required to perform different administrative operations in an information system, and Administrators have full access to the system and may pose insider threats. Superusers and administrators are the most trusted persons in an organisation. “Trust but verify” is an approach to have an eye on the superusers and administrators. Distributed ledger technology (Blockchain-based data storage) is an immutable data storage scheme and provides a built-in facility to share statistics among peers. Distributed ledgers are proposed to provide visible security and non-repudiation, which securely records administrators’ authentications requests. The presence of security, privacy, and accountability measures establish trust among its stakeholders. Securing information in an electronic data processing system is challenging, i.e., providing services and access control for the resources to only legitimate users. Authentication plays a vital role in systems’ security; therefore, authentication and identity management are the key subjects to provide information security services. The leading cause of information security breaches is the failure of identity management/authentication systems and insider threats. In this regard, visible security measures have more deterrence than other schemes. In this paper, an authentication scheme, “VisTAS,” has been introduced, which provides visible security and trusted authentication services to the tenants and keeps the records in the blockchain.",2021-05-12,2021-06-05 21:09:36,,,7,PeerJ Comput Sci,VisTAS,PubMed Central,PMID: 34084926 PMCID: PMC8157081,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8157081/,,,,PMC:Query2
714,10.7717/peerj-cs.521,34084927,PMC8157017,A,Neo4j,Neo4j,"Kerrache, Said",LinkPred: a high performance library for link prediction in complex networks,2021,PeerJ Computer Science,,"The problem of determining the likelihood of the existence of a link between two nodes in a network is called link prediction. This is made possible thanks to the existence of a topological structure in most real-life networks. In other words, the topologies of networked systems such as the World Wide Web, the Internet, metabolic networks, and human society are far from random, which implies that partial observations of these networks can be used to infer information about undiscovered interactions. Significant research efforts have been invested into the development of link prediction algorithms, and some researchers have made the implementation of their methods available to the research community. These implementations, however, are often written in different languages and use different modalities of interaction with the user, which hinders their effective use. This paper introduces LinkPred, a high-performance parallel and distributed link prediction library that includes the implementation of the major link prediction algorithms available in the literature. The library can handle networks with up to millions of nodes and edges and offers a unified interface that facilitates the use and comparison of link prediction algorithms by researchers as well as practitioners.",2021-05-21,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:09:36,,,7,PeerJ Comput Sci,LinkPred,PubMed Central,PMID: 34084927 PMCID: PMC8157017,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8157017/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
715,10.7717/peerj.1558,26844016,PMC4736989,A,Neo4j,Neo4j,"Mullen, Joseph; Cockell, Simon J.; Tipney, Hannah; Woollard, Peter M.; Wipat, Anil",Mining integrated semantic networks for drug repositioning opportunities,2016,PeerJ,,"Current research and development approaches to drug discovery have become less fruitful and more costly. One alternative paradigm is that of drug repositioning. Many marketed examples of repositioned drugs have been identified through serendipitous or rational observations, highlighting the need for more systematic methodologies to tackle the problem. Systems level approaches have the potential to enable the development of novel methods to understand the action of therapeutic compounds, but requires an integrative approach to biological data. Integrated networks can facilitate systems level analyses by combining multiple sources of evidence to provide a rich description of drugs, their targets and their interactions. Classically, such networks can be mined manually where a skilled person is able to identify portions of the graph (semantic subgraphs) that are indicative of relationships between drugs and highlight possible repositioning opportunities. However, this approach is not scalable. Automated approaches are required to systematically mine integrated networks for these subgraphs and bring them to the attention of the user. We introduce a formal framework for the definition of integrated networks and their associated semantic subgraphs for drug interaction analysis and describe DReSMin, an algorithm for mining semantically-rich networks for occurrences of a given semantic subgraph. This algorithm allows instances of complex semantic subgraphs that contain data about putative drug repositioning opportunities to be identified in a computationally tractable fashion, scaling close to linearly with network data. We demonstrate the utility of our approach by mining an integrated drug interaction network built from 11 sources. This work identified and ranked 9,643,061 putative drug-target interactions, showing a strong correlation between highly scored associations and those supported by literature. We discuss the 20 top ranked associations in more detail, of which 14 are novel and 6 are supported by the literature. We also show that our approach better prioritizes known drug-target interactions, than other state-of-the art approaches for predicting such interactions.",2016-01-19,2021-06-05 20:55:40; 2021-06-05 21:12:40; 2021-06-05 20:37:08,,,4,PeerJ,,PubMed Central,PMID: 26844016 PMCID: PMC4736989,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4736989/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
716,10.7717/peerj.3509,28695067,PMC5501156,A,Neo4j,Neo4j,"Costa, Raquel L.; Gadelha, Luiz; Ribeiro-Alves, Marcelo; Porto, Fábio",GeNNet: an integrated platform for unifying scientific workflows and graph databases for transcriptome data analysis,2017,PeerJ,,"There are many steps in analyzing transcriptome data, from the acquisition of raw data to the selection of a subset of representative genes that explain a scientific hypothesis. The data produced can be represented as networks of interactions among genes and these may additionally be integrated with other biological databases, such as Protein-Protein Interactions, transcription factors and gene annotation. However, the results of these analyses remain fragmented, imposing difficulties, either for posterior inspection of results, or for meta-analysis by the incorporation of new related data. Integrating databases and tools into scientific workflows, orchestrating their execution, and managing the resulting data and its respective metadata are challenging tasks. Additionally, a great amount of effort is equally required to run in-silico experiments to structure and compose the information as needed for analysis. Different programs may need to be applied and different files are produced during the experiment cycle. In this context, the availability of a platform supporting experiment execution is paramount. We present GeNNet, an integrated transcriptome analysis platform that unifies scientific workflows with graph databases for selecting relevant genes according to the evaluated biological systems. It includes GeNNet-Wf, a scientific workflow that pre-loads biological data, pre-processes raw microarray data and conducts a series of analyses including normalization, differential expression inference, clusterization and gene set enrichment analysis. A user-friendly web interface, GeNNet-Web, allows for setting parameters, executing, and visualizing the results of GeNNet-Wf executions. To demonstrate the features of GeNNet, we performed case studies with data retrieved from GEO, particularly using a single-factor experiment in different analysis scenarios. As a result, we obtained differentially expressed genes for which biological functions were analyzed. The results are integrated into GeNNet-DB, a database about genes, clusters, experiments and their properties and relationships. The resulting graph database is explored with queries that demonstrate the expressiveness of this data model for reasoning about gene interaction networks. GeNNet is the first platform to integrate the analytical process of transcriptome data with graph databases. It provides a comprehensive set of tools that would otherwise be challenging for non-expert users to install and use. Developers can add new functionality to components of GeNNet. The derived data allows for testing previous hypotheses about an experiment and exploring new ones through the interactive graph database environment. It enables the analysis of different data on humans, rhesus, mice and rat coming from Affymetrix platforms. GeNNet is available as an open source platform at https://github.com/raquele/GeNNet and can be retrieved as a software container with the command docker pull quelopes/gennet.",2017; 2017-07-05,2021-06-05 20:55:40; 2021-06-05 21:06:22; 2021-06-05 21:12:01; 2021-06-05 20:36:32,e3509,,5,PeerJ,GeNNet,PubMed; PubMed Central,PMID: 28695067 PMCID: PMC5501156,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5501156/; http://www.ncbi.nlm.nih.gov/pubmed/28695067,Data-to-knowledge; GeNNet; Graph database; Microarray; Provenance; Scientific workflow; Software container; Transcriptome,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PubMed:Query2; PMC:Query2
717,10.7717/peerj.6739,30993051,PMC6459178,A,Neo4j; Fauna,Neo4j; Fauna,"Page, Roderic D.M.",Ozymandias: a biodiversity knowledge graph,2019,PeerJ,,"Enormous quantities of biodiversity data are being made available online, but much of this data remains isolated in silos. One approach to breaking these silos is to map local, often database-specific identifiers to shared global identifiers. This mapping can then be used to construct a knowledge graph, where entities such as taxa, publications, people, places, specimens, sequences, and institutions are all part of a single, shared knowledge space. Motivated by the 2018 GBIF Ebbe Nielsen Challenge I explore the feasibility of constructing a “biodiversity knowledge graph” for the Australian fauna. The data cleaning and reconciliation steps involved in constructing the knowledge graph are described in detail. Examples are given of its application to understanding changes in patterns of taxonomic publication over time. A web interface to the knowledge graph (called “Ozymandias”) is available at https://ozymandias-demo.herokuapp.com.",2019-04-08,2021-06-05 20:55:01; 2021-06-06 07:33:06; 2021-06-05 20:36:32; 2021-06-05 21:10:37,,,7,PeerJ,Ozymandias,PubMed Central,PMID: 30993051 PMCID: PMC6459178,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6459178/,,Neo4j; Fauna,Neo4j; Fauna,PMC:Query3; PMC:Neo4j; PMC:Query2; PMC:Fauna
718,10.7717/peerj.9302,33240576,PMC7676376,A,Neo4j,Neo4j,"Chen, Jiaming; Cao, Hongbao; Lian, Meng; Fang, Jugao",Five genes influenced by obesity may contribute to the development of thyroid cancer through the regulation of insulin levels,2020,PeerJ,,"Previous studies indicate that obesity is an important contributor to the proceeding of thyroid cancer (TC) with limited knowledge of the underlying mechanism. Here, we hypothesize that molecules affected by obesity may play roles in the development of TC. To test the hypothesis above, we first conducted a large-scale literature-based data mining to identify genes influenced by obesity and genes related to TC. Then, a mega-analysis was conducted to study the expression changes of the obesity-specific genes in the case of TC, using 16 independent TC array-expression datasets (783 TC cases and 439 healthy controls). After that, pathway analysis was performed to explore the functional profile of the selected target genes and their potential connections with TC. We identified 1,036 genes associated with TC and 534 regulated by obesity, demonstrating a significant overlap (N = 176, p-value = 4.07e−112). Five out of the 358 obesity-specific genes, FABP4, CFD, GHR, TNFRSF11B, and LTF, presented significantly decreased expression in TC patients (LFC<−1.44; and p-value < 1e−7). Multiple literature-based pathways were identified where obesity could promote the pathologic development of TC through the regulation of these five genes and INS levels. The five obesity genes uncovered could be novel genes that play roles in the etiology of TC through the modulation of INS levels.",2020-07-28,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08,,,8,PeerJ,,PubMed Central,PMID: 33240576 PMCID: PMC7676376,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7676376/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
719,,11752346,PMC99131,,,,"Klosterman, Peter S.; Tamura, Makio; Holbrook, Stephen R.; Brenner, Steven E.",SCOR: a Structural Classification of RNA database,2002,Nucleic Acids Research,,"The Structural Classification of RNA (SCOR) database provides a survey of the three-dimensional motifs contained in 259 NMR and X-ray RNA structures. In one classification, the structures are grouped according to function. The RNA motifs, including internal and external loops, are also organized in a hierarchical classification. The 259 database entries contain 223 internal and 203 external loops; 52 entries consist of fully complementary duplexes. A classification of the well-characterized tertiary interactions found in the larger RNA structures is also included along with examples. The SCOR database is accessible at http://scor.lbl.gov.",2002-01-01,2021-06-05 21:14:07,392-394,1,30,Nucleic Acids Res,SCOR,PubMed Central,PMID: 11752346 PMCID: PMC99131,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC99131/,,,,PMC:Query2
720,,19507286,PMC2730413,,,,"Smalter, Aaron; Huan, Jun; Lushington, Gerald",GRAPH WAVELET ALIGNMENT KERNELS FOR DRUG VIRTUAL SCREENING,2009,Journal of bioinformatics and computational biology,,"In this paper we introduce a novel graph classification algorithm and demonstrate its efficacy in drug design. In our method, we use graphs to model chemical structures and apply a wavelet analysis of graphs to create features capturing graph local topology. We design a novel graph kernel function to utilize the created feature to build predictive models for chemicals. We call the new graph kernel a graph wavelet-alignment kernel., We have evaluated the efficacy of the wavelet-alignment kernel using a set of chemical structure-activity prediction benchmarks. Our results indicate that the use of the kernel function yields performance profiles comparable to, and sometimes exceeding that of the existing state-of-the-art chemical classification approaches. In addition, our results also show that the use of wavelet functions significantly decreases the computational costs for graph kernel computation with more than 10 fold speed up.",2009-06,2021-06-05 21:13:27,473-497,3,7,J Bioinform Comput Biol,,PubMed Central,PMID: 19507286 PMCID: PMC2730413,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2730413/,,,,PMC:Query2
721,,20815142,PMC2936724,,,,"Lei, Seak Fei; Huan, Jun",Towards Site-based Protein Functional Annotations,2010,International journal of data mining and bioinformatics,,"The exact relationship between protein active centers and protein functions is unclear even after decades of intensive study. To improve the functional prediction ability based on the local protein structures, we proposed three different methods. 1) We used statistical model (known as Markov Random Field) to describe protein active region based on the structure motifs. 2) We developd a filter that considers the local environment around the active sites to remove the false positives. 3) we created multiple structure motifs by extending the motif to neighboring residues for delineating their functions., Our experimental results, as evaluated in five sets of enzyme families with less than 40% sequence identity, demonstrated that our methods can obtain more remote homologs that could not be detected by traditional sequence-based methods. At the same time, our method could reduce large amount of random matches. Our methods could improve up to 70 % of the functional annotation ability (measured by their Area under the ROC curve) in extended motif method.",2010,2021-06-05 21:13:27,452-470,4,4,Int J Data Min Bioinform,,PubMed Central,PMID: 20815142 PMCID: PMC2936724,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2936724/,,,,PMC:Query2
722,,23304382,PMC3540524,A,Virtuoso,Virtuoso,"Zhang, Guo-Qiang; Luo, Lingyun; Ogbuji, Chime; Joslyn, Cliff; Mejino, Jose; Sahoo, Satya S",An Analysis of Multi-type Relational Interactions in FMA Using Graph Motifs with Disjointness Constraints,2012,AMIA Annual Symposium Proceedings,,"The interaction of multiple types of relationships among anatomical classes in the Foundational Model of Anatomy (FMA) can provide inferred information valuable for quality assurance. This paper introduces a method called Motif Checking (MOCH) to study the effects of such multi-relation type interactions for detecting logical inconsistencies as well as other anomalies represented by the motifs. MOCH represents patterns of multi-type interaction as small labeled (with multiple types of edges) sub-graph motifs, whose nodes represent class variables, and labeled edges represent relational types. By representing FMA as an RDF graph and motifs as SPARQL queries, fragments of FMA are automatically obtained as auditing candidates. Leveraging the scalability and reconfigurability of Semantic Web Technology, we performed exhaustive analyses of a variety of labeled sub-graph motifs. The quality assurance feature of MOCH comes from the distinct use of a subset of the edges of the graph motifs as constraints for disjointness, whereby bringing in rule-based flavor to the approach as well. With possible disjointness implied by antonyms, we performed manual inspection of the resulting FMA fragments and tracked down sources of abnormal inferred conclusions (logical inconsistencies), which are amendable for programmatic revision of the FMA. Our results demonstrate that MOCH provides a unique source of valuable information for quality assurance. Since our approach is general, it is applicable to any ontological system with an OWL representation.",2012-11-03,2021-06-05 21:13:27; 2021-06-05 20:56:20; 2021-06-05 20:59:14,1060-1069,,2012,AMIA Annu Symp Proc,,PubMed Central,PMID: 23304382 PMCID: PMC3540524,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3540524/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
723,,23304411,PMC3540421,,,,"Nabhan, Ahmed Ragab; Sarkar, Indra Neil",Mining Disease Fingerprints From Within Genetic Pathways,2012,AMIA Annual Symposium Proceedings,,"Mining biological networks can be an effective means to uncover system level knowledge out of micro level associations, such as encapsulated in genetic pathways. Analysis of human disease genetic pathways can lead to the identification of major mechanisms that may underlie disorders at an abstract functional level. The focus of this study was to develop an approach for structural pattern analysis and classification of genetic pathways of diseases. A probabilistic model was developed to capture characteristic components (‘fingerprints’) of functionally annotated pathways. A probability estimation procedure of this model searched for fingerprints in each disease pathway while improving probability estimates of model parameters. The approach was evaluated on data from the Kyoto Encyclopedia of Genes and Genomes (consisting of 56 pathways across seven disease categories). Based on the achieved average classification accuracy of up to ∼77%, the findings suggest that these fingerprints may be used for classification and discovery of genetic pathways.",2012-11-03,2021-06-05 21:13:27,1320-1329,,2012,AMIA Annu Symp Proc,,PubMed Central,PMID: 23304411 PMCID: PMC3540421,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3540421/,,,,PMC:Query2
724,,24187650,PMC3814183,A,Neo4j,Neo4j,"Aji, Ablimit; Wang, Fusheng; Vo, Hoang; Lee, Rubao; Liu, Qiaoling; Zhang, Xiaodong; Saltz, Joel",Hadoop-GIS: A High Performance Spatial Data Warehousing System over MapReduce,2013,Proceedings of the VLDB Endowment International Conference on Very Large Data Bases,,"Support of high performance queries on large volumes of spatial data becomes increasingly important in many application domains, including geospatial problems in numerous fields, location based services, and emerging scientific applications that are increasingly data- and compute-intensive. The emergence of massive scale spatial data is due to the proliferation of cost effective and ubiquitous positioning technologies, development of high resolution imaging technologies, and contribution from a large number of community users. There are two major challenges for managing and querying massive spatial data to support spatial queries: the explosion of spatial data, and the high computational complexity of spatial queries. In this paper, we present Hadoop-GIS – a scalable and high performance spatial data warehousing system for running large scale spatial queries on Hadoop. Hadoop-GIS supports multiple types of spatial queries on MapReduce through spatial partitioning, customizable spatial query engine RESQUE, implicit parallel spatial query execution on MapReduce, and effective methods for amending query results through handling boundary objects. Hadoop-GIS utilizes global partition indexing and customizable on demand local spatial indexing to achieve efficient query processing. Hadoop-GIS is integrated into Hive to support declarative spatial queries with an integrated architecture. Our experiments have demonstrated the high efficiency of Hadoop-GIS on query response and high scalability to run on commodity clusters. Our comparative experiments have showed that performance of Hadoop-GIS is on par with parallel SDBMS and outperforms SDBMS for compute-intensive queries. Hadoop-GIS is available as a set of library for processing spatial queries, and as an integrated software package in Hive.",2013-08,2021-06-05 21:13:27; 2021-06-05 20:56:20; 2021-06-05 20:37:08,,11,6,Proceedings VLDB Endowment,Hadoop-GIS,PubMed Central,PMID: 24187650 PMCID: PMC3814183,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3814183/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
725,,24723987,PMC3979555,,,,"Wang, Yue; Wu, Xintao",Preserving Differential Privacy in Degree-Correlation based Graph Generation,2013,Transactions on data privacy,,"Enabling accurate analysis of social network data while preserving differential privacy has been challenging since graph features such as cluster coefficient often have high sensitivity, which is different from traditional aggregate functions (e.g., count and sum) on tabular data. In this paper, we study the problem of enforcing edge differential privacy in graph generation. The idea is to enforce differential privacy on graph model parameters learned from the original network and then generate the graphs for releasing using the graph model with the private parameters. In particular, we develop a differential privacy preserving graph generator based on the dK-graph generation model. We first derive from the original graph various parameters (i.e., degree correlations) used in the dK-graph model, then enforce edge differential privacy on the learned parameters, and finally use the dK-graph model with the perturbed parameters to generate graphs. For the 2K-graph model, we enforce the edge differential privacy by calibrating noise based on the smooth sensitivity, rather than the global sensitivity. By doing this, we achieve the strict differential privacy guarantee with smaller magnitude noise. We conduct experiments on four real networks and compare the performance of our private dK-graph models with the stochastic Kronecker graph generation model in terms of utility and privacy tradeoff. Empirical evaluations show the developed private dK-graph generation models significantly outperform the approach based on the stochastic Kronecker generation model.",2013-08-01,2021-06-05 21:13:27,127-145,2,6,Trans Data Priv,,PubMed Central,PMID: 24723987 PMCID: PMC3979555,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3979555/,,,,PMC:Query2
726,,26262393,,A,Neo4j,Neo4j,"Hristovski, Dimitar; Kastrin, Andrej; Dinevski, Dejan; Rindflesch, Thomas C.",Constructing a Graph Database for Semantic Literature-Based Discovery,2015,Studies in Health Technology and Informatics,,"Literature-based discovery (LBD) generates discoveries, or hypotheses, by combining what is already known in the literature. Potential discoveries have the form of relations between biomedical concepts; for example, a drug may be determined to treat a disease other than the one for which it was intended. LBD views the knowledge in a domain as a network; a set of concepts along with the relations between them. As a starting point, we used SemMedDB, a database of semantic relations between biomedical concepts extracted with SemRep from Medline. SemMedDB is distributed as a MySQL relational database, which has some problems when dealing with network data. We transformed and uploaded SemMedDB into the Neo4j graph database, and implemented the basic LBD discovery algorithms with the Cypher query language. We conclude that storing the data needed for semantic LBD is more natural in a graph database. Also, implementing LBD discovery algorithms is conceptually simpler with a graph query language when compared with standard SQL.",2015,2021-06-05 21:24:28; 2021-06-05 21:06:22; 2021-06-05 21:16:51,1094,,216,Stud Health Technol Inform,,PubMed,PMID: 26262393,http://www.ncbi.nlm.nih.gov/pubmed/26262393,"Data Mining; Database Management Systems; Databases, Factual; Machine Learning; Natural Language Processing; Periodicals as Topic; Semantics; Terminology as Topic; Vocabulary, Controlled",Neo4j,Neo4j,PubMed:Neo4j; PubMed:Query3; PubMed:Query2
727,,26705540,PMC4688019,,,,"Tao, Fangbo; Zhao, Bo; Fuxman, Ariel; Li, Yang; Han, Jiawei",Leveraging Pattern Semantics for Extracting Entities in Enterprises,2015,Proceedings of the ... International World-Wide Web Conference. International WWW Conference,,"Entity Extraction is a process of identifying meaningful entities from text documents. In enterprises, extracting entities improves enterprise efficiency by facilitating numerous applications, including search, recommendation, etc. However, the problem is particularly challenging on enterprise domains due to several reasons. First, the lack of redundancy of enterprise entities makes previous web-based systems like NELL and OpenIE not effective, since using only high-precision/low-recall patterns like those systems would miss the majority of sparse enterprise entities, while using more low-precision patterns in sparse setting also introduces noise drastically. Second, semantic drift is common in enterprises (“Blue” refers to “Windows Blue”), such that public signals from the web cannot be directly applied on entities. Moreover, many internal entities never appear on the web. Sparse internal signals are the only source for discovering them. To address these challenges, we propose an end-to-end framework for extracting entities in enterprises, taking the input of enterprise corpus and limited seeds to generate a high-quality entity collection as output. We introduce the novel concept of Semantic Pattern Graph to leverage public signals to understand the underlying semantics of lexical patterns, reinforce pattern evaluation using mined semantics, and yield more accurate and complete entities. Experiments on Microsoft enterprise data show the effectiveness of our approach.",2015-05,2021-06-05 21:12:40,1078-1088,,2015,Proc Int World Wide Web Conf,,PubMed Central,PMID: 26705540 PMCID: PMC4688019,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4688019/,,,,PMC:Query2
728,,26958167,PMC4765692,,,,"Campbell, James Richard; Campbell, Walter Scott; Hickman, Hubert; Pedersen, Jay; McClay, James",Employing complex polyhierarchical ontologies and promoting interoperability of i2b2 data systems,2015,AMIA Annual Symposium Proceedings,,"I2b2 is in widespread use for managing research data warehouses. It employs reference ontologies as a record index and supports searching for aggregate cases using a pattern match operator on ASCII strings representing the node traversal from root to concept(PATHs). This creates complexities in dissemination and deployment for large polyhierarchical ontologies such as SNOMED CT. We hypothesized that an alternative approach employing transitive closure tables (TC) could lead to more accurate, efficient and interoperable search tools for i2b2. We evaluated search speed, accuracy and interoperability of queries employing each approach. We found both TC-based and PATH-based queries to produce accurate results. However, we observed that TC-based queries involving concepts included in large numbers of paths ran substantially faster than PATH-based queries for the same concept. Oracle query plan resource estimates differed by one to three orders of magnitude for these queries. We conclude that a simplification of dissemination tools for SNOMED CT and revision in the metadata build for i2b2 can effectively employ SNOMED CT with increased efficiency and comparable accuracy. Use of transitive closure tables in metadata can promote network query interoperability.",2015-11-05,2021-06-05 21:12:40,359-365,,2015,AMIA Annu Symp Proc,,PubMed Central,PMID: 26958167 PMCID: PMC4765692,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4765692/,,,,PMC:Query2
729,,26958175,PMC4765596,A,Virtuoso,Virtuoso,"Choquet, Remy; Maaroufi, Meriem; Fonjallaz, Yannick; de Carrara, Albane; Vandenbussche, Pierre-Yves; Dhombres, Ferdinand; Landais, Paul",LORD: a phenotype-genotype semantically integrated biomedical data tool to support rare disease diagnosis coding in health information systems,2015,AMIA Annual Symposium Proceedings,,"Characterizing a rare disease diagnosis for a given patient is often made through expert’s networks. It is a complex task that could evolve over time depending on the natural history of the disease and the evolution of the scientific knowledge. Most rare diseases have genetic causes and recent improvements of sequencing techniques contribute to the discovery of many new diseases every year. Diagnosis coding in the rare disease field requires data from multiple knowledge bases to be aggregated in order to offer the clinician a global information space from possible diagnosis to clinical signs (phenotypes) and known genetic mutations (genotype). Nowadays, the major barrier to the coding activity is the lack of consolidation of such information scattered in different thesaurus such as Orphanet, OMIM or HPO. The Linking Open data for Rare Diseases (LORD) web portal we developed stands as the first attempt to fill this gap by offering an integrated view of 8,400 rare diseases linked to more than 14,500 signs and 3,270 genes. The application provides a browsing feature to navigate through the relationships between diseases, signs and genes, and some Application Programming Interfaces to help its integration in health information systems in routine.",2015-11-05,2021-06-05 20:55:40; 2021-06-05 21:12:40; 2021-06-05 20:59:14,434-440,,2015,AMIA Annu Symp Proc,LORD,PubMed Central,PMID: 26958175 PMCID: PMC4765596,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4765596/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
730,,27013932,PMC4803025,A,AllegroGraph,AllegroGraph,"Utecht, Joseph; Brochhausen, Mathias",Measuring the Usability of Triple Stores for Knowledge Management on Trauma Care Organizations,2015,CEUR workshop proceedings,,,2015-12,2021-06-05 20:55:40; 2021-06-06 06:38:41; 2021-06-05 21:12:40,241-242,,1546,CEUR Workshop Proc,,PubMed Central,PMID: 27013932 PMCID: PMC4803025,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4803025/,,AllegroGraph,AllegroGraph,PMC:Query3; PMC:AllegroGraph; PMC:Query2
731,,27570653,PMC5001762,A,Virtuoso,Virtuoso,"Ong, Edison; He, Yongqun","Community-based Ontology Development, Annotation and Discussion with MediaWiki extension Ontokiwi and Ontokiwi-based Ontobedia",2016,AMIA Summits on Translational Science Proceedings,,"Hundreds of biological and biomedical ontologies have been developed to support data standardization, integration and analysis. Although ontologies are typically developed for community usage, community efforts in ontology development are limited. To support ontology visualization, distribution, and community-based annotation and development, we have developed Ontokiwi, an ontology extension to the MediaWiki software. Ontokiwi displays hierarchical classes and ontological axioms. Ontology classes and axioms can be edited and added using Ontokiwi form or MediaWiki source editor. Ontokiwi also inherits MediaWiki features such as Wikitext editing and version control. Based on the Ontokiwi/MediaWiki software package, we have developed Ontobedia, which targets to support community-based development and annotations of biological and biomedical ontologies. As demonstrations, we have loaded the Ontology of Adverse Events (OAE) and the Cell Line Ontology (CLO) into Ontobedia. Our studies showed that Ontobedia was able to achieve expected Ontokiwi features.",2016-07-20,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:59:14,65-74,,2016,AMIA Jt Summits Transl Sci Proc,,PubMed Central,PMID: 27570653 PMCID: PMC5001762,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5001762/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
732,,27570666,PMC5001752,,,,"Odgers, David J.; Tellis, Natalie; Hall, Heather; Dumontier, Michel",Using LASSO Regression to Predict Rheumatoid Arthritis Treatment Efficacy,2016,AMIA Summits on Translational Science Proceedings,,"Rheumatoid arthritis (RA) accounts for one-fifth of the deaths due to arthritis, the leading cause of disability in the United States. Finding effective treatments for managing arthritis symptoms are a major challenge, since the mechanisms of autoimmune disorders are not fully understood and disease presentation differs for each patient. The American College of Rheumatology clinical guidelines for treatment consider the severity of the disease when deciding treatment, but do not include any prediction of drug efficacy., Using Electronic Health Records and Biomedical Linked Open Data (LOD), we demonstrate a method to classify patient outcomes using LASSO penalized regression. We show how Linked Data improves prediction and provides insight into how drug treatment regimes have different treatment outcome. Applying classifiers like this to decision support in clinical applications could decrease time to successful disease management, lessening a physical and financial burden on patients individually and the healthcare system as a whole.",2016-07-20,2021-06-05 21:12:01,176-183,,2016,AMIA Jt Summits Transl Sci Proc,,PubMed Central,PMID: 27570666 PMCID: PMC5001752,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5001752/,,,,PMC:Query2
733,,27570667,PMC5001768,A,Neo4j,Neo4j,"Post, Andrew R.; Pai, Akshatha K.; Willard, Richard; May, Bradley J.; West, Andrew C.; Agravat, Sanjay; Granite, Stephen J.; Winslow, Raimond L.; Stephens, David S.",Metadata-driven Clinical Data Loading into i2b2 for Clinical and Translational Science Institutes,2016,AMIA Summits on Translational Science Proceedings,,"Clinical and Translational Science Award (CTSA) recipients have a need to create research data marts from their clinical data warehouses, through research data networks and the use of i2b2 and SHRINE technologies. These data marts may have different data requirements and representations, thus necessitating separate extract, transform and load (ETL) processes for populating each mart. Maintaining duplicative procedural logic for each ETL process is onerous. We have created an entirely metadata-driven ETL process that can be customized for different data marts through separate configurations, each stored in an extension of i2b2 ‘s ontology database schema. We extended our previously reported and open source Eureka! Clinical Analytics software with this capability. The same software has created i2b2 data marts for several projects, the largest being the nascent Accrual for Clinical Trials (ACT) network, for which it has loaded over 147 million facts about 1.2 million patients.",2016-07-20,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:37:08,184-193,,2016,AMIA Jt Summits Transl Sci Proc,,PubMed Central,PMID: 27570667 PMCID: PMC5001768,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5001768/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
734,,27577487,,A,,,"Hofer, Philipp; Neururer, Sabrina; Goebel, Georg",Semi-Automated Annotation of Biobank Data Using Standard Medical Terminologies in a Graph Database,2016,Studies in Health Technology and Informatics,,"Data describing biobank resources frequently contains unstructured free-text information or insufficient coding standards. (Bio-) medical ontologies like Orphanet Rare Diseases Ontology (ORDO) or the Human Disease Ontology (DOID) provide a high number of concepts, synonyms and entity relationship properties. Such standard terminologies increase quality and granularity of input data by adding comprehensive semantic background knowledge from validated entity relationships. Moreover, cross-references between terminology concepts facilitate data integration across databases using different coding standards. In order to encourage the use of standard terminologies, our aim is to identify and link relevant concepts with free-text diagnosis inputs within a biobank registry. Relevant concepts are selected automatically by lexical matching and SPARQL queries against a RDF triplestore. To ensure correctness of annotations, proposed concepts have to be confirmed by medical data administration experts before they are entered into the registry database. Relevant (bio-) medical terminologies describing diseases and phenotypes were identified and stored in a graph database which was tied to a local biobank registry. Concept recommendations during data input trigger a structured description of medical data and facilitate data linkage between heterogeneous systems.",2016,2021-06-05 21:06:22,755-759,,228,Stud Health Technol Inform,,PubMed,PMID: 27577487,http://www.ncbi.nlm.nih.gov/pubmed/27577487,"Biological Specimen Banks; Databases, Factual; Humans; Information Storage and Retrieval; Semantics; Systems Integration",,,PubMed:Query2
735,,28423797,PMC7767581,,,,"SCHLEGEL, Daniel R.; CROWNER, Chris; LEHOULLIER, Frank; ELKIN, Peter L.",HTP-NLP: A New NLP System for High Throughput Phenotyping,2017,Studies in health technology and informatics,,"Secondary use of large amounts of clinical data requires a method to quickly process such data in such a way that researchers can quickly extract cohorts of interest for a given study. We present two advances in the High Throughput Phenotyping NLP system which support the aim of truly high throughput processing of clinical data, inspired by a characterization of the linguistic properties of such data. Semantic indexing to store and generalize partially-processed results and the use of compositional expressions for ungrammatical text are discussed, along with a set of initial timing results for the system.",2017,2021-06-05 21:12:01,276-280,,235,Stud Health Technol Inform,HTP-NLP,PubMed Central,PMID: 28423797 PMCID: PMC7767581,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7767581/,,,,PMC:Query2
736,,29295165,PMC6528652,A,Neo4j,Neo4j,"Sinha, Shyamashree; Burstein, Gale R; Leonard, Kenneth E; Murphy, Timothy F; Elkin, Peter L",Prescription Opioid Dependence in Western New York: Using Data Analytics to Find an Answer to the Opioid Epidemic,2017,Studies in health technology and informatics,,"Opioid dependence and overdose is on the rise. One indicator is the increasing trends of prescription buprenorphine use among patient on chronic pain medication. In addition to the New York State Department of Health’s prescription drug monitoring programs and trainingprograms for providers and first responders to detect and treat a narcotic overdose, further examination of the population may provide important information for multidisciplinary interventions to address this epidemic. This paper uses an observational database with a Natural Language Processing (NLP) based Not Only Structured Query Language architecture to examine Electronic Health Record (EHR) data at a regional level to study the trends of prescription opioid dependence. We aim to help prioritize interventions in vulnerable population subgroups. This study provides a report of the demographic patterns of opioid dependent patients in Western New York using High Throughput Phenotyping NLP of EHR data.",2017,2021-06-05 20:55:40; 2021-06-05 21:12:01; 2021-06-05 20:37:08,594-598,,245,Stud Health Technol Inform,Prescription Opioid Dependence in Western New York,PubMed Central,PMID: 29295165 PMCID: PMC6528652,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6528652/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
737,,29782620,PMC5958914,,,,"Papageorgiou, Louis; Eleni, Picasi; Raftopoulou, Sofia; Mantaiou, Meropi; Megalooikonomou, Vasileios; Vlachakis, Dimitrios",Genomic big data hitting the storage bottleneck,2018,EMBnet.journal,,"During the last decades, there is a vast data explosion in bioinformatics. Big data centres are trying to face this data crisis, reaching high storage capacity levels. Although several scientific giants examine how to handle the enormous pile of information in their cupboards, the problem remains unsolved. On a daily basis, there is a massive quantity of permanent loss of extensive information due to infrastructure and storage space problems. The motivation for sequencing has fallen behind. Sometimes, the time that is spent to solve storage space problems is longer than the one dedicated to collect and analyse data. To bring sequencing to the foreground, scientists have to slide over such obstacles and find alternative ways to approach the issue of data volume. Scientific community experiences the data crisis era, where, out of the box solutions may ease the typical research workflow, until technological development meets the needs of Bioinformatics.",2018,2021-06-05 21:11:16,,,24,EMBnet J,,PubMed Central,PMID: 29782620 PMCID: PMC5958914,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5958914/,,,,PMC:Query2
738,,29854174,PMC5977715,,,,"Kim, Youngjun; Riloff, Ellen; Meystre, Stéphane M.",Exploiting Unlabeled Texts with Clustering-based Instance Selection for Medical Relation Classification,2018,AMIA Annual Symposium Proceedings,,"Classifying relations between pairs of medical concepts in clinical texts is a crucial task to acquire empirical evidence relevant to patient care. Due to limited labeled data and extremely unbalanced class distributions, medical relation classification systems struggle to achieve good performance on less common relation types, which capture valuable information that is important to identify. Our research aims to improve relation classification using weakly supervised learning. We present two clustering-based instance selection methods that acquire a diverse and balanced set of additional training instances from unlabeled data. The first method selects one representative instance from each cluster containing only unlabeled data. The second method selects a counterpart for each training instance using clusters containing both labeled and unlabeled data. These new instance selection methods for weakly supervised learning achieve substantial recall gains for the minority relation classes compared to supervised learning, while yielding comparable performance on the majority relation classes.",2018-04-16,2021-06-05 21:11:16,1060-1069,,2017,AMIA Annu Symp Proc,,PubMed Central,PMID: 29854174 PMCID: PMC5977715,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5977715/,,,,PMC:Query2
739,,29854223,PMC5977595,,,,"Sharma, Vivekanand; Law, Wayne; Balick, Michael J.; Sarkar, Indra Neil",Harnessing Biomedical Natural Language Processing Tools to Identify Medicinal Plant Knowledge from Historical Texts,2018,AMIA Annual Symposium Proceedings,,"The growing amount of data describing historical medicinal uses of plants from digitization efforts provides the opportunity to develop systematic approaches for identifying potential plant-based therapies. However, the task of cataloguing plant use information from natural language text is a challenging task for ethnobotanists. To date, there have been only limited adoption of informatics approaches used for supporting the identification of ethnobotanical information associated with medicinal uses. This study explored the feasibility of using biomedical terminologies and natural language processing approaches for extracting relevant plant-associated therapeutic use information from historical biodiversity literature collection available from the Biodiversity Heritage Library. The results from this preliminary study suggest that there is potential utility of informatics methods to identify medicinal plant knowledge from digitized resources as well as highlight opportunities for improvement.",2018-04-16,2021-06-05 21:11:16,1537-1546,,2017,AMIA Annu Symp Proc,,PubMed Central,PMID: 29854223 PMCID: PMC5977595,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5977595/,,,,PMC:Query2
740,,29888036,PMC5961787,A,AllegroGraph; Neo4j,AllegroGraph; Neo4j,"Al–Taie, Zainab; Thanintorn, Nattapon; Ersoy, Ilker; Kholod, Olha; Taylor, Kristen; Hammer, Richard; Shin, Dmitriy",REDESIGN: RDF–based Differential Signaling Framework for Precision Medicine Analytics,2018,AMIA Summits on Translational Science Proceedings,,"Pathway-based analysis holds promise to be instrumental in precision and personalized medicine analytics. However, the majority of pathway-based analysis methods utilize “fixed” or “rigid” data sets that limit their ability to account for complex biological inter-dependencies. Here, we present REDESIGN: RDF-based Differential Signaling Pathway informatics framework. The distinctive feature of the REDESIGN is that it is designed to run on “flexible” ontology-enabled data sets of curated signal transduction pathway maps to uncover high explanatory differential pathway mechanisms on gene-to-gene level. The experiments on two morphoproteomic cases demonstrated REDESIGN’s capability to generate actionable hypotheses in precision/personalized medicine analytics.",2018-05-18,2021-06-06 06:38:41; 2021-06-05 20:55:01; 2021-06-05 21:11:16; 2021-06-05 20:36:32,35-44,,2018,AMIA Jt Summits Transl Sci Proc,REDESIGN,PubMed Central,PMID: 29888036 PMCID: PMC5961787,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5961787/,,AllegroGraph; Neo4j,AllegroGraph; Neo4j,PMC:Query3; PMC:Neo4j; PMC:AllegroGraph; PMC:Query2
741,,29888095,PMC5961782,,,,"Paris, Nicolas; Mendis, Michael; Daniel, Christel; Murphy, Shawn; Tannier, Xavier; Zweigenbaum, Pierre",i2b2 implemented over SMART-on-FHIR,2018,AMIA Summits on Translational Science Proceedings,,"Integrating Biology and the Bedside (i2b2) is the de-facto open-source medical tool for cohort discovery. Fast Healthcare Interoperability Resources (FHIR) is a new standard for exchanging health care information electronically. Substitutable Modular third-party Applications (SMART) defines the SMART-on-FHIR specification on how applications shall interface with Electronic Health Records (EHR) through FHIR. Related work made it possible to produce FHIR from an i2b2 instance or made i2b2 able to store FHIR datasets. In this paper, we extend i2b2 to search remotely into one or multiple SMART-on-FHIR Application Programming Interfaces (APIs). This enables the federation of queries, security, terminology mapping, and also bridges the gap between i2b2 and modern big-data technologies.",2018-05-18,2021-06-05 21:11:16,369-378,,2018,AMIA Jt Summits Transl Sci Proc,,PubMed Central,PMID: 29888095 PMCID: PMC5961782,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5961782/,,,,PMC:Query2
742,,29968601,PMC6599591,,,,"MULLIN, Sarah; ZHAO, Jane; SINHA, Shyamashree; LEE, Robert; SONG, Buer; ELKIN, Peter L",Clinical Data Warehouse Query and Learning Tool Using a Human-Centered Participatory Design Process,2018,Studies in health technology and informatics,,"BMI Investigator (BMII) is an interactive web-based tool with a learning knowledge base, which provides a way for researchers to query structured, unstructured, genomic and image data contained in a data warehouse. We demonstrate how development of an efficient, usable, and learnable web interface for a diverse group of research stakeholders benefits from an iterative human- centered participatory design process utilizing a team of clinicians, students, programmers, and informatics experts.",2018,2021-06-05 21:11:16,59-62,,251,Stud Health Technol Inform,,PubMed Central,PMID: 29968601 PMCID: PMC6599591,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6599591/,,,,PMC:Query2
743,,30147040,,A,Neo4j,Neo4j,"Ulrich, Hannes; Kock-Schoppenhauer, Ann-Kristin; Duhm-Harbeck, Petra; Ingenerf, Josef",Using Graph Tools on Metadata Repositories,2018,Studies in Health Technology and Informatics,,"To exchange data across several sites or to interpret it at a later point in time, it is necessary to create a general understanding of the data. As a standard practice, this understanding is achieved through metadata. These metadata are usually stored in relational databases, so-called metadata repositories (MDR). Typical functions of such an MDR include pure storage, administration and other specific metadata functionalities such as finding relations among data elements. This results in a multitude of connections between the data elements, which can be described as highly interconnected graphs. To use alternative databases such as graph databases for modelling and visualisation it has already been proven to be beneficial in previous studies. The objective of this work is to evaluate how on-board techniques rely on matching and mapping using a graph database. Different datasets relating to cancer were entered, and algorithms for metadata management were applied.",2018,2021-06-05 21:24:28; 2021-06-05 21:06:22; 2021-06-05 21:16:51,55-59,,253,Stud Health Technol Inform,,PubMed,PMID: 30147040,http://www.ncbi.nlm.nih.gov/pubmed/30147040,"Algorithms; Databases, Factual; graph database; Metadata; Metadata repository; Neo4j; Statistics as Topic",Neo4j,Neo4j,PubMed:Neo4j; PubMed:Query3; PubMed:Query2
744,,30226672,,A,,,"Lovis, Christian; Gaudet-Blavignac, Christophe; Chevrier, Raphaël; Robert, Arnaud; Issom, David; Foufi, Vasiliki","[Bigdata, artificial intelligence and blockchain for dummies]",2018,Revue Medicale Suisse,,"Digitalization is transforming every aspect of life, it is also transforming deeply medicine. The digitalization era is characterized by a large production of new data streams while existing processes are progressively migrated, such as writing or imaging. The very large and fast-growing amount of data available requires new storage, transport and analytical tools. This paper presents some of them, such as natural language processing, artificial intelligence, and graph databases. A short introduction to the technology of blockchain is also provided, as it is increasingly used in some non-monetary transaction in medicine, such as data exchanges and consent management.",2018-09-05,2021-06-05 21:06:22,1559-1563,617,14,Rev Med Suisse,,PubMed,PMID: 30226672,http://www.ncbi.nlm.nih.gov/pubmed/30226672,Artificial Intelligence; Big Data,,,PubMed:Query2
745,,30306935,PMC7847179,,,,"Elkin, Peter L.; Mullin, Sarah; Sakilay, Sylvester; ELKIN, Peter L.; MULLIN, Sarah; SAKILAY, Sylvester",Biomedical Informatics Investigator,2018,Studies in health technology and informatics; Studies in Health Technology and Informatics,,"The BMI Investigator is a computer human interface built in .Net which allows simultaneous query of structured data such as demographics, administrative codes, medications (coded in RxNorm), laboratory test results (coded in LOINC) and formerly unstructured data in clinical notes (coded in SNOMED CT). The ontology terms identified using SNOMED are all coded as either positive, negative or uncertain assertions. They are then where applicable built into compositional expressions and stored in both a graph database and a triple store. The SNOMED CT codes are stored in a NOSQL database, Berkley DB, and the structured data is stored in SQL using the OMOP/OHDSI format. The BMI investigator also lets you develop models for cohort selection (data driven recruitment to clinical trials) and automated retrospective research using genomic criteria and we are adding image feature data currently to the system. We performed a usability experiment and the users identified some usability flaws which were used to improve the software. Overall, the BMI Investigator was felt to be usable by subject matter experts. Next steps for the software are to integrate genomic criteria and image features into the query engine.; The BMI Investigator is a computer human interface built in .Net which allows simultaneous query of structured data such as demographics, administrative codes, medications (coded in RxNorm), laboratory test results (coded in LOINC) and formerly unstructured data in clinical notes (coded in SNOMED CT). The ontology terms identified using SNOMED are all coded as either positive, negative or uncertain assertions. They are then where applicable built into compositional expressions and stored in both a graph database and a triple store. The SNOMED CT codes are stored in a NOSQL database, Berkley DB, and the structured data is stored in SQL using the OMOP / OHDSI format. The BMI investigator also lets you develop models for cohort selection (data driven recruitment to clinical trials) and automated retrospective research using genomic criteria and we are adding image feature data currently to the system. We performed a usability experiment and the users identified some usability flaws which were used to improve the software. Overall, the BMI Investigator was felt to be usable by subject matter experts. Next steps for the software are to integrate genomic criteria and image features into the query engine.",2018,2021-06-05 21:06:22; 2021-06-05 21:11:16,195-199,,255,Stud Health Technol Inform,,PubMed; PubMed Central,PMID: 30306935 PMCID: PMC7847179,http://www.ncbi.nlm.nih.gov/pubmed/30306935; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7847179/,"Automated retrospective research; clinical genomic trial recruitment; Clinical Research Informatics; Humans; Information Storage and Retrieval; Ontology; Recruitment to clinical trials; Retrospective Studies; RxNorm; Software; Systematized Nomenclature of Medicine; Vocabulary, Controlled",,,PubMed:Query2; PMC:Query2
746,,30815121,PMC6371352,A,OrientDB,OrientDB,"Mathe, Janos L.; Nelson, Scott D.; Weinberg, Stuart T.; Lehmann, Christoph U.; Nadas, Andras; Weitkamp, Asli O.",Leveraging Knowledge Representation to Maintain Immunization Clinical Decision Support,2018,AMIA Annual Symposium Proceedings,,"Immunizations are one of the most cost-effective interventions for preventing morbidity and mortality. As vaccines, related clinical knowledge and requirements change, clinical applications must be updated in a timely manner to avoid practicing outdated medicine. We use the Centers for Disease Control and Prevention (CDC) as a source for immunization knowledge for our Clinical Information Systems (CIS). After identifying knowledge management related gaps in the CDC’s content and email notification service, we developed and adapted a knowledge management tool chain – called COMET – for facilitating automatic processing of the available immunization content to implement mature knowledge lifecycle management practices locally. The implemented features include error and change tracking, content discovery and analytics, and tracking of dependencies to dependent downstream CISs. We demonstrate the creation of a tool that enables content curators to visualize, track, and implement immunization changes.",2018-12-05,2021-06-06 06:49:06; 2021-06-05 20:55:01; 2021-06-05 21:10:37,789-798,,2018,AMIA Annu Symp Proc,,PubMed Central,PMID: 30815121 PMCID: PMC6371352,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6371352/,,OrientDB,OrientDB,PMC:Query3; PMC:Query2; PMC:OrientDB
747,,30815190,PMC6371258,A,Virtuoso,Virtuoso,"Peterson, Kevin J.; Liu, Hongfang",The Sublanguage of Clinical Problem Lists: A Corpus Analysis,2018,AMIA Annual Symposium Proceedings,,"Summary-level clinical text is an important part of the overall clinical record as it provides a condensed and efficient view into the issues pertinent to the patient, or their “problem list.” These problem lists contain a wealth of information pertaining to the patient’s history as well as current state and well-being. In this study, we explore the structure of these problem list entries both grammatically and semantically in an attempt to learn the specialized rules, or “sublanguage” that governs them. Our methods focus on a large-scale corpus analysis of problem list entries. Using Resource Description Framework (RDF), we incorporate inferencing and reasoning via domain-specific ontologies into our analysis to elicit common semantic patterns. We also explore how these methods can be applied dynamically to learn specific sublanguage features of interest for a particular concept or topic within the domain.",2018-12-05,2021-06-05 20:55:01; 2021-06-05 20:59:14; 2021-06-05 21:10:37,1451-1460,,2018,AMIA Annu Symp Proc,The Sublanguage of Clinical Problem Lists,PubMed Central,PMID: 30815190 PMCID: PMC6371258,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6371258/,,Virtuoso,Virtuoso,PMC:Query3; PMC:Query2; PMC:Virtuoso
748,,31258960,PMC6568136,A,Neo4j,Neo4j,"Post, Andrew; Chappidi, Nityananda; Gunda, Dileep; Deshpande, Nita",A Method for EHR Phenotype Management in an i2b2 Data Warehouse,2019,AMIA Summits on Translational Science Proceedings,,"Electronic health record (EHR) data is valuable for finding patients for clinical research and analytics but is complex to query. EHR phenotyping involves the curation and dissemination of best practices for querying commonly studied populations. Phenotyping software computes patterns in clinical and administrative data and may add the found patterns as derived variables to a database that researchers can query. This paper describes a method for managing EHR phenotypes in a data warehouse as the warehouse is incrementally updated with new and changed data. We have implemented this method in proof-of-concept form as an extension to the Eureka! Clinical Analytics phenotyping software system and evaluated the implementation’s performance. The method shows promise for realizing the efficient addition, modification, and removal of derived variables representing phenotypes in a data warehouse.",2019-05-06,2021-06-05 20:55:01; 2021-06-05 20:36:32; 2021-06-05 21:10:37,92-101,,2019,AMIA Jt Summits Transl Sci Proc,,PubMed Central,PMID: 31258960 PMCID: PMC6568136,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6568136/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
749,,31423120,PMC6669368,A,ArangoDB,ArangoDB,"Dolezel, Diane; McLeod, Alexander",Big Data Analytics in Healthcare: Investigating the Diffusion of Innovation,2019,Perspectives in Health Information Management,,"The shortage of data scientists has restricted the implementation of big data analytics in healthcare facilities. This survey study explores big data tool and technology usage, examines the gap between the supply and the demand for data scientists through Diffusion of Innovations theory, proposes engaging academics to accelerate knowledge diffusion, and recommends adoption of curriculum-building models. For this study, data were collected through a national survey of healthcare managers. Results provide practical data on big data tool and technology skills utilized in the workplace. This information is valuable for healthcare organizations, academics, and industry leaders who collaborate to implement the necessary infrastructure for content delivery and for experiential learning. It informs academics working to reengineer their curriculum to focus on big data analytics. The paper presents numerous resources that provide guidance for building knowledge. Future research directions are discussed.",2019-07-01,2021-06-05 20:55:01; 2021-06-05 21:10:37; 2021-06-06 06:42:51,,Summer,16,Perspect Health Inf Manag,Big Data Analytics in Healthcare,PubMed Central,PMID: 31423120 PMCID: PMC6669368,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6669368/,,ArangoDB,ArangoDB,PMC:Query3; PMC:Query2; PMC:ArangoDB
750,,32477673,PMC7233100,A,Neo4j,Neo4j,"Renner, Robinette; Jiang, Guoqian",Challenges in Using a Graph Database to Represent and Analyze Mappings of Cancer Study Data Standards,2020,AMIA Joint Summits on Translational Science proceedings. AMIA Joint Summits on Translational Science; AMIA Summits on Translational Science Proceedings,,"While using data standards can facilitate research by making it easier to share data, manually mapping to data standards creates an obstacle to their adoption. Semi-automated mapping strategies can reduce the manual mapping burden. Machine learning approaches, such as artificial neural networks, can predict mappings between clinical data standards but are limited by the need for training data. We developed a graph database that incorporates the Biomedical Research Integrated Domain Group (BRIDG) model, Common Data Elements (CDEs) from the National Cancer Institute’s (NCI) cancer Data Standards Registry and Repository, and the NCI Thesaurus. We then used a shortest path algorithm to predict mappings from CDEs to classes in the BRIDG model. The resulting graph database provides a robust semantic framework for analysis and quality assurance testing. Using the graph database to predict CDE to BRIDG class mappings was limited by the subjective nature of mapping and data quality issues.; While using data standards can facilitate research by making it easier to share data, manually mapping to data standards creates an obstacle to their adoption. Semi-automated mapping strategies can reduce the manual mapping burden. Machine learning approaches, such as artificial neural networks, can predict mappings between clinical data standards but are limited by the need for training data. We developed a graph database that incorporates the Biomedical Research Integrated Domain Group (BRIDG) model, Common Data Elements (CDEs) from the National Cancer Institute's (NCI) cancer Data Standards Registry and Repository, and the NCI Thesaurus. We then used a shortest path algorithm to predict mappings from CDEs to classes in the BRIDG model. The resulting graph database provides a robust semantic framework for analysis and quality assurance testing. Using the graph database to predict CDE to BRIDG class mappings was limited by the subjective nature of mapping and data quality issues.",2020; 2020-05-30,2021-06-05 20:35:57; 2021-06-05 21:06:22; 2021-06-05 20:54:31; 2021-06-05 21:10:08,517-526,,2020,AMIA Jt Summits Transl Sci Proc,,PubMed; PubMed Central,PMID: 32477673 PMCID: PMC7233100,http://www.ncbi.nlm.nih.gov/pubmed/32477673; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233100/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PubMed:Query2; PMC:Query2
751,,32477687,PMC7233060,A,AllegroGraph; Neo4j,AllegroGraph; Neo4j,"Stothers, Jessica A. M.; Nguyen, Andrew",Can Neo4j Replace PostgreSQL in Healthcare?,2020,AMIA Joint Summits on Translational Science proceedings. AMIA Joint Summits on Translational Science; AMIA Summits on Translational Science Proceedings,,"Our current big data landscape prompts us to develop new analytical skills in order to make the best use of the abundance of datasets at hand. Traditionally, SQL databases such as PostgreSQL have been the databases of choice, and newer graph databases such as Neo4j have been relegated to the analysis of social network and transportation datasets. In this paper, we conduct a side by side comparison of PostgreSQL (using SQL) and Neo4j (using Cypher) using the MIMIC-III patient database as a case study. We found that, while Neo4j is more time intensive to implement, its queries are less complex and have a faster runtime than comparable queries performed in PostgreSQL. This leads to the conclusion that while PostgreSQL is adequate as a database, Neo4j should be considered a viable contender for health data storage and analysis.",2020; 2020-05-30,2021-06-05 20:35:57; 2021-06-05 20:54:31; 2021-06-05 21:10:08; 2021-06-06 06:38:41; 2021-06-05 21:06:22; 2021-06-05 21:16:51; 2021-06-05 21:24:28,646-653,,2020,AMIA Jt Summits Transl Sci Proc,,PubMed; PubMed Central,PMID: 32477687 PMCID: PMC7233060,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233060/; http://www.ncbi.nlm.nih.gov/pubmed/32477687,,AllegroGraph; Neo4j,AllegroGraph; Neo4j,PMC:AllegroGraph; PMC:Query2; PMC:Query3; PMC:Neo4j; PubMed:Neo4j; PubMed:Query2; PubMed:Query3
752,,32831801,PMC7437158,A,Neo4j,Neo4j,"Hedberg, Thomas D.; Manas, Bajaj; Camelio, Jaime A.",Using graphs to link data across the product lifecycle for enabling smart manufacturing digital threads,2020,Journal of computing and information science in engineering,,"Smart manufacturing promises to provide significant increases in productivity and effectiveness of manufacturing systems by better connecting the data from people, processes, and things. However, there is no uniform, generalized method for deploying linked-data concepts to the manufacturing domain. The literature describes and commercial vendors offer centralized data repository solutions, but these types of approaches quickly breakdown under the intense burden of managing and reconciling all the data flowing in and out of the various repositories across the product lifecycle. In this paper, we introduce a method for linking and tracing data throughout the product lifecycle using graphs to form digital threads. We describe a prototype implementation of the method and a case study to demonstrate an information round-trip for a product assembly between the design, manufacturing, and quality domains of the product lifecycle. The expected impact from this novel, standards-based, linked-data method is the ability to use digital threads to provide data, system, and viewpoint interoperability in the deployment of smart manufacturing to realize industry’s $30 Billion annual opportunity.",2020,2021-06-05 20:35:57; 2021-06-05 20:55:01; 2021-06-05 21:10:08,,1,20,J Comput Inf Sci Eng,,PubMed Central,PMID: 32831801 PMCID: PMC7437158,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7437158/,,Neo4j,Neo4j,PMC:Query3; PMC:Neo4j; PMC:Query2
753,,33633520,PMC7883353,A,ArangoDB,ArangoDB,"Dolezel, Diane; McLeod, Alexander",Big-Data Skills: Bridging the Data Science Theory-Practice Gap in Healthcare,2020,Perspectives in Health Information Management,,"Demand for big-data scientists continues to escalate driving a pressing need for new graduates to be more fluent in the big-data skills needed by employers. If a gap exists between the educational knowledge held by graduates and big data workplace skills needed to produce results, workers will be unable to address the big data needs of employers., This survey explores big-data skills in the classroom and those required in the workplace to determine if a skills gap exists for big-data scientists. In this work, data was collected using a national survey of healthcare professionals. Participant responses were analyzed to inform curriculum development, providing valuable information for academics and the industry leaders who hire new data talent.",2020-12-07,2021-06-05 20:54:31; 2021-06-06 06:42:51; 2021-06-05 21:09:36,,Winter,18,Perspect Health Inf Manag,Big-Data Skills,PubMed Central,PMID: 33633520 PMCID: PMC7883353,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7883353/,,ArangoDB,ArangoDB,PMC:Query3; PMC:Query2; PMC:ArangoDB
754,,33691023,PMC7958985,,,,"Durmaz, Arda; Henderson, Tim A. D.; Bebek, Gurkan",Frequent Subgraph Mining of Functional Interaction Patterns Across Multiple Cancers,2021,Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing,,"Molecular mechanisms characterizing cancer development and progression are complex and process through thousands of interacting elements in the cell. Understanding the underlying structure of interactions requires the integration of cellular networks with extensive combinations of dysregulation patterns. Recent pan-cancer studies focused on identifying common dysregulation patterns in a confined set of pathways or targeting a manually curated set of genes. However, the complex nature of the disease presents a challenge for finding pathways that would constitute a basis for tumor progression and requires evaluation of subnetworks with functional interactions. Uncovering these relationships is critical for translational medicine and the identification of future therapeutics. We present a frequent subgraph mining algorithm to find functional dysregulation patterns across the cancer spectrum. We mined frequent subgraphs coupled with biased random walks utilizing genomic alterations, gene expression profiles, and protein-protein interaction networks. In this unsupervised approach, we have recovered expert-curated pathways previously reported for explaining the underlying biology of cancer progression in multiple cancer types. Furthermore, we have clustered the genes identified in the frequent subgraphs into highly connected networks using a greedy approach and evaluated biological significance through pathway enrichment analysis. Gene clusters further elaborated on the inherent heterogeneity of cancer samples by both suggesting specific mechanisms for cancer type and common dysregulation patterns across different cancer types. Survival analysis of sample level clusters also revealed significant differences among cancer types (p < 0.001). These results could extend the current understanding of disease etiology by identifying biologically relevant interactions.",2021,2021-06-05 21:09:36,261-272,,26,Pac Symp Biocomput,,PubMed Central,PMID: 33691023 PMCID: PMC7958985,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7958985/,,,,PMC:Query2
755,,9716022,PMC2063080,,,,"Bradshaw, T. D.; Shi, D. F.; Schultz, R. J.; Paull, K. D.; Kelland, L.; Wilson, A.; Garner, C.; Fiebig, H. H.; Wrigley, S.; Stevens, M. F.",Influence of 2-(4-aminophenyl)benzothiazoles on growth of human ovarian carcinoma cells in vitro and in vivo.,1998,British Journal of Cancer,,"2-(4-Aminophenyl)benzothiazole molecules substituted in the 3 position of the phenyl ring with a halogen atom or methyl moiety comprise a group of compounds that potently inhibit specific human ovarian carcinoma cell lines. GI50 values fall within the nM range. Inhibition is highly selective -- whereas the GI50 value in IGROV1 cells consistently lies at < 10 nM, SK-OV-3 presents GI50 values > 10 microM. Biphasic dose-response relationships were observed in sensitive cell lines after 48-h drug exposure. COMPARE analyses revealed the very similar profiles of anti-tumour activity of 3-substituted benzothiazoles and 5-(4-dimethylaminophenylazo)quinoline, with Pearson correlation coefficients > 0.65. Anti-tumour activity extended to preliminary in vivo tests. The growth of OVCAR-3 cells in polyvinylidene fluoride (PVDF) hollow fibres implanted in the peritoneal cavity of mice was inhibited by more than 50% after intraperitoneal (i.p.) administration of 2-(4-amino-3-methylphenyl)benzothiazole (10 mg kg(-1)), 2-(4-amino-3-chlorophenyl)benzothiazole (100 mg kg(-1)) or 2-(4-amino-3-bromophenyl)benzothiazole (150 mg kg(-1)). The growth of OVCAR-3 tumours in subcutaneously (s.c.) implanted hollow fibres was retarded by more than 50% after treatment with 2-(4-amino-3-methylphenyl)benzothiazole (6.7 and 10 mg kg(-1)). In addition, the growth of s.c. OVCAR-3 xenografts was delayed after exposure to DF 203. However, the relationship between drug concentration and growth inhibition was inverse.",1998-08,2021-06-05 21:14:07,421-429,4,78,Br J Cancer,,PubMed Central,PMID: 9716022 PMCID: PMC2063080,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2063080/,,,,PMC:Query2
